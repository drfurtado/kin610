[
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3 - Coffee ratings",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from over 1,000 different coffees to explore the relationship between a coffee‚Äôs aroma and it‚Äôs overall quality. You will also begin working with your team and practicing a collaborative data analysis workflow.\n\n\nBy the end of the lab you will‚Ä¶\n\nCreate plots and calculate associated statistics to assess model diagnostics.\nPractice collaborating with others using a single Github repo."
  },
  {
    "objectID": "labs/lab-3.html#meet-your-team",
    "href": "labs/lab-3.html#meet-your-team",
    "title": "Lab 3 - Coffee ratings",
    "section": "Meet your team!",
    "text": "Meet your team!\nClick here to see the team assignments for STA 210. This will be your team for labs and the final project.\nBefore you get started on the lab, your TA will walk you through the following:\n\nIcebreaker activity to get to know your teammates.\nCome up with a team name. You can‚Äôt use the same name as another team, so I encourage you to be creative! Your TA will get your team name by the end of lab.\nFill out the team agreement. This will help you figure out a plan for communication and working together during labs and outside of lab times. You can find the team agreement in the GitHub repo team-agreement-[github_team_name].\nHave one person from the team clone the repo and start a new RStudio project. This person will type the team‚Äôs responses as you discuss the sections of the agreement. No one else in the team should type at this point but should be contributing to the discussion.\nBe sure to push the completed agreement to GitHub. Each team member can refer to the document in this repo or download the PDF of the agreement for future reference. You do not need to submit the agreement on Gradescope."
  },
  {
    "objectID": "labs/lab-3.html#getting-started",
    "href": "labs/lab-3.html#getting-started",
    "title": "Lab 3 - Coffee ratings",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Do not make any changes to the .qmd file until the instructions tell you do to so."
  },
  {
    "objectID": "labs/lab-3.html#workflow-using-git-and-github-as-a-team",
    "href": "labs/lab-3.html#workflow-using-git-and-github-as-a-team",
    "title": "Lab 3 - Coffee ratings",
    "section": "Workflow: Using Git and GitHub as a team",
    "text": "Workflow: Using Git and GitHub as a team\n\n\n\n\n\n\nImportant\n\n\n\nAssign each person on your team a number 1 through 4. For teams of three, Team Member 1 can take on the role of Team Member 4.\n\n\nThe following exercises must be done in order. Only one person should type in the .qmd file, commit, and push updates at a time. When it is not your turn to type, you should still share ideas and contribute to the team‚Äôs discussion.\n\n\n\n\n\n\n‚å®Ô∏è Team Member 1: Hands on the keyboard.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!1\n\n\n\nChange the author to your team name and include each team member‚Äôs name in the author field of the YAML in the following format: Team Name: Member 1, Member 2, Member 3, Member 4.\n\nTeam Member 1: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub.\n\n\nTeam Members 2, 3, 4: Once Team Member 1 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the updated name in your .qmd file."
  },
  {
    "objectID": "labs/lab-3.html#packages",
    "href": "labs/lab-3.html#packages",
    "title": "Lab 3 - Coffee ratings",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(ggfortify)"
  },
  {
    "objectID": "labs/lab-3.html#data-coffee-ratings",
    "href": "labs/lab-3.html#data-coffee-ratings",
    "title": "Lab 3 - Coffee ratings",
    "section": "Data: Coffee ratings",
    "text": "Data: Coffee ratings\nThe dataset for this lab comes from the Coffee Quality Database and was obtained from the #TidyTuesday GitHub repo. It includes information about the origin, producer, measures of various characteristics, and the quality measure for over 1000 coffees.\nThis lab will focus on the following variables:\n\naroma: Aroma grade, 0 - 10 scale\ntotal_cup_points: Measure of quality, 0 - 100 scale\n\nYou can find the definitions for all variables in the data set here. Click here for more details about how these measures are obtained.\n\ncoffee_ratings <- read_csv(\"data/coffee_ratings.csv\")"
  },
  {
    "objectID": "labs/lab-3.html#exercises",
    "href": "labs/lab-3.html#exercises",
    "title": "Lab 3 - Coffee ratings",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nNote\n\n\n\n\nInclude axis labels and an informative title for all plots.\nUse the kable function to neatly print tables and regression output. Write all interpretations in the context of the data.\nDo the following exercises in order, following each step carefully.\nOnly one person at a time should type in the .qmd file and push updates.\nIf you are working on any portion of the lab virtually, the person working should share their screen and the others should follow along.\n\n\n\n\n\n\n\n\n\n‚å®Ô∏è Team Member 1: Hands still on the keyboard. Write the answers to Exercises 1 and 2.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\nExercise 1\nVisualize the relationship between aroma and the total cup points. What do you observe from the plot? Use the plot the describe the relationship between the two variables.\n\n\nExercise 2\nFit the linear model and neatly display the results using 3 digits. Interpret the slope in context of the data.\n\nTeam Member 1: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 2, 3, 4: Once Team Member 1 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercises 1 and 2 in your .qmd file.\n\n\nNow it‚Äôs time for a hand off‚Ä¶\n\n\n\n\n\n\n‚å®Ô∏è Team Member 2: Hands on the keyboard. Write the answers to Exercises 3 and 4.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\n\nExercise 3\nWould the members of your group drink a coffee represented by the intercept? Why or why not? Discuss as a group and write the group‚Äôs consensus.\n\n\nExercise 4\nLeverage is the measure of the distance between an observation‚Äôs values of the predictor variables and the average values of the predictor variables for the entire data set. An observation s set if have high leverage if its combination of values for the predictor variables is very far from the typical combination of values in the data.An observation has high leverage if its combination of values for the predictor variables is very far from the typical combination of values in the data. Observations with high leverage should be considered as potential influential points.\nWe will proceed assuming the model conditions hold, so let‚Äôs focus on the model diagnostics. We‚Äôll start by examining if there are any points with high leverage in the data.\nTheoretically, the leverage of the \\(i^{th}\\) observation as follows:\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j = 1}^n (x_j - \\bar{x})^2}\n\\]\nNote that leverage only depends on values of the predictor variable(s).\nThe sum of the leverages for all points is \\(p + 1\\), where\n\n\\(p\\) is the number of predictors\nIn the case of SLR, \\(\\sum_{i = 1}^n h_i = 2\\)\nThe ‚Äútypical‚Äù leverage is \\(\\frac{(p + 1)}{n}\\)\n\nTherefore, an observation is said to have high leverage if\n\\[\nh_i > \\frac{2(p + 1)}{n}\n\\]\nIn addition to comparing the leverage of points to a threshold, we also generally visualize standard residuals vs.¬†leverage values our data. The autoplot() function from the ggfortify package is very useful for drawing these standard plots easily.\n\nautoplot(coffee_fit$fit, which = 5)\n\n\nWhat threshold will you use to determine if there are points with high leverage for this dataset?\nAre there any observations with high leverage? If so, how many? Briefly explain, including any output, graphs, etc. you used to determine the response. Improve your plot by adding a new year to draw a vertical line (with geom_vline()) at the value of the threshold you‚Äôre using to determine which points have high leverage.\n\n\nTeam Member 2: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 3, 4: Once Team Member 2 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercises 3 and 4 in your .qmd file.\n\n\nNow it‚Äôs time for another hand off‚Ä¶\n\n\n\n\n\n\n‚å®Ô∏è Team Member 3: Hands on the keyboard. Write the answers to Exercises 5.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\n\nExercise 5\nAnother standard model diagnostic involves identifying points that don‚Äôt fit the pattern from the regression line. We do this by determining which points have large standardized residuals (residual divided by the standard error of residuals).\n\\[\nStd.~res_i = \\frac{y_i - \\hat{y}_1}{\\hat{\\sigma}_\\epsilon ~ \\sqrt{1 - h_i}},\n\\]\nwhere \\(\\hat{\\sigma}_\\epsilon\\) is the regression standard error.\n\n\n\n\n\n\nNote\n\n\n\nThese values are already calculated in the output of augment().\n\n\nObservations that have standardized residuals of large magnitude (usually beyond \\(\\pm\\) 3) are potential outliers, since they don‚Äôt fit the pattern determined by the regression model. Therefore, a common practice is to plot standardized residuals vs.¬†fitted values, to make it easier to identify outliers.\nWe can obtain this plot with the following:\n\nautoplot(coffee_fit$fit, which = 3)\n\nCreate this visualization and horizontal lines (with geom_hline()) at the cutoff values for ‚Äúlarge‚Äù standardized residuals (\\(\\pm\\) 3). Are there any such points in the data? If so, how many? Briefly explain, including any output, graphs, etc. you used to determine the response.\n\nTeam Member 3: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 2, 4: Once Team Member 3 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercise 5 and 4 in your .qmd file.\n\n\nNow it‚Äôs time for another hand off‚Ä¶\n\n\n\n\n\n\n‚å®Ô∏è Team Member 4: Hands on the keyboard. Write the answers to Exercises 6.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\n\nExercise 6\nFinally, we‚Äôll examine Cook‚Äôs Distance. An observation‚Äôs influence on the regression line depends on how close it lies to the general trend of the data (i.e., its standardized residual) and it‚Äôs leverage (\\(h_i\\)). Cook‚Äôs Distance is a statistic that includes both of these components to measure an observation‚Äôs overall impact on the model. Cook‚Äôs Distance for the \\(i^{th}\\) observation is defined as the follows:\n\\[\nD_i = \\frac{(std.~res)^2}{p + 1} (\\frac{h_i}{1-\\frac{h_i})\n\\]\nAn observation with large \\(D_i\\) is said to have a strong influence on the predicted values. On that scale,\n\n\\(D_i\\) > 0.5 is moderately influential\n\\(D_i\\) > 1 is very influential\n\nWe can plot of Cook‚Äôs distances vs.¬†the observation number with the following:\n\nautoplot(coffee_fit$fit, which = 4, ncol = 1)\n\n\n\n\nStandardized residuals, leverage, and Cook‚Äôs Distance should all be examined together. So what do we do with observations identified as outliers or leverage points?\nIt is OK to drop an observation based on the predictor variables if‚Ä¶\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. You should mention this in the write up of the results and be careful to avoid extrapolation when making predictions.\n\nIt is not OK to drop an observation based on the response variable if‚Ä¶\n\nThese are legitimate observations and should be in the model.\nYou can try transformations or increasing the sample size by collecting more data.\n\nSo lastly, let‚Äôs analyze Cook‚Äôs D to determine if there are influential points in the data.\n\nBased on Cook‚Äôs D, are there any influential points in our data? Briefly explain, including any output, graphs, etc. you used to determine the response.\nIf there are influential points, briefly explain why they are outliers, i.e., not in the trend of the rest of the data.\nIf there are influential points, remove those points from the data and refit the model. How do the model coefficients change, if at all?\nIf there are influential points, would you recommend using the model fit with or without these points for inferential conclusions and predictions? Briefly explain why or why not. Additionally, briefly explain potential impacts your choice has on inferential conclusions and/or predictions.\n\n\nTeam Member 4: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 2, 3: Once Team Member 4 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercise 6 and 4 in your .qmd file.\n\n\nNow it‚Äôs time for one last hand off‚Ä¶"
  },
  {
    "objectID": "labs/lab-3.html#wrapping-up",
    "href": "labs/lab-3.html#wrapping-up",
    "title": "Lab 3 - Coffee ratings",
    "section": "Wrapping up",
    "text": "Wrapping up\n\n\n\n\n\n\nImportant\n\n\n\n‚å®Ô∏è Team Member 2: Hands on the keyboard. Make any edits as needed.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\nTeam Member 2: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 3, 4: Once Team Member 2 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the final version of your .qmd file."
  },
  {
    "objectID": "labs/lab-3.html#submission",
    "href": "labs/lab-3.html#submission",
    "title": "Lab 3 - Coffee ratings",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nSelect one team member to upload the team‚Äôs PDF submission to Gradescope.\nBe sure to include every team member‚Äôs name in the Gradescope submission.\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù). If any answer spans multiple pages, then mark all pages.\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section.\n\n\n\n\n\n\n\nImportant\n\n\n\nThere should only be one submission per team on Gradescope."
  },
  {
    "objectID": "labs/lab-3.html#grading",
    "href": "labs/lab-3.html#grading",
    "title": "Lab 3 - Coffee ratings",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 6\n42\n\n\nWorkflow & formatting\n52\n\n\nComplete team contract\n3"
  },
  {
    "objectID": "labs/lab-0.html",
    "href": "labs/lab-0.html",
    "title": "Lab 0 - Meet + greet",
    "section": "",
    "text": "Today‚Äôs lab is short and sweet! We just need you to fill out the ‚ÄúGetting to know you‚Äù survey. Please go here to take it. You will need to log on to Sakai to access to survey.\nYour answers can be brief. Some of your answers will be used to guide what application examples might be of interest to a majority of students in the course and some of your answers will be used to help guide team formation. We expect this will take you ~10 minutes."
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4 - The Office",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from the schrute package to predict IMDB scores for episodes of The Office.\n\n\n\n\n\n\nNote\n\n\n\nThis is a different data source than the one we‚Äôve used in class last week.\n\n\n\n\nBy the end of the lab you will‚Ä¶\n\nengineer features based on episode scripts\ntrain a model\ninterpret model coefficients\nmake predictions\nevaluate model performance on training and testing data"
  },
  {
    "objectID": "labs/lab-4.html#getting-started",
    "href": "labs/lab-4.html#getting-started",
    "title": "Lab 4 - The Office",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Throughout the lab, each person should get a chance to make commits and push to the repo."
  },
  {
    "objectID": "labs/lab-4.html#packages",
    "href": "labs/lab-4.html#packages",
    "title": "Lab 4 - The Office",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(schrute)\nlibrary(lubridate)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-4.html#data-the-office",
    "href": "labs/lab-4.html#data-the-office",
    "title": "Lab 4 - The Office",
    "section": "Data: The Office",
    "text": "Data: The Office\nThe dataset for this lab comes from the schrute package and it‚Äôs called theoffice. This dataset contains the entire script transcriptions from The Office.\nLet‚Äôs start by taking a peek at the data.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16‚Ä¶\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",‚Ä¶\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis‚Ä¶\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky‚Ä¶\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha‚Ä¶\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6‚Ä¶\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,‚Ä¶\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-‚Ä¶\n\n\nThere are 55130 observations and 12 columns in this dataset. The variable names are as follows.\n\nnames(theoffice)\n\n [1] \"index\"            \"season\"           \"episode\"          \"episode_name\"    \n [5] \"director\"         \"writer\"           \"character\"        \"text\"            \n [9] \"text_w_direction\" \"imdb_rating\"      \"total_votes\"      \"air_date\"        \n\n\nEach row in the dataset is a line spoken by a character in a given episode of the show. This means some information at the episode level (e.g., imdb_rating, air_date, etc. are repeated across the rows that belong to a single episode.\nThe air_date variable is coded as a factor, which is undesirable. We‚Äôll want to parse that variable later into its components during feature engineering. So, for now, let‚Äôs convert it to date.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nLet‚Äôs take a look at the data to confirm we‚Äôre happy with how each of the variables are encoded.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16‚Ä¶\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",‚Ä¶\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis‚Ä¶\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky‚Ä¶\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha‚Ä¶\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6‚Ä¶\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,‚Ä¶\n$ air_date         <date> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005‚Ä¶"
  },
  {
    "objectID": "labs/lab-4.html#exercises",
    "href": "labs/lab-4.html#exercises",
    "title": "Lab 4 - The Office",
    "section": "Exercises",
    "text": "Exercises\n\nData prep\n\nExercise 1\nIdentify episodes that touch on Halloween, Valentine‚Äôs Day, and Christmas.\n\nFirst, convert all text to lowercase with str_to_lower().\nThen, create three new variables (halloween_mention, valentine_mention, and christmas_mention) where that take on the value 1 if the character string \"halloween\", \"valentine\", or \"christmas\" appears in the text, respectively, and 0 otherwise.\n\nSome code is provided below to help you get started.\n\ntheoffice <- theoffice %>%\n  mutate(\n    text = ___(text),\n    halloween_mention = if_else(str_detect(text, \"___\"), ___, ___),\n    valentine_mention = ___,\n    ___ = ___\n  )\n\n\n\nExercise 2\nIn this exercise we‚Äôll accomplish two separate tasks. And there‚Äôs a good reason why we‚Äôre doing it all at once; we‚Äôre going to drastically change our data frame, from one row per line spoken to one row per episode. We‚Äôll call the resulting data frame office_episodes.\nThe two tasks are as follows:\n\nTask 1. Identify episodes where the word ‚Äúhalloween‚Äù, ‚Äúvalentine‚Äù, or ‚Äúchristmas‚Äù were ever mentioned, using variables you created above.\nTask 2. Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\nBelow are some instructions and starter code to get you started with these tasks.\n\nStart by grouping theoffice data by season, episode, episode_name, imdb_rating, total_votes, and air_date. (These variables, except for season have the same value for each given episode, hence grouping by them allows us to make sure they appear in the output of this pipeline.)\nUse summarize() to calculate the desired features at the season-episode level.\nTask 1:\n\nCalculate the number of lines per season per episode, you might name this new variable n_lines.\nThen, calculate the proportion of lines in that episode spoken by each of the four characters Jim, Pam, Michael, and Dwight. Name these new variables lines_jim, lines_pam, lines_michael, and lines_dwight, respectively.\n\nTask 2:\n\nCreate a variable called halloween that sums up the 1s in halloween_mention at the season-episode level and takes on the value \"yes\" if the sum is greater than or equal to 1, or \"no\" otherwise.\nDo something similar for new variables valentine and christmas as well based on values from valentine_mention and christmas_mention.\n\nFinish up your summarize() statement by dropping the groups, so the resulting data frame is no longer grouped and remove n_lines (we won‚Äôt use that variable in our analysis, we only calculated it as an intermediary step).\n\n\noffice_episodes <- theoffice %>%\n  group_by(___) %>%\n  summarize(\n    n_lines = n(),\n    lines_jim = sum(character == \"___\") / n_lines,\n    lines_pam = ___,\n    lines_michael = ___,\n    lines_dwight = ___,\n    halloween = if_else(sum(___) >= 1, \"yes\", \"no\"),\n    valentine = if_else(___, \"___\", \"___\"),\n    christmas = if_else(___, \"___\", \"___\"),\n    .groups = \"drop\"\n  ) %>%\n  select(-n_lines)\n\n\n\n\n\n\n\nNote\n\n\n\nWhy summarize() and not mutate()? We use mutate() to add / modify a column of a data frame. The output data frame always has the same number of rows as the input data frame. On the other hand, we use summarize() to reduce the data frame to either a single row (single summary statistic) or one row per each group (summary statistics at the group level).\nAnd what about that .groups argument in summarize? Try running your summarize() step without it first. You‚Äôll see that R print out a message saying ‚Äúsummarize() has grouped output by season, episode. You can override using the .groups argument.‚Äù summarize() will only drop the last group. So if you want a data frame that doesn‚Äôt have a grouping structure as a result of a summaerize(), you can explicitly ask for that with .groups = \"drop\". Before you proceed, read the documentation for summarize(), and specifically the explanation for the .groups argument to prepare yourself for future instances where you might see this type of message.\n\n\n\n\nExercise 3\nThe Michael Scott character (played by Steve Carrell) left the show at the end of Season 7. Add an indicator variable, michael, that takes on the value \"yes\" if Michael Scott (Steve Carrell) was in the show, and \"no\" if not.\n\noffice_episodes <- office_episodes %>%\n  mutate(michael = if_else(season > ___, \"___\", \"___\"))\n\n\n\nExercise 4\nPrint out the dimensions (dim()) of the new dataset you created as well as the names() of the columns in the dataset.\nYour new dataset, office_episodes, should have 186 rows and 14 columns. The column names should be season, episode, episode_name, imdb_rating, total_votes, air_date, lines_jim, lines_pam, lines_michael, lines_dwight, halloween, valentine, christmas, and michael. If you are not matching these numbers or columns, go back and try to figure out where you went wrong. Or ask your TA for help!\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\nIt‚Äôs also a good place to let another team member take over the keyboard! A team member who hasn‚Äôt done so yet should pull the changes and make the commits for the next few exercises.\n\n\n\n\nExploratory data analysis\nThis would be a good place to conduct some exploratory data analysis (EDA). For example, plot the proportion of lines spoken by each character over time. Or calculate the percentage of episodes that mention Halloween, or Valentine‚Äôs Day, or Christmas. Given we have limited time in the lab we‚Äôre not going to ask you to report EDA results as part of this lab, but we‚Äôre noting this here to provide suggestions for how you might go about structuring your project.\n\n\nModeling prep\n\nExercise 5\nSplit the data into training (75%) and testing (25%). Save the training and testing data as office_train and office_test respectively.\nNaming suggestion: Call the initial split office_split, the training data office_train, and testing data office_test.\n\nset.seed(123)\noffice_split <- ___(office_episodes)\noffice_train <- ___(office_split)\noffice_test <- ___(___)\n\n\n\nExercise 6\nSpecify a linear regression model with engine \"lm\" and call it office_spec.\nNaming suggestion: Call the model specification office_spec.\n\noffice_spec <- ___\n\n\n\nExercise 7\nCreate a recipe that performs feature engineering using the following steps (in the given order):\n\nupdate_role(): updates the role of episode_name to not be a predictor (be an ID)\nstep_rm(): removes air_date as a predictor\nstep_dummy(): creates dummy variables for all_nominal_predictors()\nstep_zv(): removes all zero variance predictors\n\nNaming suggestion: Call the recipe office_rec.\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  ___\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\nIt‚Äôs also a good place to let another team member take over the keyboard! A team member who hasn‚Äôt done so yet should pull the changes and make the commits for the next few exercises.\n\n\n\nExercise 8\nBuild a model workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\nNaming suggestion: Call the model workflow office_wflow.\n\noffice_wflow <- workflow() %>%\n  add_model(___) %>%\n  add_recipe(___)\n\n\n\n\nModel fit and evaluation\n\nExercise 9\nFit the model to training data, neatly display the model output, and interpret two of the slope coefficients.\nNaming suggestion: Call the model fit office_fit.\n\noffice_fit <- office_wflow %>%\n  fit(data = ___)\n\n___\n\n\n\nExercise 10\nCalculate predicted imdb_rating for the training data using the predict() function. Then, bind two columns from the training data to this result: imdb_rating and episode_name. The resulting data frame should have three columns: .pred, imdb_rating, and episode_name. Then, using this data frame, create a scatterplot of predicted and observed IMDB ratings for the training data.\nNaming suggestion: Call the resulting data frame office_train_pred.\nStretch goal. Add episode names, using geom_text(), for episodes with much higher and much lower observed IMDB ratings compared to others.\n\n\nExercise 11\nCalculate the R-squared and RMSE for this model for predictions on the training data.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\nIt‚Äôs also a good place to let another team member take over the keyboard! A team member who hasn‚Äôt done so yet should pull the changes and make the commits for the next few exercises.\n\n\n\nExercise 12\nRepeat Exercise 10, but with testing data.\nNaming suggestion: Call the resulting data frame office_test_pred.\n\n\nExercise 13\nBased on your visualization on Exercise 12, speculate on whether you expect the R-squared and RMSE for this model to be higher or lower for predictions on the testing data compared to those on the training data, or do you expect them to be the same? Explain your reasoning.\n\n\nExercise 14\nCheck your intuition in Exercise 13 by actually calculating the R-squared and RMSE for this model for predictions on the training data. Comment on whether your intuition is confirmed or not."
  },
  {
    "objectID": "labs/lab-4.html#submission",
    "href": "labs/lab-4.html#submission",
    "title": "Lab 4 - The Office",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-4.html#grading",
    "href": "labs/lab-4.html#grading",
    "title": "Lab 4 - The Office",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "labs/CopyOflab-2.html",
    "href": "labs/CopyOflab-2.html",
    "title": "Lab 2 - College scorecard",
    "section": "",
    "text": "In today‚Äôs lab, you‚Äôll use simple linear regression to analyze the relationship between the admissions rate and total cost for colleges and universities in the United States.\n\n\nBy the end of the lab you will‚Ä¶\n\nBe able to fit a simple linear regression model using R.\nBe able to interpret the slope and intercept for the model.\nBe able to use statistical inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/CopyOflab-2.html#getting-started",
    "href": "labs/CopyOflab-2.html#getting-started",
    "title": "Lab 2 - College scorecard",
    "section": "Getting started",
    "text": "Getting started\n\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClone the repo and start a new project in RStudio. See the Lab 1 instructions for details on cloning a repo, starting a new R project and configuring git."
  },
  {
    "objectID": "labs/CopyOflab-2.html#packages",
    "href": "labs/CopyOflab-2.html#packages",
    "title": "Lab 2 - College scorecard",
    "section": "Packages",
    "text": "Packages\nWe will use the following package in today‚Äôs lab.\n\nlibrary(tidyverse)  # for data wrangling + visualization\nlibrary(tidymodels) # for modeling\nlibrary(knitr)      # for pretty printing of tables"
  },
  {
    "objectID": "labs/CopyOflab-2.html#data-college-scorecard",
    "href": "labs/CopyOflab-2.html#data-college-scorecard",
    "title": "Lab 2 - College scorecard",
    "section": "Data: College scorecard",
    "text": "Data: College scorecard\nThe data for this lab is from the scorecard data set in the rcfss R package. It includes information originally obtained from the U.S. Department of Education‚Äôs College Scorecard for 1753 colleges and universities during the 2018 - 2019 academic year.\nThe lab focuses on the following variables:\n\nadmrate: Undergraduate admissions rate (from 0-100%)\ncost: The average annual total cost of attendance, including tuition and fees, books and supplies, and living expenses\ntype: Type of college (Public; Private, nonprofit; Private, for-profit)\n\nClick here to see a full list of variables and definitions.\nUse the code below to load the data set.\n\nscorecard <- read_csv(\"data/scorecard.csv\")"
  },
  {
    "objectID": "labs/CopyOflab-2.html#exercises",
    "href": "labs/CopyOflab-2.html#exercises",
    "title": "Lab 2 - College scorecard",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nNote\n\n\n\nInclude axis labels and an informative title for all plots. Use the kable() function to neatly print tables and regression output.\n\n\n\nExercise 1\nCreate a histogram to examine the distribution of admrate and calculate summary statistics for the center (mean and median) and the spread (standard deviation and IQR).\n\n\nExercise 2\nUse the results from the previous exercise to describe the distribution of admrate. Include the shape, center, spread, and if there are potential outliers.\n\n\nExercise 3\nPlot the distribution of cost and calculate the appropriate summary statistics. Describe the distribution of cost (shape, center, and spread, and outliers) using the plot and appropriate summary statistics.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 4\nThe goal of this analysis is to fit a regression model that can be used to understand the variability in the cost of college based on the admission rate. Before fitting the model, let‚Äôs look at the relationship between the two variables. Create a scatterplot to display the relationship between cost and admissions rate. Describe the relationship between the two variables based on the plot.\n\n\nExercise 5\nDoes the relationship between cost and admissions rate differ by type of college? Modify the plot from the previous exercise visualize the relationship by type of college.\n\n\nExercise 6\nDescribe two new observations from the scatterplot in Exercise 5 that you didn‚Äôt see in the scatterplot from Exercise 4.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 7\nFit the linear regression model. Use the kable function to neatly display the results with a reasonable number of decimals.\n\n\nExercise 8\nConsider the model from the previous exercise.\n\nInterpret the slope in the context of the problem.\nDoes the intercept have a meaningful interpretation? If so, write the interpretation in the context of the problem. Otherwise, explain why the interpretation is not meaningful.\n\n\n\nExercise 9\nConstruct a 95% confidence interval for the slope using bootstrapping. Follow these steps to accomplish this:\n\nFirst set a seed for simulating reproducibly.\nThen, simulate the bootstrap distribution of the slope using 1,000 bootstrap samples.\nThen, visually estimate the bounds of the bootstrap interval based on a histogram of the distribution of the bootstrapped slopes, using the percentile method.\nAnd then, use the get_confidence_interval() function to explicitly calculate the bounds of the confidence interval using the percentile method.\nFinally, interpret the confidence interval in the context of the data.\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 10\nFinally, we want to answer the question ‚ÄúDo the data provide sufficient evidence of a linear relationship between cost and admissions rate, i.e.¬†\\(\\beta_1\\) is different from 0?‚Äù\nTo answer this question we will use a hypothesis test. We can conduct a hypothesis test via simulation (what we‚Äôll do in this lab) or using mathematical models (what we‚Äôll do in the next class).\nBefore we can conduct the hypothesis test, let‚Äôs first set our hypotheses. Remember that the null hypothesis represents the status quo (nothing going on, i.e.¬†there is no relationship) and the alternative hypothesis represents our research question (there is something going on, i.e.¬†there is a relationship).\n\n\\(H_0\\): There is no linear relationship between the admissions rate and cost of colleges in the United States, \\(\\beta_1 = 0\\)\n\\(H_A\\): There is a linear relationship between the admissions rate and cost of colleges in the United States, \\(\\beta_1 \\ne 0\\)\n\nTo test these hypotheses, we will use a permutation test, where we\n\nSimulate new samples from the original sample via permutation under the assumption that the null hypothesis is true\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to calculate the p-value for the hypothesis test\n\nThe major difference between constructing a confidence interval and conducting a hypothesis test is that for the hypothesis test we assume that the null hypothesis is true. This requires a simulation scheme that will allow us to measure the natural variability in the data due to sampling but not due to cost and admission rate being correlated by permuting permute one variable to eliminate any existing relationship between the variables. To do so, we randomly assign each admrate value to cost of a given university, i.e.¬†cost and admrate are no longer matched for a given university.\nIn the following code chunk we\n\nFirst set a seed for simulating reproducibly.\nThen, we start with our data frame and specify our model as cost vs.¬†admrate.\nThen, we set our null hypothesis (cost and admrate are independent)\nAnd then we generate 1000 replicates of our data where, for each replicate, we permute values of admrate to randomly assign them to values of cost\nFinally, we fit our model to each of our 1000 permuted datasets\n\n\nset.seed(1234)\n\nperm_fits <- scorecard %>%\n  specify(cost ~ admrate) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 1000, type = \"permute\") %>%\n  fit()\n\nThe resulting dataset perm_fits has nrow(perm_fits) and ncol(perm_fits) columns. The first column, replicate indicates the replicate number of the dataset the models were fit to; the values in this column range between 1 and 1000. The second column, term, tells us which term (intercept of the model or slope of admrate) the estimate value in the third column is for.\n\nperm_fits\n\n# A tibble: 2,000 √ó 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       <int> <chr>        <dbl>\n 1         1 intercept  36857. \n 2         1 admrate     -781. \n 3         2 intercept  35901. \n 4         2 admrate      643. \n 5         3 intercept  36608. \n 6         3 admrate     -411. \n 7         4 intercept  35831. \n 8         4 admrate      746. \n 9         5 intercept  36367. \n10         5 admrate      -51.7\n# ‚Ä¶ with 1,990 more rows\n\n\n\nCreate a histogram of the slope estimates in perm_fits. (Hint: Filter the dataset for just the slope values, term == \"admrate\".)\nEstimate the p-value of the hypothesis test based on this distribution.\nState your conclusion for the test in context.\nIndicate whether or not it is consistent with the results of the hypothesis test from the previous exercise. Briefly explain your response.\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty."
  },
  {
    "objectID": "labs/CopyOflab-2.html#submission",
    "href": "labs/CopyOflab-2.html#submission",
    "title": "Lab 2 - College scorecard",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/CopyOflab-2.html#grading",
    "href": "labs/CopyOflab-2.html#grading",
    "title": "Lab 2 - College scorecard",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51\n\n\n\n\n\n1¬†The ‚ÄúWorkflow & formatting‚Äù grade is to assess the reproducible workflow. This includes having at least 3 informative commit messages and updating the name and date in the YAML."
  },
  {
    "objectID": "labs/lab-5.html",
    "href": "labs/lab-5.html",
    "title": "Lab 5 - General Social Survey",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from the General Social Survey.\n\n\nBy the end of the lab you will be able to‚Ä¶\n\nUse logistic regression to explore the relationship between a binary response variable and multiple predictor variables\nConduct exploratory data analysis for logistic regression\nInterpret coefficients of logistic regression model"
  },
  {
    "objectID": "labs/lab-5.html#getting-started",
    "href": "labs/lab-5.html#getting-started",
    "title": "Lab 5 - General Social Survey",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-5. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Throughout the lab, each person should get a chance to make commits and push to the repo."
  },
  {
    "objectID": "labs/lab-5.html#packages",
    "href": "labs/lab-5.html#packages",
    "title": "Lab 5 - General Social Survey",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-5.html#data-general-social-survey",
    "href": "labs/lab-5.html#data-general-social-survey",
    "title": "Lab 5 - General Social Survey",
    "section": "Data: General Social Survey",
    "text": "Data: General Social Survey\nThe General Social Survey (GSS) has been used to measure trends in attitudes and behaviors in American society since 1972. In addition to collecting demographic information, the survey includes questions used to gauge attitudes about government spending priorities, confidence in institutions, lifestyle, and many other topics. A full description of the survey may be found here.\nThe data for this lab are from the 2016 General Social Survey. The original data set contains 2867 observations and 935 variables. We will use and abbreviated data set that includes the following variables:\n\nnatmass: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe are faced with many problems in this country, none of which can be solved easily or inexpensively. I‚Äôm going to name some of these problems, and for each one I‚Äôd like you to tell me whether you think we‚Äôre spending too much money on it, too little money, or about the right amount‚Ä¶are we spending too much, too little, or about the right amount on mass transportation?‚Äù\nage: Age in years.\nsex: Sex recorded as male or female\nsei10: Socioeconomic index from 0 to 100\nregion: Region where interview took place\npolviews: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe hear a lot of talk these days about liberals and conservatives. I‚Äôm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal - point 1 - to extremely conservative - point 7. Where would you place yourself on this scale?‚Äù\n\nThe data are in gss2016.csv in the data folder."
  },
  {
    "objectID": "labs/lab-5.html#exercises",
    "href": "labs/lab-5.html#exercises",
    "title": "Lab 5 - General Social Survey",
    "section": "Exercises",
    "text": "Exercises\nThe goal of today‚Äôs lab is to use the GSS to examine the relationship between US adults‚Äô political views and attitudes towards government spending on mass transportation projects.\n\nPart I: Exploratory data analysis\n\nLet‚Äôs begin by making a binary variable for respondents‚Äô views on spending on mass transportation. Create a new variable that is equal to ‚Äú1‚Äù if a respondent said spending on mass transportation is about right and ‚Äú0‚Äù otherwise. Then make a plot of the new variable, using informative labels for each category.\nRecode polviews so it is a factor with levels that are in an order that is consistent with question on the survey. Note how the categories are spelled in the data.\n\nMake a plot of the distribution of polviews.\nWhich political view occurs most frequently in this data set?\n\nMake a plot displaying the relationship between satisfaction with mass transportation spending and political views. Use the plot to describe the relationship the two variables.\nWe‚Äôd like to use age as a quantitative variable in your model; however, it is currently a character data type because some observations are coded as \"89 or older\".\n\nRecode age so that is a numeric variable. Note: Before making the variable numeric, you will need to replace the values \"89 or older\" with a single value.\nThen plot the distribution of age.\n\n\n\n\nPart II: Logistic regression model\n\nBriefly explain why we should use a logistic regression model to predict the odds a randomly selected person is satisfied with spending on mass transportation.\nLet‚Äôs start by fitting a model using the demographic factors - age, sex, sei10, and region - to predict the odds a person is satisfied with spending on mass transportation. Make any necessary adjustments to the variables so the intercept will have a meaningful interpretation. Neatly display the model.\nInterpret the intercept in the context of the data.\nConsider the relationship between age and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of age in terms of the odds of being satisfied with spending on mass transportation."
  },
  {
    "objectID": "labs/lab-5.html#submission",
    "href": "labs/lab-5.html#submission",
    "title": "Lab 5 - General Social Survey",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-5.html#grading",
    "href": "labs/lab-5.html#grading",
    "title": "Lab 5 - General Social Survey",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from an online Ipsos survey that was conducted for the FiveThirtyEight article ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù.\n\n\nBy the end of the lab you will be able to‚Ä¶\n\nConduct exploratory data analysis for multinomial logistic regression.\nFit and interpret coefficients of the multinomial logistic regression model.\nUse the multinomial logistic regression model for prediction."
  },
  {
    "objectID": "labs/lab-6.html#getting-started",
    "href": "labs/lab-6.html#getting-started",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-6. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Throughout the lab, each person should get a chance to make commits and push to the repo."
  },
  {
    "objectID": "labs/lab-6.html#packages",
    "href": "labs/lab-6.html#packages",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-6.html#data-five-thirty-eight",
    "href": "labs/lab-6.html#data-five-thirty-eight",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Data: Five Thirty Eight",
    "text": "Data: Five Thirty Eight\nThe data for this assignment comes from an online Ipsos survey that was conducted for the FiveThirtyEight article ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù. You can read more about the survey design and respondents in the README of the GitHub repo for the data.\nRespondents were asked a variety of questions about their political beliefs, thoughts on multiple issues, and voting behavior. We will focus on using the demographic variables and someone‚Äôs party identification to understand whether a person is a probable voter.\nThe variables we‚Äôll focus on are (definitions from the codebook in data set GitHub repo):\n\nppage: Age of respondent\neduc: Highest educational attainment category.\nrace: Race of respondent, census categories. Note: all categories except Hispanic are non-Hispanic.\ngender: Gender of respondent\nincome_cat: Household income category of respondent\nQ30: Response to the question ‚ÄúGenerally speaking, do you think of yourself as a‚Ä¶‚Äù\n\n1: Republican\n2: Democrat\n3: Independent\n4: Another party, please specify\n5: No preference\n-1: No response\n\nvoter_category: past voting behavior:\n\nalways: respondent voted in all or all-but-one of the elections they were eligible in\nsporadic: respondent voted in at least two, but fewer than all-but-one of the elections they were eligible in\nrarely/never: respondent voted in 0 or 1 of the elections they were eligible in\n\n\nYou can read in the data directly from the GitHub repo:\n\nvoters <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv\")\n\nNote that the authors use weighting to make the final sample more representative on the US population for their article. We will not use weighting in this assignment, so we should treat the sample as a convenience sample rather than a random sample of the population."
  },
  {
    "objectID": "labs/lab-6.html#exercises",
    "href": "labs/lab-6.html#exercises",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Exercises",
    "text": "Exercises\n\nWhy do you think the authors chose to only include data from people who were eligible to vote for at least four election cycles?\nLet‚Äôs prepare the data for analysis and modeling.\n\nThe variable Q30 contains the respondent‚Äôs political party identification. Make a new variable that simplifies Q30 into four categories: ‚ÄúDemocrat‚Äù, ‚ÄúRepublican‚Äù, ‚ÄúIndependent‚Äù, ‚ÄúOther‚Äù (‚ÄúOther‚Äù also includes respondents who did not answer the question).\nThe variable voter_category identifies the respondent‚Äôs past voter behavior. Relevel the variable to make rarely/never the baseline level, followed by sporadic, then always.\n\nIn the FiveThirtyEight article, the authors include visualizations of the relationship between the voter category and demographic variables such as race, age, education, etc. Select two demographic variables. For each variable, interpret the plot to describe its relationship with voter category.\nFit a model using mean-centered age, race, gender, income, and education to predict voter category. Show the code used to fit the model, but do not display the model output.\n\nNext, we want to determine whether party identification be added to the model. In order to do this we need to compare two nested models.\n\nThe reduced model is the one we fit so far, including the predictors mean-centered age, race, gender, income, and education.\nThe full model is the one that includes, in addition to these predictors, party identification.\n\n\nShould party identification be added to the model? Use a drop-in-deviance test to determine if party identification should be added to the model. Include the hypotheses in mathematical notation, the output from the test, and the conclusion in the context of the data. Then, neatly display the model you selected.\n\nUse the model you select for the remainder of the assignment.\n\nInterpret the following coefficients in the context of the data in terms of the odds of voting sporadically versus rarely/never.\n\nInterpret the intercept in the context of the data. Use actual values in the interpretation.\nInterpret the effect of age in the context of the data.\nInterpret the effect of party ID in the context of the data. Include discussion about which level(s) differ from the baseline.\n\nIn the article, the authors write\n\n‚ÄúNonvoters were more likely to have lower incomes; to be young; to have lower levels of education; and to say they don‚Äôt belong to either political party, which are all traits that square with what we know about people less likely to engage with the political system.‚Äù\n\nDoes your model support this statement? Briefly explain why or why not.\nLet‚Äôs use the model to predict the voting categories. Obtain the predicted voter category for each observation.\n\nCreate a table of the actual versus predicted voter categories and a visualization of the association between the two.\nHow well did the model perform? Briefly assess the model performance using 2 - 3 observations from the table and/or visualization to support your response."
  },
  {
    "objectID": "labs/lab-6.html#submission",
    "href": "labs/lab-6.html#submission",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-6.html#grading",
    "href": "labs/lab-6.html#grading",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Link\nDescription\n\n\n Human benchmark\nUsed for data collection\n\n\n CSUN Canvas\nUsed for assignment submissions\n\n\n jamovi\nAn open source statistical package based on R1\n\n\n\n\n\n\n\nFootnotes\n\n\nhttps://www.r-project.org‚Ü©Ô∏é"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "KIN 610 - Spring 2023",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "weeks/one-way-anova.html",
    "href": "weeks/one-way-anova.html",
    "title": "One-Way ANOVA",
    "section": "",
    "text": "Introduction\nOne-way analysis of variance (ANOVA) is a statistical test used to compare the means of three or more groups. It is a powerful tool for understanding the relationships between variables and can be used to test hypotheses about the differences between groups. In this chapter, we will discuss the assumptions, calculations, and interpretation of one-way ANOVA, as well as its strengths and limitations.\nAssumptions\nThere are several assumptions that must be met in order to use one-way ANOVA:\n\nNormality: The data should be approximately normally distributed within each group.\nIndependence: The observations should be independent of each other, meaning that the value of one observation should not affect the value of another observation.\nEqual variance: The variance within each group should be approximately equal.\n\nIf these assumptions are not met, the results of the ANOVA may be biased or unreliable. It is important to check for these assumptions before conducting the test.\nCalculations\nTo calculate a one-way ANOVA, we first need to calculate the sum of squares within groups (SSW) and the sum of squares between groups (SSB). The SSW represents the variance within each group, while the SSB represents the variance between the groups.\nThe formula for calculating the SSW is:\nSSW = Œ£(x - xÃÑ)^2\nWhere x is the value of each observation and xÃÑ is the mean of the group.\nThe formula for calculating the SSB is:\nSSB = k * Œ£(xÃÑ - xÃÑÃÑ)^2\nWhere k is the number of groups, xÃÑ is the mean of each group, and xÃÑÃÑ is the overall mean of all the groups.\nOnce we have calculated the SSW and SSB, we can then use them to calculate the F statistic, which is used to determine whether there are significant differences between the groups. The F statistic is calculated as follows:\nF = SSB / SSW\nThe F statistic follows an F distribution, which allows us to determine the probability (p-value) that the differences between the groups are due to chance. If the p-value is less than a predetermined level of significance (usually 0.05), we can reject the null hypothesis and conclude that there are significant differences between the groups.\nInterpretation\nIf the p-value is significant, we can conclude that there are differences between the groups. However, we cannot determine which groups are significantly different from each other without conducting additional tests. To determine which groups are significantly different, we can use a post-hoc test, such as the Tukey HSD test or the Bonferroni correction.\nStrengths and Limitations\nOne-way ANOVA is a powerful statistical tool that can be used to compare the means of three or more groups. However, it has some limitations. For example, it is only appropriate for continuous data and cannot be used with categorical data. It also assumes that the variance is equal within each group, which may not always be the case. Additionally, it does not provide information about the direction or size of the differences between the groups.\nConclusion\nOne-way ANOVA is a statistical test used to compare the means of three or more groups. It is a useful tool for understanding the relationships between variables and can be used to test hypotheses about the differences between groups. However, it has some limitations and should be used with caution.\nversion 2\nOne-way analysis of variance (ANOVA) is a statistical test used to compare the means of two or more groups. It is a powerful tool for comparing the means of multiple groups to determine if there are significant differences between them. In this chapter, we will cover the basics of one-way ANOVA and how it can be used in biostatistics.\nTo begin, let‚Äôs define some key terms:\n\nThe dependent variable is the variable being measured or observed in an experiment. In the context of one-way ANOVA, the dependent variable is usually continuous (e.g., height, weight, blood pressure).\nThe independent variable is the variable being manipulated or controlled in an experiment. In one-way ANOVA, the independent variable has only one level, meaning that there is only one group being compared.\nThe null hypothesis is the assumption that there is no difference between the means of the groups being compared.\nThe alternative hypothesis is the opposite of the null hypothesis, and states that there is a difference between the means of the groups being compared.\n\nTo conduct a one-way ANOVA, we first need to ensure that our data meets the assumptions of the test. These assumptions include:\n\nNormality: The data must be approximately normally distributed within each group.\nIndependence: The observations within each group must be independent of each other.\nEqual variance: The variances of the groups being compared must be equal.\n\nIf these assumptions are not met, it may be necessary to transform the data or use a different statistical test.\nTo perform a one-way ANOVA, we first calculate the overall mean of the dependent variable. Then, we calculate the mean of the dependent variable for each group and subtract the overall mean from each group mean to obtain the group mean differences. We then divide the sum of the squares of these group mean differences by the number of groups minus one to obtain the between-groups sum of squares.\nNext, we calculate the sum of squares within each group by subtracting the group mean from each individual value, squaring the result, and summing the squared differences. We then sum these values across all groups to obtain the within-groups sum of squares.\nFinally, we divide the between-groups sum of squares by the within-groups sum of squares and compare the resulting F-statistic to a critical value from the F-distribution. If the F-statistic is greater than the critical value, we can reject the null hypothesis and conclude that there is a significant difference between the means of the groups.\nOne-way ANOVA is a useful tool for comparing the means of multiple groups, but it has some limitations. It is only appropriate for comparing the means of two or more groups, and it does not allow for comparisons between specific pairs of groups. Additionally, it does not provide information about which groups are significantly different from each other. To address these limitations, we can use follow-up tests such as the Tukey HSD test or the Bonferroni correction.\nIn summary, one-way ANOVA is a statistical test used to compare the means of two or more groups. It is important to ensure that the data meets the assumptions of the test and to use appropriate follow-up tests to understand the specific differences between groups.\nver3"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz for Week 5\nTakeaways"
  },
  {
    "objectID": "weeks/week-5.html#prepare",
    "href": "weeks/week-5.html#prepare",
    "title": "Week 5",
    "section": "Prepare",
    "text": "Prepare\nRead Navarro & Foxcroft (2022), chap.¬†4"
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\nSlides will be provided soon."
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\nTBD"
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\nTBD\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nComplete the Quiz and the Takeaways assignment before class\n\n\nDownload the lesson in PDF"
  },
  {
    "objectID": "weeks/week-4.html#prepare",
    "href": "weeks/week-4.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\n\nRead Furtado (2022)\nRead Navarro & Foxcroft (2022), chap.¬†5"
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n\nThis page will be updated before our meeting with the link to the lecture slides\n\nSlides"
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n\nPractice with jamovi in class"
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\nna\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Important\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDownload this lesson as PDF"
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\n\nRead and study the Syllabus\nRead and study this APA Style in-text citation article"
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\nBe prepared to ask questions while in class."
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\nStudents will be asked to complete activities."
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\nna\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines (before class)\n\nQuiz and Major Takeaways\n\n\nDownload this lesson as PDF"
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\n\nRead Furtado (2023)"
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\nWhile in class, students are to ask questions and take notes.\nPresentation Slides"
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\nTBD"
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\nTBD\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDownload this lesson as PDF"
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\n\njamovi\n\nRead ‚ÄúGetting Started with jamovi‚Äù (Navarro & Foxcroft, 2022, Chapter 3)\nWatch videos 1-6 by Dr. Poulson (2019)"
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\nWhile in class, ask questions and take notes."
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\nStudents will be asked to complete a series of exercises in class."
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\nComplete Lab 11 and submit it by the deadline.\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-3-act1.html",
    "href": "weeks/week-3-act1.html",
    "title": "Activity 1: DV and IV",
    "section": "",
    "text": "Exercise 1: Given a scenario, identify the independent and dependent variables.\nScenario: The impact of height on jumping ability.\nIndependent variable: height\nDependent variable: jumping ability\nExercise 2: Given a scenario, identify the independent and dependent variables.\nScenario: The relationship between training frequency and muscle endurance.\nIndependent variable: training frequency\nDependent variable: muscle endurance\nExercise 3: Given a scenario, identify the independent and dependent variables.\nScenario: The influence of warm-up on performance.\nIndependent variable: warm-up\nDependent variable: performance\nExercise 4: Given a scenario, identify the independent and dependent variables.\nScenario: The effect of weight on power output.\nIndependent variable: weight\nDependent variable: power output\nExercise 5: Given a scenario, identify the independent and dependent variables.\nScenario: The impact of rest time on recovery.\nIndependent variable: rest time\nDependent variable: recovery"
  },
  {
    "objectID": "weeks/CopyOfweek-3.html",
    "href": "weeks/CopyOfweek-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\n\nDue dates:\n\nCh02, Ch03 Quiz - after class\nCh02, Ch03 Major Takeaways (MT) - before class"
  },
  {
    "objectID": "weeks/CopyOfweek-3.html#prepare",
    "href": "weeks/CopyOfweek-3.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\n\nRead Furtado (2023)\nSubmit the MT assignment and take the quiz\nWatch the mini lectures1 1-3 from Human Kinetics (2021); chap.¬†1"
  },
  {
    "objectID": "weeks/CopyOfweek-3.html#participate",
    "href": "weeks/CopyOfweek-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\nTBD"
  },
  {
    "objectID": "weeks/CopyOfweek-3.html#practice",
    "href": "weeks/CopyOfweek-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\nTBD"
  },
  {
    "objectID": "weeks/CopyOfweek-3.html#perform",
    "href": "weeks/CopyOfweek-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\nTBD\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/CopyOfweek-4.html",
    "href": "weeks/CopyOfweek-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\n\nIf you can‚Äôt be in class for the lectures, you can watch the live stream or watch the recording later on Panopto.\nDue dates:\n\nHW 1: Fri, Jan 28, 5pm ET\nLab 1: Fri, Jan 28, 5pm ET"
  },
  {
    "objectID": "weeks/CopyOfweek-4.html#prepare",
    "href": "weeks/CopyOfweek-4.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 24.4: Mathematical model for testing the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.5: Mathematical model, interval for the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.6: Checking model conditions\nüìñ Read Introduction to Modern Statistics, Sec 24.7: Chapter review"
  },
  {
    "objectID": "weeks/CopyOfweek-4.html#participate",
    "href": "weeks/CopyOfweek-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 2 - College scorecard\nüñ•Ô∏è Lecture 6 - SLR: Mathematical models for inference\nüñ•Ô∏è Lecture 7 - SLR: Model diagnostics"
  },
  {
    "objectID": "weeks/CopyOfweek-4.html#practice",
    "href": "weeks/CopyOfweek-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 3 - Checking model conditions"
  },
  {
    "objectID": "weeks/CopyOfweek-4.html#perform",
    "href": "weeks/CopyOfweek-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 2 - College scorecard\n‚úçÔ∏è HW 1 - In-person voting trends\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you‚Äôre welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that‚Äôs fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called ‚ÄúReferences‚Äù at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called ‚ÄúAppendix‚Äù.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you‚Äôre using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n‚ùå NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n‚úÖ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon‚Äôt use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n‚ùå There is a negative linear relationship between mpg and hp.\n‚úÖ There is a negative linear relationship between a car‚Äôs fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don‚Äôt assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the ‚Äúso what‚Äù: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e.¬†what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n‚ùå For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n‚úÖ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it‚Äôs from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you‚Äôll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you‚Äôll use for the course."
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "KIN 610 - Quantitative Analysis of Research in Kinesiology",
    "section": "",
    "text": "This course focuses on the introductory statistical techniques used in social science research. Students will be introduced to concepts such as reliability, validity, measures of central tendency, variability, probability, and statistical techniques including: t tests (independent & dependent samples), Analysis of Variance (ANOVA), Chi-square, correlation, and regression.\nStudents are expected to take the material/concepts presented in this course and apply them through a series of homework assignments and quizzes. The overall goal of the course is not only to help students understand the mathematical/statistical concepts presented but also to assist in the application of these procedures."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KIN 610 - Spring 2023",
    "section": "",
    "text": "Optional Textbook: Weir and Vincent (2021); Required ebook: Navarro and Foxcroft (2022)\n\n\n\n\n\n\n\n\n\n\n\nWeek1\nDate2\nReading3\nAssignments4\n\n\n\n\n\nWk01\nJan 26\nCourse Introduction (Online via Zoom)\nRead and study the Syllabus\n\n\n\nWK02\nFeb 2\nIntroduction to jamovi & Data Collection\nLab 1\n\n\n\nWK03\nFeb 9\nIntroduction to Statistics and Measurement\nQuiz; Major Takeaways\n\n\n\nWK04\nFeb 16\nOrganizing and Displaying Data\nPercentiles\nQuizzes; Major Takeaways\n\n\n\nWK05\nFeb 23\nMeasures of Central Tendency\nMeasures of Variability\nQuizzes; Major Takeaways; Lab 2\n\n\n\nWK06\nMar 2\nFundamentals of Inferential Statistical\n\nQuiz; Major Takeaways\n\n\n\nWK07\nMar 9\nCorrelation and Bivariate Regression\nQuiz; Major Takeaways\n\n\n\nWK08\nMar 16\nMultiple Correlation and Multiple Regression\nQuiz; Major Takeaways; Lab 3\n\n\n\nWK09\nMar 23\nExam 15\nna\n\n\n\nWK10\nMar 30\nThe Student‚Äôs t-test\nQuiz; Major Takeaways\n\n\n\nWK11\nApr 6\nOne-way Analysis of Variance\nQuiz; Major Takeaways\n\n\n\nWK12\nApr 13\nAnalysis of Variance With Repeated Measures\nQuiz; Major Takeaways; Lab 4\n\n\n\nWK13\nApr 20\nSpring Recess\nna\n\n\n\nWK14\nApr 27\n\nFactorial Analysis of Variance: Between-Between\nQuiz; Major Takeaways\n\n\n\nWK15\nMay 4\n\nFactorial Analysis of Variance: Between-Within, Within-Within\nQuiz; Major Takeaways; Lab 5\n\n\n\nWK16\nMay 11\nAnalysis of Nonparametric Data\nQuiz; Major Takeaways\n\n\n\nFinal‚Äôs Week\nMay 18\n5:30PM - 7:30PM\nRedwood Hall 276\nExam 26\nna\n\n\n\n\nKIN 610 - Spring 2023 KIN 610 - Spring 2023 Useful links Support Course information Overview Syllabus Support Schedule Useful links FAQ Weekly materials Week 1 Week 2 Week 3 Week 4 Supplemental notes Statistical Tests ¬© Copyright 2022, Ovande Furtado Jr This page is built with Quarto.\n\n\n  KIN 610 - Spring 2023\n\n\n\nNavarro, Danielle J, and David R Foxcroft. 2022. Learning Statistics with Jamovi: A Tutorial for Psychology Students and Other Beginners (Version 0.75). Danielle J. Navarro; David R. Foxcroft. https://doi.org/10.24384/HGC3-7P15.\n\n\nWeir, Joseph P., and William J. Vincent. 2021. Statistics in Kinesiology. Human Kinetics. https://us.humankinetics.com/products/statistics-in-kinesiology-5th-edition-with-web-resource.\n\n\n\n\nFootnotes\n\n\nThe schedule is subject to change.‚Ü©Ô∏é\nClass Dates: Aug 29, 2022 - Dec 12, 2022‚Ü©Ô∏é\nStudents are expected to read and study the assigned chapters prior to attending each class meeting.‚Ü©Ô∏é\nQuizzes and Major Takeaways assignments are due before class; other assignment are due after class.‚Ü©Ô∏é\nCovers all previously covered topics.‚Ü©Ô∏é\nCovers mainly topics presented after Exam 1.‚Ü©Ô∏é"
  },
  {
    "objectID": "slides/lec-4.html#credits",
    "href": "slides/lec-4.html#credits",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Credits",
    "text": "Credits\nFurtado (2022); Navarro and Foxcroft (2022)"
  },
  {
    "objectID": "slides/lec-4.html#percentile-and-percentile-rank",
    "href": "slides/lec-4.html#percentile-and-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Percentile and Percentile Rank",
    "text": "Percentile and Percentile Rank\nPercentiles and percentile rank are related concepts, but they have slightly different meanings.\nA percentile is a specific value that indicates the percentage of values that are equal to or below a given value in a dataset. For example, the 75th percentile is the value below which 75% of the values in a dataset fall.\nPercentile rank, on the other hand, is a measure of the relative position of a score within a distribution of scores. It indicates the percentage of scores that are equal to or below a given score. For example, if a score has a percentile rank of 75, it means that 75% of the scores in the distribution are equal to or below that score.\nIn essence, percentile rank uses percentiles to determine the relative position of a score within a dataset. While percentiles focus on specific values in a dataset, percentile rank focuses on the relative position of a score within the distribution of scores."
  },
  {
    "objectID": "slides/lec-4.html#definition-of-percentiles",
    "href": "slides/lec-4.html#definition-of-percentiles",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Definition of Percentiles",
    "text": "Definition of Percentiles\n\nA measure used in statistics\nIndicates the value below which a certain percentage of observations in a group fall"
  },
  {
    "objectID": "slides/lec-4.html#example-20th-percentile",
    "href": "slides/lec-4.html#example-20th-percentile",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example: 20th Percentile",
    "text": "Example: 20th Percentile\n\nThe value below which 20% of the observations may be found\nCan be used to compare the relative standing of a value within a dataset (Percentile Rank)"
  },
  {
    "objectID": "slides/lec-4.html#example-90th-percentile",
    "href": "slides/lec-4.html#example-90th-percentile",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example: 90th Percentile",
    "text": "Example: 90th Percentile\n\nIf a student‚Äôs test score is in the 90th percentile, it means that the student scored higher than 90% of the other students who took the test"
  },
  {
    "objectID": "slides/lec-4.html#determining-distribution",
    "href": "slides/lec-4.html#determining-distribution",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Determining Distribution",
    "text": "Determining Distribution\n\nPercentiles can be used to determine the distribution of values within a dataset\nIf the majority of scores fall within the lower percentiles, it may indicate that the scores are generally lower\nIf the majority of scores fall within the higher percentiles, it may indicate that the scores are generally higher"
  },
  {
    "objectID": "slides/lec-4.html#in-a-nutshell",
    "href": "slides/lec-4.html#in-a-nutshell",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "In a nutshell‚Ä¶",
    "text": "In a nutshell‚Ä¶\n\nPercentiles can be calculated using a variety of methods\nOne common method is to first arrange the data in order from smallest to largest\nThen identify the value that corresponds to the desired percentile"
  },
  {
    "objectID": "slides/lec-4.html#doing-it-by-hand",
    "href": "slides/lec-4.html#doing-it-by-hand",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Doing it by hand",
    "text": "Doing it by hand\n\nArrange the data set in numerical order\nDetermine the position of the percentile you want to calculate in the data set\nE.g. 50th percentile is also known as the median\nCalculate the percentile by multiplying the position of the percentile by the total number of values in the data set and then dividing that number by 100\nE.g. (5 * 10) / 100 = 0.5 for the 50th percentile of a data set with 10 values\nTo find the value at the percentile you calculated, go to the position in the data set that corresponds to the percentile value"
  },
  {
    "objectID": "slides/lec-4.html#example-1",
    "href": "slides/lec-4.html#example-1",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example 1:",
    "text": "Example 1:\n\nData set: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nFind 50th percentile (median)\nPosition: 50th percentile = (50 / 100) * 10 = 5\nValue: 5"
  },
  {
    "objectID": "slides/lec-4.html#example-2",
    "href": "slides/lec-4.html#example-2",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example 2:",
    "text": "Example 2:\n\nData set: {5, 7, 8, 12, 14, 15, 16, 17, 18, 20}\nFind 75th percentile\nPosition: 75th percentile = (75 / 100) * 10 = 7.5\nValue: average of 7th and 8th values = (16 + 17) / 2 = 16.5"
  },
  {
    "objectID": "slides/lec-4.html#understanding-the-distribution-of-data",
    "href": "slides/lec-4.html#understanding-the-distribution-of-data",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Understanding the distribution of data",
    "text": "Understanding the distribution of data\n\nPercentile can be used to understand the distribution of data.\nIt indicates the value below which a certain percentage of data falls.\nFor example, if the 50th percentile of a dataset is 50, it means that 50% of the data falls below that value."
  },
  {
    "objectID": "slides/lec-4.html#interpreting-percentile-values",
    "href": "slides/lec-4.html#interpreting-percentile-values",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Interpreting percentile values",
    "text": "Interpreting percentile values\nExample 1: If the 10th percentile is 20 and the 90th percentile is 80, it means that 10% of the data falls below 20 and 90% of the data falls below 80.\n\nThis indicates that the data is distributed relatively evenly, with a few outliers on either side.\n\nExample 2: If the 10th percentile is 20 and the 90th percentile is 90, it means that there is a larger concentration of data towards the higher end of the scale."
  },
  {
    "objectID": "slides/lec-4.html#using-percentile-to-understand-data",
    "href": "slides/lec-4.html#using-percentile-to-understand-data",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Using percentile to understand data",
    "text": "Using percentile to understand data\n\nUsing percentile can help us understand the distribution of data and identify patterns or trends in the data.\nIt can also be used to compare different datasets and see how they differ in terms of distribution."
  },
  {
    "objectID": "slides/lec-4.html#comparing-data-sets",
    "href": "slides/lec-4.html#comparing-data-sets",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Comparing Data Sets",
    "text": "Comparing Data Sets\n\nComparing data sets can be useful to understand how a particular value in one data set compares to values in another data set.\nPercentiles can be used for comparing data sets, especially when they have different scales or units of measurement."
  },
  {
    "objectID": "slides/lec-4.html#definition-of-percentile-rank",
    "href": "slides/lec-4.html#definition-of-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Definition of Percentile Rank",
    "text": "Definition of Percentile Rank\n\nPercentile rank is a measure of the relative standing of a value in a dataset\nIndicates the percentage of values in the dataset that are equal to or less than the value in question\nExample: if a value has a percentile rank of 75, it means that 75% of the values in the dataset are equal to or less than that value."
  },
  {
    "objectID": "slides/lec-4.html#application-of-percentile-rank",
    "href": "slides/lec-4.html#application-of-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Application of Percentile Rank",
    "text": "Application of Percentile Rank\n\nPercentile ranks are commonly used to describe how well a person has performed on a test or assessment relative to a group of people\nExample: a person scores in the 75th percentile on a test, it means that they scored higher than 75% of the people who took the test\nPercentile ranks can also be used to compare the scores of different groups of people, such as comparing the scores of students in different schools or at different grade levels."
  },
  {
    "objectID": "slides/lec-4.html#difference-between-percentile-rank-and-percentage",
    "href": "slides/lec-4.html#difference-between-percentile-rank-and-percentage",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Difference between Percentile Rank and Percentage",
    "text": "Difference between Percentile Rank and Percentage\n\nIt‚Äôs important to note that percentile rank is different from percentage\nPercentile rank describes the relative standing of a value within a dataset\nPercentage is a measure of the number of items in a set relative to the total number of items."
  },
  {
    "objectID": "slides/lec-4.html#how-to-calculate-percentile-rank",
    "href": "slides/lec-4.html#how-to-calculate-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "How to Calculate Percentile Rank",
    "text": "How to Calculate Percentile Rank\n\nOrganize the scores in ascending order.\nThe lowest score should be at the bottom.\nIdentify the position of the score in the ordered distribution."
  },
  {
    "objectID": "slides/lec-4.html#calculate-the-percentile-rank-as-a-percentage.",
    "href": "slides/lec-4.html#calculate-the-percentile-rank-as-a-percentage.",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Calculate the percentile rank as a percentage.",
    "text": "Calculate the percentile rank as a percentage.\n\nDivide the position of the score by the total number of scores.\nMultiply the result by 100 to get the percentile rank as a percentage.\n\nExample: Let‚Äôs say we have the following distribution of scores: 60, 70, 75, 80, 85, 90, 95, 100. The percentile rank for a score of 80 would be:\n\nOrganize the scores in ascending order: 60, 70, 75, 80, 85, 90, 95, 100.\nDetermine the position of the score in question: The score of 80 is the 4th score in the distribution.\nCalculate the percentile rank as a percentage: 4/8 * 100 = 50%. The score of 80 is at the 50th percentile."
  },
  {
    "objectID": "slides/lec-0.html#meet-each-other",
    "href": "slides/lec-0.html#meet-each-other",
    "title": "Welcome to KIN 610!",
    "section": "Meet each other!",
    "text": "Meet each other!\nIn breakout rooms:\n\nName, year, major, hometown\nWhat did you do over the winter break?\nWhat do you hope to get out of this course?\nAnything else you want to share/ask?\n\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/lec-0.html#what-to-expect-in-class",
    "href": "slides/lec-0.html#what-to-expect-in-class",
    "title": "Welcome to KIN 610!",
    "section": "What to expect in class",
    "text": "What to expect in class\n\n\n\nTry to arrive 10 minutes before class begins to set up the computer, open lecture notes, etc.\nI will go over any announcements and begin the lecture shortly after\nA PDF version of the lecture notes will be provide to students, which can used for note taking purposes - electronically1 or hand writing2\nWhen covering jamovi, students are expected to follow along and turn in the generated output at the end of class - will count toward participation points\n\n\n\nUse Acrobat Reader for this purpose.The computer lab has a printer."
  },
  {
    "objectID": "slides/lec-0.html#wrap-up",
    "href": "slides/lec-0.html#wrap-up",
    "title": "Welcome to KIN 610!",
    "section": "Wrap up",
    "text": "Wrap up\nAre there any questions \n\n\n\nhttps://drfurtado.github.io/kin610/"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-professor",
    "href": "slides/lec-1.html#meet-the-professor",
    "title": "Welcome to KIN 610!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\nDr.¬†Furtado - Cal State Northridge\n\n\n\n\nAssociate Professor in Motor Behavior, Department Kinesiology, Cal State Northridge\nFind out more at my academic site"
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to KIN 610!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Introductory statistics or probability course.\nWill we be doing computing? Yes. We will use jamovi."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to KIN 610!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to KIN 610!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching mini lecture videos)\nParticipate: Attend and actively participate in lectures and labs\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you‚Äôve learned to analyze real-world data\n\nLab assignments x 6\nExam 1 and Exam 2"
  },
  {
    "objectID": "slides/lec-1.html#cadence",
    "href": "slides/lec-1.html#cadence",
    "title": "Welcome to KIN 610!",
    "section": "Cadence",
    "text": "Cadence\n\n\nActivities: Start and complete in class (completed/not completed)\nLabs: Start and make large progress on Friday-Saturday-Sunday and, finish it up by Thursday 4 pm of that week\nExams: Start and make large progress during the first two hours, then use the remaining time (~45 min) to check your answers"
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to KIN 610!",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions using our mailing list email address\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to KIN 610!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email (course mailing list), be sure to check both regularly\nI‚Äôll assume that you‚Äôve read an announcement by the next ‚Äúbusiness‚Äù day\nI‚Äôll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to KIN 610!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official CSUN records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to KIN 610!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times! \nRead and follow university guidance"
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to KIN 610!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to KIN 610!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nLabs must be completed individually. You may not directly share answers with others; however, you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to KIN 610!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the CSUN Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to KIN 610!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you‚Äôre not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to KIN 610!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class\nAsk questions\nDo the readings\nDo the and labs\nDon‚Äôt procrastinate and don‚Äôt let a week pass by with lingering questions"
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic",
    "href": "slides/lec-1.html#learning-during-a-pandemic",
    "title": "Welcome to KIN 610!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this ongoing crisis."
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to KIN 610!",
    "section": "This week‚Äôs tasks",
    "text": "This week‚Äôs tasks\n\nPrepare for next week by clicking here\nRe-read the syllabus\nWatch out for next week‚Äôs announcement email, in your inbox sometime tomorrow"
  },
  {
    "objectID": "slides/lec-1.html#bi-question-any-questions",
    "href": "slides/lec-1.html#bi-question-any-questions",
    "title": "Welcome to KIN 610!",
    "section": " Any Questions",
    "text": "Any Questions\n\n\n\nhttps://drfurtado.github.io/kin610/"
  },
  {
    "objectID": "slides/lec-3.html#credits",
    "href": "slides/lec-3.html#credits",
    "title": "Week 3: Intro to Stats",
    "section": "Credits",
    "text": "Credits\nFurtado (2023)"
  },
  {
    "objectID": "slides/lec-3.html#introduction-to-measurement-in-kinesiology",
    "href": "slides/lec-3.html#introduction-to-measurement-in-kinesiology",
    "title": "Week 3: Intro to Stats",
    "section": "Introduction to Measurement in Kinesiology",
    "text": "Introduction to Measurement in Kinesiology\n\nThe importance of measurement in Kinesiology\nMeasurement as the process of determining the value of a characteristic or quantity"
  },
  {
    "objectID": "slides/lec-3.html#why-measurement-is-important-in-kinesiology",
    "href": "slides/lec-3.html#why-measurement-is-important-in-kinesiology",
    "title": "Week 3: Intro to Stats",
    "section": "Why Measurement is Important in Kinesiology",
    "text": "Why Measurement is Important in Kinesiology\n\nMeasurement provides objective data\nMeasurement allows for comparison"
  },
  {
    "objectID": "slides/lec-3.html#evaluation-of-interventions",
    "href": "slides/lec-3.html#evaluation-of-interventions",
    "title": "Week 3: Intro to Stats",
    "section": "Evaluation of Interventions",
    "text": "Evaluation of Interventions\n\nMeasurement is essential for evaluating the effectiveness of interventions\nMeasurement can help to identify patterns or trends in large amounts of data"
  },
  {
    "objectID": "slides/lec-3.html#intro",
    "href": "slides/lec-3.html#intro",
    "title": "Week 3: Intro to Stats",
    "section": "Intro",
    "text": "Intro\n\nStatistics plays a crucial role in Kinesiology\nAllows researchers and practitioners to analyze and interpret data related to human movement, physical activity, and exercise"
  },
  {
    "objectID": "slides/lec-3.html#data-analysis-techniques",
    "href": "slides/lec-3.html#data-analysis-techniques",
    "title": "Week 3: Intro to Stats",
    "section": "Data Analysis Techniques",
    "text": "Data Analysis Techniques\n\nOne of the most common uses of statistics in Kinesiology is for data analyses This includes:\nDescriptive statistics: summarize and describe the main characteristics of a dataset\nInferential statistics: infer about a specific population based on a sample of data\nDescriptive statistics: mean, median, standard deviation, range\nInferential statistics: t-tests, ANOVA, regression analysis"
  },
  {
    "objectID": "slides/lec-3.html#design-and-analysis-of-experiments-and-studies",
    "href": "slides/lec-3.html#design-and-analysis-of-experiments-and-studies",
    "title": "Week 3: Intro to Stats",
    "section": "Design and Analysis of Experiments and Studies",
    "text": "Design and Analysis of Experiments and Studies\n\nStatistics used to design and analyze experiments and studies in Kinesiology\nStatistical tests: determine if there is a significant difference between groups or if an intervention has an effect\nExamples: t-test, ANOVA"
  },
  {
    "objectID": "slides/lec-3.html#correlation-and-causal-inference",
    "href": "slides/lec-3.html#correlation-and-causal-inference",
    "title": "Week 3: Intro to Stats",
    "section": "Correlation and Causal Inference",
    "text": "Correlation and Causal Inference\n\nCorrelation: measures the association between two variables\nCausal inference: determines if an observed association is due to a causal relationship"
  },
  {
    "objectID": "slides/lec-3.html#interpreting-results",
    "href": "slides/lec-3.html#interpreting-results",
    "title": "Week 3: Intro to Stats",
    "section": "Interpreting Results",
    "text": "Interpreting Results\n\nConsider level of significance: probability that results occurred by chance (p < 0.05)\nConsider practical significance: meaningful results in the real world"
  },
  {
    "objectID": "slides/lec-3.html#visualizing-data",
    "href": "slides/lec-3.html#visualizing-data",
    "title": "Week 3: Intro to Stats",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nGraphical methods used to visualize data: histograms, scatter plots, box plots\nHelp identify patterns, outliers, and communicate results in an easily understandable format"
  },
  {
    "objectID": "slides/lec-3.html#variables",
    "href": "slides/lec-3.html#variables",
    "title": "Week 3: Intro to Stats",
    "section": "Variables",
    "text": "Variables\n\nA variable is a characteristic or factor that can change or take on different values within a study or experiment.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the variable of interest would be muscle strength."
  },
  {
    "objectID": "slides/lec-3.html#constants",
    "href": "slides/lec-3.html#constants",
    "title": "Week 3: Intro to Stats",
    "section": "Constants",
    "text": "Constants\n\nA constant is a characteristic or factor that remains unchanged or fixed within a study or experiment.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the age of the participants could be considered a constant."
  },
  {
    "objectID": "slides/lec-3.html#benefits-of-controlling-constants",
    "href": "slides/lec-3.html#benefits-of-controlling-constants",
    "title": "Week 3: Intro to Stats",
    "section": "Benefits of Controlling Constants",
    "text": "Benefits of Controlling Constants\n\nAllows researchers to isolate the effects of a particular variable of interest.\nConfidence that any changes observed are due to the variable of interest and not other factors."
  },
  {
    "objectID": "slides/lec-3.html#summary",
    "href": "slides/lec-3.html#summary",
    "title": "Week 3: Intro to Stats",
    "section": "Summary",
    "text": "Summary\n\nVariables and constants are important concepts in scientific research.\nVariables are factors that can change, while constants are factors that remain unchanged.\nUnderstanding and controlling constants is important to isolate the effects of the variables of interest."
  },
  {
    "objectID": "slides/lec-3.html#continuous-variables",
    "href": "slides/lec-3.html#continuous-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Continuous Variables",
    "text": "Continuous Variables\n\nA continuous variable is a variable that can take on any value within a specific range.\nExamples: height, weight, time\nCan be measured to an infinite number of decimal places."
  },
  {
    "objectID": "slides/lec-3.html#discrete-variables",
    "href": "slides/lec-3.html#discrete-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Discrete Variables",
    "text": "Discrete Variables\n\nA discrete variable is a variable that can only take on specific values.\nExamples: number of children in a household\nDiscrete variables are countable, usually measured by counting."
  },
  {
    "objectID": "slides/lec-3.html#difference-between-continuous-and-discrete-variables",
    "href": "slides/lec-3.html#difference-between-continuous-and-discrete-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Difference between Continuous and Discrete Variables",
    "text": "Difference between Continuous and Discrete Variables\n\nThe main difference between continuous and discrete variables is how data is collected and analyzed.\nExample 1: Study investigating the relationship between weight and blood pressure, weight is a continuous variable, and blood pressure is also continuous. Pearson Correlation Coefficient would be used to investigate the relationship.\nExample 2: Study investigating the relationship between the number of hours of sleep and the number of absenteeism in a company, hours of sleep are continuous and can have an infinite number of values, while absenteeism is discrete. Spearman Rho would be used to investigate the correlation."
  },
  {
    "objectID": "slides/lec-3.html#importance-of-understanding-continuous-vs.-discrete-variables",
    "href": "slides/lec-3.html#importance-of-understanding-continuous-vs.-discrete-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Importance of Understanding Continuous vs.¬†Discrete Variables",
    "text": "Importance of Understanding Continuous vs.¬†Discrete Variables\n\nAffects the methods used to collect and analyze data.\nResearchers must use the appropriate statistical techniques for their specific type of variables to draw valid conclusions from their data."
  },
  {
    "objectID": "slides/lec-3.html#summary-1",
    "href": "slides/lec-3.html#summary-1",
    "title": "Week 3: Intro to Stats",
    "section": "Summary",
    "text": "Summary\n\nContinuous and discrete variables are two types of variables used in research.\nContinuous variables can take on any value within a specific range, while discrete variables can only take on specific values.\nUnderstanding the difference between these two types of variables is important because it can affect the methods used to collect and analyze data."
  },
  {
    "objectID": "slides/lec-3.html#intro-1",
    "href": "slides/lec-3.html#intro-1",
    "title": "Week 3: Intro to Stats",
    "section": "Intro",
    "text": "Intro\n\nNumerical data is classified into four types based on their level of measurement and the types of statistical analysis that can be used.\nNominal, ordinal, interval, and ratio data are different types of numerical data."
  },
  {
    "objectID": "slides/lec-3.html#nominal-data",
    "href": "slides/lec-3.html#nominal-data",
    "title": "Week 3: Intro to Stats",
    "section": "Nominal Data",
    "text": "Nominal Data\n\nNominal data is a non-numeric type of data that can be placed into categories but cannot be meaningfully ordered or quantified.\nExamples: color, gender, religion\nAnalysis methods: frequency distributions, chi-squared tests, contingency tables"
  },
  {
    "objectID": "slides/lec-3.html#ordinal-data",
    "href": "slides/lec-3.html#ordinal-data",
    "title": "Week 3: Intro to Stats",
    "section": "Ordinal Data",
    "text": "Ordinal Data\n\nOrdinal data is a type of data that can be placed into categories and can be meaningfully ordered, but the difference between the data points is not necessarily equal.\nExamples: education level, socioeconomic status, satisfaction level\nAnalysis methods: medians, quartiles, percentiles"
  },
  {
    "objectID": "slides/lec-3.html#interval-data",
    "href": "slides/lec-3.html#interval-data",
    "title": "Week 3: Intro to Stats",
    "section": "Interval Data",
    "text": "Interval Data\n\nInterval data is a type of data that has equal intervals between the data points but does not have an absolute zero point.\nExamples: temperature measured in Celsius or Fahrenheit\nAnalysis methods: central tendency and variability measures"
  },
  {
    "objectID": "slides/lec-3.html#ratio-data",
    "href": "slides/lec-3.html#ratio-data",
    "title": "Week 3: Intro to Stats",
    "section": "Ratio Data",
    "text": "Ratio Data\n\nRatio data is a type of data with equal intervals between the data points and an absolute zero point.\nExamples: weight, height, time\nAnalysis methods: central tendency and variability measures, correlation, and regression analysis"
  },
  {
    "objectID": "slides/lec-3.html#conclusion",
    "href": "slides/lec-3.html#conclusion",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nUnderstanding the differences between nominal, ordinal, interval, and ratio data is crucial because it affects the statistical methods used to analyze and interpret the data.\nChoosing the appropriate type of data and analysis is important to draw meaningful and accurate conclusions."
  },
  {
    "objectID": "slides/lec-3.html#independent-variable",
    "href": "slides/lec-3.html#independent-variable",
    "title": "Week 3: Intro to Stats",
    "section": "Independent Variable",
    "text": "Independent Variable\n\nIndependent variable (IV) is the variable that is manipulated or changed in an experiment.\nThe IV is the factor the researcher is interested in studying.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the IV would be the exercise program itself."
  },
  {
    "objectID": "slides/lec-3.html#dependent-variable",
    "href": "slides/lec-3.html#dependent-variable",
    "title": "Week 3: Intro to Stats",
    "section": "Dependent Variable",
    "text": "Dependent Variable\n\nDependent variable (DV) is the factor affected by the independent variable.\nThe DV is the variable that is measured or observed in response to the manipulation of the independent variable.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the DV would be muscle strength, measured before and after the exercise program to see if there is an improvement."
  },
  {
    "objectID": "slides/lec-3.html#the-relationship-between-iv-and-dv",
    "href": "slides/lec-3.html#the-relationship-between-iv-and-dv",
    "title": "Week 3: Intro to Stats",
    "section": "The Relationship between IV and DV",
    "text": "The Relationship between IV and DV\n\nThe independent variable is manipulated or controlled by the researcher.\nThe dependent variable is measured or observed.\nUnderstanding the relationship between these two variables allows researchers to establish a cause-and-effect relationship and draw valid conclusions from their research."
  },
  {
    "objectID": "slides/lec-3.html#another-example",
    "href": "slides/lec-3.html#another-example",
    "title": "Week 3: Intro to Stats",
    "section": "Another Example",
    "text": "Another Example\n\nA study investigating the effect of a specific training program on running performance.\nIndependent variable: The training program\nDependent variable: Running performance, measured before and after the program."
  },
  {
    "objectID": "slides/lec-3.html#conclusion-1",
    "href": "slides/lec-3.html#conclusion-1",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nDependent and independent variables are important concepts in scientific research.\nThe researcher manipulates independent variables and dependent variables are measured or observed.\nUnderstanding the relationship between these two variables is crucial to establish a cause-and-effect relationship and draw valid conclusions from research."
  },
  {
    "objectID": "slides/lec-3.html#intro-2",
    "href": "slides/lec-3.html#intro-2",
    "title": "Week 3: Intro to Stats",
    "section": "Intro",
    "text": "Intro\n\nResearch is a systematic and scientific inquiry into a subject or phenomenon\nIt involves a process of discovering new knowledge, understanding complex issues, and making informed decisions"
  },
  {
    "objectID": "slides/lec-3.html#three-common-types-of-research",
    "href": "slides/lec-3.html#three-common-types-of-research",
    "title": "Week 3: Intro to Stats",
    "section": "Three Common Types of Research",
    "text": "Three Common Types of Research\n\nHistorical Research\nObservational Research\nExperimental Research"
  },
  {
    "objectID": "slides/lec-3.html#historical-research",
    "href": "slides/lec-3.html#historical-research",
    "title": "Week 3: Intro to Stats",
    "section": "Historical Research",
    "text": "Historical Research\n\nInvolves the collection and analysis of primary and secondary sources\nInvestigates events, phenomena, or people in the past\nRelying on written documents, photographs, and other artifacts to reconstruct the past\nUnderstanding the origin of events, historical trends, and the development of ideas, institutions, or societies\nObservational Research\nThe researcher observes but does not manipulate the phenomenon of interest\nMay involve collecting both quantitative and qualitative data\nTypically does not involve manipulation of independent variables\nCan be conducted in natural settings, such as in the field or controlled laboratory settings\nExample: studying athletes‚Äô natural movement patterns or assessing the effectiveness of rehabilitation programs"
  },
  {
    "objectID": "slides/lec-3.html#experimental-research",
    "href": "slides/lec-3.html#experimental-research",
    "title": "Week 3: Intro to Stats",
    "section": "Experimental Research",
    "text": "Experimental Research\n\nThe researcher manipulates one or more independent variables and measures their effects on one or more dependent variables\nEstablishes cause-and-effect relationships between variables\nInvolves using control groups and randomly assigning participants to treatment or control groups\nExample: investigating the effects of different training protocols on physical performance or testing the effectiveness of different therapeutic interventions"
  },
  {
    "objectID": "slides/lec-3.html#conclusion-2",
    "href": "slides/lec-3.html#conclusion-2",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nResearch is a systematic and scientific inquiry into a particular subject or phenomenon\nHistorical research, observational research, and experimental research are three common types of research\nEach type of research has its strengths, limitations, and purposes\nThe choice of which type to use will depend on the research question and the study‚Äôs goals."
  },
  {
    "objectID": "slides/lec-3.html#introduction",
    "href": "slides/lec-3.html#introduction",
    "title": "Week 3: Intro to Stats",
    "section": "Introduction",
    "text": "Introduction\n\nResearch is a systematic and scientific inquiry into a particular subject or phenomenon\nTwo critical concepts in research: internal and external validity"
  },
  {
    "objectID": "slides/lec-3.html#internal-validity",
    "href": "slides/lec-3.html#internal-validity",
    "title": "Week 3: Intro to Stats",
    "section": "Internal Validity",
    "text": "Internal Validity\n\nDefinition: degree to which the results of a study can be attributed to the manipulation of the independent variable\nImportance in Kinesiology: ensuring that the results of a study can be attributed to the specific training protocol or intervention tested\nExample: investigating the effects of a specific strength training program on muscle mass"
  },
  {
    "objectID": "slides/lec-3.html#external-validity",
    "href": "slides/lec-3.html#external-validity",
    "title": "Week 3: Intro to Stats",
    "section": "External Validity",
    "text": "External Validity\n\nDefinition: degree to which the results of a study can be generalized to other populations, settings, and periods\nImportance in Kinesiology: ensuring that the results of a study can be applied to real-world situations and other populations\nExample: investigating the effects of a specific strength training program on muscle mass in young men"
  },
  {
    "objectID": "slides/lec-3.html#internal-and-external-validity-1",
    "href": "slides/lec-3.html#internal-and-external-validity-1",
    "title": "Week 3: Intro to Stats",
    "section": "Internal and External Validity",
    "text": "Internal and External Validity\n\nSeparate concepts, but related\nResearchers should strive to achieve high internal and external validity\nTrade-offs between the two may be necessary"
  },
  {
    "objectID": "slides/lec-3.html#conclusion-3",
    "href": "slides/lec-3.html#conclusion-3",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nStatistics is a critical component of kinesiology\nUnderstanding and applying statistical concepts and methods is crucial for informed decision-making\nKey concepts like measurement, variables, and research types must be understood and applied properly\nUnderstanding and applying concepts like internal and external validity is essential for drawing valid conclusions from research findings."
  },
  {
    "objectID": "supplemental/mlr-matrix.html",
    "href": "supplemental/mlr-matrix.html",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides the details for the matrix notation for multiple linear regression. We assume the reader has familiarity with some linear algebra. Please see Chapter 1 of An Introduction to Statistical Learning for a brief review of linear algebra."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#introduction",
    "href": "supplemental/mlr-matrix.html#introduction",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation¬†1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation¬†2\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "href": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Matrix Representation for the Regression Model",
    "text": "Matrix Representation for the Regression Model\nWe can represent the Equation¬†1 and Equation¬†2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "href": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Estimating the Coefficients",
    "text": "Estimating the Coefficients\nThe least-squares model is the one that minimizes the sum of the squared residuals. Therefore, we want to find the coefficients, \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes\n\\[\n\\sum\\limits_{i=1}^{n} e_{i}^2 = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})\n\\tag{5}\\]\nwhere \\(\\mathbf{e}^T\\), the transpose of the matrix \\(\\mathbf{e}\\).\n\\[\n(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{Y}^T\\mathbf{Y} -\n\\mathbf{Y}^T \\mathbf{X}\\hat{\\boldsymbol{\\beta}} - (\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y} +\n\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}})\n\\tag{6}\\]\nNote that \\((\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Since these are both constants (i.e.¬†\\(1\\times 1\\) vectors), \\(\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Thus, Equation¬†7 becomes\n\\[\n\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}}\n\\tag{7}\\]\nSince we want to find the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes Equation¬†5, will find the value of \\(\\hat{\\boldsymbol{\\beta}}\\) such that the derivative with respect to \\(\\hat{\\boldsymbol{\\beta}}\\) is equal to 0.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\mathbf{e}^T\\mathbf{e}}{\\partial \\hat{\\boldsymbol{\\beta}}} & = \\frac{\\partial}{\\partial \\hat{\\boldsymbol{\\beta}}}(\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^T\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = 0 \\\\\n&\\Rightarrow - 2 \\mathbf{X}^T\\mathbf{Y} + 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = 0 \\\\\n& \\Rightarrow 2 \\mathbf{X}^T\\mathbf{Y} = 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow \\mathbf{X}^T\\mathbf{Y} = \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = \\mathbf{I}\\hat{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\tag{8}\\]\nThus, the estimate of the model coefficients is \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\)."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "href": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Variance-covariance matrix of the coefficients",
    "text": "Variance-covariance matrix of the coefficients\nWe will use two properties to derive the form of the variance-covariance matrix of the coefficients:\n\n\\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\)\n\nFirst, we will show that \\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\[\n\\begin{aligned}\nE[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] &= E \\begin{bmatrix}\\epsilon_1  & \\epsilon_2 & \\dots & \\epsilon_n \\end{bmatrix}\\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}  \\\\\n& = E \\begin{bmatrix} \\epsilon_1^2  & \\epsilon_1 \\epsilon_2 & \\dots & \\epsilon_1 \\epsilon_n \\\\\n\\epsilon_2 \\epsilon_1 & \\epsilon_2^2 & \\dots & \\epsilon_2 \\epsilon_n \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\epsilon_n \\epsilon_1 & \\epsilon_n \\epsilon_2 & \\dots & \\epsilon_n^2\n\\end{bmatrix} \\\\\n& = \\begin{bmatrix} E[\\epsilon_1^2]  & E[\\epsilon_1 \\epsilon_2] & \\dots & E[\\epsilon_1 \\epsilon_n] \\\\\nE[\\epsilon_2 \\epsilon_1] & E[\\epsilon_2^2] & \\dots & E[\\epsilon_2 \\epsilon_n] \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nE[\\epsilon_n \\epsilon_1] & E[\\epsilon_n \\epsilon_2] & \\dots & E[\\epsilon_n^2]\n\\end{bmatrix}\n\\end{aligned}\n\\tag{9}\\]\nRecall, the regression assumption that the errors \\(\\epsilon_i's\\) are Normally distributed with mean 0 and variance \\(\\sigma^2\\). Thus, \\(E(\\epsilon_i^2) = Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). Additionally, recall the regression assumption that the errors are uncorrelated, i.e.¬†\\(E(\\epsilon_i \\epsilon_j) = Cov(\\epsilon_i, \\epsilon_j) = 0\\) for all \\(i,j\\). Using these assumptions, we can write Equation¬†9 as\n\\[\nE[\\mathbf{\\epsilon}\\mathbf{\\epsilon}^T]  = \\begin{bmatrix} \\sigma^2  & 0 & \\dots & 0 \\\\\n0 & \\sigma^2  & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & \\sigma^2\n\\end{bmatrix} = \\sigma^2 \\mathbf{I}\n\\tag{10}\\]\nwhere \\(\\mathbf{I}\\) is the \\(n \\times n\\) identity matrix.\nNext, we show that \\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\).\nRecall that the \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\) and \\(\\mathbf{Y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}\\). Then,\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{\\beta}} &= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\\\\n&= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}) \\\\\n&= \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{\\epsilon} \\\\\n\\end{aligned}\n\\tag{11}\\]\nUsing these two properties, we derive the form of the variance-covariance matrix for the coefficients. Note that the covariance matrix is \\(E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T]\\)\n\\[\n\\begin{aligned}\nE[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] &= E[(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})^T]\\\\\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T]\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T (\\sigma^2\\mathbf{I})\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&= \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&  = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n\\end{aligned}\n\\tag{12}\\]"
  },
  {
    "objectID": "supplemental/stats-tests.html",
    "href": "supplemental/stats-tests.html",
    "title": "Statistical Tests",
    "section": "",
    "text": "Parametric tests are a class of statistical tests that make assumptions about the underlying probability distribution of the data being analyzed. These assumptions include that the data are sampled from a population that follows a normal distribution, and that the sample size is large enough to make these assumptions valid. The most commonly used parametric tests include t-tests, ANOVA (analysis of variance) and multiple regression analysis. These tests are known to have more powerful results than non-parametric tests, which makes them more useful for exploring the difference between groups or testing hypotheses about a population.\nThe assumptions of parametric tests are met when the data are approximately normal and when the sample size is large enough. Therefore, it is recommended to check for normality of the data using normality test such as the Shapiro-Wilk test and check for outliers using box plots and histograms.\nParametric tests are useful when the researcher wants to compare means of two or more groups, establish a relationship between two or more variables, or investigate the correlation between variables. Examples of parametric tests include: t-test, ANOVA, multiple regression analysis, and chi-square tests.\n\n\n\\[\nt = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n\\tag{1}\\]\nwhere:\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu\\) is the population mean\n\\(s\\) is the sample standard deviation\n\\(n\\) is the sample size\n\nIt also can be written as:\n\\[\nt = \\frac{\\bar{x} - \\mu}{s_x/\\sqrt{n}}\n\\tag{2}\\]\nwhere:\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu\\) is the population mean\n\\(s_x\\) is the sample standard deviation\n\\(n\\) is the sample size\n\n\n\nThe one-sample t-test should be run when you have a single sample of data and you want to compare the mean of that sample to a known or hypothesized population mean.\nExample in kinesiology: A kinesiologist wants to know if a new exercise program improves muscle strength in older adults. The kinesiologist recruits a sample of 20 older adults and has them complete the exercise program for 8 weeks. The kinesiologist measures muscle strength using a dynamometer before and after the 8 week program. The kinesiologist wants to know if the mean muscle strength of the sample is significantly different from the population mean muscle strength of older adults (which is hypothesized to be 40 kg). The kinesiologist would run a one-sample t-test to compare the mean muscle strength of the sample (after completing the exercise program) to the hypothesized population mean of 40 kg. If the t-value is significant, the kinesiologist can conclude that the exercise program does improve muscle strength in older adults.\n\n\n\nThe test makes several assumptions about the data:\n\nIndependence: The observations in the sample are independent of one another.\nNormality: The population from which the sample is drawn is normally distributed.\nEqual variances: The population variances of the two groups are equal.\nRandom sampling: The sample is drawn randomly and independently from the population.\nSample size: The sample size is large enough (usually greater than 30) for the Central Limit Theorem to be applied.\n\nIt is important to check these assumptions before running the one-sample t-test to ensure the validity of the test results. In case the sample size is small or the data distribution is not normal, a non-parametric test such as the Wilcoxon signed-rank test should be used instead.\n\n\n\nWhen reporting the results of a one-sample t-test in APA style, you should include the following information:\n\nThe test statistic and the associated degrees of freedom (df). For example: ‚Äút(df) = 2.45, p = .03.‚Äù\nThe p-value of the test. This should be rounded to two decimal places and reported as a probability (e.g., ‚Äúp = .03‚Äù rather than ‚Äúp < .05‚Äù).\nThe sample size (n). This should be reported as a whole number (e.g., ‚Äún = 20‚Äù).\nThe mean and standard deviation of the sample. For example: ‚ÄúM = 5.6, SD = 1.2.‚Äù\nThe direction of the effect. For example, ‚ÄúThe mean score was significantly higher than the hypothesized mean (M = 4.0, t(df) = 2.45, p = .03).‚Äù\nAny relevant effect size measures. For example, you might report the Cohen‚Äôs d effect size as ‚Äúd = 0.87.‚Äù\n\nIt is also good practice to include a brief description of the research question or hypothesis being tested, as well as a description of the sample and any relevant study variables.\nFor example: ‚ÄúIn this study, we tested the hypothesis that the mean score on a memory task would be significantly higher than 4.0. A sample of 20 participants completed the task, with a mean score of 5.6 (SD = 1.2). The one-sample t-test revealed a significant difference, t(df) = 2.45, p = .03, d = 0.87, indicating that the mean score was significantly higher than the hypothesized mean.‚Äù\n\n\n\nThe results of the one-sample t test indicated that the mean (M = X, SD = Y) was significantly different from the hypothesized value (t(df) = t-value, p < .05).\nIn a one-sample t test, the mean of the sample was significantly different from the hypothesized mean (t(df) = t-value, p < .05). Specifically, the mean of the sample was X (SD = standard deviation) while the hypothesized mean was Y.\nThe results of the one-sample t test indicated that the mean of the sample (M = X, SD = Y) was significantly different from the hypothesized mean (Œº = t) t(df) = t-value, p < .05.\n\n\n\n\n\n\nThe independent-samples t-test should be run when comparing the means of two independent groups. For example, in the field of kinesiology, an independent-samples t-test can be used to compare the muscle strength of a group of individuals who have completed a resistance training program to a group of individuals who have not completed a resistance training program. The independent variable would be whether or not the individual completed the resistance training program and the dependent variable would be muscle strength. The t-test would be used to determine if there is a significant difference in muscle strength between the two groups, indicating that the resistance training program had an effect on muscle strength.\n\n\n\nThe assumptions of the independent-samples t-test include:\n\nNormality: The data should be approximately normally distributed within each group.\nIndependence: The observations in each group should be independent of one another.\nEqual variances: The variances of the two groups should be roughly equal.\nRandom Sampling: The sample of each group should be random and representative of the population.\nEqual sample size: The sample size in each group should be equal or similar.\n\nIt is important to note that not all these assumptions need to be perfectly met for the test to be valid, but the deviations from these assumptions should be small. If the data do not meet these assumptions, the non-parametric version of the independent-samples t-test, such as the Mann-Whitney U test, can be used instead.\n\n\n\nTo report the results of an independent samples t-test in APA style, you should include the following information:\n\nThe type of test that was conducted (e.g., ‚ÄúAn independent samples t-test was conducted to compare the mean scores of two groups on a measure of stress.‚Äù)\nThe sample size for each group (e.g., ‚ÄúThe sample consisted of 20 participants in Group A and 25 participants in Group B.‚Äù)\nThe mean and standard deviation for each group (e.g., ‚ÄúThe mean score for Group A was M = 3.5, SD = 1.2, and the mean score for Group B was M = 2.8, SD = 0.9.‚Äù)\nThe t-value and p-value obtained from the test (e.g., ‚ÄúThe t-value was t(43) = 2.3, p = .03, indicating that there was a significant difference between the mean scores of the two groups, with Group A scoring higher than Group B.‚Äù)\nThe effect size (e.g., ‚ÄúThe effect size for the difference between the two groups was d = .7, indicating a moderate effect.‚Äù)\n\nIt is also a good idea to provide a brief interpretation of the results, explaining what they mean in the context of your research question or hypothesis.\nHere is an example of how you might report the results of an independent samples t-test in APA style:\n\n\n\n‚ÄúAn independent samples t-test was conducted to compare the mean scores of two groups on a measure of stress. The sample consisted of 20 participants in Group A and 25 participants in Group B. The mean score for Group A was M = 3.5, SD = 1.2, and the mean score for Group B was M = 2.8, SD = 0.9. The t-value was t(43) = 2.3, p = .03, indicating that there was a significant difference between the mean scores of the two groups, with Group A scoring higher than Group B. The effect size for the difference between the two groups was d = .7, indicating a moderate effect. These results suggest that participants in Group A experienced significantly higher levels of stress than those in Group B.‚Äù\n‚ÄúThe purpose of this study was to examine the effect of a new teaching method on student achievement. A sample of 50 students was randomly assigned to either the experimental group, which received the new teaching method, or the control group, which received the traditional teaching method. Student achievement was measured using a standardized test. The results of the independent samples t-test showed that there was a statistically significant difference between the experimental and control groups, t(48) = 2.57, p = .01. The experimental group had a higher mean score on the achievement test than the control group. These findings suggest that the new teaching method was effective in improving student achievement. However, it is important to note that the small sample size and lack of generalizability to other populations are limitations of this study.‚Äù\n\n\n\n\n\n\nThe paired-samples t-test should be run when you have two sets of related (or paired) data that you want to compare. For example, if you want to compare the effectiveness of two different treatments on a group of patients, you would use a paired-samples t-test. This test is also commonly used in pre- and post-test designs, where you want to compare scores before and after an intervention or treatment. Additionally, if you want to compare the mean differences between two groups or conditions, but you want to control for individual differences, you can use a paired-samples t-test.\n\n\n\nThe assumptions of the paired-samples t-test include:\n\nIndependence: The observations within each pair are independent of one another.\nNormality: The differences between the pairs of observations are approximately normally distributed.\nEqual variances: The variances of the differences between the pairs of observations are equal.\nPaired data: The observations are paired, meaning that each individual is measured twice, once before and once after some intervention, or in two different conditions.\nRandom Sampling: The sample being used is selected randomly from the population.\n\nIt‚Äôs important to note that violations of these assumptions may lead to inaccurate results, so it‚Äôs necessary to check them before applying the test. Checking for normality can be done using a normal probability plot, and checking for equal variances can be done using Levene‚Äôs test. The paired sample t-test is sensitive to the violation of normality and equal variances assumptions, thus if the assumptions are not met, there are other options that can be used, such as the Wilcoxon signed-rank test which is a non-parametric version of the paired-samples t-test.\n\n\n\nWhen reporting the results of a paired-samples t-test, it is important to include the following information:\n\nThe test statistic (e.g.¬†t-value) and the associated p-value. The t-value tells us how many standard errors the mean difference is from zero, and the p-value tells us the probability of observing a t-value as extreme as the one we calculated under the assumption that the null hypothesis is true.\nThe sample size (e.g.¬†the number of pairs of observations).\nThe mean difference and the standard deviation of the differences.\nThe effect size, such as Cohen‚Äôs d, which is a measure of the magnitude of the difference between the means.\n\nExample:\n‚ÄúA paired-samples t-test was conducted to compare the pre-test and post-test scores of a group of students. The sample size was 20 pairs of observations. The mean difference between the pre-test and post-test scores was 5.3 (SD = 2.5). The t-value was 3.87, with a p-value of 0.001. The effect size (Cohen‚Äôs d) was 0.67, which indicates a moderate effect size.‚Äù\n‚ÄúThe results of the paired-samples t-test revealed that there was a statistically significant difference between the pre-test and post-test scores of the students, t(19) = 3.87, p = 0.001. The mean difference was 5.3 (95% CI [3.4, 7.2]), and the effect size (d = 0.67) suggests moderate effect size.‚Äù\n\n\n\n\n\n\nA one-way ANOVA (Analysis of Variance) is used to test for differences in the mean of a continuous outcome variable across two or more categorical groups. It is used when you have one independent variable (also known as a factor) with two or more levels or groups and one continuous dependent variable.\nIn other words, you should run a one-way ANOVA when:\n\nYou want to compare the means of a continuous outcome variable across two or more groups.\nYou have one independent variable (factor) with two or more levels or groups\nThe dependent variable is continuous\n\nExample: A researcher wants to know if there is a difference in the mean test scores of students who studied using different methods (Method A, Method B, Method C). The researcher collect data on test scores and the method used. The test scores are continuous variable and method of study is categorical variable with 3 levels. So, the researcher can use one-way ANOVA to test for the difference in mean test scores across different method of study.\n\n\n\nThe one-way ANOVA (analysis of variance) makes several assumptions about the data being analyzed:\n\nIndependence: The observations in each group are independent of each other and do not affect the observations in the other groups.\nNormality: The data within each group is normally distributed, or at least approximately normally distributed. This assumption can be checked using normality tests such as the Shapiro-Wilk test.\nEqual variances: The variances of the data within each group are equal. This assumption can be checked using tests such as the Levene‚Äôs test.\nRandom sampling: The data are randomly sampled from the population, so that the sample is representative of the population.\n\nViolations of these assumptions can lead to biased or incorrect results. If the assumptions are not met, non-parametric alternatives such as Kruskal-Wallis test could be used.\n\n\n\nWhen reporting the results of a one-way ANOVA, it is important to include the following information:\n\nThe F-value and the associated p-value. The F-value tells us how much variation in the dependent variable is accounted for by the independent variable, and the p-value tells us the probability of observing an F-value as extreme as the one we calculated under the assumption that the null hypothesis is true.\nThe sample size for each group, or the number of observations in each group.\nThe means and standard deviations for each group.\nThe effect size, such as eta-squared (Œ∑¬≤) or omega-squared (œâ¬≤), which is a measure of the proportion of variance in the dependent variable that is accounted for by the independent variable.\n\nExample:\n‚ÄúA one-way ANOVA was conducted to compare the scores of three groups of students on a test. The sample size for each group was 10, 10, and 12. The means and standard deviations for each group were: Group 1 = 80 (SD = 5), Group 2 = 75 (SD = 4), Group 3 = 70 (SD = 3). The F-value was 12.5, with a p-value of 0.001. The effect size (Œ∑¬≤) was 0.17, which indicates a moderate effect size.‚Äù\n‚ÄúThe results of the one-way ANOVA revealed that there was a statistically significant difference between the scores of the three groups of students, F(2, 28) = 12.5, p = 0.001. Post-hoc comparisons revealed that group 1 significantly different from group 2 (p = 0.05) and group 3 (p = 0.001). The mean scores for each group were: Group 1 = 80 (95% CI [78, 82]), Group 2 = 75 (95% CI [73, 77]), Group 3 = 70 (95% CI [69, 72]). The effect size (Œ∑¬≤ = 0.17) suggests that the independent variable accounted for a moderate proportion of variance in the dependent variable.‚Äù\n\n\n\n\n\n\nYou should run a Between-subjects Two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and the levels of these independent variables are different between groups of participants.\nAn example related to physical activity could be comparing the effect of two different types of exercise programs (e.g.¬†resistance training vs.¬†cardio) on muscle mass gain in two different age groups (e.g.¬†older adults vs.¬†younger adults). In this example, the independent variables would be the type of exercise program and the age group, and the dependent variable would be muscle mass gain. The levels of the independent variables would be different between groups of participants, as the older adults would be in one group and the younger adults would be in another. A Between-subjects Two-way ANOVA would allow you to test for any interactions between the two independent variables (i.e.¬†whether the effect of the exercise program on muscle mass gain is different in older adults vs.¬†younger adults) and any main effects of each independent variable on the dependent variable.\n\n\n\nThe assumptions of the between-subjects two-way ANOVA are as follows:\n\nIndependence: The observations in each group are independent of each other, meaning that the responses of one participant do not affect the responses of another participant.\nNormality: The distribution of the residuals (the difference between the observed and predicted values) is approximately normal. It is important to check the normality assumptions using normality test such as the Shapiro-Wilk test and check for outliers using box plots and histograms.\nEqual variances: The variances of the residuals are equal across all groups and levels of the independent variables. This assumption can be checked using Levene‚Äôs test for equality of variances.\nAdditivity: The effect of each independent variable on the dependent variable is additive, meaning that the effect of one independent variable does not depend on the level of the other independent variable.\nLinearity: The relationship between the independent variables and the dependent variable is linear, meaning that a straight line can be used to represent the relationship.\nIndependence of errors: the residuals are independent, meaning that the residuals of one observation are not correlated with the residuals of any other observation.\n\nIt‚Äôs important to note that when these assumptions are not met, the results of the ANOVA should be interpreted with caution and alternative methods of analysis should be considered.\n\n\n\nWhen reporting the results of a between-subjects Two-way ANOVA, you should include the following information:\n\nA description of the study design, including the independent variables, dependent variable, and the levels of each independent variable.\nThe results of the ANOVA, including the F-value, degrees of freedom, and p-value for each independent variable and any interaction between the two independent variables.\nA summary of the main findings, including any significant main effects or interactions between the independent variables.\nFollow-up tests, such as post-hoc tests, to determine which specific levels of the independent variables were responsible for the significant effects.\n\nExample:\n‚ÄúThe study aimed to examine the effect of two different types of physical education programs (e.g.¬†traditional vs.¬†adventure-based) on physical fitness in two different age groups (e.g.¬†younger children vs.¬†older children). A between-subjects Two-way ANOVA was conducted, with the independent variables being the type of program and the age group, and the dependent variable being physical fitness. The results of the ANOVA showed a significant main effect of the type of program, F (1, 48) = 8.32, p = 0.006, with the adventure-based program resulting in higher physical fitness scores than the traditional program. A significant interaction was also found between the type of program and the age group, F (1, 48) = 4.12, p = 0.047. Follow-up tests showed that the adventure-based program resulted in significantly higher physical fitness scores in older children compared to the traditional program, but there was no significant difference in younger children.‚Äù\n\n\n\n\nYou should run a Within-subjects Two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and the levels of these independent variables are the same for all participants, but are manipulated within each participant.\nAn example related to motor skill learning could be comparing the effect of two different types of feedback (e.g.¬†verbal vs.¬†visual) on the learning of a new motor skill (e.g.¬†throwing a ball) in a group of participants. In this example, the independent variables would be the type of feedback and the time of testing (e.g.¬†pre-test and post-test), and the dependent variable would be the accuracy of the throwing skill. The levels of the independent variables would be the same for all participants, as each participant would receive both types of feedback and be tested both before and after training. A Within-subjects Two-way ANOVA would allow you to test for any interactions between the two independent variables (i.e.¬†whether the effect of feedback on motor skill learning is different at the pre-test vs.¬†the post-test) and any main effects of each independent variable on the dependent variable.\n\n\nThe assumptions of the within-subjects two-way ANOVA (also known as a repeated-measures ANOVA) include:\n\nIndependence: The observations within each cell of the design must be independent of one another.\nNormality: The observations within each cell should be approximately normally distributed.\nEqual variances: The variances of the observations within each cell should be approximately equal.\nSphericity: The variances of the differences between the observations for each condition should be approximately equal across the levels of the other independent variable. This assumption is often tested using Mauchly‚Äôs test.\nNo carryover effects: There should be no carryover effects from one level of one independent variable to the next level of the same independent variable.\nNo missing data: There should be no missing data in the dataset.\n\nIt is important to note that when the assumptions of the within-subjects two-way ANOVA are not met, the results may not be reliable and alternative methods such as mixed-design ANOVA or non-parametric methods may be needed.\n\n\n\nWhen reporting the results of a within-subjects Two-way ANOVA, you should first indicate the dependent variable, the independent variables and the levels of each independent variable. You should then report the main effect of each independent variable on the dependent variable, as well as any interaction effects between the independent variables.\nFor example, if you were studying the effect of two different types of practice schedules (random vs.¬†blocked) and two different types of feedback (verbal vs.¬†visual) on motor skill learning, your report would look something like this:\nDependent variable: Motor skill learning Independent variables: Practice schedule (random vs.¬†blocked) and feedback (verbal vs.¬†visual)\nMain Effects:\n\nPractice schedule: There was a significant main effect of practice schedule on motor skill learning, F(1,24) = 7.32, p = .012, Œ∑p¬≤ = .234, such that participants who practiced in a random schedule showed better motor skill learning than those who practiced in a blocked schedule.\nFeedback: There was a significant main effect of feedback on motor skill learning, F(1,24) = 4.56, p = .045, Œ∑p¬≤ = .158, such that participants who received visual feedback showed better motor skill learning than those who received verbal feedback.\n\nInteraction Effects:\n\nThere was no significant interaction between practice schedule and feedback on motor skill learning, F(1,24) = .21, p = .65, Œ∑p¬≤ = .009.\n\nIt is worth noting that p values less than 0.05 would be considered statistically significant, and Œ∑p¬≤ indicates the effect size of the interaction effects.\nIt is also important to report the means and standard deviations of the dependent variable within each level of the independent variables. This will give a more detailed understanding of the pattern of results.\n\n\n\n\n\n\nYou should run a mixed-factors two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and one of the independent variables is a between-subjects variable and the other is a within-subjects variable.\nA mixed-factors two-way ANOVA is useful when you want to examine the effect of a manipulation that varies within subjects (e.g.¬†different levels of a treatment) while also taking into account individual differences among participants (e.g.¬†gender, age, etc.).\nAn example of when to run a mixed-factors two-way ANOVA would be if you wanted to investigate the effect of two different types of exercise programs (e.g.¬†resistance training vs.¬†cardio) on muscle mass gain in two different age groups (e.g.¬†older adults vs.¬†younger adults) but the program is applied to the same group of people. In this example, the independent variables would be the type of exercise program (between-subjects) and the age group (within-subjects) and the dependent variable would be muscle mass gain.\nA mixed-factors two-way ANOVA would allow you to test for any interactions between the two independent variables, and any main effects of each independent variable on the dependent variable, while also taking into account the individual differences among participants.\n\n\n\nThe assumptions of the mixed-factors two-way ANOVA (also known as a mixed-design two-way ANOVA) include:\n\nIndependence of observations: Each participant‚Äôs response should be independent of the responses of other participants.\nNormality: The residuals (the difference between the observed and predicted values) should be approximately normally distributed.\nEqual variances: The variances of the residuals should be equal across all levels of the independent variables.\nSphericity: The variances of the differences between the levels of the within-subjects variable should be equal.\nLinearity: The relationship between the independent and dependent variables should be linear.\nAdditivity: The effect of each independent variable should be additive, meaning that the effect of one variable should not depend on the level of the other variable.\n\nIt‚Äôs important to note that the violation of these assumptions can lead to inaccurate results, therefore, it‚Äôs important to check them by using various graphical methods, like box plots, histograms and Q-Q plots, and statistical methods like Shapiro-Wilk test, Levene‚Äôs test, and Mauchly‚Äôs test.\n\n\n\nWhen reporting the results of a mixed-factors Two-way ANOVA, you should include the following information:\n\nA description of the study design, including the independent variables, dependent variable, and the levels of each independent variable. Specify which variable is the within-subject variable and which one is the between-subject variable.\nThe results of the ANOVA, including the F-value, degrees of freedom, and p-value for each independent variable and any interaction between the two independent variables.\nA summary of the main findings, including any significant main effects or interactions between the independent variables.\nFollow-up tests, such as post-hoc tests, to determine which specific levels of the independent variables were responsible for the significant effects.\n\nExample:\n‚ÄúThe study aimed to examine the effect of two different types of motor development programs (e.g.¬†traditional vs.¬†adventure-based) on balance skills in two different age groups (e.g.¬†preschool children vs.¬†school-aged children). A mixed-factors Two-way ANOVA was conducted, with the independent variables being time (within-subject variable) and the age group (between-subject variable) and the dependent variable being balance skills. The results of the ANOVA showed a significant main effect of time, F (1, 48) = 8.32, p = 0.006, with post-test resulting in higher balance skills scores than pretest. A significant interaction was also found between time and the age group, F (1, 48) = 4.12, p = 0.047. Follow-up tests showed that post-test resulted in significantly higher balance skills scores in preschool children compared to pre-test, but there was no significant difference in school-aged children.‚Äù\nIt is important to note that in a mixed-factors ANOVA, the assumptions of normality and equal variances are tested at each level of the within-subject variable separately.\n\n\n\n\nThe Pearson correlation coefficient (r) is used to measure the strength and direction of the linear relationship between two continuous variables. It is appropriate to use when you want to determine if there is a linear relationship between two variables and the data are at least interval level. It is important to note that the Pearson correlation coefficient only measures linear relationships, and it is not appropriate to use if the relationship between the variables is non-linear.\nIt is generally considered appropriate to use the Pearson correlation coefficient when the following conditions are met:\n\nThe data for both variables is continuous (i.e., interval or ratio level).\nBoth variables are normally distributed or the sample size is large enough (n>30)\nThe variables are not categorical\nThe data are free from outliers\nThe relationship between the two variables is believed to be linear\n\nIt‚Äôs also worth noting that the Pearson correlation coefficient assumes that there is no causality between the two variables, it just measures the association between them. If you want to establish causality, you should use other statistical techniques such as regression analysis.\n\n\nWhen reporting the results of a Pearson correlation coefficient, it is important to include the following information:\n\nThe correlation coefficient (r) and the associated p-value. The correlation coefficient tells us the strength and direction of the linear relationship between two variables, and the p-value tells us the probability of observing a correlation coefficient as extreme as the one we calculated under the assumption that there is no correlation.\nThe sample size (e.g.¬†the number of observations)\nThe scatter plot of the data with the line of best fit and the equation of that line.\nThe effect size, such as Cohen‚Äôs d, which is a measure of the magnitude of the correlation.\n\nExample:\n‚ÄúA Pearson correlation coefficient was calculated to examine the relationship between hours of sleep and test scores of a group of students. The sample size was 30. The correlation coefficient was 0.75, with a p-value of 0.001. The scatter plot of the data with the line of best fit showing a positive correlation and equation of the line y = 0.5x+50 . The effect size (Cohen‚Äôs d) was 0.5, which indicates a moderate effect size.‚Äù\n‚ÄúThe results of the Pearson correlation coefficient revealed a statistically significant positive correlation between hours of sleep and test scores of the students (r(28) = 0.75, p = 0.001). The scatter plot of the data with the line of best fit y = 0.5x+50 illustrates the positive correlation. The effect size (d = 0.5) suggests a moderate correlation.‚Äù"
  },
  {
    "objectID": "supplemental/stats-tests.html#wilcoxon-signed-rank",
    "href": "supplemental/stats-tests.html#wilcoxon-signed-rank",
    "title": "Statistical Tests",
    "section": "Wilcoxon signed-rank",
    "text": "Wilcoxon signed-rank\nThe Wilcoxon signed-rank test is a non-parametric test used to determine whether two related samples have the same median. It is used when the data do not meet the assumptions of a parametric test such as the t-test, such as when the data are not normally distributed or the sample size is small. The Wilcoxon signed-rank test is a good alternative to the t-test for comparing two related samples.\nYou should run the Wilcoxon signed-rank test when:\n\nYou have two related samples (e.g.¬†pre-test and post-test scores for the same individuals)\nThe data are not normally distributed\nThe sample size is small\nYou want to compare the median of two related samples\n\nAn example of when you would use the Wilcoxon signed-rank test would be if you were studying the effectiveness of a new treatment for a medical condition, and you collected pre-treatment and post-treatment scores for a small group of patients. Since the sample size is small, and the distribution of scores is not normal, you would use the Wilcoxon signed-rank test to compare the median pre-treatment and post-treatment scores and determine if there was a significant difference between them.\n\nAssumptions\nIt is a robust test and doesn‚Äôt require the assumptions of normality, equal variances and large sample size that parametric tests like t-test require.\nThe Wilcoxon signed-rank test assumes the following:\n\nThe data are ordinal or continuous, not categorical.\nThe two samples being compared are related or dependent, meaning that the observations in one sample correspond to the observations in the other sample in some meaningful way.\nThe data are at least ordinal, it doesn‚Äôt assume normality.\nThe data are independent and randomly selected from the population.\nThe observations in the two samples should be continuous or ordinal, not categorical.\nThe data should be free of outliers, as they can have a large impact on the test results.\n\nIt is important to note that the Wilcoxon signed-rank test is a non-parametric test, so it is less powerful than a t-test and a parametric test. Therefore, it is advisable to use the Wilcoxon signed-rank test only when the assumptions of the t-test are not met.\n\n\nReporting Results\nWhen reporting the results of a Wilcoxon signed-rank test, you should include the following information:\n\nA description of the study design, including the dependent variable and the groups being compared.\nThe results of the test, including the test statistic (e.g.¬†W) and the p-value.\nA summary of the main findings, including whether the difference between the groups is statistically significant.\nThe effect size, such as Cohen‚Äôs d or r, to indicate the magnitude of the difference between the groups.\n\nExample:\n‚ÄúThe study aimed to examine the effect of a physical therapy intervention on pain levels in patients with knee osteoarthritis. A Wilcoxon signed-rank test was conducted to compare the pain levels before and after the intervention. The results of the test showed a significant decrease in pain levels after the intervention, W = 45, p = 0.03. The effect size was r = 0.5, indicating a moderate effect size. This suggests that the physical therapy intervention was effective in reducing pain levels in patients with knee osteoarthritis.‚Äù\nIt is important to note that the Wilcoxon signed-rank test is a non-parametric test that is used when the data are not normally distributed or the sample size is small. This test is used to compare two related samples or matched-pairs data."
  },
  {
    "objectID": "supplemental/stats-tests.html#mann-whitney-u-test",
    "href": "supplemental/stats-tests.html#mann-whitney-u-test",
    "title": "Statistical Tests",
    "section": "Mann-Whitney U test",
    "text": "Mann-Whitney U test\nThe Mann-Whitney U test is a non-parametric test that is used to compare two independent groups to determine whether there is a significant difference in the distribution of scores between the two groups. This test is used when the assumptions of a parametric test such as the independent t-test cannot be met. These assumptions include normality of the data and equal variances between groups.\n\n\nThe Mann-Whitney U test is equivalent to the Independent-Samples t-test.\nThe Mann-Whitney U test is particularly useful when the data are not normally distributed, when the sample size is small, or when the data have outliers. It is also used when the data are ordinal or non-normally distributed, and when the variances of the two groups are not equal.\nAn example of when to run the Mann-Whitney U test is when you want to compare the muscle mass gain of two groups of athletes, one group using a new supplement, and the other using a placebo. The muscle mass gain is measured in kilograms and the sample size is small(less than 30), thus, it would be appropriate to use the Mann-Whitney U test to determine if there is a significant difference in muscle mass gain between the two groups.\n\nAssumptions\nThe Mann-Whitney U test is a non-parametric test that is used to compare the medians of two independent groups. In order for the test to be valid, the following assumptions must be met:\n\nIndependence: The observations in each group must be independent of one another. This means that there should be no relationship between the observations within a group.\nOrdinal or continuous data: The data must be ordinal or continuous in nature. The Mann-Whitney U test cannot be used for categorical or discrete data.\nNo ties: There should be no ties in the data. Ties occur when two or more observations have the same value.\nNo outliers: The data should not contain outliers. Outliers are observations that are far away from the rest of the data and can have a strong impact on the results of the test.\nNo normal distribution: The data do not need to follow a normal distribution, which makes the test a good option when dealing with non-normal data.\nSame population : The two groups being compared should be sampled from the same population.\n\nIt is important to check for these assumptions before running the test and report the results accordingly.\n\n\nReporting results\nWhen reporting the results of a Mann-Whitney U test, you should include the following information:\n\nA brief description of the test and its purpose.\nThe test statistic (U) and the p-value.\nA statement about the outcome of the test, such as whether the null hypothesis was rejected or not.\nA summary of the main findings, such as the differences in the two groups being compared.\nA visual representation of the data, such as box plots or histograms, to help users understand the results.\n\nExample:\n‚ÄúMann-Whitney U Test\nPurpose: To compare the differences in physical activity levels between two groups of individuals (e.g.¬†active vs.¬†sedentary).\nTest statistic: U = 50\np-value: 0.03\nOutcome: The null hypothesis is rejected.\nFindings: The active group had significantly higher physical activity levels than the sedentary group.\nVisual representation: A box plot is shown to help the user understand the distribution of physical activity levels in the two groups. The active group has a higher median value and a smaller interquartile range than the sedentary group.‚Äù\nIt is important to note that the Mann-Whitney U test is a non-parametric test that is used to compare two independent samples when the data are not normally distributed. This test is also useful to compare two groups when the sample size is small."
  },
  {
    "objectID": "supplemental/stats-tests.html#spearman-rho-correlation-coefficient",
    "href": "supplemental/stats-tests.html#spearman-rho-correlation-coefficient",
    "title": "Statistical Tests",
    "section": "Spearman Rho Correlation Coefficient",
    "text": "Spearman Rho Correlation Coefficient\n\nWhen to use it?\nThe Spearman rank-order correlation coefficient (Spearman‚Äôs rho, or simply rho) is a nonparametric measure of the correlation between two variables. It is used when the assumptions of the Pearson correlation coefficient, such as normality of the data, are not met, or when the variables are ordinal or interval with non-linear relationship.\nSpearman‚Äôs rho should be used when your data are ordinal or interval and non-normally distributed. Or when you suspect that the relationship between the two variables is non-linear.\nIt‚Äôs also useful when your data have outliers or extreme values as it is less affected by them compared to Pearson correlation coefficient.\nIt‚Äôs also useful when you want to investigate the correlation between two ordinal variables, or when you want to investigate the correlation between an ordinal variable and an interval variable.\nKeep in mind that, Spearman‚Äôs rho assumes that the relationship between the two variables is monotonic, it does not test for linearity.\n\n\nReporting results\nWhen reporting the results of a Spearman‚Äôs rank correlation coefficient (rho), it is important to include the following information:\n\nThe correlation coefficient (rho) and the associated p-value. The correlation coefficient tells us the strength and direction of the monotonic relationship between two variables, and the p-value tells us the probability of observing a correlation coefficient as extreme as the one we calculated under the assumption that there is no correlation.\nThe sample size (e.g.¬†the number of observations)\nA scatter plot of the data with the line of best fit if possible\nThe effect size, such as Cohen‚Äôs d, which is a measure of the magnitude of the correlation.\n\nExample:\n‚ÄúA Spearman‚Äôs rank correlation coefficient was calculated to examine the relationship between blood pressure and weight of a group of patients. The sample size was 40. The correlation coefficient was 0.6, with a p-value of 0.001. The scatter plot of the data with the line of best fit showing a positive correlation. The effect size (Cohen‚Äôs d) was 0.3, which indicates a weak effect size.‚Äù\n‚ÄúThe results of the Spearman‚Äôs rank correlation coefficient revealed a statistically significant positive correlation between blood pressure and weight of the patients (rho(38) = 0.6, p = 0.001). The scatter plot of the data with the line of best fit illustrates the positive correlation. The effect size (d = 0.3) suggests a weak correlation.‚Äù\nIt‚Äôs important to note that when there is a non-parametric test like spearman correlation, it is better to report the median, percentiles and interquartile range of the variables instead of mean and standard deviation."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html",
    "href": "supplemental/model-diagnostics-matrix.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of the model diagnostics - leverage, standardized residuals, and Cook‚Äôs distance. We assume the reader knowledge of the matrix form for multiple linear regression. Please see Matrix Form of Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#introduction",
    "href": "supplemental/model-diagnostics-matrix.html#introduction",
    "title": "Model Diagnostics",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation¬†1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation¬†2.\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "href": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "title": "Model Diagnostics",
    "section": "Matrix Form for the Regression Model",
    "text": "Matrix Form for the Regression Model\nWe can represent the Equation¬†1 and Equation¬†2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "href": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "title": "Model Diagnostics",
    "section": "Hat Matrix & Leverage",
    "text": "Hat Matrix & Leverage\nRecall from the notes Matrix Form of Linear Regression that \\(\\hat{\\boldsymbol{\\beta}}\\) can be written as the following:\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\n\\tag{5}\\]\nCombining Equation¬†4 and Equation¬†5, we can write \\(\\hat{\\mathbf{Y}}\\) as the following:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{Y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n&= \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\\\\n\\end{aligned}\n\\tag{6}\\]\nWe define the hat matrix as an \\(n \\times n\\) matrix of the form \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\). Thus Equation¬†6 becomes\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{H}\\mathbf{Y}\n\\tag{7}\\]\nThe diagonal elements of the hat matrix are a measure of how far the predictor variables of each observation are from the means of the predictor variables. For example, \\(h_{ii}\\) is a measure of how far the values of the predictor variables for the \\(i^{th}\\) observation, \\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\), are from the mean values of the predictor variables, \\(\\bar{x}_1, \\bar{x}_2, \\ldots, \\bar{x}_p\\). In the case of simple linear regression, the \\(i^{th}\\) diagonal, \\(h_{ii}\\), can be written as\n\\[\nh_{ii} =  \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n}(x_j-\\bar{x})^2}\n\\]\nWe call these diagonal elements, the leverage of each observation.\nThe diagonal elements of the hat matrix have the following properties:\n\n\\(0 \\leq h_ii \\leq 1\\)\n\\(\\sum\\limits_{i=1}^{n} h_{ii} = p+1\\), where \\(p\\) is the number of predictor variables in the model.\nThe mean hat value is \\(\\bar{h} = \\frac{\\sum\\limits_{i=1}^{n} h_{ii}}{n} = \\frac{p+1}{n}\\).\n\nUsing these properties, we consider a point to have high leverage if it has a leverage value that is more than 2 times the average. In other words, observations with leverage greater than \\(\\frac{2(p+1)}{n}\\) are considered to be high leverage points, i.e.¬†outliers in the predictor variables. We are interested in flagging high leverage points, because they may have an influence on the regression coefficients.\nWhen there are high leverage points in the data, the regression line will tend towards those points; therefore, one property of high leverage points is that they tend to have small residuals. We will show this by rewriting the residuals from Equation¬†4 using Equation¬†7.\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{Y} - \\hat{\\mathbf{Y}} \\\\[10pt]\n& = \\mathbf{Y} - \\mathbf{H}\\mathbf{Y} \\\\[10pt]\n&= (1-\\mathbf{H})\\mathbf{Y}\n\\end{aligned}\n\\tag{8}\\]\nNote that the identity matrix and hat matrix are idempotent, i.e.¬†\\(\\mathbf{I}\\mathbf{I} = \\mathbf{I}\\), \\(\\mathbf{H}\\mathbf{H} = \\mathbf{H}\\). Thus, \\((\\mathbf{I} - \\mathbf{H})\\) is also idempotent. These matrices are also symmetric. Using these properties and Equation¬†8, we have that the variance-covariance matrix of the residuals \\(\\boldsymbol{e}\\), is\n\\[\n\\begin{aligned}\nVar(\\mathbf{e}) &= \\mathbf{e}\\mathbf{e}^T \\\\[10pt]\n&=  (1-\\mathbf{H})Var(\\mathbf{Y})^T(1-\\mathbf{H})^T \\\\[10pt]\n&= (1-\\mathbf{H})\\hat{\\sigma}^2(1-\\mathbf{H})^T  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})(1-\\mathbf{H})  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})\n\\end{aligned}\n\\tag{9}\\]\nwhere \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^{n}e_i^2}{n-p-1}\\) is the estimated regression variance. Thus, the variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\hat{\\sigma}^2(1-h_{ii})\\). Therefore, the higher the leverage, the smaller the variance of the residual. Because the expected value of the residuals is 0, we conclude that points with high leverage tend to have smaller residuals than points with lower leverage."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "href": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "title": "Model Diagnostics",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIn general, we standardize a value by shifting by the expected value and rescaling by the standard deviation (or standard error). Thus, the \\(i^{th}\\) standardized residual takes the form\n\\[\nstd.res_i = \\frac{e_i - E(e_i)}{SE(e_i)}\n\\]\nThe expected value of the residuals is 0, i.e.¬†\\(E(e_i) = 0\\). From Equation¬†9), the standard error of the residual is \\(SE(e_i) = \\hat{\\sigma}\\sqrt{1-h_{ii}}\\). Therefore,\n\\[\nstd.res_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}\n\\tag{10}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "href": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "title": "Model Diagnostics",
    "section": "Cook‚Äôs Distance",
    "text": "Cook‚Äôs Distance\nCook‚Äôs distance is a measure of how much each observation influences the model coefficients, and thus the predicted values. The Cook‚Äôs distance for the \\(i^{th}\\) observation can be written as\n\\[\nD_i = \\frac{(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})^T(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})}{(p+1)\\hat{\\sigma}}\n\\tag{11}\\]\nwhere \\(\\hat{\\mathbf{Y}}_{(i)}\\) is the vector of predicted values from the model fitted when the \\(i^{th}\\) observation is deleted. Cook‚Äôs Distance can be calculated without deleting observations one at a time, since Equation¬†12 below is mathematically equivalent to Equation¬†11.\n\\[\nD_i = \\frac{1}{p+1}std.res_i^2\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg] = \\frac{e_i^2}{(p+1)\\hat{\\sigma}^2(1-h_{ii})}\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg]\n\\tag{12}\\]"
  },
  {
    "objectID": "supplemental/log-transformations.html",
    "href": "supplemental/log-transformations.html",
    "title": "Log Transformations in Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides details about the model interpretation when the predictor and/or response variables are log-transformed. For simplicity, we will discuss transformations for the simple linear regression model as shown in Equation¬†1.\n\\[\n\\label{orig}\ny = \\beta_0 + \\beta_1 x\n\\tag{1}\\]\nAll results and interpretations can be easily extended to transformations in multiple regression models.\nNote: log refers to the natural logarithm."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the response variable",
    "text": "Log-transformation on the response variable\nSuppose we fit a linear regression model with \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(x\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 x, \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(x\\) and \\(\\log(y)\\) using the model in Equation¬†2.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 x\n\\tag{2}\\]\nIf we interpret the model in terms of \\(\\log(y)\\), then we can use the usual interpretations for slope and intercept. When reporting results, however, it is best to give all interpretations in terms of the original response variable \\(y\\), since interpretations using log-transformed variables are often more difficult to truly understand.\nIn order to get back on the original scale, we need to use the exponential function (also known as the anti-log), \\(\\exp\\{x\\} = e^x\\). Therefore, we use the model in Equation¬†2 for interpretations and predictions, we will use Equation¬†3 to state our conclusions in terms of \\(y\\).\n\\[\n\\begin{aligned}\n&\\exp\\{\\log(y)\\} = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\n\\end{aligned}\n\\tag{3}\\]\nIn order to interpret the slope and intercept, we need to first understand the relationship between the mean, median and log transformations.\n\nMean, Median, and Log Transformations\nSuppose we have a dataset y that contains the following observations:\n\n\n[1] 3 5 6 7 8\n\n\nIf we log-transform the values of y then calculate the mean and median, we have\n\n\n\n\n\nmean_log_y\nmedian_log_y\n\n\n\n\n1.70503\n1.79176\n\n\n\n\n\nIf we calculate the mean and median of y, then log-transform the mean and median, we have\n\n\n\n\n\nlog_mean\nlog_median\n\n\n\n\n1.75786\n1.79176\n\n\n\n\n\nThis is a simple illustration to show\n\n\\(\\text{Mean}[{\\log(y)}] \\neq \\log[\\text{Mean}(y)]\\) - the mean and log are not commutable\n\\(\\text{Median}[\\log(y)] = \\log[\\text{Median}(y)]\\) - the median and log are commutable\n\n\n\nInterpretaton of model coefficients\nUsing Equation¬†2, the mean \\(\\log(y)\\) for any given value of \\(x\\) is \\(\\beta_0 + \\beta_1 x\\); however, this does not indicate that the mean of \\(y = \\exp\\{\\beta_0 + \\beta_1 x\\}\\) (see previous section). From the assumptions of linear regression, we assume that for any given value of \\(x\\), the distribution of \\(\\log(y)\\) is Normal, and therefore symmetric. Thus the median of \\(\\log(y)\\) is equal to the mean of \\(\\log(y)\\), i.e \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x\\).\nSince the log and the median are commutable, \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x \\Rightarrow \\text{Median}(y) = \\exp\\{\\beta_0 + \\beta_1 x\\}\\). Thus, when we log-transform the response variable, the interpretation of the intercept and slope are in terms of the effect on the median of \\(y\\).\nIntercept: The intercept is expected median of \\(y\\) when the predictor variable equals 0. Therefore, when \\(x=0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x=0\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is the expected change in the median of \\(y\\) when \\(x\\) increases by 1 unit. The change in the median of \\(y\\) is\n\\[\n\\exp\\{[\\beta_0 + \\beta_1 (x+1)] - [\\beta_0 + \\beta_1 x]\\} = \\frac{\\exp\\{\\beta_0 + \\beta_1 (x+1)\\}}{\\exp\\{\\beta_0 + \\beta_1 x\\}} = \\frac{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\\exp\\{\\beta_1\\}}{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}} = \\exp\\{\\beta_1\\}\n\\]\nThus, the median of \\(y\\) for \\(x+1\\) is \\(\\exp\\{\\beta_1\\}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) increases by one unit, the median of \\(y\\) is expected to multiply by a factor of \\(\\exp\\{\\beta_1\\}\\)."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the predictor variable",
    "text": "Log-transformation on the predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(y\\), such that \\(y \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(y\\) using the model in #eq-log-x.\n\\[\ny = \\beta_0 + \\beta_1 \\log(x)\n\\tag{4}\\]\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e.¬†\\(x = 1\\).\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the mean of \\(y\\) is expected to be \\(\\beta_0\\).\nSlope: The slope is interpreted in terms of the change in the mean of \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the mean of \\(y\\) is\n\\[\n\\begin{aligned}\n[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)] &= \\beta_1 [\\log(Cx) - \\log(x)] \\\\[10pt]\n& = \\beta_1[\\log(C) + \\log(x) - \\log(x)] \\\\[10pt]\n& = \\beta_1 \\log(C)\n\\end{aligned}\n\\]\nThus the mean of \\(y\\) changes by \\(\\beta_1 \\log(C)\\) units.\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(C)\\) units. For example, if \\(x\\) is doubled, then the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(2)\\) units."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the the response and predictor variable",
    "text": "Log-transformation on the the response and predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable and \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(\\log(y)\\) using the model in Equation¬†5.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 \\log(x)\n\\tag{5}\\]\nBecause the response variable is log-transformed, the interpretations on the original scale will be in terms of the median of \\(y\\) (see the section on the log-transformed response variable for more detail).\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e.¬†\\(x = 1\\). Therefore, when \\(\\log(x) = 0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is interpreted in terms of the change in the median \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the median of \\(y\\) is\n\\[\n\\begin{aligned}\n\\exp\\{[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)]\\} &=\n\\exp\\{\\beta_1 [\\log(Cx) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1[\\log(C) + \\log(x) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1 \\log(C)\\} = C^{\\beta_1}\n\\end{aligned}\n\\]\nThus, the median of \\(y\\) for \\(Cx\\) is \\(C^{\\beta_1}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the median of \\(y\\) is expected to multiple by a factor of \\(C^{\\beta_1}\\). For example, if \\(x\\) is doubled, then the median of \\(y\\) is expected to multiply by \\(2^{\\beta_1}\\)."
  },
  {
    "objectID": "supplemental/tables.html",
    "href": "supplemental/tables.html",
    "title": "Statistical Tables",
    "section": "",
    "text": "The \\(z\\) table\nThe z-table is a statistical table that shows the values of the standard normal distribution. The standard normal distribution is a normal distribution with a mean of 0 and a standard deviation of 1.\n\n\n   z_value area_percent\n1     -3.0  0.001349898\n2     -2.9  0.001865813\n3     -2.8  0.002555130\n4     -2.7  0.003466974\n5     -2.6  0.004661188\n6     -2.5  0.006209665\n7     -2.4  0.008197536\n8     -2.3  0.010724110\n9     -2.2  0.013903448\n10    -2.1  0.017864421\n11    -2.0  0.022750132\n12    -1.9  0.028716560\n13    -1.8  0.035930319\n14    -1.7  0.044565463\n15    -1.6  0.054799292\n16    -1.5  0.066807201\n17    -1.4  0.080756659\n18    -1.3  0.096800485\n19    -1.2  0.115069670\n20    -1.1  0.135666061\n21    -1.0  0.158655254\n22    -0.9  0.184060125\n23    -0.8  0.211855399\n24    -0.7  0.241963652\n25    -0.6  0.274253118\n26    -0.5  0.308537539\n27    -0.4  0.344578258\n28    -0.3  0.382088578\n29    -0.2  0.420740291\n30    -0.1  0.460172163\n31     0.0  0.500000000\n32     0.1  0.539827837\n33     0.2  0.579259709\n34     0.3  0.617911422\n35     0.4  0.655421742\n36     0.5  0.691462461\n37     0.6  0.725746882\n38     0.7  0.758036348\n39     0.8  0.788144601\n40     0.9  0.815939875\n41     1.0  0.841344746\n42     1.1  0.864333939\n43     1.2  0.884930330\n44     1.3  0.903199515\n45     1.4  0.919243341\n46     1.5  0.933192799\n47     1.6  0.945200708\n48     1.7  0.955434537\n49     1.8  0.964069681\n50     1.9  0.971283440\n51     2.0  0.977249868\n52     2.1  0.982135579\n53     2.2  0.986096552\n54     2.3  0.989275890\n55     2.4  0.991802464\n56     2.5  0.993790335\n57     2.6  0.995338812\n58     2.7  0.996533026\n59     2.8  0.997444870\n60     2.9  0.998134187\n61     3.0  0.998650102\n\n\n\nlibrary(stats)\n\nf_table <- data.frame(df1=rep(1:30, each=30), df2=rep(1:30, 30), \n                      p=qf(seq(0.01, 0.99, 0.01), df1=rep(1:30, each=30), df2=rep(1:30, 30)))\n\nprint(f_table)\n\n    df1 df2            p\n1     1   1 2.467807e-04\n2     1   2 8.003201e-04\n3     1   3 1.666730e-03\n4     1   4 2.847820e-03\n5     1   5 4.344768e-03\n6     1   6 6.158721e-03\n7     1   7 8.290949e-03\n8     1   8 1.074289e-02\n9     1   9 1.351619e-02\n10    1  10 1.661268e-02\n11    1  11 2.003441e-02\n12    1  12 2.378365e-02\n13    1  13 2.786290e-02\n14    1  14 3.227486e-02\n15    1  15 3.702251e-02\n16    1  16 4.210904e-02\n17    1  17 4.753789e-02\n18    1  18 5.331278e-02\n19    1  19 5.943768e-02\n20    1  20 6.591684e-02\n21    1  21 7.275479e-02\n22    1  22 7.995635e-02\n23    1  23 8.752666e-02\n24    1  24 9.547119e-02\n25    1  25 1.037957e-01\n26    1  26 1.125064e-01\n27    1  27 1.216096e-01\n28    1  28 1.311124e-01\n29    1  29 1.410220e-01\n30    1  30 1.513461e-01\n31    2   1 5.501995e-01\n32    2   2 4.705882e-01\n33    2   3 4.590314e-01\n34    2   4 4.618298e-01\n35    2   5 4.701246e-01\n36    2   6 4.811916e-01\n37    2   7 4.939196e-01\n38    2   8 5.077733e-01\n39    2   9 5.224659e-01\n40    2  10 5.378317e-01\n41    2  11 5.537706e-01\n42    2  12 5.702201e-01\n43    2  13 5.871410e-01\n44    2  14 6.045090e-01\n45    2  15 6.223102e-01\n46    2  16 6.405377e-01\n47    2  17 6.591898e-01\n48    2  18 6.782691e-01\n49    2  19 6.977813e-01\n50    2  20 7.177346e-01\n51    2  21 7.381399e-01\n52    2  22 7.590099e-01\n53    2  23 7.803592e-01\n54    2  24 8.022045e-01\n55    2  25 8.245641e-01\n56    2  26 8.474584e-01\n57    2  27 8.709095e-01\n58    2  28 8.949415e-01\n59    2  29 9.195807e-01\n60    2  30 9.448557e-01\n61    3   1 3.103835e+00\n62    3   2 1.776235e+00\n63    3   3 1.517822e+00\n64    3   4 1.422547e+00\n65    3   5 1.381678e+00\n66    3   6 1.365706e+00\n67    3   7 1.363397e+00\n68    3   8 1.369572e+00\n69    3   9 1.381530e+00\n70    3  10 1.397742e+00\n71    3  11 1.417290e+00\n72    3  12 1.439607e+00\n73    3  13 1.464335e+00\n74    3  14 1.491255e+00\n75    3  15 1.520241e+00\n76    3  16 1.551235e+00\n77    3  17 1.584233e+00\n78    3  18 1.619273e+00\n79    3  19 1.656434e+00\n80    3  20 1.695833e+00\n81    3  21 1.737624e+00\n82    3  22 1.782007e+00\n83    3  23 1.829224e+00\n84    3  24 1.879580e+00\n85    3  25 1.933443e+00\n86    3  26 1.991271e+00\n87    3  27 2.053632e+00\n88    3  28 2.121236e+00\n89    3  29 2.194991e+00\n90    3  30 2.276071e+00\n91    4   1 6.902748e+01\n92    4   2 1.174479e+01\n93    4   3 7.068554e+00\n94    4   4 5.710646e+00\n95    4   5 5.192168e+00\n96    4   6 5.037634e+00\n97    4   7 5.127216e+00\n98    4   8 5.488919e+00\n99    4   9 6.422085e+00\n100   4  10 6.874789e-02\n101   4  11 1.005671e-01\n102   4  12 1.264667e-01\n103   4  13 1.493282e-01\n104   4  14 1.702607e-01\n105   4  15 1.898332e-01\n106   4  16 2.083852e-01\n107   4  17 2.261397e-01\n108   4  18 2.432533e-01\n109   4  19 2.598411e-01\n110   4  20 2.759913e-01\n111   4  21 2.917734e-01\n112   4  22 3.072433e-01\n113   4  23 3.224471e-01\n114   4  24 3.374236e-01\n115   4  25 3.522057e-01\n116   4  26 3.668215e-01\n117   4  27 3.812960e-01\n118   4  28 3.956509e-01\n119   4  29 4.099055e-01\n120   4  30 4.240774e-01\n121   5   1 5.091590e-01\n122   5   2 4.999058e-01\n123   5   3 5.129588e-01\n124   5   4 5.283505e-01\n125   5   5 5.438409e-01\n126   5   6 5.590668e-01\n127   5   7 5.740021e-01\n128   5   8 5.886885e-01\n129   5   9 6.031761e-01\n130   5  10 6.175103e-01\n131   5  11 6.317295e-01\n132   5  12 6.458658e-01\n133   5  13 6.599461e-01\n134   5  14 6.739933e-01\n135   5  15 6.880274e-01\n136   5  16 7.020657e-01\n137   5  17 7.161240e-01\n138   5  18 7.302164e-01\n139   5  19 7.443563e-01\n140   5  20 7.585559e-01\n141   5  21 7.728270e-01\n142   5  22 7.871810e-01\n143   5  23 8.016288e-01\n144   5  24 8.161813e-01\n145   5  25 8.308491e-01\n146   5  26 8.456430e-01\n147   5  27 8.605737e-01\n148   5  28 8.756523e-01\n149   5  29 8.908898e-01\n150   5  30 9.062976e-01\n151   6   1 2.142680e+00\n152   6   2 1.414313e+00\n153   6   3 1.258411e+00\n154   6   4 1.199063e+00\n155   6   5 1.172888e+00\n156   6   6 1.162038e+00\n157   6   7 1.159581e+00\n158   6   8 1.162277e+00\n159   6   9 1.168415e+00\n160   6  10 1.177012e+00\n161   6  11 1.187468e+00\n162   6  12 1.199398e+00\n163   6  13 1.212549e+00\n164   6  14 1.226750e+00\n165   6  15 1.241887e+00\n166   6  16 1.257883e+00\n167   6  17 1.274688e+00\n168   6  18 1.292274e+00\n169   6  19 1.310628e+00\n170   6  20 1.329752e+00\n171   6  21 1.349656e+00\n172   6  22 1.370364e+00\n173   6  23 1.391907e+00\n174   6  24 1.414327e+00\n175   6  25 1.437674e+00\n176   6  26 1.462011e+00\n177   6  27 1.487411e+00\n178   6  28 1.513961e+00\n179   6  29 1.541761e+00\n180   6  30 1.570932e+00\n181   7   1 1.791611e+01\n182   7   2 5.225245e+00\n183   7   3 3.602058e+00\n184   7   4 3.035693e+00\n185   7   5 2.768198e+00\n186   7   6 2.626216e+00\n187   7   7 2.549944e+00\n188   7   8 2.513765e+00\n189   7   9 2.505313e+00\n190   7  10 2.518389e+00\n191   7  11 2.550194e+00\n192   7  12 2.600247e+00\n193   7  13 2.670169e+00\n194   7  14 2.764199e+00\n195   7  15 2.890905e+00\n196   7  16 3.067892e+00\n197   7  17 3.337117e+00\n198   7  18 3.840639e+00\n199   7  19 1.617909e-01\n200   7  20 2.066421e-01\n201   7  21 2.400607e-01\n202   7  22 2.679894e-01\n203   7  23 2.925733e-01\n204   7  24 3.148643e-01\n205   7  25 3.354679e-01\n206   7  26 3.547695e-01\n207   7  27 3.730320e-01\n208   7  28 3.904446e-01\n209   7  29 4.071483e-01\n210   7  30 4.232523e-01\n211   8   1 3.511928e-01\n212   8   2 3.938170e-01\n213   8   3 4.279724e-01\n214   8   4 4.559084e-01\n215   8   5 4.798862e-01\n216   8   6 5.012053e-01\n217   8   7 5.206408e-01\n218   8   8 5.386830e-01\n219   8   9 5.556596e-01\n220   8  10 5.717991e-01\n221   8  11 5.872670e-01\n222   8  12 6.021872e-01\n223   8  13 6.166548e-01\n224   8  14 6.307444e-01\n225   8  15 6.445161e-01\n226   8  16 6.580191e-01\n227   8  17 6.712940e-01\n228   8  18 6.843754e-01\n229   8  19 6.972926e-01\n230   8  20 7.100712e-01\n231   8  21 7.227335e-01\n232   8  22 7.352994e-01\n233   8  23 7.477868e-01\n234   8  24 7.602116e-01\n235   8  25 7.725887e-01\n236   8  26 7.849315e-01\n237   8  27 7.972529e-01\n238   8  28 8.095646e-01\n239   8  29 8.218779e-01\n240   8  30 8.342035e-01\n241   9   1 1.464657e+00\n242   9   2 1.110321e+00\n243   9   3 1.034990e+00\n244   9   4 1.009445e+00\n245   9   5 1.000980e+00\n246   9   6 1.000284e+00\n247   9   7 1.003754e+00\n248   9   8 1.009726e+00\n249   9   9 1.017331e+00\n250   9  10 1.026078e+00\n251   9  11 1.035670e+00\n252   9  12 1.045921e+00\n253   9  13 1.056709e+00\n254   9  14 1.067954e+00\n255   9  15 1.079600e+00\n256   9  16 1.091611e+00\n257   9  17 1.103964e+00\n258   9  18 1.116645e+00\n259   9  19 1.129645e+00\n260   9  20 1.142963e+00\n261   9  21 1.156601e+00\n262   9  22 1.170565e+00\n263   9  23 1.184864e+00\n264   9  24 1.199510e+00\n265   9  25 1.214519e+00\n266   9  26 1.229907e+00\n267   9  27 1.245696e+00\n268   9  28 1.261910e+00\n269   9  29 1.278574e+00\n270   9  30 1.295719e+00\n271  10   1 7.937231e+00\n272  10   2 3.222103e+00\n273  10   3 2.444669e+00\n274  10   4 2.148218e+00\n275  10   5 1.999855e+00\n276  10   6 1.916225e+00\n277  10   7 1.866925e+00\n278  10   8 1.838298e+00\n279  10   9 1.823340e+00\n280  10  10 1.818130e+00\n281  10  11 1.820345e+00\n282  10  12 1.828563e+00\n283  10  13 1.841918e+00\n284  10  14 1.859914e+00\n285  10  15 1.882322e+00\n286  10  16 1.909135e+00\n287  10  17 1.940550e+00\n288  10  18 1.976980e+00\n289  10  19 2.019100e+00\n290  10  20 2.067933e+00\n291  10  21 2.125017e+00\n292  10  22 2.192699e+00\n293  10  23 2.274728e+00\n294  10  24 2.377526e+00\n295  10  25 2.513389e+00\n296  10  26 2.710532e+00\n297  10  27 3.061754e+00\n298  10  28 2.341947e-01\n299  10  29 2.830520e-01\n300  10  30 3.181824e-01\n301  11   1 1.844938e-01\n302  11   2 2.511113e-01\n303  11   3 3.000211e-01\n304  11   4 3.393016e-01\n305  11   5 3.724455e-01\n306  11   6 4.013234e-01\n307  11   7 4.270647e-01\n308  11   8 4.504066e-01\n309  11   9 4.718578e-01\n310  11  10 4.917846e-01\n311  11  11 5.104593e-01\n312  11  12 5.280899e-01\n313  11  13 5.448391e-01\n314  11  14 5.608365e-01\n315  11  15 5.761867e-01\n316  11  16 5.909760e-01\n317  11  17 6.052761e-01\n318  11  18 6.191470e-01\n319  11  19 6.326402e-01\n320  11  20 6.457996e-01\n321  11  21 6.586633e-01\n322  11  22 6.712644e-01\n323  11  23 6.836323e-01\n324  11  24 6.957928e-01\n325  11  25 7.077690e-01\n326  11  26 7.195817e-01\n327  11  27 7.312496e-01\n328  11  28 7.427898e-01\n329  11  29 7.542178e-01\n330  11  30 7.655479e-01\n331  12   1 1.012788e+00\n332  12   2 8.716379e-01\n333  12   3 8.509786e-01\n334  12   4 8.508789e-01\n335  12   5 8.570677e-01\n336  12   6 8.657150e-01\n337  12   7 8.754606e-01\n338  12   8 8.857381e-01\n339  12   9 8.962877e-01\n340  12  10 9.069830e-01\n341  12  11 9.177617e-01\n342  12  12 9.285933e-01\n343  12  13 9.394647e-01\n344  12  14 9.503723e-01\n345  12  15 9.613180e-01\n346  12  16 9.723068e-01\n347  12  17 9.833453e-01\n348  12  18 9.944418e-01\n349  12  19 1.005605e+00\n350  12  20 1.016844e+00\n351  12  21 1.028168e+00\n352  12  22 1.039588e+00\n353  12  23 1.051114e+00\n354  12  24 1.062756e+00\n355  12  25 1.074525e+00\n356  12  26 1.086434e+00\n357  12  27 1.098493e+00\n358  12  28 1.110716e+00\n359  12  29 1.123116e+00\n360  12  30 1.135706e+00\n361  13   1 4.361172e+00\n362  13   2 2.245281e+00\n363  13   3 1.834349e+00\n364  13   4 1.669849e+00\n365  13   5 1.585821e+00\n366  13   6 1.538024e+00\n367  13   7 1.509739e+00\n368  13   8 1.493265e+00\n369  13   9 1.484573e+00\n370  13  10 1.481358e+00\n371  13  11 1.482213e+00\n372  13  12 1.486241e+00\n373  13  13 1.492851e+00\n374  13  14 1.501646e+00\n375  13  15 1.512360e+00\n376  13  16 1.524819e+00\n377  13  17 1.538919e+00\n378  13  18 1.554605e+00\n379  13  19 1.571871e+00\n380  13  20 1.590749e+00\n381  13  21 1.611311e+00\n382  13  22 1.633671e+00\n383  13  23 1.657986e+00\n384  13  24 1.684470e+00\n385  13  25 1.713404e+00\n386  13  26 1.745158e+00\n387  13  27 1.780221e+00\n388  13  28 1.819250e+00\n389  13  29 1.863149e+00\n390  13  30 1.913200e+00\n391  14   1 1.702824e+02\n392  14   2 1.942438e+01\n393  14   3 1.023428e+01\n394  14   4 7.848463e+00\n395  14   5 7.155501e+00\n396  14   6 7.604897e+00\n397  14   7 2.337605e-01\n398  14   8 2.869820e-01\n399  14   9 3.271479e-01\n400  14  10 3.606293e-01\n401  14  11 3.897880e-01\n402  14  12 4.158364e-01\n403  14  13 4.395075e-01\n404  14  14 4.612897e-01\n405  14  15 4.815302e-01\n406  14  16 5.004868e-01\n407  14  17 5.183580e-01\n408  14  18 5.353002e-01\n409  14  19 5.514391e-01\n410  14  20 5.668779e-01\n411  14  21 5.817022e-01\n412  14  22 5.959839e-01\n413  14  23 6.097842e-01\n414  14  24 6.231553e-01\n415  14  25 6.361428e-01\n416  14  26 6.487862e-01\n417  14  27 6.611200e-01\n418  14  28 6.731751e-01\n419  14  29 6.849786e-01\n420  14  30 6.965549e-01\n421  15   1 6.982922e-01\n422  15   2 6.776778e-01\n423  15   3 6.933909e-01\n424  15   4 7.119283e-01\n425  15   5 7.297244e-01\n426  15   6 7.463400e-01\n427  15   7 7.618650e-01\n428  15   8 7.764714e-01\n429  15   9 7.903211e-01\n430  15  10 8.035491e-01\n431  15  11 8.162646e-01\n432  15  12 8.285554e-01\n433  15  13 8.404927e-01\n434  15  14 8.521348e-01\n435  15  15 8.635300e-01\n436  15  16 8.747185e-01\n437  15  17 8.857347e-01\n438  15  18 8.966079e-01\n439  15  19 9.073637e-01\n440  15  20 9.180244e-01\n441  15  21 9.286101e-01\n442  15  22 9.391387e-01\n443  15  23 9.496263e-01\n444  15  24 9.600880e-01\n445  15  25 9.705378e-01\n446  15  26 9.809885e-01\n447  15  27 9.914526e-01\n448  15  28 1.001942e+00\n449  15  29 1.012468e+00\n450  15  30 1.023042e+00\n451  16   1 2.681622e+00\n452  16   2 1.662933e+00\n453  16   3 1.444452e+00\n454  16   4 1.356139e+00\n455  16   5 1.311920e+00\n456  16   6 1.287861e+00\n457  16   7 1.274720e+00\n458  16   8 1.268193e+00\n459  16   9 1.266008e+00\n460  16  10 1.266858e+00\n461  16  11 1.269941e+00\n462  16  12 1.274742e+00\n463  16  13 1.280917e+00\n464  16  14 1.288231e+00\n465  16  15 1.296519e+00\n466  16  16 1.305667e+00\n467  16  17 1.315596e+00\n468  16  18 1.326252e+00\n469  16  19 1.337603e+00\n470  16  20 1.349629e+00\n471  16  21 1.362327e+00\n472  16  22 1.375703e+00\n473  16  23 1.389776e+00\n474  16  24 1.404573e+00\n475  16  25 1.420132e+00\n476  16  26 1.436504e+00\n477  16  27 1.453751e+00\n478  16  28 1.471948e+00\n479  16  29 1.491188e+00\n480  16  30 1.511583e+00\n481  17   1 2.712052e+01\n482  17   2 6.571644e+00\n483  17   3 4.236673e+00\n484  17   4 3.440831e+00\n485  17   5 3.062201e+00\n486  17   6 2.854986e+00\n487  17   7 2.736524e+00\n488  17   8 2.672213e+00\n489  17   9 2.646005e+00\n490  17  10 2.650786e+00\n491  17  11 2.685100e+00\n492  17  12 2.752919e+00\n493  17  13 2.866780e+00\n494  17  14 3.060261e+00\n495  17  15 3.452308e+00\n496  17  16 3.053600e-01\n497  17  17 3.561953e-01\n498  17  18 3.927636e-01\n499  17  19 4.226055e-01\n500  17  20 4.483593e-01\n501  17  21 4.713002e-01\n502  17  22 4.921574e-01\n503  17  23 5.113941e-01\n504  17  24 5.293267e-01\n505  17  25 5.461829e-01\n506  17  26 5.621336e-01\n507  17  27 5.773107e-01\n508  17  28 5.918193e-01\n509  17  29 6.057443e-01\n510  17  30 6.191556e-01\n511  18   1 4.655340e-01\n512  18   2 5.106141e-01\n513  18   3 5.500654e-01\n514  18   4 5.822687e-01\n515  18   5 6.093890e-01\n516  18   6 6.329213e-01\n517  18   7 6.538279e-01\n518  18   8 6.727467e-01\n519  18   9 6.901177e-01\n520  18  10 7.062554e-01\n521  18  11 7.213918e-01\n522  18  12 7.357025e-01\n523  18  13 7.493235e-01\n524  18  14 7.623621e-01\n525  18  15 7.749050e-01\n526  18  16 7.870225e-01\n527  18  17 7.987731e-01\n528  18  18 8.102059e-01\n529  18  19 8.213623e-01\n530  18  20 8.322779e-01\n531  18  21 8.429835e-01\n532  18  22 8.535061e-01\n533  18  23 8.638695e-01\n534  18  24 8.740946e-01\n535  18  25 8.842006e-01\n536  18  26 8.942044e-01\n537  18  27 9.041217e-01\n538  18  28 9.139667e-01\n539  18  29 9.237528e-01\n540  18  30 9.334922e-01\n541  19   1 1.758231e+00\n542  19   2 1.272529e+00\n543  19   3 1.166204e+00\n544  19   4 1.126133e+00\n545  19   5 1.108648e+00\n546  19   6 1.101380e+00\n547  19   7 1.099549e+00\n548  19   8 1.100945e+00\n549  19   9 1.104414e+00\n550  19  10 1.109302e+00\n551  19  11 1.115213e+00\n552  19  12 1.121898e+00\n553  19  13 1.129191e+00\n554  19  14 1.136982e+00\n555  19  15 1.145195e+00\n556  19  16 1.153779e+00\n557  19  17 1.162698e+00\n558  19  18 1.171928e+00\n559  19  19 1.181453e+00\n560  19  20 1.191265e+00\n561  19  21 1.201361e+00\n562  19  22 1.211742e+00\n563  19  23 1.222414e+00\n564  19  24 1.233385e+00\n565  19  25 1.244665e+00\n566  19  26 1.256271e+00\n567  19  27 1.268218e+00\n568  19  28 1.280529e+00\n569  19  29 1.293226e+00\n570  19  30 1.306339e+00\n571  20   1 1.042664e+01\n572  20   2 3.776288e+00\n573  20   3 2.750549e+00\n574  20   4 2.362625e+00\n575  20   5 2.165992e+00\n576  20   6 2.051799e+00\n577  20   7 1.980915e+00\n578  20   8 1.935921e+00\n579  20   9 1.907942e+00\n580  20  10 1.892036e+00\n581  20  11 1.885291e+00\n582  20  12 1.885952e+00\n583  20  13 1.892978e+00\n584  20  14 1.905820e+00\n585  20  15 1.924314e+00\n586  20  16 1.948641e+00\n587  20  17 1.979357e+00\n588  20  18 2.017495e+00\n589  20  19 2.064792e+00\n590  20  20 2.124155e+00\n591  20  21 2.200693e+00\n592  20  22 2.304322e+00\n593  20  23 2.458026e+00\n594  20  24 2.737997e+00\n595  20  25 3.516919e-01\n596  20  26 4.015074e-01\n597  20  27 4.365531e-01\n598  20  28 4.647858e-01\n599  20  29 4.889558e-01\n600  20  30 5.103762e-01\n601  21   1 2.743554e-01\n602  21   2 3.502136e-01\n603  21   3 4.048237e-01\n604  21   4 4.477589e-01\n605  21   5 4.833096e-01\n606  21   6 5.137625e-01\n607  21   7 5.404859e-01\n608  21   8 5.643666e-01\n609  21   9 5.860129e-01\n610  21  10 6.058607e-01\n611  21  11 6.242332e-01\n612  21  12 6.413767e-01\n613  21  13 6.574830e-01\n614  21  14 6.727047e-01\n615  21  15 6.871649e-01\n616  21  16 7.009647e-01\n617  21  17 7.141876e-01\n618  21  18 7.269041e-01\n619  21  19 7.391735e-01\n620  21  20 7.510469e-01\n621  21  21 7.625681e-01\n622  21  22 7.737753e-01\n623  21  23 7.847019e-01\n624  21  24 7.953774e-01\n625  21  25 8.058278e-01\n626  21  26 8.160766e-01\n627  21  27 8.261446e-01\n628  21  28 8.360507e-01\n629  21  29 8.458122e-01\n630  21  30 8.554446e-01\n631  22   1 1.193851e+00\n632  22   2 9.887137e-01\n633  22   3 9.518077e-01\n634  22   4 9.440411e-01\n635  22   5 9.454889e-01\n636  22   6 9.506882e-01\n637  22   7 9.576423e-01\n638  22   8 9.654898e-01\n639  22   9 9.738181e-01\n640  22  10 9.824155e-01\n641  22  11 9.911685e-01\n642  22  12 1.000015e+00\n643  22  13 1.008922e+00\n644  22  14 1.017873e+00\n645  22  15 1.026859e+00\n646  22  16 1.035880e+00\n647  22  17 1.044938e+00\n648  22  18 1.054037e+00\n649  22  19 1.063184e+00\n650  22  20 1.072386e+00\n651  22  21 1.081652e+00\n652  22  22 1.090989e+00\n653  22  23 1.100408e+00\n654  22  24 1.109917e+00\n655  22  25 1.119528e+00\n656  22  26 1.129251e+00\n657  22  27 1.139097e+00\n658  22  28 1.149078e+00\n659  22  29 1.159207e+00\n660  22  30 1.169497e+00\n661  23   1 5.366535e+00\n662  23   2 2.549706e+00\n663  23   3 2.024456e+00\n664  23   4 1.813931e+00\n665  23   5 1.704374e+00\n666  23   6 1.639855e+00\n667  23   7 1.599437e+00\n668  23   8 1.573534e+00\n669  23   9 1.557146e+00\n670  23  10 1.547418e+00\n671  23  11 1.542610e+00\n672  23  12 1.541614e+00\n673  23  13 1.543697e+00\n674  23  14 1.548369e+00\n675  23  15 1.555302e+00\n676  23  16 1.564284e+00\n677  23  17 1.575187e+00\n678  23  18 1.587955e+00\n679  23  19 1.602589e+00\n680  23  20 1.619150e+00\n681  23  21 1.637756e+00\n682  23  22 1.658592e+00\n683  23  23 1.681924e+00\n684  23  24 1.708123e+00\n685  23  25 1.737701e+00\n686  23  26 1.771379e+00\n687  23  27 1.810193e+00\n688  23  28 1.855686e+00\n689  23  29 1.910287e+00\n690  23  30 1.978122e+00\n691  24   1 6.924281e+02\n692  24   2 4.945666e+01\n693  24   3 2.659752e+01\n694  24   4 2.370542e-01\n695  24   5 3.001909e-01\n696  24   6 3.490371e-01\n697  24   7 3.896563e-01\n698  24   8 4.246138e-01\n699  24   9 4.553636e-01\n700  24  10 4.828454e-01\n701  24  11 5.077130e-01\n702  24  12 5.304433e-01\n703  24  13 5.513968e-01\n704  24  14 5.708526e-01\n705  24  15 5.890316e-01\n706  24  16 6.061118e-01\n707  24  17 6.222382e-01\n708  24  18 6.375310e-01\n709  24  19 6.520907e-01\n710  24  20 6.660020e-01\n711  24  21 6.793372e-01\n712  24  22 6.921581e-01\n713  24  23 7.045186e-01\n714  24  24 7.164651e-01\n715  24  25 7.280387e-01\n716  24  26 7.392754e-01\n717  24  27 7.502071e-01\n718  24  28 7.608622e-01\n719  24  29 7.712662e-01\n720  24  30 7.814420e-01\n721  25   1 8.200968e-01\n722  25   2 7.684965e-01\n723  25   3 7.759285e-01\n724  25   4 7.905547e-01\n725  25   5 8.059323e-01\n726  25   6 8.207704e-01\n727  25   7 8.348258e-01\n728  25   8 8.481181e-01\n729  25   9 8.607320e-01\n730  25  10 8.727606e-01\n731  25  11 8.842897e-01\n732  25  12 8.953933e-01\n733  25  13 9.061346e-01\n734  25  14 9.165673e-01\n735  25  15 9.267366e-01\n736  25  16 9.366815e-01\n737  25  17 9.464355e-01\n738  25  18 9.560276e-01\n739  25  19 9.654834e-01\n740  25  20 9.748253e-01\n741  25  21 9.840735e-01\n742  25  22 9.932462e-01\n743  25  23 1.002360e+00\n744  25  24 1.011430e+00\n745  25  25 1.020470e+00\n746  25  26 1.029494e+00\n747  25  27 1.038513e+00\n748  25  28 1.047541e+00\n749  25  29 1.056589e+00\n750  25  30 1.065667e+00\n751  26   1 3.184158e+00\n752  26   2 1.857056e+00\n753  26   3 1.578177e+00\n754  26   4 1.463848e+00\n755  26   5 1.404665e+00\n756  26   6 1.370572e+00\n757  26   7 1.350029e+00\n758  26   8 1.337671e+00\n759  26   9 1.330670e+00\n760  26  10 1.327399e+00\n761  26  11 1.326859e+00\n762  26  12 1.328406e+00\n763  26  13 1.331608e+00\n764  26  14 1.336170e+00\n765  26  15 1.341885e+00\n766  26  16 1.348608e+00\n767  26  17 1.356236e+00\n768  26  18 1.364701e+00\n769  26  19 1.373957e+00\n770  26  20 1.383979e+00\n771  26  21 1.394761e+00\n772  26  22 1.406309e+00\n773  26  23 1.418644e+00\n774  26  24 1.431802e+00\n775  26  25 1.445831e+00\n776  26  26 1.460799e+00\n777  26  27 1.476788e+00\n778  26  28 1.493906e+00\n779  26  29 1.512285e+00\n780  26  30 1.532093e+00\n781  27   1 4.305230e+01\n782  27   2 8.544216e+00\n783  27   3 5.171797e+00\n784  27   4 4.077014e+00\n785  27   5 3.571090e+00\n786  27   6 3.302916e+00\n787  27   7 3.159095e+00\n788  27   8 3.095428e+00\n789  27   9 3.096267e+00\n790  27  10 3.165110e+00\n791  27  11 3.333982e+00\n792  27  12 3.736435e+00\n793  27  13 3.482515e-01\n794  27  14 4.003084e-01\n795  27  15 4.380686e-01\n796  27  16 4.689518e-01\n797  27  17 4.955723e-01\n798  27  18 5.192082e-01\n799  27  19 5.406004e-01\n800  27  20 5.602260e-01\n801  27  21 5.784155e-01\n802  27  22 5.954095e-01\n803  27  23 6.113908e-01\n804  27  24 6.265019e-01\n805  27  25 6.408570e-01\n806  27  26 6.545494e-01\n807  27  27 6.676563e-01\n808  27  28 6.802428e-01\n809  27  29 6.923640e-01\n810  27  30 7.040676e-01\n811  28   1 5.542825e-01\n812  28   2 5.863048e-01\n813  28   3 6.222192e-01\n814  28   4 6.527268e-01\n815  28   5 6.787421e-01\n816  28   6 7.013957e-01\n817  28   7 7.215124e-01\n818  28   8 7.396706e-01\n819  28   9 7.562827e-01\n820  28  10 7.716499e-01\n821  28  11 7.859977e-01\n822  28  12 7.994991e-01\n823  28  13 8.122893e-01\n824  28  14 8.244761e-01\n825  28  15 8.361465e-01\n826  28  16 8.473722e-01\n827  28  17 8.582124e-01\n828  28  18 8.687174e-01\n829  28  19 8.789295e-01\n830  28  20 8.888853e-01\n831  28  21 8.986165e-01\n832  28  22 9.081508e-01\n833  28  23 9.175126e-01\n834  28  24 9.267236e-01\n835  28  25 9.358032e-01\n836  28  26 9.447692e-01\n837  28  27 9.536373e-01\n838  28  28 9.624223e-01\n839  28  29 9.711378e-01\n840  28  30 9.797963e-01\n841  29   1 2.045513e+00\n842  29   2 1.408487e+00\n843  29   3 1.267765e+00\n844  29   4 1.212027e+00\n845  29   5 1.185253e+00\n846  29   6 1.171634e+00\n847  29   7 1.165051e+00\n848  29   8 1.162661e+00\n849  29   9 1.162974e+00\n850  29  10 1.165137e+00\n851  29  11 1.168633e+00\n852  29  12 1.173131e+00\n853  29  13 1.178411e+00\n854  29  14 1.184324e+00\n855  29  15 1.190767e+00\n856  29  16 1.197667e+00\n857  29  17 1.204973e+00\n858  29  18 1.212650e+00\n859  29  19 1.220673e+00\n860  29  20 1.229027e+00\n861  29  21 1.237705e+00\n862  29  22 1.246704e+00\n863  29  23 1.256027e+00\n864  29  24 1.265681e+00\n865  29  25 1.275678e+00\n866  29  26 1.286031e+00\n867  29  27 1.296761e+00\n868  29  28 1.307891e+00\n869  29  29 1.319449e+00\n870  29  30 1.331468e+00\n871  30   1 1.385050e+01\n872  30   2 4.448169e+00\n873  30   3 3.113835e+00\n874  30   4 2.620683e+00\n875  30   5 2.372444e+00\n876  30   6 2.228125e+00\n877  30   7 2.137929e+00\n878  30   8 2.079964e+00\n879  30   9 2.043205e+00\n880  30  10 2.021604e+00\n881  30  11 2.011693e+00\n882  30  12 2.011492e+00\n883  30  13 2.020000e+00\n884  30  14 2.036960e+00\n885  30  15 2.062826e+00\n886  30  16 2.098892e+00\n887  30  17 2.147708e+00\n888  30  18 2.214068e+00\n889  30  19 2.307574e+00\n890  30  20 2.450868e+00\n891  30  21 2.719955e+00\n892  30  22 3.991164e-01\n893  30  23 4.483312e-01\n894  30  24 4.830048e-01\n895  30  25 5.109395e-01\n896  30  26 5.348283e-01\n897  30  27 5.559591e-01\n898  30  28 5.750608e-01\n899  30  29 5.925923e-01\n900  30  30 6.088646e-01\n\n\n\nx <- seq(-3, 3, 0.01)\ncurve(dnorm(x, mean=0, sd=1), from=-3, to=3, xlab=\"x\", ylab=\"Probability Density\")"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html",
    "href": "supplemental/model-selection-criteria.html",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of Akaike‚Äôs Information Criterion (AIC) and Schwarz‚Äôs Bayesian Information Criterion (BIC). We assume the reader knowledge of the matrix form for multiple linear regression.Please see Matrix Notation for Multiple Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "href": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)",
    "text": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)\nTo understand the formulas for AIC and BIC, we will first briefly explain the likelihood function and maximum likelihood estimates for regression.\nLet \\(\\mathbf{Y}\\) be \\(n \\times 1\\) matrix of responses, \\(\\mathbf{X}\\), the \\(n \\times (p+1)\\) matrix of predictors, and \\(\\boldsymbol{\\beta}\\), \\((p+1) \\times 1\\) matrix of coefficients. If the multiple linear regression model is correct then,\n\\[\n\\mathbf{Y} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2)\n\\tag{1}\\]\nWhen we do linear regression, our goal is to estimate the unknown parameters \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) from Equation¬†1. In Matrix Notation for Multiple Linear Regression, we showed a way to estimate these parameters using matrix alegbra. Another approach for estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is using maximum likelihood estimation.\nA likelihood function is used to summarise the evidence from the data in support of each possible value of a model parameter. Using Equation¬†1, we will write the likelihood function for linear regression as\n\\[\nL(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) = \\prod\\limits_{i=1}^n (2\\pi \\sigma^2)^{-\\frac{1}{2}} \\exp\\bigg\\{-\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})\\bigg\\}\n\\tag{2}\\]\nwhere \\(Y_i\\) is the \\(i^{th}\\) response and \\(\\mathbf{X}_i\\) is the vector of predictors for the \\(i^{th}\\) observation. One approach estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is to find the values of those parameters that maximize the likelihood in Equation¬†2, i.e.¬†maximum likelhood estimation. To make the calculations more manageable, instead of maximizing the likelihood function, we will instead maximize its logarithm, i.e.¬†the log-likelihood function. The values of the parameters that maximize the log-likelihood function are those that maximize the likelihood function. The log-likelihood function we will maximize is\n\\[\n\\begin{aligned}\n\\log L(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) &= \\sum\\limits_{i=1}^n -\\frac{1}{2}\\log(2\\pi\\sigma^2) -\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta}) \\\\\n&= -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\\\\n\\end{aligned}\n\\tag{3}\\]\n\nThe maximum likelihood estimate of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) are \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\hspace{10mm} \\hat{\\sigma}^2 = \\frac{1}{n}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta}) = \\frac{1}{n}RSS\n\\tag{4}\\]\nwhere \\(RSS\\) is the residual sum of squares. Note that the maximum likelihood estimate is not exactly equal to the estimate of \\(\\sigma^2\\) we typically use \\(\\frac{RSS}{n-p-1}\\). This is because the maximum likelihood estimate of \\(\\sigma^2\\) in Equation¬†4 is a biased estimator of \\(\\sigma^2\\). When \\(n\\) is much larger than the number of predictors \\(p\\), then the differences in these two estimates are trivial."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#aic",
    "href": "supplemental/model-selection-criteria.html#aic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "AIC",
    "text": "AIC\nAkaike‚Äôs Information Criterion (AIC) is\n\\[\nAIC = -2 \\log L + 2(p+1)\n\\tag{5}\\]\nwhere \\(\\log L\\) is the log-likelihood. This is the general form of AIC that can be applied to a variety of models, but for now, let‚Äôs focus on AIC for mutliple linear regression.\n\\[\n\\begin{aligned}\nAIC &= -2 \\log L + 2(p+1) \\\\\n&= -2\\bigg[-\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\bigg] + 2(p+1) \\\\\n&= n\\log\\big(2\\pi\\frac{RSS}{n}\\big) + \\frac{1}{RSS/n}RSS \\\\\n&= n\\log(2\\pi) + n\\log(RSS) - n\\log(n) + 2(p+1)\n\\end{aligned}\n\\tag{6}\\]"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#bic",
    "href": "supplemental/model-selection-criteria.html#bic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "BIC",
    "text": "BIC\n[To be added.]"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Do I have to use jamovi for the statistical analyses that would be demonstrated in this course? How about SPSS?\n\n\nThis course will involve statistical analyses done with jamovi (The jamovi project 2022) , a free, open source statistical package based on R (R Core Team 2017). To supplement the course, I will provide links to several resources that cover SPSS (SPSS Inc. 2008), including written and video tutorials. If you learn jamovi, you will be able to transfer your skills to other statistical programs. Jamovi also has a lot of resources available such as guides, manuals, and tutorials.\n\n\n\n\n\nReferences\n\nR Core Team. 2017. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. http://www.R-project.org/.\n\n\nSPSS Inc. 2008. SPSS Statistics for Windows. Chicago, IL: SPSS Inc.\n\n\nThe jamovi project. 2022. Jamovi. Syndey, Australia. https://www.jamovi.org."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "CSUN aims to make all learning experiences as accessible as possible, and has a variety of resources available to help support students. If you believe the design of this course poses barriers to effectively participate or demonstrate your learning, please contact me to discuss possible options and adjustments.\n\nThe IT Help Center (818)677-1400, helpcenter@csun.edu is available to help with Canvas, CSUN e-mail, SOLAR/Portal, and other technical issues.\nCSUN Device Loaner Program (https://bit.ly/3t1G0An) provides devices that can be checked out that includes laptops, webcams, hotspots and headsets\nThe Learning Resource Center (818) 677-2033 The mission of the LRC is to enable students to improve their academic performance through a variety of learning programs, including workshops, one-on-one and group tutoring, supplemental instruction classes and interactive subject area computer programs and videos. Student who use the LRC learning programs will develop and strengthen their critical thinking skills, study strategies, writing skills and performance in subject matter courses.\nUniversity Counseling Services (818) 677-2366, Bayramian Hall 520. UCS provides resources and information to assist students in dealing with a variety of large and small psychological obstacles that may interfere with academic progress and/or relationship satisfaction. Services include individual, group, and crisis counseling.\nIn accordance with the CSUN Accessibility Policy (https://bit.ly/3yqGHE9), CSUN is working to ensure that campus communication and course materials are accessible to everyone. Please reach out to me if you have difficulty with any of the materials for this course.\nIf you have a disability and need accommodations, please register with the Disability Resources and Educational Services (DRES) office or the National Center on Deafness (NCOD).\n\nThe DRES office can be reached at (818) 677-2684.\nNCOD can be reached at (818) 677-2611.\nReasonable accommodations and services will be provided to students if requests are made in a timely manner and with appropriate documentation\nIf you would like to discuss your need for accommodations with me, please drop in office hours or contact me to set up an appointment.\n\nFood Pantry (https://bit.ly/38nTsVH) at CSUN: Anybody who faces challenges securing food or housing and believes this impacts course performance, should contact CSUN‚Äôs Food Pantry website and the corresponding contacts. If you also feel comfortable contacting me, the department chair, or the Dean‚Äôs Office, we can also facilitate assistance. You don‚Äôt have to be alone in this moment.\nEmergency MataCare grants (https://bit.ly/2WAZkIz), one-time grants to prevent evictions, urgent child care issues, etc. - DACA (Deferred Action for Childhood Arrivals) Resources: Check out the Central American Resource Center facebook page (https://bit.ly/2Yg0p9z), legal resources listed on CSUN‚Äôs Educational Opportunity Program (EOP) Dream Center that was created to support all undocumented students & allies (Dream Center flyer). CSUN President Harrison issued a support statement on the CSUN homepage for DACA and resources.\nHelp lines (https://bit.ly/3sYbMOo)(after hours when the University Counseling is closed) for numerous topics/needs (e.g., suicide, drug, rape, LGBQT, military, or any crisis). You don‚Äôt have to manage these feelings alone.\nPride Center (https://bit.ly/3jqNZUi) offers support and resources to lesbian, gay, bisexual, transgender, queer, & questioning students, faculty, & staff.\nKlotz Student Health Center (https://bit.ly/3zx1Y0s): Numerous health services including primary care, dental, nutritional counseling, acupuncture, massage and lots more.\nCareer Center (https://bit.ly/3jtTcL2) for resume writing & interviewing and much more; Matty‚Äôs Closet (https://bit.ly/3jAResx) has free professional clothes for students who need interview or professional attire.\nUSU 9https://bit.ly/38uz59j) for more student services; Clubs & Organizations (https://bit.ly/38tBhOa): Hopefully a dozen people have already advised you to ‚Äúget involved‚Äù (https://bit.ly/3ysqYVb) at CSUN in something that interests you.\nAssociated Students (https://bit.ly/3yuWjGT) offers recycling, and a Children‚Äôs Center providing child care\nFinancial Aid & Scholarships (https://bit.ly/3sYFzqr) offers aid for applications\nUniversity Library https://bit.ly/3yuIEQ9) for many additional academic resources\nVeterans Resource Center (https://bit.ly/38qYtg7) assists CSUN students as they transition from military service to academic success.\n\nTitle 5, California Code of Regulations,¬ß 41301. Standards for Student Conduct ‚Äì (a) Campus Community Values: The university is committed to maintaining a safe and healthy living and learning environment for students, faculty, and staff. Each member of the campus community should choose behaviors that contribute toward this end. Students are expected to be good citizens and to engage in responsible behaviors that reflect well upon their university, to be civil to one another and to others in the campus community, and contribute positively to student and university life.\nCSUN with A HEART If you are facing challenges related to food insecurity, housing precarity/homelessness, mental health, access to technology, eldercare/childcare, or healthcare, you can find guidance, help, and resources from CSUN with A HEART (https://www.csun.edu/heart).\n\n\nAs a professor, I am committed to providing students with the highest quality of education and support. To this end, I will be offering weekly office hours every Thursday from 2-4 pm or by appointment via Zoom. Additionally, I am readily available to answer questions and provide guidance via email.\nA lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class."
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Exam 1 will be released on Friday, Feb 4 at 9 am ET and must be completed by Mon, Feb 7 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes. This portion may only be submitted one time. Go here to complete Part 1 of the exam.\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope (like a usual lab and homework). Go to the GitHub organization for the course and find the exam-1- repo to complete Part 3 of your exam. Add your answers to the exam-1.qmd file in your repo.\n\nBoth portions must be completed and submitted by Mon, Feb 7 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ\n\n\n\nBy taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nThis is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor or the head TA (Rick Presman) on Slack or post on Sakai Conversations for ‚ÄúInstructors in this site‚Äù only or attend my office hours (Monday, 10:30 am - 11:30 am).\n\n\n\n\n\nPart 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "exams/exam-3.html",
    "href": "exams/exam-3.html",
    "title": "Exam 2",
    "section": "",
    "text": "Exam 3 is released on Friday, April 15 at 9 am ET and must be completed by Mon, April 18 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes.\n\nGo here to complete Part 1 of the exam.\nThis portion is comprised of 10 multiple choice / fill in the blank questions may only be submitted one time, so start it when you can set aside ~30 minutes to work on it. You will likely be done quicker but it‚Äôs best to set aside ample time.\n\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope, like a usual lab and homework.\n\nGo to the GitHub organization for the course and find the exam-3- repo to complete Part 2 of your exam.\nAdd your answers to the exam-3.qmd file in your repo.\nYou can work on this portion at your own pace and come back to it however many times you like until the deadline. I recommend setting aside ~2 hours. You will likely be done quicker, but it‚Äôs best to set aside ample time.\n\n\nBoth portions must be completed and submitted by Mon, April 18 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ\n\n\n\nBy taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nThis is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor on Slack or email or request an appointment to meet on Zoom.\n\n\n\n\n\nPart 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "exams/exam-2.html",
    "href": "exams/exam-2.html",
    "title": "Exam 2",
    "section": "",
    "text": "Exam 1 will be released on Friday, Feb 25 at 9 am ET and must be completed by Mon, Feb 28 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes. This portion may only be submitted one time. Go here to complete Part 1 of the exam.\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope (like a usual lab and homework). Go to the GitHub organization for the course and find the exam-2- repo to complete Part 2 of your exam. Add your answers to the exam-2.qmd file in your repo.\n\nBoth portions must be completed and submitted by Mon, Feb 28 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ\n\n\n\nBy taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nThis is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor or the head TA (Rick Presman) on Slack or post on Sakai Conversations for ‚ÄúInstructors in this site‚Äù only or attend my office hours (Monday, 10:30 am - 11:30 am).\n\n\n\n\n\nPart 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group‚Äôs interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team‚Äôs project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you‚Äôre interested in potentially using for the final project. If you‚Äôre unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you‚Äôre interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as ‚Äúname‚Äù, ‚Äúsocial security number‚Äù, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g.¬†‚Äústate abbreviation‚Äù and ‚Äústate name‚Äù), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you‚Äôre unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you‚Äôre interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you‚Äôre investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others‚Äô work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams‚Äôs projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams‚Äô GitHub repos. Provide your review in the form of GitHub issues to your partner team‚Äôs GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team‚Äôs report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team‚Äôs project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team‚Äôs repo.\nOpen the repo of the team you‚Äôre reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model‚Äôs predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you‚Äôll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the ‚Äú+‚Äù and select ‚ÄúUpload files‚Äù.\nLocate the video on your computer and click to upload.\nOnce you‚Äôve uploaded the video to Warpwire, click to share the video and copy the video‚Äôs URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick ‚ÄúStart a new conversation‚Äù.\nMake the title ‚ÄúYour Team Name: Project Title‚Äù. For example, ‚ÄúTeaching Team: Our Awesome Presentation‚Äù.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click ‚ÄúInsert 1 item.‚Äù This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou‚Äôre done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group‚Äôs video, then click ‚ÄúReply‚Äù to post a question for the group. You may not post a question that‚Äôs already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e.¬†it shouldn‚Äôt be ‚ÄúWhy did you use a bar plot instead of a pie chart‚Äù?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group‚Äôs specific presentation, i.e demonstrating that you‚Äôve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "syllabus2.html",
    "href": "syllabus2.html",
    "title": "Syllabus",
    "section": "",
    "text": "Navarro and Foxcroft (2022)\nDownload the syllabus as PDF"
  },
  {
    "objectID": "syllabus2.html#sec-course-description",
    "href": "syllabus2.html#sec-course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course focuses on the introductory statistical techniques used in social science research. Students will be introduced to concepts such as reliability, validity, measures of central tendency, variability, probability, and statistical techniques including: t tests (independent & dependent samples), Analysis of Variance (ANOVA), Chi-square, correlation, and regression.\nStudents are expected to take the material/concepts presented in this course and apply them through a series of homework assignments and quizzes. The overall goal of the course is not only to help students understand the mathematical/statistical concepts presented but also to assist in the application of these procedures."
  },
  {
    "objectID": "syllabus2.html#expectations-and-goals",
    "href": "syllabus2.html#expectations-and-goals",
    "title": "Syllabus",
    "section": "Expectations and Goals",
    "text": "Expectations and Goals\nUpon completion of this course, you will be able to adequately:\n\nIntroduce statistical concepts utilized in research within the social sciences\nApply the mathematical/statistical techniques presented for social science research\nDemonstrate an ability to analyze and interpret data within the social sciences\nProvide practical examples as to when statistical techniques presented are appropriate methods for analysis."
  },
  {
    "objectID": "syllabus2.html#text-readings-instructional-resources",
    "href": "syllabus2.html#text-readings-instructional-resources",
    "title": "Syllabus",
    "section": "Text, readings & instructional resources",
    "text": "Text, readings & instructional resources\n\nRequired eBook (free)\nNavarro and Foxcroft (2022)\n\n\nOptional Textbook\n\n\nOther readings\nAll extra study content for this course can be found in the course‚Äôs website.\n\n\nInstructional resources\n\njamovi Statistical Software(The jamovi project 2021) (Free)\njamovi Video Tutorials (Free)"
  },
  {
    "objectID": "syllabus2.html#sec-structure-requirements",
    "href": "syllabus2.html#sec-structure-requirements",
    "title": "Syllabus",
    "section": "Structure & Requirements",
    "text": "Structure & Requirements\nI will adopt the 4 ‚ÄúPs‚Äù1 in this course. This means that while taking this course you will be asked to prepare, participate, practice, and perform.\nYou are responsible for the material covered in class prior to attending each class. Note that the week‚Äôs readings are specified in the course schedule.\nIn addition to these readings, the instructor may assign supplemental readings throughout the semester. These supplemental readings do not appear on the schedule as these readings will be assigned at the instructor‚Äôs discretion.\nThe assignments used to enhance your learning experience in this course include:\n\nParticipation & Attendance\nClass presence and participation points are given to encourage your active class participation and discussion. You will be rewarded with a perfect score as long as you frequently come to class and actively contribute to the class discussion during lectures.\nAlthough it is not required, most students send their professor a brief e-mail to explain their absence in advance.\n\n\nPreparedness\nYou will be evaluated on your preparedness by completing the a quiz and the major takeaways assignment before each class.\n\n\nQuizzes\nBefore each class, you will complete a multiple-choice quiz on the week‚Äôs topic. You must score 100% on each quiz. If you score below 100%, you will have to retake the quiz until you score 100%. You can only move to the following quiz if you score 100% on a quiz.\n\n\nLabs\nStudents will complete four (4) labs on this course. The purpose of each lab is to assist students in applying their understanding of the statistical procedures discussed in class as well as to provide an opportunity for students to respond to the readings.\n\n\n\n\n\n\nWarning\n\n\n\nYou are allowed to discuss the labs with other students (and with the instructor), but you must write the final answers yourself in your own words. Solutions prepared ‚Äúin committee‚Äù or by, copying or paraphrasing someone else‚Äôs work is not acceptable; your hand-in assignments must represent your thoughts.\n\n\n\n\nExams\nYou will complete two (2) exams in this course. Students may use their notes and textbook for the exams, but no outside resource other than a calculator can be used.\nEach exam has between six to ten questions, with each question worth 10 points. Exams must be completed in the allotted time. The exams (and quizzes) focus on concepts and interpretation, with most of the computational activities occurring in the homework assignments.\nAlthough the quizzes and exams will not focus on previously tested material (they are not meant to be cumulative), knowledge of previously tested material may be inherently required to answer questions related to new material.\nMost of the computational activities will be via lab assignments. In addition, selected readings will be assigned throughout the semester. The content of these readings will be included in exam and quiz questions and homework assignments.\n\n\nDejavu\nOrganization is a prerequisite for effective learning. Throughout the semester, you will be asked to organize the material presented in class in a single directory in Google Drive.\nThe directory should have a Doc file (essential links), the syllabus in PDF format, and several subdirectories for each topic covered in the course. Inside each subdirectory, you must include the week‚Äôs lesson in PDF format and any assignments or activities you did. The structure of the main directory should look like this:\nKIN610\n\nEssential Links\nSyllabus in pdf\nNavarro and Foxcroft (2022) ebook\n\nWeek 1: <topic>\n\nLesson in pdf\nAny assignment and/or activity completed\n\nWeek 2 <topic> ‚Ä¶."
  },
  {
    "objectID": "syllabus2.html#course-policy",
    "href": "syllabus2.html#course-policy",
    "title": "Syllabus",
    "section": "Course Policy",
    "text": "Course Policy\nI will detail the policy for this course below. Basically, don‚Äôt cheat and try to learn stuff.\n\nGrading\n\n\n\nAssignment\nPercentage\n\n\n\n\nParticipation & Attendance\n5%\n\n\nWeekly Quizzes\n10%\n\n\nMajor Takeaways2\n20%\n\n\nLabs\n20%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\ndeJavu\n5%\n\n\n\n\n\nGrading Scale\nA 93.00-100.00 | A- 90.00-92.99 B+ 87.00-89.99 | B 83.00-86.99 | B- 80.00-82.99 C+ 77.00-79.99 | C 73.00-76.99 | C- 70.00-72.99 D+ 67.00-69.99 | D 63.00-66.99 | D- 60.00-62.99 F <59.99\n\n\n\n\n\n\nNote\n\n\n\nIn recognition of the fact that grading, however carefully done, will always be imperfect, this class will utilize a ‚Äúround up‚Äù rule for assigning final grades. I will round up from .5% and above, but anything below this will round down. In other words, 79.5 will round up to 80, while 79.4 will round down to 79 even.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRequests for an Incomplete (I) must conform to university policies. Among other requirements, ‚ÄúI‚Äù is possible only for instances in which you are demonstrating passing work in the class.\n\n\n\n\nAttendance\n\nShowing up is 80 percent of life ‚Äì Woody Allen, via Marshall Brickman\n\nAttendance will be taken at the beginning of every class; please, plan accordingly.\n\n\nE-mail\nPlease, do not use the built-in email (Inbox) in Canvas. Instead, use your CSUN Gmail to communicate with me.\nIf your message concerns a non-private matter (e.g., assignments, content, deadlines, etc.), then please post your question to our mailing list, which can be answered by any student taking the course. The mailing list address is provided in Canvas.\n\n\nOffice Hours\n\nIn-person\nThursdays from 2-4 pm at RE 289.\n\n\nOnline via Zoom\nBy appointment only: www.calendly.com/drfurtado\n\n\n\nLate Assignments\nIt is important to note that late assignments are assessed a 10% deduction for each day it is late, not to exceed four days. After the fourth day of the deadline, no assignments will be accepted. Therefore, it is important to plan ahead and submit all assignments on time to receive full credit for your work. The instructor reserves the right to make exceptions to this policy on a case-by-case basis.\n\n\nExtra Credit\nThere is no individual extra credit granted. Therefore, do not plan to make-up poor grades at the end of the semester by asking to do extra credit work. I might provide extra credit opportunities, but these will be offered to the entire class, not to individuals.\n\n\nDisabilities\nFederal law mandates the provision of services at the university-level to qualified students with disabilities.\nThis instructor, in conjunction with California State University Northridge, is committed to upholding and maintaining all aspects of the federal Americans with Disabilities Act of 1990 (ADA) and Section 504 of the Rehabilitation Act of 1973.\nIf you are a student with a disability and wish to request accommodations, please contact the office of Students with Disabilities Resources located in 110 Student Services Building, or call (818) 677-2684 for an appointment. Any information regarding your disability will remain confidential. Because many accommodations require early planning, requests for accommodations should be made as early as possible. Any requests for accommodations will be reviewed in a timely manner to determine their appropriateness to this setting.\n\n\nAcademic Dishonesty\nTL;DR: Don‚Äôt cheat!\nPlease, stop and read the information below; this is important!\n\n\n\n\n\n\nImportant\n\n\n\nEach student is expected to be familiar with, and abide by, the conditions of student conduct, as presented in the CSUN Catalog, with emphasis on sections entitled, Student Conduct Code, Academic Dishonesty, Faculty Policy on Academic Dishonesty, and Penalties. Any student engaging in academic dishonesty (e.g., cheating, fabrication, facilitating academic dishonesty, plagiarism) is subject to discipline, which may include a failing grade in the course, and may also be subject to more severe discipline by the University. Students are encouraged to visit the link below and become familiar with the Standards for Student Conduct.\nhttp://www.csun.edu/a&r/soc/studentconduct.html\n\n\n\nAbout Plagiarism\nPlagiarism means using words, ideas, or arguments from another person or source without citation3. Cite all sources consulted to any extent (including material from the internet), whether or not assigned and whether or not quoted directly. For quotations, four or more words used in sequence must be set off in quotation marks, with the source identified.\nPlagiarism is a serious violation of the CSUN Student Conduct Code.. Any form of cheating will immediately earn you a failing grade for the entire course. By remaining enrolled, you consent to this policy.\n\nTurnitin (see below) will detect such misconducts as it checks every submission against a database of papers, as well as against the Internet.\n\nWhat is Turnitin?\nTurnitin is an automated system that instructors can use to quickly and easily compare each student‚Äôs assignment with billions of websites, as well as an enormous database of student papers that grows with each submission. Accordingly, you will be expected to submit assignments through the Canvas Assignment Tool in electronic format. After the assignment is processed, as an instructor, I receive a report from Turnitin that states if and how another author‚Äôs work was used in the assignment."
  },
  {
    "objectID": "syllabus2.html#sec-final-notes",
    "href": "syllabus2.html#sec-final-notes",
    "title": "Syllabus",
    "section": "Final (yet important) Notes",
    "text": "Final (yet important) Notes\n\nHow to Access our Course and Get Started\n\nLog into Canvas: https://canvas.csun.edu\nUnder ‚ÄúMy Courses,‚Äù locate our course and click on it.\nThis will take you to the course home page.\n\n\n\nTechnology Requirements and Support:\n\nA computer and access to the internet (reliable connection)\nFirefox, Safari, etc. (web browser)\n\n\n\nWhat I Expect of You:\n\nPlan your schedule to ensure you several hours per week to spend on this class and take time to identify where and when you‚Äôll do your learning.\nReview the due dates for the assignments (refer to our Course Schedule in Canvas) to orient yourself to the flow of the learning.\nThis course requires regular engagement and practice using jamovi (Statistical Package)."
  },
  {
    "objectID": "syllabus2.html#sec-success",
    "href": "syllabus2.html#sec-success",
    "title": "Syllabus",
    "section": "How to be Success in this Course",
    "text": "How to be Success in this Course\nConsider the goals you have for engaging in this course as you determine how to allocate time to complete course requirements.\nEach student has a different pace when comes to studying for a course. Thus, I will let you figure out how many hours you need to reserve each week for this course. Regardless of the number of hours chosen, try to divide your time so that you devote more time to assignments and assigned readings.\nThe Module Time chart below provides a visual representation of the typical time spent completing a module, followed by an example weekly schedule."
  },
  {
    "objectID": "syllabus2.html#sec-student-support-services",
    "href": "syllabus2.html#sec-student-support-services",
    "title": "Syllabus",
    "section": "Student Support Services",
    "text": "Student Support Services\nCSUN aims to make all learning experiences as accessible as possible, and has a variety of resources available to help support students. If you believe the design of this course poses barriers to effectively participate or demonstrate your learning, please contact me to discuss possible options and adjustments.\n\nThe IT Help Center (818)677-1400, helpcenter@csun.edu is available to help with Canvas, CSUN e-mail, SOLAR/Portal, and other technical issues.\nCSUN Device Loaner Program (https://bit.ly/3t1G0An) provides devices that can be checked out that includes laptops, webcams, hotspots and headsets\nThe Learning Resource Center (818) 677-2033 The mission of the LRC is to enable students to improve their academic performance through a variety of learning programs, including workshops, one-on-one and group tutoring, supplemental instruction classes and interactive subject area computer programs and videos. Student who use the LRC learning programs will develop and strengthen their critical thinking skills, study strategies, writing skills and performance in subject matter courses.\nUniversity Counseling Services (818) 677-2366, Bayramian Hall 520. UCS provides resources and information to assist students in dealing with a variety of large and small psychological obstacles that may interfere with academic progress and/or relationship satisfaction. Services include individual, group, and crisis counseling.\nIn accordance with the CSUN Accessibility Policy (https://bit.ly/3yqGHE9), CSUN is working to ensure that campus communication and course materials are accessible to everyone. Please reach out to me if you have difficulty with any of the materials for this course.\nIf you have a disability and need accommodations, please register with the Disability Resources and Educational Services (DRES) office or the National Center on Deafness (NCOD).\n\nThe DRES office can be reached at (818) 677-2684.\nNCOD can be reached at (818) 677-2611.\nReasonable accommodations and services will be provided to students if requests are made in a timely manner and with appropriate documentation\nIf you would like to discuss your need for accommodations with me, please drop in office hours or contact me to set up an appointment.\n\nFood Pantry (https://bit.ly/38nTsVH) at CSUN: Anybody who faces challenges securing food or housing and believes this impacts course performance, should contact CSUN‚Äôs Food Pantry website and the corresponding contacts. If you also feel comfortable contacting me, the department chair, or the Dean‚Äôs Office, we can also facilitate assistance. You don‚Äôt have to be alone in this moment.\nEmergency MataCare grants (https://bit.ly/2WAZkIz), one-time grants to prevent evictions, urgent child care issues, etc. - DACA (Deferred Action for Childhood Arrivals) Resources: Check out the Central American Resource Center facebook page (https://bit.ly/2Yg0p9z), legal resources listed on CSUN‚Äôs Educational Opportunity Program (EOP) Dream Center that was created to support all undocumented students & allies (Dream Center flyer). CSUN President Harrison issued a support statement on the CSUN homepage for DACA and resources.\nHelp lines (https://bit.ly/3sYbMOo)(after hours when the University Counseling is closed) for numerous topics/needs (e.g., suicide, drug, rape, LGBQT, military, or any crisis). You don‚Äôt have to manage these feelings alone.\nPride Center (https://bit.ly/3jqNZUi) offers support and resources to lesbian, gay, bisexual, transgender, queer, & questioning students, faculty, & staff.\nKlotz Student Health Center (https://bit.ly/3zx1Y0s): Numerous health services including primary care, dental, nutritional counseling, acupuncture, massage and lots more.\nCareer Center (https://bit.ly/3jtTcL2) for resume writing & interviewing and much more; Matty‚Äôs Closet (https://bit.ly/3jAResx) has free professional clothes for students who need interview or professional attire.\nUSU 9https://bit.ly/38uz59j) for more student services; Clubs & Organizations (https://bit.ly/38tBhOa): Hopefully a dozen people have already advised you to ‚Äúget involved‚Äù (https://bit.ly/3ysqYVb) at CSUN in something that interests you.\nAssociated Students (https://bit.ly/3yuWjGT) offers recycling, and a Children‚Äôs Center providing child care\nFinancial Aid & Scholarships (https://bit.ly/3sYFzqr) offers aid for applications\nUniversity Library https://bit.ly/3yuIEQ9) for many additional academic resources\nVeterans Resource Center (https://bit.ly/38qYtg7) assists CSUN students as they transition from military service to academic success.\n\nTitle 5, California Code of Regulations,¬ß 41301. Standards for Student Conduct ‚Äì (a) Campus Community Values: The university is committed to maintaining a safe and healthy living and learning environment for students, faculty, and staff. Each member of the campus community should choose behaviors that contribute toward this end. Students are expected to be good citizens and to engage in responsible behaviors that reflect well upon their university, to be civil to one another and to others in the campus community, and contribute positively to student and university life.\nCSUN with A HEART If you are facing challenges related to food insecurity, housing precarity/homelessness, mental health, access to technology, eldercare/childcare, or healthcare, you can find guidance, help, and resources from CSUN with A HEART (https://www.csun.edu/heart)."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "",
    "text": "Download the syllabus as PDF"
  },
  {
    "objectID": "course-syllabus.html#sec-course-description",
    "href": "course-syllabus.html#sec-course-description",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Course Description",
    "text": "Course Description\nThis course focuses on the introductory statistical techniques used in social science research. Students will be introduced to concepts such as reliability, validity, measures of central tendency, variability, probability, and statistical techniques including: t tests (independent & dependent samples), Analysis of Variance (ANOVA), Chi-square, correlation, and regression.\nStudents are expected to take the material/concepts presented in this course and apply them through a series of homework assignments and quizzes. The overall goal of the course is not only to help students understand the mathematical/statistical concepts presented but also to assist in the application of these procedures."
  },
  {
    "objectID": "course-syllabus.html#expectations-and-goals",
    "href": "course-syllabus.html#expectations-and-goals",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Expectations and Goals",
    "text": "Expectations and Goals\nUpon completion of this course, you will be able to adequately:\n\nIntroduce statistical concepts utilized in research within the social sciences\nApply the mathematical/statistical techniques presented for social science research\nDemonstrate an ability to analyze and interpret data within the social sciences\nProvide practical examples as to when statistical techniques presented are appropriate methods for analysis."
  },
  {
    "objectID": "course-syllabus.html#text-readings-instructional-resources",
    "href": "course-syllabus.html#text-readings-instructional-resources",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Text, readings & instructional resources",
    "text": "Text, readings & instructional resources\n\nRequired eBook (free)\nNavarro and Foxcroft (2022)\n\n\nOptional Textbook\nWeir and Vincent (2021)\n\n\nOther readings\nAll extra study content for this course can be found in the course‚Äôs website.\n\n\nInstructional resources\n\njamovi Statistical Software (The jamovi project 2021) (Free)\njamovi Video Tutorials Poulson (2019) (Free)"
  },
  {
    "objectID": "course-syllabus.html#sec-structure-requirements",
    "href": "course-syllabus.html#sec-structure-requirements",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Structure & Requirements",
    "text": "Structure & Requirements\nI will adopt the 4 ‚ÄúPs‚Äù1 in this course. This means that while taking this course you will be asked to prepare, participate, practice, and perform.\nYou are responsible for the material covered in class prior to attending each class. Note that the week‚Äôs readings are specified in the course schedule.\nIn addition to these readings, the instructor may assign supplemental readings throughout the semester. These supplemental readings do not appear on the schedule as these readings will be assigned at the instructor‚Äôs discretion.\nThe assignments used to enhance your learning experience in this course include:\n\nParticipation & Attendance2\nClass presence and participation points are given to encourage your active class participation and discussion. You will be rewarded with a perfect score as long as you frequently come to class and actively contribute to the class discussion during lectures.\nIn addition, some in-class activities will count toward participation points. These are unannounced assignments.\n\n\nPreparedness\nYou will be evaluated on your preparedness by completing the a quiz and the major takeaways assignment before each class.\n\n\nQuizzes\nBefore each class, you will complete a multiple-choice quiz on the week‚Äôs topic. You must score 100% on each quiz. If you score below 100%, you will have to retake the quiz until you score 100%. You can only move to the following quiz if you score 100% on a quiz.\nA few notes about quizzes:\n\nYou will be allowed to take the quiz as many times as you want (as long as the quiz is still open);\nThe highest score of taken attempts will be recorded for grading purposes;\nYou will be presented with ten questions on each attempt. Questions are drawn from a database comprised of more than ten questions;\nQuizzes are timed; once started, students have 20 minutes to complete each attempt.\n\n\n\nLabs\nStudents will complete several labs in this course. The purpose of each lab is to assist students in applying their understanding of the statistical procedures discussed in class as well as to provide an opportunity for students to respond to the readings.\n\n\n\n\n\n\nWarning\n\n\n\nYou are allowed to discuss the labs with other students (and with the instructor), but you must write the final answers yourself in your own words. Solutions prepared ‚Äúin committee‚Äù or by, copying or paraphrasing someone else‚Äôs work is not acceptable; your hand-in assignments must represent your thoughts.\n\n\n\n\nMajor Takeaways\nYou will be evaluated on your preparedness by submitting an assignment before each class. This assignment is meant to be a reflection of your learning. You will be asked to submit at least ten major takeaways from the readings. The content of the assignment must come from the assigned readings for the corresponding class session.\n\n\nExams\nYou will complete two (2) exams in this course. Students may use their notes and textbook for the exams, but no outside resource other than a calculator can be used.\nEach exam has between six to ten questions, with each question worth 10 points. Exams must be completed in the allotted time. The exams (and quizzes) focus on concepts and interpretation, with most of the computational activities occurring in the homework assignments.\nAlthough the quizzes and exams will not focus on previously tested material (they are not meant to be cumulative), knowledge of previously tested material may be inherently required to answer questions related to new material.\nMost of the computational activities will be via lab assignments. In addition, selected readings will be assigned throughout the semester. The content of these readings will be included in exam and quiz questions and homework assignments.\n\n\nD√©j√† vu\nOrganization is a prerequisite for effective learning. Throughout the semester, you will be asked to organize the material presented in class in a single directory in Google Drive.\nThe directory should have a Doc file (essential links), the syllabus in PDF format, and several sub-directories for each topic covered in the course. Inside each sub-directory, you must include the week‚Äôs lesson in PDF format and any assignments or activities you did. The structure of the main directory should look like this:\nKIN610\n\nEssential Links\nSyllabus in pdf\nNavarro and Foxcroft (2022) ebook\n\nWeek 1: <topic>\n\nLesson in pdf\nAny assignment and/or activity completed\n\nWeek 2 <topic> ‚Ä¶."
  },
  {
    "objectID": "course-syllabus.html#sec-course-policy",
    "href": "course-syllabus.html#sec-course-policy",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Course Policy",
    "text": "Course Policy\nI will detail the policy for this course below. Basically, don‚Äôt cheat and try to learn stuff.\n\nGrading\n\n\n\nAssignment\nPercentage\n\n\n\n\nParticipation & Attendance\n5%\n\n\nWeekly Quizzes\n10%\n\n\nMajor Takeaways3\n20%\n\n\nLabs\n20%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\nD√©j√† vu\n5%\n\n\n\n\n\nGrading Scale\nA 93.00-100.00 | A- 90.00-92.99 B+ 87.00-89.99 | B 83.00-86.99 | B- 80.00-82.99 C+ 77.00-79.99 | C 73.00-76.99 | C- 70.00-72.99 D+ 67.00-69.99 | D 63.00-66.99 | D- 60.00-62.99 F <59.99\n\n\n\n\n\n\nNote\n\n\n\nIn recognition of the fact that grading, however carefully done, will always be imperfect, this class will utilize a ‚Äúround up‚Äù rule for assigning final grades. I will round up from .5% and above, but anything below this will round down. In other words, 79.5 will round up to 80, while 79.4 will round down to 79 even.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRequests for an Incomplete (I) must conform to university policies. Among other requirements, ‚ÄúI‚Äù is possible only for instances in which you are demonstrating passing work in the class.\n\n\n\n\nAttendance\n\nShowing up is 80 percent of life ‚Äì Woody Allen, via Marshall Brickman\n\nAttendance will be taken at the beginning of every class; please, plan accordingly.\n\n\nE-mail\nPlease, do not use the built-in email (Inbox) in Canvas. Instead, use your CSUN Gmail to communicate with me.\nIf your message concerns a non-private matter (e.g., assignments, content, deadlines, etc.), then please post your question to our mailing list, which can be answered by any student taking the course. The mailing list address is provided in Canvas.\n\n\nOffice Hours\n\nIn-person\nThursdays from 2-4 pm at RE 289.\n\n\nOnline via Zoom\nBy appointment only: www.calendly.com/drfurtado\n\n\n\nLate Assignments\nIt is important to note that late assignments are assessed a 10% deduction for each day it is late, not to exceed four days. After the fourth day of the deadline, no assignments will be accepted. Therefore, it is important to plan ahead and submit all assignments on time to receive full credit for your work. The instructor reserves the right to make exceptions to this policy on a case-by-case basis.\n\n\nExtra Credit\nThere is no individual extra credit granted. Therefore, do not plan to make-up poor grades at the end of the semester by asking to do extra credit work. I might provide extra credit opportunities, but these will be offered to the entire class, not to individuals.\n\n\nDisabilities\nFederal law mandates the provision of services at the university-level to qualified students with disabilities.\nThis instructor, in conjunction with California State University Northridge, is committed to upholding and maintaining all aspects of the federal Americans with Disabilities Act of 1990 (ADA) and Section 504 of the Rehabilitation Act of 1973.\nIf you are a student with a disability and wish to request accommodations, please contact the office of Students with Disabilities Resources located in 110 Student Services Building, or call (818) 677-2684 for an appointment. Any information regarding your disability will remain confidential. Because many accommodations require early planning, requests for accommodations should be made as early as possible. Any requests for accommodations will be reviewed in a timely manner to determine their appropriateness to this setting.\n\n\nAcademic Dishonesty\nTL;DR: Don‚Äôt cheat!\nPlease, stop and read the information below; this is important!\n\n\n\n\n\n\nImportant\n\n\n\nEach student is expected to be familiar with, and abide by, the conditions of student conduct, as presented in the CSUN Catalog, with emphasis on sections entitled, Student Conduct Code, Academic Dishonesty, Faculty Policy on Academic Dishonesty, and Penalties. Any student engaging in academic dishonesty (e.g., cheating, fabrication, facilitating academic dishonesty, plagiarism) is subject to discipline, which may include a failing grade in the course, and may also be subject to more severe discipline by the University. Students are encouraged to visit the link below and become familiar with the Standards for Student Conduct.\nhttp://www.csun.edu/a&r/soc/studentconduct.html\n\n\n\nAbout Plagiarism\nPlagiarism means using words, ideas, or arguments from another person or source without citation4. Cite all sources consulted to any extent (including material from the internet), whether or not assigned and whether or not quoted directly. For quotations, four or more words used in sequence must be set off in quotation marks, with the source identified.\nPlagiarism is a serious violation of the CSUN Student Conduct Code.. Any form of cheating will immediately earn you a failing grade for the entire course. By remaining enrolled, you consent to this policy.\n\nTurnitin (see below) will detect such misconducts as it checks every submission against a database of papers, as well as against the Internet.\n\nWhat is Turnitin?\nTurnitin is an automated system that instructors can use to quickly and easily compare each student‚Äôs assignment with billions of websites, as well as an enormous database of student papers that grows with each submission. Accordingly, you will be expected to submit assignments through the Canvas Assignment Tool in electronic format. After the assignment is processed, as an instructor, I receive a report from Turnitin that states if and how another author‚Äôs work was used in the assignment."
  },
  {
    "objectID": "course-syllabus.html#sec-final-notes",
    "href": "course-syllabus.html#sec-final-notes",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Final (yet important) Notes",
    "text": "Final (yet important) Notes\n\nHow to Access our Course and Get Started\n\nLog into Canvas: https://canvas.csun.edu\nUnder ‚ÄúMy Courses,‚Äù locate our course and click on it.\nThis will take you to the course home page.\n\n\n\nTechnology Requirements and Support:\n\nA computer and access to the internet (reliable connection)\nFirefox, Safari, etc. (web browser)\n\n\n\nWhat I Expect of You:\n\nPlan your schedule to ensure you several hours per week to spend on this class and take time to identify where and when you‚Äôll do your learning.\nReview the due dates for the assignments (refer to our Course Schedule in Canvas) to orient yourself to the flow of the learning.\nThis course requires regular engagement and practice using jamovi (Statistical Package)."
  },
  {
    "objectID": "course-syllabus.html#sec-success",
    "href": "course-syllabus.html#sec-success",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "How to be Success in this Course",
    "text": "How to be Success in this Course\nConsider the goals you have for engaging in this course as you determine how to allocate time to complete course requirements.\nEach student has a different pace when comes to studying for a course. Thus, I will let you figure out how many hours you need to reserve each week for this course. Regardless of the number of hours chosen, try to divide your time so that you devote more time to assignments and assigned readings."
  },
  {
    "objectID": "course-syllabus.html#sec-student-support-services",
    "href": "course-syllabus.html#sec-student-support-services",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Student Support Services",
    "text": "Student Support Services\nCSUN aims to make all learning experiences as accessible as possible, and has a variety of resources available to help support students. If you believe the design of this course poses barriers to effectively participate or demonstrate your learning, please contact me to discuss possible options and adjustments.\n\nThe IT Help Center (818)677-1400, helpcenter@csun.edu is available to help with Canvas, CSUN e-mail, SOLAR/Portal, and other technical issues.\nCSUN Device Loaner Program (https://bit.ly/3t1G0An) provides devices that can be checked out that includes laptops, webcams, hotspots and headsets\nThe Learning Resource Center (818) 677-2033 The mission of the LRC is to enable students to improve their academic performance through a variety of learning programs, including workshops, one-on-one and group tutoring, supplemental instruction classes and interactive subject area computer programs and videos. Student who use the LRC learning programs will develop and strengthen their critical thinking skills, study strategies, writing skills and performance in subject matter courses.\nUniversity Counseling Services (818) 677-2366, Bayramian Hall 520. UCS provides resources and information to assist students in dealing with a variety of large and small psychological obstacles that may interfere with academic progress and/or relationship satisfaction. Services include individual, group, and crisis counseling.\nIn accordance with the CSUN Accessibility Policy (https://bit.ly/3yqGHE9), CSUN is working to ensure that campus communication and course materials are accessible to everyone. Please reach out to me if you have difficulty with any of the materials for this course.\nIf you have a disability and need accommodations, please register with the Disability Resources and Educational Services (DRES) office or the National Center on Deafness (NCOD).\n\nThe DRES office can be reached at (818) 677-2684.\nNCOD can be reached at (818) 677-2611.\nReasonable accommodations and services will be provided to students if requests are made in a timely manner and with appropriate documentation\nIf you would like to discuss your need for accommodations with me, please drop in office hours or contact me to set up an appointment.\n\nFood Pantry (https://bit.ly/38nTsVH) at CSUN: Anybody who faces challenges securing food or housing and believes this impacts course performance, should contact CSUN‚Äôs Food Pantry website and the corresponding contacts. If you also feel comfortable contacting me, the department chair, or the Dean‚Äôs Office, we can also facilitate assistance. You don‚Äôt have to be alone in this moment.\nEmergency MataCare grants (https://bit.ly/2WAZkIz), one-time grants to prevent evictions, urgent child care issues, etc. - DACA (Deferred Action for Childhood Arrivals) Resources: Check out the Central American Resource Center facebook page (https://bit.ly/2Yg0p9z), legal resources listed on CSUN‚Äôs Educational Opportunity Program (EOP) Dream Center that was created to support all undocumented students & allies (Dream Center flyer). CSUN President Harrison issued a support statement on the CSUN homepage for DACA and resources.\nHelp lines (https://bit.ly/3sYbMOo)(after hours when the University Counseling is closed) for numerous topics/needs (e.g., suicide, drug, rape, LGBQT, military, or any crisis). You don‚Äôt have to manage these feelings alone.\nPride Center (https://bit.ly/3jqNZUi) offers support and resources to lesbian, gay, bisexual, transgender, queer, & questioning students, faculty, & staff.\nKlotz Student Health Center (https://bit.ly/3zx1Y0s): Numerous health services including primary care, dental, nutritional counseling, acupuncture, massage and lots more.\nCareer Center (https://bit.ly/3jtTcL2) for resume writing & interviewing and much more; Matty‚Äôs Closet (https://bit.ly/3jAResx) has free professional clothes for students who need interview or professional attire.\nUSU 9https://bit.ly/38uz59j) for more student services; Clubs & Organizations (https://bit.ly/38tBhOa): Hopefully a dozen people have already advised you to ‚Äúget involved‚Äù (https://bit.ly/3ysqYVb) at CSUN in something that interests you.\nAssociated Students (https://bit.ly/3yuWjGT) offers recycling, and a Children‚Äôs Center providing child care\nFinancial Aid & Scholarships (https://bit.ly/3sYFzqr) offers aid for applications\nUniversity Library https://bit.ly/3yuIEQ9) for many additional academic resources\nVeterans Resource Center (https://bit.ly/38qYtg7) assists CSUN students as they transition from military service to academic success.\n\nTitle 5, California Code of Regulations,¬ß 41301. Standards for Student Conduct ‚Äì (a) Campus Community Values: The university is committed to maintaining a safe and healthy living and learning environment for students, faculty, and staff. Each member of the campus community should choose behaviors that contribute toward this end. Students are expected to be good citizens and to engage in responsible behaviors that reflect well upon their university, to be civil to one another and to others in the campus community, and contribute positively to student and university life.\nCSUN with A HEART If you are facing challenges related to food insecurity, housing precarity/homelessness, mental health, access to technology, eldercare/childcare, or healthcare, you can find guidance, help, and resources from CSUN with A HEART (https://www.csun.edu/heart)."
  },
  {
    "objectID": "course-syllabus.html#diversity-inclusion",
    "href": "course-syllabus.html#diversity-inclusion",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official CSUN records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "course-syllabus.html#course-schedule",
    "href": "course-syllabus.html#course-schedule",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Course Schedule",
    "text": "Course Schedule\nOptional Textbook: Weir and Vincent (2021); Required ebook: Navarro and Foxcroft (2022)\n\n\n\n\nWeek5\nDate6\nReading7\nAssignments8\n\n\n\n\n\nWk01\nJan 26\nCourse Introduction (Online via Zoom)\nRead and study the Syllabus\n\n\n\nWK02\nFeb 2\nIntroduction to jamovi & Data Collection\nLab 1\n\n\n\nWK03\nFeb 9\nIntroduction to Statistics and Measurement\nQuiz; Major Takeaways\n\n\n\nWK04\nFeb 16\nOrganizing and Displaying Data\nPercentiles\nQuizzes; Major Takeaways\n\n\n\nWK05\nFeb 23\nMeasures of Central Tendency\nMeasures of Variability\nQuizzes; Major Takeaways; Lab 2\n\n\n\nWK06\nMar 2\nFundamentals of Inferential Statistical\n\nQuiz; Major Takeaways\n\n\n\nWK07\nMar 9\nCorrelation and Bivariate Regression\nQuiz; Major Takeaways\n\n\n\nWK08\nMar 16\nMultiple Correlation and Multiple Regression\nQuiz; Major Takeaways; Lab 3\n\n\n\nWK09\nMar 23\nExam 19\nna\n\n\n\nWK10\nMar 30\nThe Student‚Äôs t-test\nQuiz; Major Takeaways\n\n\n\nWK11\nApr 6\nOne-way Analysis of Variance\nQuiz; Major Takeaways\n\n\n\nWK12\nApr 13\nAnalysis of Variance With Repeated Measures\nQuiz; Major Takeaways; Lab 4\n\n\n\nWK13\nApr 20\nSpring Recess\nna\n\n\n\nWK14\nApr 27\n\nFactorial Analysis of Variance: Between-Between\nQuiz; Major Takeaways\n\n\n\nWK15\nMay 4\n\nFactorial Analysis of Variance: Between-Within, Within-Within\nQuiz; Major Takeaways; Lab 5\n\n\n\nWK16\nMay 11\nAnalysis of Nonparametric Data\nQuiz; Major Takeaways\n\n\n\nFinal‚Äôs Week\nMay 18\n5:30PM - 7:30PM\nRedwood Hall 276\nExam 210\nna"
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you‚Äôre having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you‚Äôll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it‚Äôs been resolved. If there‚Äôs a deadline coming up soon, post on the course forum to let us know that there‚Äôs an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don‚Äôt anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you‚Äôve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They‚Äôll be able to help diagnose the issue."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html",
    "href": "CopyOfcourse-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#course-info",
    "href": "CopyOfcourse-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\n\n\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nLectures\nTue & Thu\n1:45 pm - 3:00 pm\nReuben-Cooke Building 130\n\n\nSection 1\nMon\n1:45 pm - 3:00 pm\nPerkins LINK 087 (Classroom 3)\n\n\nSection 2\nMon\n3:30 pm - 4:45 pm\nOld Chemistry 003\n\n\nSection 3\nMon\n5:15 pm - 6:30 pm\nSocial Sciences 311"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#learning-objectives",
    "href": "CopyOfcourse-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to‚Ä¶\n\nanalyze real-world data to answer questions about multivariable relationships.\nfit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nuse Quarto to write reproducible reports and GitHub for version control and collaboration.\ncommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#community",
    "href": "CopyOfcourse-syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke‚Äôs Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at sta210-s22.github.io/website.\nI will regularly send course announcements via email and Sakai, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course forum Conversations. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include ‚ÄúSTA 210‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#textbooks",
    "href": "CopyOfcourse-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine √áetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#lectures-and-labs",
    "href": "CopyOfcourse-syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. More information on loaner laptops can be found here."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#teams",
    "href": "CopyOfcourse-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team‚Äôs overall mark.\nYou are expected to make use of the provided GitHub repository as their central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member‚Äôs relative contribution for each project."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#assessment",
    "href": "CopyOfcourse-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of six components: application exercises, homework assignments, labs, exams, projects, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the readings and lectures. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Tuesday lectures are due Friday by 11:59 pm ET, and AEs from Thursday lectures are due Sunday by 11:59 pm ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team‚Äôs GitHub repository on the course‚Äôs GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member‚Äôs relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you‚Äôve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you‚Äôre learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be three, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you‚Äôve learned in the course thus far. The exams will focus on the conceptual understanding of the content, and they may also include small analysis and computational tasks. The content of the exam will be related to the content in the prepare, practice, and perform assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the project is to apply what you‚Äôve learned throughout the semester to analyze an interesting, data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#grading",
    "href": "CopyOfcourse-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2.33% x 6)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#five-tips-for-success",
    "href": "CopyOfcourse-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you‚Äôre not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It‚Äôs not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon‚Äôt procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won‚Äôt know where to begin asking questions. Don‚Äôt let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours, and let me help you identify a good (re)starting point."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#course-policies",
    "href": "CopyOfcourse-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nTL;DR: Don‚Äôt cheat!\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard:\nStudents affirm their commitment to uphold the values of the Duke University community by signing a pledge that states:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;\nI will act if the Standard is compromised\n\nRegardless of course delivery format, it is your responsibility to understand and follow Duke policies regarding academic integrity, including doing one‚Äôs own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Duke Community Standard. If you have any questions about how to follow these requirements, please contact Jeanna McCullers (jeanna.mccullers@duke.edu), Director of the Office of Student Conduct.\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what‚Äôs the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course‚Äôs policy is that you may make use of any online resources (e.g.¬†RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email Dr.¬†√áetinkaya-Rundel and our head TA Rick Presman before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Dr.¬†√áetinkaya-Rundel know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Lab time is dedicated to working on your lab assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you‚Äôre going to miss a lab session and you‚Äôre feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others‚Äô time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university‚Äôs top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 919-681-9355. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nAll lectures will be recorded and available on Panopto, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get permission from me ahead of time and these recordings should be used for personal study only, no for distribution. The full policy on recording of lectures falls under the Duke University Policy on Intellectual Property Rights, available at provost.duke.edu/sites/default/files/FHB_App_P.pdf. Unauthorized distribution is a cause for disciplinary action by the Judicial Board."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#learning-during-a-pandemic",
    "href": "CopyOfcourse-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n\nNote: If you‚Äôve read this far in the syllabus, email me a picture of your pet if you have one or your favourite meme!"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#important-dates",
    "href": "CopyOfcourse-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 5: Classes begin (Monday meeting schedule)\nJanuary 6: Regular class meeting schedule begins\nJanuary 17: Martin Luther King, Jr.¬†Day holiday, no classes are held\nJanuary 19: Drop/add ends\nMarch 7-11: Spring recess, no classes are held\nMarch 23: Last day to withdraw with W\nApril 20: Classes end\nApril 21-24: Reading period\nApril 25-30: Final exams\n\nClick here for the full Duke academic calendar."
  }
]