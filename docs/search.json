[
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "Objective: To assess students’ understanding of measures of central tendency and measures of variability and their ability to use jamovi for data analysis."
  },
  {
    "objectID": "labs/lab-2.html#objective",
    "href": "labs/lab-2.html#objective",
    "title": "Lab 2",
    "section": "",
    "text": "Objective: To assess students’ understanding of measures of central tendency and measures of variability and their ability to use jamovi for data analysis."
  },
  {
    "objectID": "labs/lab-2.html#instructions",
    "href": "labs/lab-2.html#instructions",
    "title": "Lab 2",
    "section": "Instructions",
    "text": "Instructions\n\nOpen Jamovi and create a new data set with the following variables: Gender and Reaction Time (ms).\nEnter the provided data set into the Jamovi data spreasheet.\nClick on “Descriptives” under the “Exploration” tab in the top menu.\nSelect the “Reaction Time (ms)” variable and drag it into the “Variables” box.\nSelect the “Gender” variable and drag it into the “Split by” box.\nUnder “Statistics” and “Plots”, select all checked items depicted in Figure 1.\nReview the generated table and graphs to ensure that the output is accurate and complete.\nExport the output as PDF and choose the desired destination to save the PDF file.\nName the file with your first initial and last name and submit the file via Canvas (Lab 2 - Part 1).\nComplete Part 2 on Canvas - 2-question quiz\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember that this assignment must be completed individually, and that plagiarism is prohibited. Review the plagiarism policy posted on the CSUN website before submitting your assignment. Note: The generated PDF file should contain the Descriptives Table (variables across columns) and the relevant graphs. Be sure to review the file before submitting it to ensure it contains all the required information."
  },
  {
    "objectID": "labs/lab-2.html#grading-rubric",
    "href": "labs/lab-2.html#grading-rubric",
    "title": "Lab 2",
    "section": "Grading rubric",
    "text": "Grading rubric\nTotal points available: 90\n\n\n\n\n\n\n\nComponent\nPoints\n\n\n\n\nFile submission (Part 1) containing the following:\n\nthe Descriptives Table (Variables across columns)\nbar blot comparing gender\nsingle graph with both histograms - w/ density curves (males, females)\nsingle graph with both boxplots (males, females)\nsingle graph with both QQ Plots (males, females)\n\n50\n\n\n20-question quiz\n40\n\n\n\n\n\n\nFigure 1: Screenshot jamovi"
  },
  {
    "objectID": "labs/lab-2.html#sec-data",
    "href": "labs/lab-2.html#sec-data",
    "title": "Lab 2",
    "section": "Data",
    "text": "Data\nCopy the data below and paste it to jamovi, or download it as .csv.\n\n\n\n\n\n\n\nGender\nReaction Time (ms)\n\n\n\n\nMale\n215\n\n\nMale\n203\n\n\nMale\n197\n\n\nMale\n208\n\n\nMale\n222\n\n\nMale\n212\n\n\nMale\n194\n\n\nMale\n219\n\n\nMale\n201\n\n\nMale\n214\n\n\nFemale\n185\n\n\nFemale\n172\n\n\nFemale\n190\n\n\nFemale\n165\n\n\nFemale\n150\n\n\nFemale\n180\n\n\nFemale\n195\n\n\nFemale\n170\n\n\nFemale\n210\n\n\nFemale\n148"
  },
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3",
    "section": "",
    "text": "Here are the learning objectives for this assignment:\n\nUnderstand the concepts of simple and multiple regression analysis in the context of Kinesiology.\nDevelop proficiency in using jamovi to conduct and interpret simple and multiple regression analyses.\nLearn to interpret regression coefficients, R-squared values, and other related statistics from regression output.\nUnderstand the importance of assessing model assumptions and the impact of multicollinearity in multiple regression analysis.\nApply critical thinking skills to evaluate the relationships between multiple factors affecting athletic performance.\nDevelop the ability to interpret and communicate the results of regression analyses to both technical and non-technical audiences.\nEnhance problem-solving skills by addressing real-world Kinesiology-related questions using statistical analyses."
  },
  {
    "objectID": "labs/lab-3.html#objective",
    "href": "labs/lab-3.html#objective",
    "title": "Lab 3",
    "section": "",
    "text": "Here are the learning objectives for this assignment:\n\nUnderstand the concepts of simple and multiple regression analysis in the context of Kinesiology.\nDevelop proficiency in using jamovi to conduct and interpret simple and multiple regression analyses.\nLearn to interpret regression coefficients, R-squared values, and other related statistics from regression output.\nUnderstand the importance of assessing model assumptions and the impact of multicollinearity in multiple regression analysis.\nApply critical thinking skills to evaluate the relationships between multiple factors affecting athletic performance.\nDevelop the ability to interpret and communicate the results of regression analyses to both technical and non-technical audiences.\nEnhance problem-solving skills by addressing real-world Kinesiology-related questions using statistical analyses."
  },
  {
    "objectID": "labs/lab-3.html#introduction",
    "href": "labs/lab-3.html#introduction",
    "title": "Lab 3",
    "section": "Introduction",
    "text": "Introduction\nWelcome to this week’s lab on regression analysis using jamovi! In this lab, we will be applying the concepts of simple and multiple regression analysis to a dataset related to Kinesiology. The dataset contains information on various factors affecting athletic performance."
  },
  {
    "objectID": "labs/lab-3.html#sec-dataset",
    "href": "labs/lab-3.html#sec-dataset",
    "title": "Lab 3",
    "section": "Dataset",
    "text": "Dataset\nThe dataset is provided in a CSV format, which you can download here: data-lab3.csv\nThe dataset contains the following variables:\n\nID - Unique identifier for each participant\nAge - Age of the participant (in years)\nHeight - Height of the participant (in centimeters)\nWeight - Weight of the participant (in kilograms)\nBMI - Body Mass Index of the participant\nVO2max - Maximum oxygen consumption (in ml/kg/min)\n40YD - Time to complete a 40-yard dash (in seconds)\nVerticalJump - Maximum vertical jump height (in inches)"
  },
  {
    "objectID": "labs/lab-3.html#sec-instructions",
    "href": "labs/lab-3.html#sec-instructions",
    "title": "Lab 3",
    "section": "Instructions",
    "text": "Instructions\nPart 1: Data Analysis using jamovi\n\nDownload and install jamovi (https://www.jamovi.org) if you haven’t already.\nOpen jamovi and import the data-lab3.csv file.\nPerform a simple regression analysis to predict VO2max based on Age.\nPerform a multiple regression analysis to predict VO2max based on Age, Height, Weight, and BMI.\nInterpret the results of both simple and multiple regression analyses.\n\nPart 2: Open-ended Questions\nAfter completing the data analysis in jamovi, please access Canvas to answer the 10 questions related to the analysis. I urge you to answer the questions first, then copy and paste them in Canvas.\nOpen-ended Questions\n\nWhat is the primary purpose of conducting a regression analysis?\nIn simple regression analysis, what is the role of the independent variable and the dependent variable?\nHow can you determine the strength and direction of the relationship between the independent and dependent variables in a simple regression analysis?\nWhat is the difference between simple and multiple regression analysis?\nHow do you interpret the R-squared value in a regression analysis?\nIn the simple regression analysis predicting VO2max based on Age, what is the direction of the relationship between Age and VO2max?\nIn the multiple regression analysis predicting VO2max, which variable(s) had a significant effect on VO2max?\nIn the multiple regression analysis predicting VO2max, which variable(s) had the strongest effect on VO2max?\nHow can multicollinearity affect the results of a multiple regression analysis?\nWhat can be done to address multicollinearity in a multiple regression analysis?\n\nRemember to submit your jamovi output and your responses to the multiple-choice questions on Canvas by the due date. Good luck!"
  },
  {
    "objectID": "labs/lab-3.html#grading-rubric",
    "href": "labs/lab-3.html#grading-rubric",
    "title": "Lab 3",
    "section": "Grading rubric",
    "text": "Grading rubric\nTotal points available: 90\n\n\n\nComponent\nPoints\n\n\n\n\n10 open-ended questions\n90\n\n\njamovi output in PDF format\n10"
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1 - Data Collection",
    "section": "",
    "text": "This lab in intended to collect data that will be used for several purposes throughout the semester.\n\n\nBelow, you will find the links to several cognitive tests. Wait for further instructions from your instruction before start taking the tests. This is important because becoming familiar with the tests before other students will likely add noise to the data.\n\n\nThis test measures how many words you can keep in short term memory at once. The number of words you need to remember grows continually, until you can’t keep them in your head anymore. Go as long as you can. You have 3 strikes until game over. Your score is how many turns you lasted.\n\n\n\nThe average person can only remember 7 digit numbers reliably. Can you do more? You will be presented with a single-digit number and be asked to remember it. The numbers will increase unit you can no longer remember.\n\n\n\nMemorize the sequence of buttons that light up, then press them in order. Every time you finish the pattern, it gets longer. Make a mistake, and the test is over.\n\n\n\nThis is a test of working memory, made famous by a study that found that chimpanzees consistently outperform humans on this task.\nIn the study, the chimps consistently outperformed humans, and some chimps were able to remember 9 digits over 90% of the time.\nThis test is a variant of that concept, that gets increasingly difficult every turn, starting at 4 digits, and adding one every turn. If you pass a level, the number increases. If you fail, you get a strike. Three strikes and the test is over.\n\n\n\nThis is a simple test of typing speed, measuring words per minute, or WPM. The standard measure of WPM is (number of characters / 5) / (time taken). By that measurement, “quick brown fox” is 15 characters, including spaces. The recorded score is WPM * Accuracy.\n\n\n\nThis is a simple tool to measure your reaction time. When the red box turns green, click on the screen as soon as you can. Then, click anywhere to start the new trial.\n\n\n\nClick the targets as quickly and accurately as you can. This tests reflexes and hand-eye coordination. Once you’ve clicked 30 targets, your score and average time per target will be displayed.\n\n\n\nEvery level, a number of tiles will flash white. Memorize them, and pick them again after the tiles are reset! Levels get progressively more difficult, to challenge your skills. If you miss 3 tiles on a level, you lose one life. You have three lives. Make it as far as you can!"
  },
  {
    "objectID": "labs/lab-1.html#introductions",
    "href": "labs/lab-1.html#introductions",
    "title": "Lab 1 - Data Collection",
    "section": "",
    "text": "This lab in intended to collect data that will be used for several purposes throughout the semester.\n\n\nBelow, you will find the links to several cognitive tests. Wait for further instructions from your instruction before start taking the tests. This is important because becoming familiar with the tests before other students will likely add noise to the data.\n\n\nThis test measures how many words you can keep in short term memory at once. The number of words you need to remember grows continually, until you can’t keep them in your head anymore. Go as long as you can. You have 3 strikes until game over. Your score is how many turns you lasted.\n\n\n\nThe average person can only remember 7 digit numbers reliably. Can you do more? You will be presented with a single-digit number and be asked to remember it. The numbers will increase unit you can no longer remember.\n\n\n\nMemorize the sequence of buttons that light up, then press them in order. Every time you finish the pattern, it gets longer. Make a mistake, and the test is over.\n\n\n\nThis is a test of working memory, made famous by a study that found that chimpanzees consistently outperform humans on this task.\nIn the study, the chimps consistently outperformed humans, and some chimps were able to remember 9 digits over 90% of the time.\nThis test is a variant of that concept, that gets increasingly difficult every turn, starting at 4 digits, and adding one every turn. If you pass a level, the number increases. If you fail, you get a strike. Three strikes and the test is over.\n\n\n\nThis is a simple test of typing speed, measuring words per minute, or WPM. The standard measure of WPM is (number of characters / 5) / (time taken). By that measurement, “quick brown fox” is 15 characters, including spaces. The recorded score is WPM * Accuracy.\n\n\n\nThis is a simple tool to measure your reaction time. When the red box turns green, click on the screen as soon as you can. Then, click anywhere to start the new trial.\n\n\n\nClick the targets as quickly and accurately as you can. This tests reflexes and hand-eye coordination. Once you’ve clicked 30 targets, your score and average time per target will be displayed.\n\n\n\nEvery level, a number of tiles will flash white. Memorize them, and pick them again after the tiles are reset! Levels get progressively more difficult, to challenge your skills. If you miss 3 tiles on a level, you lose one life. You have three lives. Make it as far as you can!"
  },
  {
    "objectID": "labs/lab-1.html#submission",
    "href": "labs/lab-1.html#submission",
    "title": "Lab 1 - Data Collection",
    "section": "Submission",
    "text": "Submission\n\nVisit the Human Benchmark Dashboard and copy the permalink associated with dashboard.\nVisit the Lab 1 assignment in Canvas and submit the link.\nWhile in class, you will be asked to input your scores on a spreadsheet. The data will be used throughout the semester for various purposes.\n\nLink to create ID: https://www.getuniqueid.com\n\nVisit the link above\nCopy ONLY the first sequence of characters + the first dash (9 characters including the dash)\nPaste the code sequence elsewhere (i.e., Word doc)\nAdd the current year and semester (i.e., spring2023 or fall2024) after the dash\nThe final form of your ID should look like this: c7b96573-spring2023\n\nSubmit scores here: https://bit.ly/3JYNheP\n\nVisit the Human Benchmark Dashboard\nOpen the link above; it will take you to a online spreadsheet (Google Sheets)\nEnter your ID in the ID column\nSelect the first test you completed under Test; then select Sex, Term, Year, and input the raw Score and the Percentile associated with the test you took.\nRepeat this process for the other tests"
  },
  {
    "objectID": "labs/lab-1.html#grading",
    "href": "labs/lab-1.html#grading",
    "title": "Lab 1 - Data Collection",
    "section": "Grading",
    "text": "Grading\nTotal points available: 80 points.\n\n\n\nComponent\nPoints1\n\n\n\n\nTest 1\n10\n\n\nTest 2\n10\n\n\nTest 3\n10\n\n\nTest 4\n10\n\n\nTest 5\n10\n\n\nTest 6\n10\n\n\nTest 7\n10\n\n\nTest 8\n10\n\n\n\n\n\n1 To earn full points on each test, students must follow the instructions, take the test, and submit the scores and their respective percentiles via Canvas."
  },
  {
    "objectID": "labs/lab-0.html",
    "href": "labs/lab-0.html",
    "title": "Lab 0 - Meet + greet",
    "section": "",
    "text": "Today’s lab is short and sweet! We just need you to fill out the “Getting to know you” survey. Please go here to take it. You will need to log on to Sakai to access to survey.\nYour answers can be brief. Some of your answers will be used to guide what application examples might be of interest to a majority of students in the course and some of your answers will be used to help guide team formation. We expect this will take you ~10 minutes."
  },
  {
    "objectID": "labs/CopyOflab-2.html",
    "href": "labs/CopyOflab-2.html",
    "title": "Lab 2 - College scorecard",
    "section": "",
    "text": "In today’s lab, you’ll use simple linear regression to analyze the relationship between the admissions rate and total cost for colleges and universities in the United States.\n\n\nBy the end of the lab you will…\n\nBe able to fit a simple linear regression model using R.\nBe able to interpret the slope and intercept for the model.\nBe able to use statistical inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/CopyOflab-2.html#introduction",
    "href": "labs/CopyOflab-2.html#introduction",
    "title": "Lab 2 - College scorecard",
    "section": "",
    "text": "In today’s lab, you’ll use simple linear regression to analyze the relationship between the admissions rate and total cost for colleges and universities in the United States.\n\n\nBy the end of the lab you will…\n\nBe able to fit a simple linear regression model using R.\nBe able to interpret the slope and intercept for the model.\nBe able to use statistical inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/CopyOflab-2.html#getting-started",
    "href": "labs/CopyOflab-2.html#getting-started",
    "title": "Lab 2 - College scorecard",
    "section": "Getting started",
    "text": "Getting started\n\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClone the repo and start a new project in RStudio. See the Lab 1 instructions for details on cloning a repo, starting a new R project and configuring git."
  },
  {
    "objectID": "labs/CopyOflab-2.html#packages",
    "href": "labs/CopyOflab-2.html#packages",
    "title": "Lab 2 - College scorecard",
    "section": "Packages",
    "text": "Packages\nWe will use the following package in today’s lab.\n\nlibrary(tidyverse)  # for data wrangling + visualization\nlibrary(tidymodels) # for modeling\nlibrary(knitr)      # for pretty printing of tables"
  },
  {
    "objectID": "labs/CopyOflab-2.html#data-college-scorecard",
    "href": "labs/CopyOflab-2.html#data-college-scorecard",
    "title": "Lab 2 - College scorecard",
    "section": "Data: College scorecard",
    "text": "Data: College scorecard\nThe data for this lab is from the scorecard data set in the rcfss R package. It includes information originally obtained from the U.S. Department of Education’s College Scorecard for 1753 colleges and universities during the 2018 - 2019 academic year.\nThe lab focuses on the following variables:\n\nadmrate: Undergraduate admissions rate (from 0-100%)\ncost: The average annual total cost of attendance, including tuition and fees, books and supplies, and living expenses\ntype: Type of college (Public; Private, nonprofit; Private, for-profit)\n\nClick here to see a full list of variables and definitions.\nUse the code below to load the data set.\n\nscorecard &lt;- read_csv(\"data/scorecard.csv\")"
  },
  {
    "objectID": "labs/CopyOflab-2.html#exercises",
    "href": "labs/CopyOflab-2.html#exercises",
    "title": "Lab 2 - College scorecard",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nNote\n\n\n\nInclude axis labels and an informative title for all plots. Use the kable() function to neatly print tables and regression output.\n\n\n\nExercise 1\nCreate a histogram to examine the distribution of admrate and calculate summary statistics for the center (mean and median) and the spread (standard deviation and IQR).\n\n\nExercise 2\nUse the results from the previous exercise to describe the distribution of admrate. Include the shape, center, spread, and if there are potential outliers.\n\n\nExercise 3\nPlot the distribution of cost and calculate the appropriate summary statistics. Describe the distribution of cost (shape, center, and spread, and outliers) using the plot and appropriate summary statistics.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you’ve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 4\nThe goal of this analysis is to fit a regression model that can be used to understand the variability in the cost of college based on the admission rate. Before fitting the model, let’s look at the relationship between the two variables. Create a scatterplot to display the relationship between cost and admissions rate. Describe the relationship between the two variables based on the plot.\n\n\nExercise 5\nDoes the relationship between cost and admissions rate differ by type of college? Modify the plot from the previous exercise visualize the relationship by type of college.\n\n\nExercise 6\nDescribe two new observations from the scatterplot in Exercise 5 that you didn’t see in the scatterplot from Exercise 4.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you’ve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 7\nFit the linear regression model. Use the kable function to neatly display the results with a reasonable number of decimals.\n\n\nExercise 8\nConsider the model from the previous exercise.\n\nInterpret the slope in the context of the problem.\nDoes the intercept have a meaningful interpretation? If so, write the interpretation in the context of the problem. Otherwise, explain why the interpretation is not meaningful.\n\n\n\nExercise 9\nConstruct a 95% confidence interval for the slope using bootstrapping. Follow these steps to accomplish this:\n\nFirst set a seed for simulating reproducibly.\nThen, simulate the bootstrap distribution of the slope using 1,000 bootstrap samples.\nThen, visually estimate the bounds of the bootstrap interval based on a histogram of the distribution of the bootstrapped slopes, using the percentile method.\nAnd then, use the get_confidence_interval() function to explicitly calculate the bounds of the confidence interval using the percentile method.\nFinally, interpret the confidence interval in the context of the data.\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you’ve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 10\nFinally, we want to answer the question “Do the data provide sufficient evidence of a linear relationship between cost and admissions rate, i.e. \\(\\beta_1\\) is different from 0?”\nTo answer this question we will use a hypothesis test. We can conduct a hypothesis test via simulation (what we’ll do in this lab) or using mathematical models (what we’ll do in the next class).\nBefore we can conduct the hypothesis test, let’s first set our hypotheses. Remember that the null hypothesis represents the status quo (nothing going on, i.e. there is no relationship) and the alternative hypothesis represents our research question (there is something going on, i.e. there is a relationship).\n\n\\(H_0\\): There is no linear relationship between the admissions rate and cost of colleges in the United States, \\(\\beta_1 = 0\\)\n\\(H_A\\): There is a linear relationship between the admissions rate and cost of colleges in the United States, \\(\\beta_1 \\ne 0\\)\n\nTo test these hypotheses, we will use a permutation test, where we\n\nSimulate new samples from the original sample via permutation under the assumption that the null hypothesis is true\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to calculate the p-value for the hypothesis test\n\nThe major difference between constructing a confidence interval and conducting a hypothesis test is that for the hypothesis test we assume that the null hypothesis is true. This requires a simulation scheme that will allow us to measure the natural variability in the data due to sampling but not due to cost and admission rate being correlated by permuting permute one variable to eliminate any existing relationship between the variables. To do so, we randomly assign each admrate value to cost of a given university, i.e. cost and admrate are no longer matched for a given university.\nIn the following code chunk we\n\nFirst set a seed for simulating reproducibly.\nThen, we start with our data frame and specify our model as cost vs. admrate.\nThen, we set our null hypothesis (cost and admrate are independent)\nAnd then we generate 1000 replicates of our data where, for each replicate, we permute values of admrate to randomly assign them to values of cost\nFinally, we fit our model to each of our 1000 permuted datasets\n\n\nset.seed(1234)\n\nperm_fits &lt;- scorecard %&gt;%\n  specify(cost ~ admrate) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  fit()\n\nThe resulting dataset perm_fits has nrow(perm_fits) and ncol(perm_fits) columns. The first column, replicate indicates the replicate number of the dataset the models were fit to; the values in this column range between 1 and 1000. The second column, term, tells us which term (intercept of the model or slope of admrate) the estimate value in the third column is for.\n\nperm_fits\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept  36857. \n 2         1 admrate     -781. \n 3         2 intercept  35901. \n 4         2 admrate      643. \n 5         3 intercept  36608. \n 6         3 admrate     -411. \n 7         4 intercept  35831. \n 8         4 admrate      746. \n 9         5 intercept  36367. \n10         5 admrate      -51.7\n# … with 1,990 more rows\n\n\n\nCreate a histogram of the slope estimates in perm_fits. (Hint: Filter the dataset for just the slope values, term == \"admrate\".)\nEstimate the p-value of the hypothesis test based on this distribution.\nState your conclusion for the test in context.\nIndicate whether or not it is consistent with the results of the hypothesis test from the previous exercise. Briefly explain your response.\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you’ve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty."
  },
  {
    "objectID": "labs/CopyOflab-2.html#submission",
    "href": "labs/CopyOflab-2.html#submission",
    "title": "Lab 2 - College scorecard",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ➡️ Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be “checked”).\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” section."
  },
  {
    "objectID": "labs/CopyOflab-2.html#grading",
    "href": "labs/CopyOflab-2.html#grading",
    "title": "Lab 2 - College scorecard",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51\n\n\n\n\n\n1 The “Workflow & formatting” grade is to assess the reproducible workflow. This includes having at least 3 informative commit messages and updating the name and date in the YAML."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Course Links",
    "section": "",
    "text": "Link\nDescription\n\n\n Human benchmark\nUsed for data collection\n\n\n CSUN Canvas\nUsed for assignment submissions\n\n\n jamovi\nAn open source statistical package based on R1"
  },
  {
    "objectID": "course-links.html#footnotes",
    "href": "course-links.html#footnotes",
    "title": "Course Links",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.r-project.org↩︎"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz for Week 6\nTakeaways\n\n\nDownload the lesson in PDF"
  },
  {
    "objectID": "weeks/week-6.html#prepare",
    "href": "weeks/week-6.html#prepare",
    "title": "Week 6",
    "section": "Prepare",
    "text": "Prepare\nRead Furtado (2023)"
  },
  {
    "objectID": "weeks/week-6.html#participate",
    "href": "weeks/week-6.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\nLecture Slides"
  },
  {
    "objectID": "weeks/week-6.html#practice",
    "href": "weeks/week-6.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\ntbd"
  },
  {
    "objectID": "weeks/week-6.html#perform",
    "href": "weeks/week-6.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\n\nOnline (refer to email for Zoom link)\n\nDeadlines\n\nQuiz\nTakeaways\n\n\nDownload the lesson in PDF"
  },
  {
    "objectID": "weeks/week-7.html#prepare",
    "href": "weeks/week-7.html#prepare",
    "title": "Week 7",
    "section": "Prepare",
    "text": "Prepare\nCorrelation\n\nRead\nRead (Navarro & Foxcroft, 2022, Chapters 12.1–12.2)\nRead the supplementary material on Correlation Coefficient\nTest your knowledge here\n\nSimple Linear Regression (moved to Week 8)"
  },
  {
    "objectID": "weeks/week-7.html#participate",
    "href": "weeks/week-7.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\nLecture Slides"
  },
  {
    "objectID": "weeks/week-7.html#practice",
    "href": "weeks/week-7.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-7.html#perform",
    "href": "weeks/week-7.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/one-way-anova.html",
    "href": "weeks/one-way-anova.html",
    "title": "One-Way ANOVA",
    "section": "",
    "text": "Introduction\nOne-way analysis of variance (ANOVA) is a statistical test used to compare the means of three or more groups. It is a powerful tool for understanding the relationships between variables and can be used to test hypotheses about the differences between groups. In this chapter, we will discuss the assumptions, calculations, and interpretation of one-way ANOVA, as well as its strengths and limitations.\nAssumptions\nThere are several assumptions that must be met in order to use one-way ANOVA:\n\nNormality: The data should be approximately normally distributed within each group.\nIndependence: The observations should be independent of each other, meaning that the value of one observation should not affect the value of another observation.\nEqual variance: The variance within each group should be approximately equal.\n\nIf these assumptions are not met, the results of the ANOVA may be biased or unreliable. It is important to check for these assumptions before conducting the test.\nCalculations\nTo calculate a one-way ANOVA, we first need to calculate the sum of squares within groups (SSW) and the sum of squares between groups (SSB). The SSW represents the variance within each group, while the SSB represents the variance between the groups.\nThe formula for calculating the SSW is:\nSSW = Σ(x - x̄)^2\nWhere x is the value of each observation and x̄ is the mean of the group.\nThe formula for calculating the SSB is:\nSSB = k * Σ(x̄ - x̄̄)^2\nWhere k is the number of groups, x̄ is the mean of each group, and x̄̄ is the overall mean of all the groups.\nOnce we have calculated the SSW and SSB, we can then use them to calculate the F statistic, which is used to determine whether there are significant differences between the groups. The F statistic is calculated as follows:\nF = SSB / SSW\nThe F statistic follows an F distribution, which allows us to determine the probability (p-value) that the differences between the groups are due to chance. If the p-value is less than a predetermined level of significance (usually 0.05), we can reject the null hypothesis and conclude that there are significant differences between the groups.\nInterpretation\nIf the p-value is significant, we can conclude that there are differences between the groups. However, we cannot determine which groups are significantly different from each other without conducting additional tests. To determine which groups are significantly different, we can use a post-hoc test, such as the Tukey HSD test or the Bonferroni correction.\nStrengths and Limitations\nOne-way ANOVA is a powerful statistical tool that can be used to compare the means of three or more groups. However, it has some limitations. For example, it is only appropriate for continuous data and cannot be used with categorical data. It also assumes that the variance is equal within each group, which may not always be the case. Additionally, it does not provide information about the direction or size of the differences between the groups.\nConclusion\nOne-way ANOVA is a statistical test used to compare the means of three or more groups. It is a useful tool for understanding the relationships between variables and can be used to test hypotheses about the differences between groups. However, it has some limitations and should be used with caution.\nversion 2\nOne-way analysis of variance (ANOVA) is a statistical test used to compare the means of two or more groups. It is a powerful tool for comparing the means of multiple groups to determine if there are significant differences between them. In this chapter, we will cover the basics of one-way ANOVA and how it can be used in biostatistics.\nTo begin, let’s define some key terms:\n\nThe dependent variable is the variable being measured or observed in an experiment. In the context of one-way ANOVA, the dependent variable is usually continuous (e.g., height, weight, blood pressure).\nThe independent variable is the variable being manipulated or controlled in an experiment. In one-way ANOVA, the independent variable has only one level, meaning that there is only one group being compared.\nThe null hypothesis is the assumption that there is no difference between the means of the groups being compared.\nThe alternative hypothesis is the opposite of the null hypothesis, and states that there is a difference between the means of the groups being compared.\n\nTo conduct a one-way ANOVA, we first need to ensure that our data meets the assumptions of the test. These assumptions include:\n\nNormality: The data must be approximately normally distributed within each group.\nIndependence: The observations within each group must be independent of each other.\nEqual variance: The variances of the groups being compared must be equal.\n\nIf these assumptions are not met, it may be necessary to transform the data or use a different statistical test.\nTo perform a one-way ANOVA, we first calculate the overall mean of the dependent variable. Then, we calculate the mean of the dependent variable for each group and subtract the overall mean from each group mean to obtain the group mean differences. We then divide the sum of the squares of these group mean differences by the number of groups minus one to obtain the between-groups sum of squares.\nNext, we calculate the sum of squares within each group by subtracting the group mean from each individual value, squaring the result, and summing the squared differences. We then sum these values across all groups to obtain the within-groups sum of squares.\nFinally, we divide the between-groups sum of squares by the within-groups sum of squares and compare the resulting F-statistic to a critical value from the F-distribution. If the F-statistic is greater than the critical value, we can reject the null hypothesis and conclude that there is a significant difference between the means of the groups.\nOne-way ANOVA is a useful tool for comparing the means of multiple groups, but it has some limitations. It is only appropriate for comparing the means of two or more groups, and it does not allow for comparisons between specific pairs of groups. Additionally, it does not provide information about which groups are significantly different from each other. To address these limitations, we can use follow-up tests such as the Tukey HSD test or the Bonferroni correction.\nIn summary, one-way ANOVA is a statistical test used to compare the means of two or more groups. It is important to ensure that the data meets the assumptions of the test and to use appropriate follow-up tests to understand the specific differences between groups.\nver3"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz for Week 5\nTakeaways\n\n\nDownload the lesson in PDF"
  },
  {
    "objectID": "weeks/week-5.html#prepare",
    "href": "weeks/week-5.html#prepare",
    "title": "Week 5",
    "section": "Prepare",
    "text": "Prepare\nRead Furtado (2023)\nPractice questions for this topic"
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\nLecture Slides"
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\nClick here to complete various exercises related to this topic"
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\nComplete Lab 2\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\n\nDownload the lesson in PDF"
  },
  {
    "objectID": "weeks/week-4.html#prepare",
    "href": "weeks/week-4.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\n\nRead Furtado (2022)\nRead Navarro & Foxcroft (2022), chap. 5"
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n\nThis page will be updated before our meeting with the link to the lecture slides\n\nSlides"
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n\nPractice with jamovi in class"
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\nna\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Important\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDownload this lesson as PDF"
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\n\nRead and study the Syllabus\nRead and study this APA Style in-text citation article"
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\nBe prepared to ask questions while in class."
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\nStudents will be asked to complete activities."
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\nna\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines (before class)\n\nQuiz and Major Takeaways\n\n\nDownload this lesson as PDF"
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\n\nRead Furtado (2023)"
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\nWhile in class, students are to ask questions and take notes.\nPresentation Slides"
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\nTBD"
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\nTBD\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDownload this lesson as PDF"
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\n\njamovi\n\nRead “Getting Started with jamovi” (Navarro & Foxcroft, 2022, Chapter 3)\nWatch videos 1-6 by Dr. Poulson (2019)"
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\nWhile in class, ask questions and take notes."
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\nStudents will be asked to complete a series of exercises in class."
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\nComplete Lab 11 and submit it by the deadline.\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-2.html#footnotes",
    "href": "weeks/week-2.html#footnotes",
    "title": "Week 2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLink will be provided during our meeting.↩︎"
  },
  {
    "objectID": "weeks/week-3-act1.html",
    "href": "weeks/week-3-act1.html",
    "title": "Activity 1: DV and IV",
    "section": "",
    "text": "Exercise 1: Given a scenario, identify the independent and dependent variables.\nScenario: The impact of height on jumping ability.\nIndependent variable: height\nDependent variable: jumping ability\nExercise 2: Given a scenario, identify the independent and dependent variables.\nScenario: The relationship between training frequency and muscle endurance.\nIndependent variable: training frequency\nDependent variable: muscle endurance\nExercise 3: Given a scenario, identify the independent and dependent variables.\nScenario: The influence of warm-up on performance.\nIndependent variable: warm-up\nDependent variable: performance\nExercise 4: Given a scenario, identify the independent and dependent variables.\nScenario: The effect of weight on power output.\nIndependent variable: weight\nDependent variable: power output\nExercise 5: Given a scenario, identify the independent and dependent variables.\nScenario: The impact of rest time on recovery.\nIndependent variable: rest time\nDependent variable: recovery"
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways"
  },
  {
    "objectID": "weeks/week-11.html#prepare",
    "href": "weeks/week-11.html#prepare",
    "title": "Week 11",
    "section": "Prepare",
    "text": "Prepare\nRead Furtado (2023)\nStudy the Student’s t table under Statistical Tables\nWatch these videos:\n\nOverview of t-test\nOne-sample t-test\nIndependent-samples t-test\nPaired-samples t-test"
  },
  {
    "objectID": "weeks/week-11.html#participate",
    "href": "weeks/week-11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\nSlides for this lecture"
  },
  {
    "objectID": "weeks/week-11.html#practice",
    "href": "weeks/week-11.html#practice",
    "title": "Week 11",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-11.html#perform",
    "href": "weeks/week-11.html#perform",
    "title": "Week 11",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways"
  },
  {
    "objectID": "weeks/week-13.html#prepare",
    "href": "weeks/week-13.html#prepare",
    "title": "Week 13",
    "section": "Prepare",
    "text": "Prepare\nRead Furtado (2023)\nWatch the videos below\n\nRepeated measures ANOVA by datalabcc (2018)"
  },
  {
    "objectID": "weeks/week-13.html#participate",
    "href": "weeks/week-13.html#participate",
    "title": "Week 13",
    "section": "Participate",
    "text": "Participate\nComing soon"
  },
  {
    "objectID": "weeks/week-13.html#practice",
    "href": "weeks/week-13.html#practice",
    "title": "Week 13",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-13.html#perform",
    "href": "weeks/week-13.html#perform",
    "title": "Week 13",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways"
  },
  {
    "objectID": "weeks/week-12.html#prepare",
    "href": "weeks/week-12.html#prepare",
    "title": "Week 12",
    "section": "Prepare",
    "text": "Prepare\nRead Furtado (2023)\nStudy the Student’s F table under Statistical Tables\nWatch these videos:\n\nOne-ANOVA\nKruskal-Wallis H test (non-parametric equivalent to the F test)"
  },
  {
    "objectID": "weeks/week-12.html#participate",
    "href": "weeks/week-12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\nSlides for this lecture"
  },
  {
    "objectID": "weeks/week-12.html#practice",
    "href": "weeks/week-12.html#practice",
    "title": "Week 12",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-12.html#perform",
    "href": "weeks/week-12.html#perform",
    "title": "Week 12",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-16.html",
    "href": "weeks/week-16.html",
    "title": "Week 16",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways\n\n\nDownload the lesson in PDF"
  },
  {
    "objectID": "weeks/week-16.html#prepare",
    "href": "weeks/week-16.html#prepare",
    "title": "Week 16",
    "section": "Prepare",
    "text": "Prepare\nComing soon"
  },
  {
    "objectID": "weeks/week-16.html#participate",
    "href": "weeks/week-16.html#participate",
    "title": "Week 16",
    "section": "Participate",
    "text": "Participate\nComing soon"
  },
  {
    "objectID": "weeks/week-16.html#practice",
    "href": "weeks/week-16.html#practice",
    "title": "Week 16",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-16.html#perform",
    "href": "weeks/week-16.html#perform",
    "title": "Week 16",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways"
  },
  {
    "objectID": "weeks/week-8.html#prepare",
    "href": "weeks/week-8.html#prepare",
    "title": "Week 8",
    "section": "Prepare",
    "text": "Prepare\nSimple & Multiple Linear Regression\n\nRead (Navarro & Foxcroft, 2022), chap. 12.3-12.12]\nWatch the video(s) below:\n\nRegression overview datalabcc (2018)\nLinear regression datalabcc (2019a)\nRegression diagnostics datalabcc (2019b)"
  },
  {
    "objectID": "weeks/week-8.html#participate",
    "href": "weeks/week-8.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\nThe slides can found here1"
  },
  {
    "objectID": "weeks/week-8.html#practice",
    "href": "weeks/week-8.html#practice",
    "title": "Week 8",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-8.html#perform",
    "href": "weeks/week-8.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-8.html#footnotes",
    "href": "weeks/week-8.html#footnotes",
    "title": "Week 8",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe link will take you to a html page with the slides content. To view the actual slides (in presentation view) click on RevealJS under Other Formats.↩︎"
  },
  {
    "objectID": "weeks/week-15.html",
    "href": "weeks/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways"
  },
  {
    "objectID": "weeks/week-15.html#prepare",
    "href": "weeks/week-15.html#prepare",
    "title": "Week 15",
    "section": "Prepare",
    "text": "Prepare\nRead"
  },
  {
    "objectID": "weeks/week-15.html#participate",
    "href": "weeks/week-15.html#participate",
    "title": "Week 15",
    "section": "Participate",
    "text": "Participate\nComing soon"
  },
  {
    "objectID": "weeks/week-15.html#practice",
    "href": "weeks/week-15.html#practice",
    "title": "Week 15",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-15.html#perform",
    "href": "weeks/week-15.html#perform",
    "title": "Week 15",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Important\n\n\n\n\nWe will meet at the Redwood Hall Computer Lab (Re 276) at 4 pm.\nDeadlines\n\nQuiz\nTakeaways"
  },
  {
    "objectID": "weeks/week-14.html#prepare",
    "href": "weeks/week-14.html#prepare",
    "title": "Week 14",
    "section": "Prepare",
    "text": "Prepare\nRead Furtado (2023)\n ANOVA in jamovi (datalabcc, 2019)"
  },
  {
    "objectID": "weeks/week-14.html#participate",
    "href": "weeks/week-14.html#participate",
    "title": "Week 14",
    "section": "Participate",
    "text": "Participate\nComing soon"
  },
  {
    "objectID": "weeks/week-14.html#practice",
    "href": "weeks/week-14.html#practice",
    "title": "Week 14",
    "section": "Practice",
    "text": "Practice\nComing soon"
  },
  {
    "objectID": "weeks/week-14.html#perform",
    "href": "weeks/week-14.html#perform",
    "title": "Week 14",
    "section": "Perform",
    "text": "Perform\n\nTake the quiz\nComplete the major takeaways assignment\n\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/pe.html",
    "href": "weeks/pe.html",
    "title": "Practice Exercises",
    "section": "",
    "text": "Visit the the link below take the quiz to test your knowledge on this topic.\nhttps://drfurtado.shinyapps.io/Practice-Questions/\n\n\n\n\n\n\nWarning\n\n\n\nThe studies below are fictitious.\n\n\n\n\n\nBelow are several practice exercises for Week 5. Write down your answers, then click Tip at the end of each exercise to review the answers.\nFor exercises 1-3, fill the blank with wither Mean, Median, or Mode.\n\n\nA study titled “Symptoms and Quality of Life in Patients with Fibromyalgia: A Cross-Sectional Study” used the ___________ to report the most frequently experienced symptoms by patients with fibromyalgia. The study surveyed 200 patients with fibromyalgia and asked them to report their symptoms using a questionnaire. The questionnaire included questions about 19 different symptoms commonly associated with fibromyalgia, such as pain, fatigue, sleep disturbances, depression, and anxiety.\nWhen reporting the results, the authors used the _________ to describe the most common symptoms experienced by the patients. For example, they reported that the __________ for pain intensity was 7 (on a scale of 0 to 10), indicating that a pain intensity score of 7 was the most frequently reported by patients. The authors also reported the ___________ for each of the other 18 symptoms, such as the ___________ for fatigue severity, sleep quality, and anxiety level.\nUsing the ___________ in this study allowed the researchers to identify the symptoms that were most commonly reported by patients with fibromyalgia, which could help clinicians to better understand and manage the condition. The ___________ is an appropriate measure of central tendency in this study because it is useful for identifying the most frequently occurring value in a dataset, which can be important information for clinical decision-making.\n\n\n\n\n\n\nTip\n\n\n\nmode\n\n\n\n\n\nIn this study, the authors aimed to investigate the associations between physical activity, adiposity, cardiorespiratory fitness, and academic performance in a sample of Spanish youth. The authors used a cross-sectional design and recruited 1,700 children aged 6 to 18 years. The authors measured the children’s physical activity using self-report questionnaires, and they measured their adiposity using body mass index (BMI), waist circumference, and skinfold thickness. The authors also assessed the children’s cardiorespiratory fitness using a 20-m shuttle run test, and they measured academic performance using grade point averages.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the distribution of the physical activity and adiposity measures. For example, they reported the ___________ minutes per day spent in moderate-to-vigorous physical activity (MVPA) instead of the ___________ MVPA. The authors chose to use the ___________ because the distributions of the physical activity and adiposity measures were skewed, meaning that a few extreme values could heavily influence the ___________.\nOverall, the study found that higher levels of physical activity, lower levels of adiposity, and higher levels of cardiorespiratory fitness were all positively associated with better academic performance in youth. The authors also found evidence to suggest that cardiorespiratory fitness mediated the relationship between physical activity and academic performance.\n\n\n\n\n\n\nTip\n\n\n\nmedian, mean, median, mean, median, mean\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of caffeine ingestion on tennis skill performance. The authors used a randomized, double-blind, crossover design and recruited 16 male tennis players. The players consumed either caffeine or a placebo before performing a tennis skill test, which consisted of serving, forehand, backhand, and volley. The authors measured the time to complete the skill test, the accuracy of the shots, and the total score of the test.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the central tendency of the data. For example, they reported the ___________ time to complete the skill test instead of the ___________ time. The authors chose to use the ___________ because the distributions of the skill test measures were approximately normal, meaning that the ___________ was a representative value of the data.\nOverall, the study found that caffeine ingestion improved tennis skill performance compared to the placebo condition. The authors found significant improvements in the time to complete the skill test, the accuracy of the shots, and the total score of the test. The authors concluded that caffeine ingestion may enhance tennis skill performance and could be used as an ergogenic aid in tennis.\n\n\n\n\n\n\nTip\n\n\n\nmean, median, mean, median, mean, mean\n\n\n\n\n\n\nFor exercises 4-6, fill the blank with either the Interquartile Range, Variance, Range, or Standard Deviation.\n\n\nn this study, the authors aimed to investigate the effect of protein supplementation combined with resistance training on muscle mass, strength, and function in individuals with chronic obstructive pulmonary disease (COPD). The authors conducted a systematic review and meta-analysis of randomized controlled trials that evaluated the effect of protein supplementation and resistance training on COPD patients. The authors extracted data on muscle mass, strength, and function outcomes and calculated effect sizes using Hedges’ g.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the dispersion of the effect sizes. The authors chose to use the __________ because the effect size distributions were not normally distributed and contained outliers, which could heavily influence the _________ . The _________ is a more robust measure of dispersion that is less affected by outliers.\nOverall, the meta-analysis found that protein supplementation combined with resistance training was effective in improving muscle mass, strength, and function in individuals with COPD. The authors found significant improvements in the outcomes of muscle mass, strength, and function in the protein supplementation group compared to the control group. The authors concluded that protein supplementation combined with resistance training could be a promising intervention for improving muscle health in individuals with COPD.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR\nRecall that the SD should be reported instead of the variance since the former is aligned to the scale of the original data.\n\n\n\n\n\nIn this study, the authors aimed to investigate the relationship between physical activity and depressive symptoms in older women. The authors used a cross-sectional design and recruited 198 women aged 65 years and older. The authors measured the women’s physical activity using self-report questionnaires, and they assessed their depressive symptoms using the Geriatric Depression Scale.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the variability of the data. For example, they reported the ___________ of the physical activity levels instead of the ____________ of the physical activity levels. The authors chose to use the ___________ because the distributions of the physical activity levels and the depressive symptoms scores were skewed and had outliers, which could heavily influence the ____________.\nOverall, the study found a significant negative relationship between physical activity levels and depressive symptoms scores in older women. The authors also found that the relationship was strongest for moderate-intensity physical activity. The authors concluded that physical activity could be an effective non-pharmacological intervention for preventing and treating depressive symptoms in older women.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR, Standard Deviation\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of resistance training frequency on neuromuscular performance and muscle morphology in trained men. The authors used a randomized controlled trial design and recruited 28 trained men. The men were randomly assigned to either a high-frequency resistance training group (six sessions per week) or a low-frequency resistance training group (three sessions per week). The authors measured the men’s neuromuscular performance using maximal isometric and dynamic strength tests, and they assessed the muscle morphology using muscle biopsies.\nWhen reporting the results, the authors used the ____________ instead of the ___________ to describe the variability of the data. For example, they reported the ____________ of the maximal isometric strength instead of the ___________ of the maximal isometric strength. The authors chose to use the ____________ because the distributions of the neuromuscular performance measures and the muscle morphology measures were approximately normal, meaning that the ____________ was a representative value of the data.\nOverall, the study found that the high-frequency resistance training group had greater improvements in neuromuscular performance and muscle morphology compared to the low-frequency resistance training group. The authors found significant increases in maximal isometric and dynamic strength, muscle cross-sectional area, and myofibrillar protein content in the high-frequency group. The authors concluded that high-frequency resistance training could be a superior training strategy for enhancing neuromuscular performance and muscle morphology in trained men.\n\n\n\n\n\n\nTip\n\n\n\nStandard Deviation, IQR or Range, Standard Deviation, IQR, Standard Deviation, Standard Deviation"
  },
  {
    "objectID": "weeks/pe.html#practice-questions",
    "href": "weeks/pe.html#practice-questions",
    "title": "Practice Exercises",
    "section": "",
    "text": "Visit the the link below take the quiz to test your knowledge on this topic.\nhttps://drfurtado.shinyapps.io/Practice-Questions/\n\n\n\n\n\n\nWarning\n\n\n\nThe studies below are fictitious."
  },
  {
    "objectID": "weeks/pe.html#practice-exercises---measures-of-central-tendency",
    "href": "weeks/pe.html#practice-exercises---measures-of-central-tendency",
    "title": "Practice Exercises",
    "section": "",
    "text": "Below are several practice exercises for Week 5. Write down your answers, then click Tip at the end of each exercise to review the answers.\nFor exercises 1-3, fill the blank with wither Mean, Median, or Mode.\n\n\nA study titled “Symptoms and Quality of Life in Patients with Fibromyalgia: A Cross-Sectional Study” used the ___________ to report the most frequently experienced symptoms by patients with fibromyalgia. The study surveyed 200 patients with fibromyalgia and asked them to report their symptoms using a questionnaire. The questionnaire included questions about 19 different symptoms commonly associated with fibromyalgia, such as pain, fatigue, sleep disturbances, depression, and anxiety.\nWhen reporting the results, the authors used the _________ to describe the most common symptoms experienced by the patients. For example, they reported that the __________ for pain intensity was 7 (on a scale of 0 to 10), indicating that a pain intensity score of 7 was the most frequently reported by patients. The authors also reported the ___________ for each of the other 18 symptoms, such as the ___________ for fatigue severity, sleep quality, and anxiety level.\nUsing the ___________ in this study allowed the researchers to identify the symptoms that were most commonly reported by patients with fibromyalgia, which could help clinicians to better understand and manage the condition. The ___________ is an appropriate measure of central tendency in this study because it is useful for identifying the most frequently occurring value in a dataset, which can be important information for clinical decision-making.\n\n\n\n\n\n\nTip\n\n\n\nmode\n\n\n\n\n\nIn this study, the authors aimed to investigate the associations between physical activity, adiposity, cardiorespiratory fitness, and academic performance in a sample of Spanish youth. The authors used a cross-sectional design and recruited 1,700 children aged 6 to 18 years. The authors measured the children’s physical activity using self-report questionnaires, and they measured their adiposity using body mass index (BMI), waist circumference, and skinfold thickness. The authors also assessed the children’s cardiorespiratory fitness using a 20-m shuttle run test, and they measured academic performance using grade point averages.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the distribution of the physical activity and adiposity measures. For example, they reported the ___________ minutes per day spent in moderate-to-vigorous physical activity (MVPA) instead of the ___________ MVPA. The authors chose to use the ___________ because the distributions of the physical activity and adiposity measures were skewed, meaning that a few extreme values could heavily influence the ___________.\nOverall, the study found that higher levels of physical activity, lower levels of adiposity, and higher levels of cardiorespiratory fitness were all positively associated with better academic performance in youth. The authors also found evidence to suggest that cardiorespiratory fitness mediated the relationship between physical activity and academic performance.\n\n\n\n\n\n\nTip\n\n\n\nmedian, mean, median, mean, median, mean\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of caffeine ingestion on tennis skill performance. The authors used a randomized, double-blind, crossover design and recruited 16 male tennis players. The players consumed either caffeine or a placebo before performing a tennis skill test, which consisted of serving, forehand, backhand, and volley. The authors measured the time to complete the skill test, the accuracy of the shots, and the total score of the test.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the central tendency of the data. For example, they reported the ___________ time to complete the skill test instead of the ___________ time. The authors chose to use the ___________ because the distributions of the skill test measures were approximately normal, meaning that the ___________ was a representative value of the data.\nOverall, the study found that caffeine ingestion improved tennis skill performance compared to the placebo condition. The authors found significant improvements in the time to complete the skill test, the accuracy of the shots, and the total score of the test. The authors concluded that caffeine ingestion may enhance tennis skill performance and could be used as an ergogenic aid in tennis.\n\n\n\n\n\n\nTip\n\n\n\nmean, median, mean, median, mean, mean"
  },
  {
    "objectID": "weeks/pe.html#practice-exercises---measures-of-variability",
    "href": "weeks/pe.html#practice-exercises---measures-of-variability",
    "title": "Practice Exercises",
    "section": "",
    "text": "For exercises 4-6, fill the blank with either the Interquartile Range, Variance, Range, or Standard Deviation.\n\n\nn this study, the authors aimed to investigate the effect of protein supplementation combined with resistance training on muscle mass, strength, and function in individuals with chronic obstructive pulmonary disease (COPD). The authors conducted a systematic review and meta-analysis of randomized controlled trials that evaluated the effect of protein supplementation and resistance training on COPD patients. The authors extracted data on muscle mass, strength, and function outcomes and calculated effect sizes using Hedges’ g.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the dispersion of the effect sizes. The authors chose to use the __________ because the effect size distributions were not normally distributed and contained outliers, which could heavily influence the _________ . The _________ is a more robust measure of dispersion that is less affected by outliers.\nOverall, the meta-analysis found that protein supplementation combined with resistance training was effective in improving muscle mass, strength, and function in individuals with COPD. The authors found significant improvements in the outcomes of muscle mass, strength, and function in the protein supplementation group compared to the control group. The authors concluded that protein supplementation combined with resistance training could be a promising intervention for improving muscle health in individuals with COPD.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR\nRecall that the SD should be reported instead of the variance since the former is aligned to the scale of the original data.\n\n\n\n\n\nIn this study, the authors aimed to investigate the relationship between physical activity and depressive symptoms in older women. The authors used a cross-sectional design and recruited 198 women aged 65 years and older. The authors measured the women’s physical activity using self-report questionnaires, and they assessed their depressive symptoms using the Geriatric Depression Scale.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the variability of the data. For example, they reported the ___________ of the physical activity levels instead of the ____________ of the physical activity levels. The authors chose to use the ___________ because the distributions of the physical activity levels and the depressive symptoms scores were skewed and had outliers, which could heavily influence the ____________.\nOverall, the study found a significant negative relationship between physical activity levels and depressive symptoms scores in older women. The authors also found that the relationship was strongest for moderate-intensity physical activity. The authors concluded that physical activity could be an effective non-pharmacological intervention for preventing and treating depressive symptoms in older women.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR, Standard Deviation\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of resistance training frequency on neuromuscular performance and muscle morphology in trained men. The authors used a randomized controlled trial design and recruited 28 trained men. The men were randomly assigned to either a high-frequency resistance training group (six sessions per week) or a low-frequency resistance training group (three sessions per week). The authors measured the men’s neuromuscular performance using maximal isometric and dynamic strength tests, and they assessed the muscle morphology using muscle biopsies.\nWhen reporting the results, the authors used the ____________ instead of the ___________ to describe the variability of the data. For example, they reported the ____________ of the maximal isometric strength instead of the ___________ of the maximal isometric strength. The authors chose to use the ____________ because the distributions of the neuromuscular performance measures and the muscle morphology measures were approximately normal, meaning that the ____________ was a representative value of the data.\nOverall, the study found that the high-frequency resistance training group had greater improvements in neuromuscular performance and muscle morphology compared to the low-frequency resistance training group. The authors found significant increases in maximal isometric and dynamic strength, muscle cross-sectional area, and myofibrillar protein content in the high-frequency group. The authors concluded that high-frequency resistance training could be a superior training strategy for enhancing neuromuscular performance and muscle morphology in trained men.\n\n\n\n\n\n\nTip\n\n\n\nStandard Deviation, IQR or Range, Standard Deviation, IQR, Standard Deviation, Standard Deviation"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#data-sources",
    "href": "project-tips-resources.html#data-sources",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %&gt;%\n  count(manufacturer) %&gt;%\n  mutate(manufacturer = str_to_title(manufacturer)) %&gt;%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course."
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "KIN 610 - Quantitative Analysis of Research in Kinesiology",
    "section": "",
    "text": "This course focuses on the introductory statistical techniques used in social science research. Students will be introduced to concepts such as reliability, validity, measures of central tendency, variability, probability, and statistical techniques including: t tests (independent & dependent samples), Analysis of Variance (ANOVA), Chi-square, correlation, and regression.\nStudents are expected to take the material/concepts presented in this course and apply them through a series of homework assignments and quizzes. The overall goal of the course is not only to help students understand the mathematical/statistical concepts presented but also to assist in the application of these procedures."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KIN 610 - Spring 2023",
    "section": "",
    "text": "Optional Textbook: Weir and Vincent (2021); Required ebook: Navarro and Foxcroft (2022)"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "KIN 610 - Spring 2023",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe schedule is subject to change.↩︎\nClass Dates: Aug 29, 2022 - Dec 12, 2022↩︎\nStudents are expected to read and study the assigned chapters prior to attending each class meeting.↩︎\nQuizzes and Major Takeaways assignments are due before class; other assignment are due after class.↩︎\nCovers all previously covered topics.↩︎\nCovers mainly topics presented after Exam 1.↩︎"
  },
  {
    "objectID": "slides/lec-9.html#credits",
    "href": "slides/lec-9.html#credits",
    "title": "Week 11: The t-test",
    "section": "Credits",
    "text": "Credits\nFurtado (2023)"
  },
  {
    "objectID": "slides/lec-9.html#learning-objectives",
    "href": "slides/lec-9.html#learning-objectives",
    "title": "Week 11: The t-test",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nHistory and development of the Student’s t-test\n\nWilliam Sealy Gosset\nPseudonym “Student”\n\nT-distribution in statistical testing\n\nRelationship to the normal distribution\nImportance for small sample sizes\n\nMain types of t-tests\n\nOne-sample t-test\nIndependent samples t-test\nPaired samples t-test\n\nAssumptions underlying the t-test\n\nIndependence of observations\nNormality of the data\nHomogeneity of variances\nImplications of violating assumptions\n\nConducting a t-test\n\nHypothesis formulation\nCalculation of test statistics\nInterpretation of p-values and confidence intervals\n\nEvaluating effect size\n\nUnderstanding Cohen’s d\n\nAlternative nonparametric tests\n\nWilcoxon signed-rank test\nMann-Whitney U test\n\nT-test application in real-world research\n\nExamples in Kinesiology\n\nGuidance on conducting t-tests with statistical software\n\njamovi\nSPSS\nR"
  },
  {
    "objectID": "slides/lec-9.html#data-summary",
    "href": "slides/lec-9.html#data-summary",
    "title": "Week 11: The t-test",
    "section": "Data summary",
    "text": "Data summary\nI will use a data set called dynamometer to demonstrate the analyses in this blog post. You can download the CSV file here and a summary of the data is provided in Table 1.\n\n\nTable 1: Descriptive Statistics for dynamometer\n\n\n\nAge_Group\nN\nMean\nSD\n\n\nAge\n18-39\n20\n27.9\n6.43\n\n\n\n40-60\n20\n49.3\n6.38\n\n\nBefore\n18-39\n20\n45.6\n1.84\n\n\n\n40-60\n20\n38.5\n3.12\n\n\nAfter\n18-39\n20\n52.6\n1.84\n\n\n\n40-60\n20\n43.7\n3.64"
  },
  {
    "objectID": "slides/lec-9.html#one-sample-t-test",
    "href": "slides/lec-9.html#one-sample-t-test",
    "title": "Week 11: The t-test",
    "section": "One-Sample T-Test",
    "text": "One-Sample T-Test\n\nCompares the mean of a single sample to a known population mean or hypothesized value\nDetermines if the sample mean significantly differs from an expected value\nExample: Comparing the average height of a sample to the known population mean height"
  },
  {
    "objectID": "slides/lec-9.html#independent-samples-t-test",
    "href": "slides/lec-9.html#independent-samples-t-test",
    "title": "Week 11: The t-test",
    "section": "Independent Samples T-Test",
    "text": "Independent Samples T-Test\n\nCompares the means of two independent groups\nUsed to determine if there is a significant difference between groups\nExample: Comparing test scores between students taught using different teaching methods"
  },
  {
    "objectID": "slides/lec-9.html#paired-samples-t-test",
    "href": "slides/lec-9.html#paired-samples-t-test",
    "title": "Week 11: The t-test",
    "section": "Paired Samples T-Test",
    "text": "Paired Samples T-Test\n\nAlso known as the dependent samples t-test\nCompares the means of two related groups or repeated measures\nOften used in pre-post study designs\nExample: Comparing participants’ muscle strength before and after an exercise program"
  },
  {
    "objectID": "slides/lec-9.html#assumptions",
    "href": "slides/lec-9.html#assumptions",
    "title": "Week 11: The t-test",
    "section": "Assumptions",
    "text": "Assumptions\nAssumption of Normality\n\nData should be approximately normally distributed\nT-test is robust against violations of normality with large sample sizes\nIf assumption is violated, consider using non-parametric tests\n\nAssumption of Homogeneity of Variances\n\nFor independent samples t-test, variances should be equal between groups\nIf assumption is violated, use Welch’s t-test, which does not require equal variances\nUse Levene’s test to assess homogeneity of variances\n\nAssumption of Independence\n\nObservations within each group should be independent\nParticularly relevant for the independent samples t-test\nEnsure proper study design and data collection to meet this assumption"
  },
  {
    "objectID": "slides/lec-9.html#effect-size",
    "href": "slides/lec-9.html#effect-size",
    "title": "Week 11: The t-test",
    "section": "Effect Size",
    "text": "Effect Size\nCohen’s d\n\nMeasure of effect size\nExpresses the magnitude of the difference between a sample mean and a known or hypothesized population mean in standardized units\nCan be used for all types of t-tests (One-sample, independent samples, paired samples)\nProvides a more comprehensive understanding of the effect of an intervention or treatment on the outcome of interest\n\nOne-sample t-test\n\nCohen’s d formula: \\[ Cohen's\\,d = \\frac{\\overline{X} - \\mu}{SD} \\qquad(1)\\]\n\nIndependent samples t-test\n\nCohen’s d formula: \\[ Cohen's\\,d = \\frac{\\overline{X_1} - \\overline{X_2}}{SD_{pooled}} \\qquad(2)\\]\nPooled standard deviation formula: \\[ SD_{pooled} = \\sqrt{\\frac{(n_1 - 1) \\times SD_1^2 + (n_2 - 1) \\times SD_2^2}{n_1 + n_2 - 2}} \\qquad(3)\\]\n\nPaired samples t-test\n\nCohen’s d formula: \\[ Cohen's\\,d = \\frac{\\overline{D}}{SD_D} \\qquad(4)\\]\n\nInterpreting Cohen’s d\n\nSmall effect: 0.2\nMedium effect: 0.5\nLarge effect: 0.8 or higher\nConsider research context and field of study"
  },
  {
    "objectID": "slides/lec-9.html#interpreting-t-test-results",
    "href": "slides/lec-9.html#interpreting-t-test-results",
    "title": "Week 11: The t-test",
    "section": "Interpreting t-test results",
    "text": "Interpreting t-test results\nKey concepts\n\nt-value\np-value\nSignificance level (commonly 0.05)\nNull hypothesis\nEffect size measures (e.g., Cohen’s d)"
  },
  {
    "objectID": "slides/lec-9.html#the-t-distribution",
    "href": "slides/lec-9.html#the-t-distribution",
    "title": "Week 11: The t-test",
    "section": "The t-distribution",
    "text": "The t-distribution\nStudent’s t-distribution\n\nProbability distribution\nEstimating the mean of a normally distributed population with unknown variance\nContinuous, symmetric distribution\nThicker tails than standard normal distribution\n\nRole in hypothesis testing\n\nUsed in t-tests to compare sample means\nEstimating the sampling distribution of the sample mean"
  },
  {
    "objectID": "slides/lec-9.html#the-t-distribution-1",
    "href": "slides/lec-9.html#the-t-distribution-1",
    "title": "Week 11: The t-test",
    "section": "The t-distribution",
    "text": "The t-distribution\nKey features\n\nSymmetry\n\nSymmetric around its mean (zero)\n\nThicker tails\n\nHigher likelihood of observing extreme values or outliers\n\nDegrees of freedom\n\nRelated to the sample size\nAs degrees of freedom increase, the t-distribution approaches the standard normal distribution"
  },
  {
    "objectID": "slides/lec-9.html#when-to-use-it",
    "href": "slides/lec-9.html#when-to-use-it",
    "title": "Week 11: The t-test",
    "section": "When to use it?",
    "text": "When to use it?\n\nUse when comparing the mean of a single sample to a known or hypothesized population mean"
  },
  {
    "objectID": "slides/lec-9.html#assumptions-1",
    "href": "slides/lec-9.html#assumptions-1",
    "title": "Week 11: The t-test",
    "section": "Assumptions",
    "text": "Assumptions\n\nIndependence: Observations in the sample are independent\nNormality: Sample is drawn from a normally distributed population\nEqual variances: Population variances of the two groups are equal\nRandom sampling: Sample is drawn randomly and independently from the population\nSample size: Sample size is large enough (usually &gt; 30) for the Central Limit Theorem"
  },
  {
    "objectID": "slides/lec-9.html#equation",
    "href": "slides/lec-9.html#equation",
    "title": "Week 11: The t-test",
    "section": "Equation",
    "text": "Equation\n\nt = (x̄ - μ) / (s / √n)\nt = (x̄ - μ) / (s_x / √n)"
  },
  {
    "objectID": "slides/lec-9.html#example",
    "href": "slides/lec-9.html#example",
    "title": "Week 11: The t-test",
    "section": "Example",
    "text": "Example\n\nResearch question: Do older adults improve muscle strength following an 8-week exercise program?\nNull Hypothesis (H0): μ_After = 40\nAlternative Hypothesis (H1): μ_After ≠ 40"
  },
  {
    "objectID": "slides/lec-9.html#analyzing-with-jamovi",
    "href": "slides/lec-9.html#analyzing-with-jamovi",
    "title": "Week 11: The t-test",
    "section": "Analyzing with jamovi",
    "text": "Analyzing with jamovi\n\nDownload and install jamovi\nOpen jamovi and import the dataset\nRun the One-sample t-test"
  },
  {
    "objectID": "slides/lec-9.html#analyzing-with-spss",
    "href": "slides/lec-9.html#analyzing-with-spss",
    "title": "Week 11: The t-test",
    "section": "Analyzing with SPSS",
    "text": "Analyzing with SPSS\n\nOpen SPSS and load the dataset\nRun One-sample t-test using the menu or syntax"
  },
  {
    "objectID": "slides/lec-9.html#reporting-results-in-apa-style",
    "href": "slides/lec-9.html#reporting-results-in-apa-style",
    "title": "Week 11: The t-test",
    "section": "Reporting Results in APA Style",
    "text": "Reporting Results in APA Style\n\nDescription of the test used\nStatement of the null and alternative hypotheses\nTest statistic (t-value) with degrees of freedom (df) and p-value\nEffect size (e.g., Cohen’s d)\nConclusion about the null hypothesis\nDiscussion of practical significance and limitations"
  },
  {
    "objectID": "slides/lec-9.html#example-apa-style-reporting",
    "href": "slides/lec-9.html#example-apa-style-reporting",
    "title": "Week 11: The t-test",
    "section": "Example APA Style Reporting",
    "text": "Example APA Style Reporting\n\nOne-sample t-test conducted\nSample mean muscle strength: M = 48.2, SD = 5.35\nt(39) = 9.66, p &lt; .001, Cohen’s d = 1.53\nAssumption of normality violated (Shapiro-Wilk test, p = .032)\nResults should be interpreted with caution\nAlternative: Wilcoxon rank test (non-parametric equivalent)\nRefer to Furtado (2023) for more examples"
  },
  {
    "objectID": "slides/lec-9.html#when-to-use-it-1",
    "href": "slides/lec-9.html#when-to-use-it-1",
    "title": "Week 11: The t-test",
    "section": "When to use it?",
    "text": "When to use it?\n\nCompares the means of two independent groups\nExample: comparing muscle strength between groups who completed or did not complete a resistance training program\nIndependent variable: resistance training program completion\nDependent variable: muscle strength"
  },
  {
    "objectID": "slides/lec-9.html#assumptions-2",
    "href": "slides/lec-9.html#assumptions-2",
    "title": "Week 11: The t-test",
    "section": "Assumptions",
    "text": "Assumptions\n\nNormality: approximately normal distribution within each group\nIndependence: observations in each group are independent\nEqual variances: variances of the two groups should be roughly equal\nRandom Sampling: random and representative samples of the population\nEqual sample size: similar sample sizes in each group\nNon-parametric Alternative\n\nMann-Whitney U test can be used if assumptions are not met"
  },
  {
    "objectID": "slides/lec-9.html#equation---students-t-test-equal-variances",
    "href": "slides/lec-9.html#equation---students-t-test-equal-variances",
    "title": "Week 11: The t-test",
    "section": "Equation - Student’s t-test (Equal Variances)",
    "text": "Equation - Student’s t-test (Equal Variances)\n\\[\nt = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\]\n\n\\(t\\): t-statistic\n\\(\\bar{X}_1\\) and \\(\\bar{X}_2\\): sample means of the two groups\n\\(s_p\\): pooled standard deviation\n\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\n\n\\(n_1\\) and \\(n_2\\): sample sizes of the two groups\n\\(s_1\\) and \\(s_2\\): sample standard deviations of the two groups"
  },
  {
    "objectID": "slides/lec-9.html#equation---welchs-t-test-equal-variance-not-assumed",
    "href": "slides/lec-9.html#equation---welchs-t-test-equal-variance-not-assumed",
    "title": "Week 11: The t-test",
    "section": "Equation - Welch’s t-test (Equal Variance Not Assumed)",
    "text": "Equation - Welch’s t-test (Equal Variance Not Assumed)\n\\[\nt = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\n\n\\(t\\): t-statistic\n\\(\\bar{X}_1\\) and \\(\\bar{X}_2\\): sample means of the two groups\n\\(n_1\\) and \\(n_2\\): sample sizes of the two groups\n\\(s_1\\) and \\(s_2\\): sample standard deviations of the two groups"
  },
  {
    "objectID": "slides/lec-9.html#example-1",
    "href": "slides/lec-9.html#example-1",
    "title": "Week 11: The t-test",
    "section": "Example",
    "text": "Example\nIn this example, the researcher wanted to investigate mean differences between the age groups.\nResearch question\n\nIs there a significant difference in the mean ‘After’ scores between age groups 18-39 and 40-60 in terms of dynamometer performance?\n\nHypothesis statements\n\nNull Hypothesis (H0): μ(18-39) = μ(40-60)\n\nNo significant difference in mean ‘After’ scores between age groups\n\nAlternative Hypothesis (H1): μ(18-39) ≠ μ(40-60)\n\nSignificant difference in mean ‘After’ scores between age groups"
  },
  {
    "objectID": "slides/lec-9.html#analyzing-with-jamovi-1",
    "href": "slides/lec-9.html#analyzing-with-jamovi-1",
    "title": "Week 11: The t-test",
    "section": "Analyzing with jamovi",
    "text": "Analyzing with jamovi\n\nImport the data\nPerform the independent samples t-test\nSet additional options (optional)\nView the results"
  },
  {
    "objectID": "slides/lec-9.html#analyzing-with-spss-1",
    "href": "slides/lec-9.html#analyzing-with-spss-1",
    "title": "Week 11: The t-test",
    "section": "Analyzing with SPSS",
    "text": "Analyzing with SPSS\n\nImport the data\nPerform the independent samples t-test using the menu\nView the results"
  },
  {
    "objectID": "slides/lec-9.html#interpreting-the-results",
    "href": "slides/lec-9.html#interpreting-the-results",
    "title": "Week 11: The t-test",
    "section": "Interpreting the Results",
    "text": "Interpreting the Results\n\nCheck assumptions: normality and equal variances\nExamine descriptive statistics\nInterpret Levene’s test results\nInterpret t-test results: t-value, degrees of freedom, and p-value\nDetermine significance based on p-value\nConsider effect size (Cohen’s d or Hedges’ g)\nInterpret results in context of research question"
  },
  {
    "objectID": "slides/lec-9.html#reporting-results-in-apa-style-1",
    "href": "slides/lec-9.html#reporting-results-in-apa-style-1",
    "title": "Week 11: The t-test",
    "section": "Reporting Results in APA Style",
    "text": "Reporting Results in APA Style\n\nInclude test statistic, degrees of freedom, and p-value\nDescribe compared variables, sample sizes, and means\nState null and alternative hypotheses\nInterpret results (reject or fail to reject null hypothesis)\nReport effect size (Cohen’s d)\nBriefly interpret results in context of research question"
  },
  {
    "objectID": "slides/lec-9.html#example-report",
    "href": "slides/lec-9.html#example-report",
    "title": "Week 11: The t-test",
    "section": "Example Report",
    "text": "Example Report\n\nIndependent-samples t-test results\nSignificant difference in “After” scores between age groups 18-39 and 40-60\n18-39: M = 52.6, SD = 1.84\n40-60: M = 43.7, SD = 43.5\nt(28.1) = 9.80, p &lt; .001, Cohen’s d = 3.10\nWelch’s correction used due to unequal variances"
  },
  {
    "objectID": "slides/lec-9.html#when-to-use-it-2",
    "href": "slides/lec-9.html#when-to-use-it-2",
    "title": "Week 11: The t-test",
    "section": "When to use it?",
    "text": "When to use it?\n\nCompare two sets of related (or paired) data\nAssess effectiveness of different treatments on a group\nPre- and post-test designs\nControl for individual differences"
  },
  {
    "objectID": "slides/lec-9.html#assumptions-3",
    "href": "slides/lec-9.html#assumptions-3",
    "title": "Week 11: The t-test",
    "section": "Assumptions",
    "text": "Assumptions\n\nIndependence: observations within each pair are independent\nNormality: differences between pairs are normally distributed\nEqual variances: variances of differences between pairs are equal\nPaired data: each individual measured twice\nRandom Sampling: sample selected randomly from population"
  },
  {
    "objectID": "slides/lec-9.html#equation-1",
    "href": "slides/lec-9.html#equation-1",
    "title": "Week 11: The t-test",
    "section": "Equation",
    "text": "Equation\n\\[\nt = \\frac{\\bar{d}}{s_d/\\sqrt{n}}\n\\]\n\n\\(\\bar{d}\\): mean difference\n\\(s_d\\): standard deviation of the differences\n\\(n\\): sample size\n\\(t\\): t-statistic"
  },
  {
    "objectID": "slides/lec-9.html#example-2",
    "href": "slides/lec-9.html#example-2",
    "title": "Week 11: The t-test",
    "section": "Example",
    "text": "Example\nA researcher wanted to investigate whether an intervention (such as an exercise program) has a significant effect on muscle strength. Participants were recruited based on specific inclusion criteria (e.g., age range, health status, etc.), and muscle strength measurements (in kg) were taken for each participant both before and after the intervention. The null hypothesis would be that there is no significant difference between the “Before” and “After” measurements, while the alternative hypothesis would be that there is a significant difference. The Paired-samples t test would be an appropriate statistical analysis to test this hypothesis.\nResearch Question\n\nInvestigate difference in muscle strength before and after a training program among participants\n\nHypotheses Statements\n\nNull Hypothesis (H0): \\(\\mu_{D} = 0\\)\nAlternative Hypothesis (H1): \\(\\mu_{D} \\neq 0\\)"
  },
  {
    "objectID": "slides/lec-9.html#analyzing-with-jamovi-2",
    "href": "slides/lec-9.html#analyzing-with-jamovi-2",
    "title": "Week 11: The t-test",
    "section": "Analyzing with jamovi",
    "text": "Analyzing with jamovi\n\nDownload and install jamovi\nOpen jamovi and import the dynamometer.csv dataset\nClick “T-tests” and select “Paired Samples t-test”\nMove Before and After variables under Paired Variables\nSelect desired options\nView results in the “Results” tab"
  },
  {
    "objectID": "slides/lec-9.html#analyzing-with-spss-2",
    "href": "slides/lec-9.html#analyzing-with-spss-2",
    "title": "Week 11: The t-test",
    "section": "Analyzing with SPSS",
    "text": "Analyzing with SPSS\n\nOpen SPSS and import dynamometer.csv dataset\nGo to Analyze &gt; Compare Means &gt; Paired-samples T Test\nSelect “Before” and “After” variables\nClick “Options” and select “Descriptive statistics” and “Paired samples test”\nClick “Continue” and “OK” to run the analysis"
  },
  {
    "objectID": "slides/lec-9.html#interpreting-the-results-1",
    "href": "slides/lec-9.html#interpreting-the-results-1",
    "title": "Week 11: The t-test",
    "section": "Interpreting the Results",
    "text": "Interpreting the Results\n\nCheck the t-test’s p-value\n\np-value &lt; significance level: reject the null hypothesis\np-value &gt; significance level: cannot reject the null hypothesis\n\nEvaluate Cohen’s d\n\nSmall effect: |d| = 0.2\nMedium effect: |d| = 0.5\nLarge effect: |d| = 0.8"
  },
  {
    "objectID": "slides/lec-9.html#reporting-results",
    "href": "slides/lec-9.html#reporting-results",
    "title": "Week 11: The t-test",
    "section": "Reporting Results",
    "text": "Reporting Results\n\nTest statistic and p-value\nSample size\nMean difference and standard deviation of the differences\nEffect size, such as Cohen’s d\n\nSuggested Reporting:\nA Paired-samples t-test was conducted to compare the scores before and after the intervention. There was a significant difference in the scores for before (M = 42.1, SD = 4.42) and after (M = 48.2, SD = 5.35) conditions; t(39) = -31.208, p &lt; .001, 95% CI [-6.495, -5.705], Cohen’s d = 4.93. The results indicate that there is a significant difference between the “Before” and “After” scores, with the “After” scores being higher on average. The effect size (Cohen’s d) is large, suggesting that the intervention had a substantial impact on the scores."
  },
  {
    "objectID": "slides/lec-9.html#references",
    "href": "slides/lec-9.html#references",
    "title": "Week 11: The t-test",
    "section": "References",
    "text": "References\n\n\n\nhttps://drfurtado.github.io/kin610/\n\n\n\nFurtado, Ovande. 2023. “RandomStats - Comparing Two Means.” Blog. RandomStats. April 1, 2023. https://drfurtado.github.io/randomstats/posts/04012023-ttest/."
  },
  {
    "objectID": "slides/lec-8.qmd.html#linear-regression-models",
    "href": "slides/lec-8.qmd.html#linear-regression-models",
    "title": "Week 8: Regression Analysis",
    "section": "Linear Regression Models",
    "text": "Linear Regression Models\n\nA way of measuring the relationship between two variables\nSimilar to Pearson correlation, but more powerful\nCan be used to predict one variable from another"
  },
  {
    "objectID": "slides/lec-8.qmd.html#example-parenthood-data-set",
    "href": "slides/lec-8.qmd.html#example-parenthood-data-set",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood Data Set",
    "text": "Example: Parenthood Data Set\n\n\n\nData set contains measures of sleep and grumpiness for Dani\nHypothesis: less sleep leads to more grumpiness\nScatterplot shows a strong negative correlation (r = -.90)"
  },
  {
    "objectID": "slides/lec-8.qmd.html#regression-line",
    "href": "slides/lec-8.qmd.html#regression-line",
    "title": "Week 8: Regression Analysis",
    "section": "Regression Line",
    "text": "Regression Line\n\nA straight line that best fits the data\nRepresents the average relationship between the variables\nCan be used to estimate grumpiness from sleep"
  },
  {
    "objectID": "slides/lec-8.qmd.html#how-to-draw-a-regression-line",
    "href": "slides/lec-8.qmd.html#how-to-draw-a-regression-line",
    "title": "Week 8: Regression Analysis",
    "section": "How to Draw a Regression Line?",
    "text": "How to Draw a Regression Line?\n\nThe line should go through the middle of the data\nThe line should minimize the vertical distances between the data points and the line\nThe line should have a slope and an intercept that can be calculated from the data"
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-formula-for-a-straight-line",
    "href": "slides/lec-8.qmd.html#the-formula-for-a-straight-line",
    "title": "Week 8: Regression Analysis",
    "section": "The formula for a straight line",
    "text": "The formula for a straight line\n\nUsually written like this: \\(y = a + bx\\)\nTwo variables: \\(x\\) and \\(y\\)\nTwo coefficients: \\(a\\) and \\(b\\)\nCoefficient \\(a\\) represents the y-intercept of the line\nCoefficient \\(b\\) represents the slope of the line"
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-interpretation-of-intercept-and-slope",
    "href": "slides/lec-8.qmd.html#the-interpretation-of-intercept-and-slope",
    "title": "Week 8: Regression Analysis",
    "section": "The interpretation of intercept and slope",
    "text": "The interpretation of intercept and slope\n\n\n\n\n\n\n\n\n\nIntercept: the value of \\(y\\) that you get when \\(x\\) = 0\nSlope: the change in \\(y\\) that you get when you increase \\(x\\) by 1 unit\nPositive slope: \\(y\\) goes up as \\(x\\) goes up\nNegative slope: \\(y\\) goes down as \\(x\\) goes up"
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-formula-for-a-regression-line",
    "href": "slides/lec-8.qmd.html#the-formula-for-a-regression-line",
    "title": "Week 8: Regression Analysis",
    "section": "The formula for a Regression line",
    "text": "The formula for a Regression line\n\nSame as the formula for a straight line, but with some extra notation\nSo if \\(y\\) is the outcome variable (DV) and \\(x\\) is the predictor variable (IV), then:\n\n\\[\\hat{y}_i = b_0 + b_1 x_i\\]\n\\(\\hat{y}_i\\): the predicted value of the outcome variable (\\(y\\)) for observation \\(i\\)\n\\({y}_i\\): the actual value of the outcome variable (\\(y\\)) for observation \\(i\\)\n\\({x}_i\\): the value of the predictor variable (\\(x\\)) for observation \\(i\\)\n\\({b}_0\\): the estimated intercept of the regression line\n\\({b}_1\\): the estimated slope of the regression line\n\nxi is the value of the predictor variable (#of hours on day 1) and yi is the corresponding value of the outcome variable (grumpiness on that day) - works for all observations."
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-assumptions-of-the-regression-model",
    "href": "slides/lec-8.qmd.html#the-assumptions-of-the-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "The assumptions of the regression model",
    "text": "The assumptions of the regression model\n\nWe assume that the formula works for all observations in the data set (i.e., for all i)\nWe distinguish between the actual data \\({y}_i\\) and the estimate \\(\\hat{y}_i\\) (i.e., the prediction that our regression line is making)\nWe use \\(b_0\\) and \\(b_1\\) to refer to the coefficients of the regression model\n\n\\(b_0\\): the estimated intercept of the regression line\n\\(b_1\\): the estimated slope of the regression line"
  },
  {
    "objectID": "slides/lec-8.qmd.html#residuals-of-the-regression-model",
    "href": "slides/lec-8.qmd.html#residuals-of-the-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "Residuals of the Regression model",
    "text": "Residuals of the Regression model\n\n\n\n\nCode\n# Generate some example data with a strong negative correlation\nset.seed(123)\nx &lt;- rnorm(100)\ny &lt;- -0.8*x + rnorm(100, sd=0.5)\n\n# Plot the data\nplot(x,y)\n\n# Add the best fit line\nabline(lm(y ~ x), col=\"red\")\n\n\n\n\n\nNow, we have the complete linear regression model\n\\[\\hat{y}_i = b_0 + b_1 x_i + {e}_i\\]\n\n\nThe data do not fall perfectly on the regression line\nThe difference between the model prediction and that actual data point is called a residual, and we refer to it as \\({e}_i\\)\nMathematically, the residuals are defined as \\({e}_i = {y}_i - \\hat{y}_i\\)\nThe residuals measure how well the regression line fits the data\n\nSmaller residuals: better fit\nLarger residuals: worse fit"
  },
  {
    "objectID": "slides/lec-8.qmd.html#estimating-a-linear-regression-model",
    "href": "slides/lec-8.qmd.html#estimating-a-linear-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "Estimating a linear regression model",
    "text": "Estimating a linear regression model\n\nWe want to find the regression line that fits the data best\nWe can measure how well the regression line fits the data by looking at the residuals\nThe residuals are the differences between the actual data and the model predictions\nSmaller residuals mean better fit, larger residuals mean worse fit"
  },
  {
    "objectID": "slides/lec-8.qmd.html#ordinary-least-squares-regression",
    "href": "slides/lec-8.qmd.html#ordinary-least-squares-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Ordinary least squares regression",
    "text": "Ordinary least squares regression\n\nWe use the method of least squares to estimate the regression coefficients\nThe regression coefficients are estimates of the population parameters\nWe use \\(\\hat{b}_0\\) and \\(\\hat{b}_1\\) to denote the estimated coefficients\nOrdinary least squares (OLS) regression is the most common way to estimate a linear regression model"
  },
  {
    "objectID": "slides/lec-8.qmd.html#how-to-find-the-estimated-coefficients",
    "href": "slides/lec-8.qmd.html#how-to-find-the-estimated-coefficients",
    "title": "Week 8: Regression Analysis",
    "section": "How to find the estimated coefficients",
    "text": "How to find the estimated coefficients\n\nThere are formulas to calculate \\(\\hat{b}_0\\) and \\(\\hat{b}_1\\) from the data\nThe formulas involve some algebra and calculus that are not essential to understand the logic of regression\nWe can use jamovi to do all the calculations for us\njamovi will also provide other useful information about the regression model"
  },
  {
    "objectID": "slides/lec-8.qmd.html#linear-regression-in-jamovi",
    "href": "slides/lec-8.qmd.html#linear-regression-in-jamovi",
    "title": "Week 8: Regression Analysis",
    "section": "Linear Regression in jamovi",
    "text": "Linear Regression in jamovi\n\n\n\nWe can use jamovi to estimate a linear regression model from the data\nWe need to specify the dependent variable and the covariate(s) in the analysis\njamovi will output the estimated coefficients and other statistics"
  },
  {
    "objectID": "slides/lec-8.qmd.html#example-parenthood-data",
    "href": "slides/lec-8.qmd.html#example-parenthood-data",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\nData file: parenthood.csv (found in module lsj data in jamovi)\nDependent variable: dani.grump (Dani’s grumpiness)\nCovariate: dani.sleep (Dani’s hours of sleep)\nEstimated intercept: \\(\\hat{b}_0\\) = 125.96\nEstimated slope: \\(\\hat{b}_1\\) = -8.94\nRegression equation: \\(\\hat{Y}_i = 125.96+(-8.94 X_i)\\)"
  },
  {
    "objectID": "slides/lec-8.qmd.html#interpreting-the-estimated-model",
    "href": "slides/lec-8.qmd.html#interpreting-the-estimated-model",
    "title": "Week 8: Regression Analysis",
    "section": "Interpreting the estimated model",
    "text": "Interpreting the estimated model\n\nWe need to understand what the estimated coefficients mean\nThe slope \\(\\hat{b}_1\\) tells us how much the dependent variable changes when the covariate increases by one unit\nThe intercept \\(\\hat{b}_0\\) tells us what the expected value of the dependent variable is when the covariate is zero"
  },
  {
    "objectID": "slides/lec-8.qmd.html#example-parenthood-data-1",
    "href": "slides/lec-8.qmd.html#example-parenthood-data-1",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\n\nDependent variable: dani.grump (Dani’s grumpiness)\nCovariate: dani.sleep (Dani’s hours of sleep)\nEstimated slope: \\(\\hat{b}_1\\) = -8.94\n\nInterpretation: Each additional hour of sleep reduces grumpiness by 8.94 points\n\nEstimated intercept: \\(\\hat{b}_0\\) = 125.96\n\nInterpretation: If Dani gets zero hours of sleep, her grumpiness will be 125.96 points"
  },
  {
    "objectID": "slides/lec-8.qmd.html#introduction",
    "href": "slides/lec-8.qmd.html#introduction",
    "title": "Week 8: Regression Analysis",
    "section": "Introduction",
    "text": "Introduction\n\nWe can use more than one predictor variable to explain the variation in the outcome variable\n\nAdd more terms to our regression equation to represent each predictor variable\n\nEach term has a coefficient that indicates how much the outcome variable changes when that predictor variable increases by one unit"
  },
  {
    "objectID": "slides/lec-8.qmd.html#example-parenthood-data-2",
    "href": "slides/lec-8.qmd.html#example-parenthood-data-2",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\n\nOutcome variable: dani.grump (Dani’s grumpiness)\nPredictor variables: dani.sleep (Dani’s hours of sleep) and baby.sleep (Baby’s hours of sleep)\n\nRegression equation: \\(Y_i=b_0+b_1X_{i1}+b_2X_{i2}+\\epsilon_i\\)\n\\(Y_i\\): Dani’s grumpiness on day \\(i\\)\n\\(X_{i1}\\): Dani’s hours of sleep on day \\(i\\)\n\\(X_{i2}\\): Baby’s hours of sleep on day \\(i\\)\n\\(b_0\\): Intercept\n\\(b_1\\): Coefficient for Dani’s sleep\n\\(b_2\\): Coefficient for Baby’s sleep\n\\(\\epsilon_i\\): Error term on day \\(i\\)"
  },
  {
    "objectID": "slides/lec-8.qmd.html#estimating-the-coefficients-in-multiple-regression",
    "href": "slides/lec-8.qmd.html#estimating-the-coefficients-in-multiple-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Estimating the coefficients in multiple regression",
    "text": "Estimating the coefficients in multiple regression\n\nWe want to find the coefficients that minimize the sum of squared residuals\nResiduals are the differences between the observed and predicted values of the outcome variable\nWe use a similar method as in simple regression, but with more terms in the equation"
  },
  {
    "objectID": "slides/lec-8.qmd.html#doing-it-in-jamovi",
    "href": "slides/lec-8.qmd.html#doing-it-in-jamovi",
    "title": "Week 8: Regression Analysis",
    "section": "Doing it in jamovi",
    "text": "Doing it in jamovi\n\n\n\n\n\njamovi can estimate multiple regression models easily\nWe just need to add more variables to the Covariates box in the analysis\njamovi will output the estimated coefficients and other statistics for each predictor variable\nThe Table shows the coefficients for dani.sleep and baby.sleep as predictors of dani.grump"
  },
  {
    "objectID": "slides/lec-8.qmd.html#interpreting-the-coefficients-in-multiple-regression",
    "href": "slides/lec-8.qmd.html#interpreting-the-coefficients-in-multiple-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Interpreting the coefficients in multiple regression",
    "text": "Interpreting the coefficients in multiple regression\n\nThe coefficients tell us how much the outcome variable changes when one predictor variable increases by one unit, holding the other predictor variables constant\nThe larger the absolute value of the coefficient, the stronger the effect of that predictor variable on the outcome variable\nThe sign of the coefficient indicates whether the effect is positive or negative"
  },
  {
    "objectID": "slides/lec-8.qmd.html#example-parenthood-data-3",
    "href": "slides/lec-8.qmd.html#example-parenthood-data-3",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\n\nCoefficient (slope) for dani.sleep: -8.94\n\nInterpretation: Each additional hour of sleep reduces Dani’s grumpiness by 8.94 points, regardless of how much sleep the baby gets\n\nCoefficient (slope) for baby.sleep: 0.01\n\nInterpretation: Each additional hour of sleep for the baby increases Dani’s grumpiness by 0.01 points, regardless of how much sleep Dani gets"
  },
  {
    "objectID": "slides/lec-8.qmd.html#quantifying-the-fit-of-the-regression-model",
    "href": "slides/lec-8.qmd.html#quantifying-the-fit-of-the-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "Quantifying the fit of the regression model",
    "text": "Quantifying the fit of the regression model\n\nWe want to know how well our regression model predicts the outcome variable\nWe can compare the predicted values ( \\(\\hat{Y}_i\\) ) to the observed values ( \\(Y_i\\) ) using two sums of squares\n\nResidual sum of squares ( \\(SS_{res}\\) ): measures how much error there is in our predictions\nTotal sum of squares ( \\(SS_{tot}\\) ): measures how much variability there is in the outcome variable"
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-r2-value-effect-size",
    "href": "slides/lec-8.qmd.html#the-r2-value-effect-size",
    "title": "Week 8: Regression Analysis",
    "section": "The \\(R^2\\) value (effect size)",
    "text": "The \\(R^2\\) value (effect size)\n\nThe \\(R^2\\) value is a proportion that tells us how much of the variability in the outcome variable is explained by our regression model\nIt is calculated as:\n\n\\[R^2=1-\\frac{SS_{res}}{SS_{tot}}\\]\n\nIt ranges from 0 to 1, with higher values indicating better fit\nIt can be interpreted as the percentage of variance explained by our regression model"
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-relationship-between-regression-and-correlation",
    "href": "slides/lec-8.qmd.html#the-relationship-between-regression-and-correlation",
    "title": "Week 8: Regression Analysis",
    "section": "The relationship between regression and correlation",
    "text": "The relationship between regression and correlation\n\nRegression and correlation are both ways of measuring the strength and direction of a linear relationship between two variables\nFor a simple regression model with one predictor variable, the \\(R^2\\) value is equal to the square of the Pearson correlation coefficient (\\(r^2\\))\n\nRunning a Pearson correlation is equivalent to running a simple linear regression model"
  },
  {
    "objectID": "slides/lec-8.qmd.html#the-adjusted-r2-value",
    "href": "slides/lec-8.qmd.html#the-adjusted-r2-value",
    "title": "Week 8: Regression Analysis",
    "section": "The adjusted \\(R^2\\) value",
    "text": "The adjusted \\(R^2\\) value\n\nThe adjusted \\(R^2\\) value is a modified version of the \\(R^2\\) value that takes into account the number of predictors in the model\n\nThe adjusted \\(R^2\\) value adjusts for the degrees of freedom in the model\n\nIt increases only if adding a predictor improves the model more than expected by chance"
  },
  {
    "objectID": "slides/lec-8.qmd.html#which-one-to-report-r2-or-adjusted-r2",
    "href": "slides/lec-8.qmd.html#which-one-to-report-r2-or-adjusted-r2",
    "title": "Week 8: Regression Analysis",
    "section": "Which one to report: \\(R^2\\) or adjusted \\(R^2\\)?",
    "text": "Which one to report: \\(R^2\\) or adjusted \\(R^2\\)?\n\nThere is no definitive answer to this question\nIt depends on your preference and your research question\nSome factors to consider are:\n\nInterpretability: \\(R^2\\) is easier to understand and explain\nBias correction: Adjusted \\(R^2\\) is less likely to overestimate the model performance\nHypothesis testing: There are other ways to test if adding a predictor improves the model significantly"
  },
  {
    "objectID": "slides/lec-8.qmd.html#hypothesis-tests-for-regression-models",
    "href": "slides/lec-8.qmd.html#hypothesis-tests-for-regression-models",
    "title": "Week 8: Regression Analysis",
    "section": "Hypothesis tests for regression models",
    "text": "Hypothesis tests for regression models\n\nWe can use hypothesis tests to evaluate the significance of our regression model and its coefficients\nThere are two types of hypothesis tests for regression models:\n\nTesting the model as a whole: Is there any relationship between the predictors and the outcome?\nTesting a specific coefficient: Is a particular predictor significantly related to the outcome?"
  },
  {
    "objectID": "slides/lec-8.qmd.html#test-the-model-as-a-whole",
    "href": "slides/lec-8.qmd.html#test-the-model-as-a-whole",
    "title": "Week 8: Regression Analysis",
    "section": "Test the model as a whole",
    "text": "Test the model as a whole\n\\(H_0\\): there is no relationship between the predictors and the outcome\n\\(H_a\\): data follow the regression model\n\\[F=\\frac{(R^2/K)}{(1-R^2)/(N-K-1)}\\]\n\nwhere \\(R^2\\) is the proportion of variance explained by our model, \\(K\\) is the number of predictors, and \\(N\\) is the number of observations\nThe F-test statistic follows an F-distribution with \\(K\\) and \\(N-K-1\\) degrees of freedom\nWe can use a p-value to determine if our F-test statistic is significant\n jamovi can do this for us!"
  },
  {
    "objectID": "slides/lec-8.qmd.html#tests-for-individual-coefficients",
    "href": "slides/lec-8.qmd.html#tests-for-individual-coefficients",
    "title": "Week 8: Regression Analysis",
    "section": "Tests for Individual Coefficients",
    "text": "Tests for Individual Coefficients\n\nThe F-test checks if the model as a whole is performing better than chance\nIf the F-test is not significant, then the regression model may not be good\nHowever, passing the F-test does not imply that the model is good"
  },
  {
    "objectID": "slides/lec-8.qmd.html#example-of-multiple-linear-regression",
    "href": "slides/lec-8.qmd.html#example-of-multiple-linear-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Example of Multiple Linear Regression",
    "text": "Example of Multiple Linear Regression\n\nIn a multiple linear regression model with baby.sleep and dani.sleep as predictors:\n\nThe estimated regression coefficient for baby.sleep is small (0.01) compared to dani.sleep (-.8.95)\nThis suggests that only dani.sleep matters in predicting grumpiness"
  },
  {
    "objectID": "slides/lec-8.qmd.html#hypothesis-testing-for-regression-coefficients",
    "href": "slides/lec-8.qmd.html#hypothesis-testing-for-regression-coefficients",
    "title": "Week 8: Regression Analysis",
    "section": "Hypothesis Testing for Regression Coefficients",
    "text": "Hypothesis Testing for Regression Coefficients\n\nA t-test can be used to test if a regression coefficient is significantly different from zero\n\n\\(H_0\\): b = 0 (the true regression coefficient is zero)\n\\(H_0\\): b ≠ 0 (the true regression coefficient is not zero)"
  },
  {
    "objectID": "slides/lec-8.qmd.html#running-hypothesis-tests-in-jamovi",
    "href": "slides/lec-8.qmd.html#running-hypothesis-tests-in-jamovi",
    "title": "Week 8: Regression Analysis",
    "section": "Running Hypothesis Tests in Jamovi",
    "text": "Running Hypothesis Tests in Jamovi\n\nTo compute statistics, check relevant options and run regression in jamovi\nSee result in the next slide"
  },
  {
    "objectID": "slides/lec-8.qmd.html#output",
    "href": "slides/lec-8.qmd.html#output",
    "title": "Week 8: Regression Analysis",
    "section": "Output",
    "text": "Output\n\n\nModel Coefficients\n\nLocated at bottom of jamovi analysis results\nEach row refers to one coefficient in regression model\nFirst row is intercept term; later rows look at each predictor\n\nCoefficient Information\n\nFirst column: estimate of b\nSecond column: standard error estimate\nThird and fourth columns: lower and upper values for 95% confidence interval around b estimate\nFifth column: t-statistic ( \\(t = b / se(b)\\) )\nLast column: p-value for each test\n\nDegrees of Freedom\n\nNot listed in coefficients table itself\nAlways N - K - 1\nListed in table at top of output"
  },
  {
    "objectID": "slides/lec-8.qmd.html#interpretation",
    "href": "slides/lec-8.qmd.html#interpretation",
    "title": "Week 8: Regression Analysis",
    "section": "Interpretation",
    "text": "Interpretation\n\n\n\nConclusion\n\nThe current regression model may not be the best fit for the data\nDropping baby.sleep predictor entirely may improve the model\n\n\n\nThe model performs significantly better than chance\n\n\\(F(2,97) = 215.24\\), \\(p&lt; .001\\)\n\\(R^2 = .81\\) value indicates that the regression model accounts for 81% of the variability in the outcome measure\n\nIndividual Coefficients\n\nbaby.sleep variable has no significant effect\nAll work in this model is being done by the dani.sleep variable"
  },
  {
    "objectID": "slides/lec-8.qmd.html#assumptions-of-regression",
    "href": "slides/lec-8.qmd.html#assumptions-of-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Assumptions of Regression",
    "text": "Assumptions of Regression\nThe linear regression model relies on several assumptions.\n\nLinearity: The relationship between X and Y is assumed to be linear.\nIndependence: Residuals are assumed to be independent of each other.\nNormality: The residuals are assumed to be normally distributed.\nEquality of Variance: The standard deviation of the residual is assumed to be the same for all values of Y-hat."
  },
  {
    "objectID": "slides/lec-8.qmd.html#assumptions-of-regression-cont.",
    "href": "slides/lec-8.qmd.html#assumptions-of-regression-cont.",
    "title": "Week 8: Regression Analysis",
    "section": "Assumptions of Regression, cont.",
    "text": "Assumptions of Regression, cont.\nAlso…\n\nUncorrelated Predictors: In a multiple regression model, predictors should not be too strongly correlated with each other.\n\nStrongly correlated predictors (collinearity) can cause problems when evaluating the model.\n\nNo “Bad” Outliers: The regression model should not be too strongly influenced by one or two anomalous data points.\n\nAnomalous data points can raise questions about the adequacy of the model and trustworthiness of data."
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-linearity",
    "href": "slides/lec-8.qmd.html#checking-for-linearity",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for linearity",
    "text": "Checking for linearity\n\n\n\n\nChecking Linearity\n\nIt is important to check for the linearity of relationships between predictors and outcomes.\n\nPlotting Relationships\n\nOne way to check for linearity is to plot the relationship between predicted values and observed values for the outcome variable.\n\nUsing Jamovi\n\nIn Jamovi, you can save predicted values to the dataset and then draw a scatterplot of observed against predicted (fitted) values.\n\nInterpreting Results\n\nIf the plot looks approximately linear, then it suggests that your model is not doing too badly. However, if there are big departures from linearity, it suggests that changes need to be made."
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-linearity-cont.",
    "href": "slides/lec-8.qmd.html#checking-for-linearity-cont.",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for linearity, cont.",
    "text": "Checking for linearity, cont.\n\n\n\n\nTo get a more detailed picture of linearity, it can be helpful to look at the relationship between predicted values and residuals.\nUsing Jamovi\n\nIn Jamovi, you can save residuals to the dataset and then draw a scatterplot of predicted values against residual values.\n\nInterpreting Results\n\nIdeally, the relationship between predicted values and residuals should be a straight, perfectly horizontal line. In practice, we’re looking for a reasonably straight or flat line. This is a matter of judgement."
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-normality-residuals",
    "href": "slides/lec-8.qmd.html#checking-for-normality-residuals",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for normality (residuals)",
    "text": "Checking for normality (residuals)\n\n\n\n\nRegression models rely on a normality assumption: the residuals should be normally distributed.\nUsing Jamovi\n\nIn Jamovi, you can draw a QQ-plot via the ‘Assumption Checks’ - ‘Assumption Checks’ - ‘Q-Q plot of residuals’ option.\n\nInterpreting Results\n\nThe output shows the standardized residuals plotted as a function of their theoretical quantiles according to the regression model. The dots should be somewhat near the line."
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-normality-residuals-cont.",
    "href": "slides/lec-8.qmd.html#checking-for-normality-residuals-cont.",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for normality (residuals), cont.",
    "text": "Checking for normality (residuals), cont.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChecking Relationship between Predicted Values and Residuals\n\nIn Jamovi, you can use the ‘Residuals Plots’ option to check the relationship between predicted values and residuals.\nThe output provides a scatterplot for each predictor variable, the outcome variable, and the predicted values against residuals.\n\nInterpreting Results\n\nWe are looking for a fairly uniform distribution of dots with no clear bunching or patterning.\n\nThe dots are fairly evenly spread across the whole plot \n\nIssues with the relationship between predicted values and residuals? \n\nTransform one or more of the variables (Box-Cox Transform in jamovi)"
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-equality-of-variance",
    "href": "slides/lec-8.qmd.html#checking-for-equality-of-variance",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for equality of variance",
    "text": "Checking for equality of variance\n\n\n\n\nRegression models make an assumption of equality (homogeneity) of variance.\n\nThis means that the variance of the residuals is assumed to be constant.\n\nPlotting Equality of Variance in Jamovi\n\nTo check this assumption in Jamovi, first calculate the square root of the absolute size of the residual.\n\nCompute this new variable using the formula SQRT(ABS(Residuals))\n\nThen plot this against the predicted values.\nThe plot should show a straight horizontal line running through the middle."
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-collineary",
    "href": "slides/lec-8.qmd.html#checking-for-collineary",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for Collineary",
    "text": "Checking for Collineary\n\n\n\n\n\nVariance Inflation Factors (VIFs) can be used to determine if predictors in a regression model are too highly correlated with each other.\n\nEach predictor has an associated VIF.\n\nIn Jamovi, click on the ‘Collinearity’ checkbox in the ‘Regression’ - ‘Assumptions’ options to see VIF values.\nInterpreting VIF\n\nA VIF of 1 means no correlation among the predictor and the remaining predictor variables\nVIFs exceeding 4 warrant further investigation\nVIFs exceeding 10 are signs of serious multicollinearity requiring correction"
  },
  {
    "objectID": "slides/lec-8.qmd.html#checking-for-outliers",
    "href": "slides/lec-8.qmd.html#checking-for-outliers",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for outliers",
    "text": "Checking for outliers\n\n\n\n\n\nUsed in regression analysis to identify influential data points that may negatively affect your regression model\nDatasets with a large number of highly influential points might not be suitable for linear regression without further processing such as outlier removal or imputation\nIdentifying Outliers\n\nA general rule of thumb: Cook’s distance greater than 1 is often considered large\n\nWhat if the value is greater than 1?\n\nremove the outlier and run the regression again\nHow? In jamovi you can save the Cook’s distance values to the dataset, then draw a boxplot of the Cook’s distance values to identify the specific outliers."
  },
  {
    "objectID": "slides/lec-8.qmd.html#references",
    "href": "slides/lec-8.qmd.html#references",
    "title": "Week 8: Regression Analysis",
    "section": "References",
    "text": "References\n\n\n\nhttps://drfurtado.github.io/kin610/\n\n\n\nNavarro, Danielle J, and David R Foxcroft. 2022. Learning Statistics with Jamovi: A Tutorial for Psychology Students and Other Beginners (Version 0.75). Danielle J. Navarro; David R. Foxcroft. https://doi.org/10.24384/HGC3-7P15."
  },
  {
    "objectID": "slides/lec-8.html",
    "href": "slides/lec-8.html",
    "title": "Week 8: Regression Analysis",
    "section": "",
    "text": "Navarro and Foxcroft (2022)"
  },
  {
    "objectID": "slides/lec-8.html#linear-regression-models",
    "href": "slides/lec-8.html#linear-regression-models",
    "title": "Week 8: Regression Analysis",
    "section": "Linear Regression Models",
    "text": "Linear Regression Models\n\nA way of measuring the relationship between two variables\nSimilar to Pearson correlation, but more powerful\nCan be used to predict one variable from another"
  },
  {
    "objectID": "slides/lec-8.html#example-parenthood-data-set",
    "href": "slides/lec-8.html#example-parenthood-data-set",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood Data Set",
    "text": "Example: Parenthood Data Set\n\n\n\nData set contains measures of sleep and grumpiness for Dani\nHypothesis: less sleep leads to more grumpiness\nScatterplot shows a strong negative correlation (r = -.90)"
  },
  {
    "objectID": "slides/lec-8.html#regression-line",
    "href": "slides/lec-8.html#regression-line",
    "title": "Week 8: Regression Analysis",
    "section": "Regression Line",
    "text": "Regression Line\n\nA straight line that best fits the data\nRepresents the average relationship between the variables\nCan be used to estimate grumpiness from sleep"
  },
  {
    "objectID": "slides/lec-8.html#how-to-draw-a-regression-line",
    "href": "slides/lec-8.html#how-to-draw-a-regression-line",
    "title": "Week 8: Regression Analysis",
    "section": "How to Draw a Regression Line?",
    "text": "How to Draw a Regression Line?\n\nThe line should go through the middle of the data\nThe line should minimize the vertical distances between the data points and the line\nThe line should have a slope and an intercept that can be calculated from the data"
  },
  {
    "objectID": "slides/lec-8.html#the-formula-for-a-straight-line",
    "href": "slides/lec-8.html#the-formula-for-a-straight-line",
    "title": "Week 8: Regression Analysis",
    "section": "The formula for a straight line",
    "text": "The formula for a straight line\n\nUsually written like this: \\(y = a + bx\\)\nTwo variables: \\(x\\) and \\(y\\)\nTwo coefficients: \\(a\\) and \\(b\\)\nCoefficient \\(a\\) represents the y-intercept of the line\nCoefficient \\(b\\) represents the slope of the line"
  },
  {
    "objectID": "slides/lec-8.html#the-interpretation-of-intercept-and-slope",
    "href": "slides/lec-8.html#the-interpretation-of-intercept-and-slope",
    "title": "Week 8: Regression Analysis",
    "section": "The interpretation of intercept and slope",
    "text": "The interpretation of intercept and slope\n\n\n\n\n\n\n\n\n\nIntercept: the value of \\(y\\) that you get when \\(x\\) = 0\nSlope: the change in \\(y\\) that you get when you increase \\(x\\) by 1 unit\nPositive slope: \\(y\\) goes up as \\(x\\) goes up\nNegative slope: \\(y\\) goes down as \\(x\\) goes up"
  },
  {
    "objectID": "slides/lec-8.html#the-formula-for-a-regression-line",
    "href": "slides/lec-8.html#the-formula-for-a-regression-line",
    "title": "Week 8: Regression Analysis",
    "section": "The formula for a Regression line",
    "text": "The formula for a Regression line\n\nSame as the formula for a straight line, but with some extra notation\nSo if \\(y\\) is the outcome variable (DV) and \\(x\\) is the predictor variable (IV), then:\n\n\\[\\hat{y}_i = b_0 + b_1 x_i\\]\n\\(\\hat{y}_i\\): the predicted value of the outcome variable (\\(y\\)) for observation \\(i\\)\n\\({y}_i\\): the actual value of the outcome variable (\\(y\\)) for observation \\(i\\)\n\\({x}_i\\): the value of the predictor variable (\\(x\\)) for observation \\(i\\)\n\\({b}_0\\): the estimated intercept of the regression line\n\\({b}_1\\): the estimated slope of the regression line\n\nxi is the value of the predictor variable (#of hours on day 1) and yi is the corresponding value of the outcome variable (grumpiness on that day) - works for all observations."
  },
  {
    "objectID": "slides/lec-8.html#the-assumptions-of-the-regression-model",
    "href": "slides/lec-8.html#the-assumptions-of-the-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "The assumptions of the regression model",
    "text": "The assumptions of the regression model\n\nWe assume that the formula works for all observations in the data set (i.e., for all i)\nWe distinguish between the actual data \\({y}_i\\) and the estimate \\(\\hat{y}_i\\) (i.e., the prediction that our regression line is making)\nWe use \\(b_0\\) and \\(b_1\\) to refer to the coefficients of the regression model\n\n\\(b_0\\): the estimated intercept of the regression line\n\\(b_1\\): the estimated slope of the regression line"
  },
  {
    "objectID": "slides/lec-8.html#residuals-of-the-regression-model",
    "href": "slides/lec-8.html#residuals-of-the-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "Residuals of the Regression model",
    "text": "Residuals of the Regression model\n\n\n\n# Generate some example data with a strong negative correlation\nset.seed(123)\nx &lt;- rnorm(100)\ny &lt;- -0.8*x + rnorm(100, sd=0.5)\n\n# Plot the data\nplot(x,y)\n\n# Add the best fit line\nabline(lm(y ~ x), col=\"red\")\n\n\n\n\nNow, we have the complete linear regression model\n\\[\\hat{y}_i = b_0 + b_1 x_i + {e}_i\\]\n\n\nThe data do not fall perfectly on the regression line\nThe difference between the model prediction and that actual data point is called a residual, and we refer to it as \\({e}_i\\)\nMathematically, the residuals are defined as \\({e}_i = {y}_i - \\hat{y}_i\\)\nThe residuals measure how well the regression line fits the data\n\nSmaller residuals: better fit\nLarger residuals: worse fit"
  },
  {
    "objectID": "slides/lec-8.html#estimating-a-linear-regression-model",
    "href": "slides/lec-8.html#estimating-a-linear-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "Estimating a linear regression model",
    "text": "Estimating a linear regression model\n\nWe want to find the regression line that fits the data best\nWe can measure how well the regression line fits the data by looking at the residuals\nThe residuals are the differences between the actual data and the model predictions\nSmaller residuals mean better fit, larger residuals mean worse fit"
  },
  {
    "objectID": "slides/lec-8.html#ordinary-least-squares-regression",
    "href": "slides/lec-8.html#ordinary-least-squares-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Ordinary least squares regression",
    "text": "Ordinary least squares regression\n\nWe use the method of least squares to estimate the regression coefficients\nThe regression coefficients are estimates of the population parameters\nWe use \\(\\hat{b}_0\\) and \\(\\hat{b}_1\\) to denote the estimated coefficients\nOrdinary least squares (OLS) regression is the most common way to estimate a linear regression model"
  },
  {
    "objectID": "slides/lec-8.html#how-to-find-the-estimated-coefficients",
    "href": "slides/lec-8.html#how-to-find-the-estimated-coefficients",
    "title": "Week 8: Regression Analysis",
    "section": "How to find the estimated coefficients",
    "text": "How to find the estimated coefficients\n\nThere are formulas to calculate \\(\\hat{b}_0\\) and \\(\\hat{b}_1\\) from the data\nThe formulas involve some algebra and calculus that are not essential to understand the logic of regression\nWe can use jamovi to do all the calculations for us\njamovi will also provide other useful information about the regression model"
  },
  {
    "objectID": "slides/lec-8.html#linear-regression-in-jamovi",
    "href": "slides/lec-8.html#linear-regression-in-jamovi",
    "title": "Week 8: Regression Analysis",
    "section": "Linear Regression in jamovi",
    "text": "Linear Regression in jamovi\n\n\n\nWe can use jamovi to estimate a linear regression model from the data\nWe need to specify the dependent variable and the covariate(s) in the analysis\njamovi will output the estimated coefficients and other statistics"
  },
  {
    "objectID": "slides/lec-8.html#example-parenthood-data",
    "href": "slides/lec-8.html#example-parenthood-data",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\nData file: parenthood.csv (found in module lsj data in jamovi)\nDependent variable: dani.grump (Dani’s grumpiness)\nCovariate: dani.sleep (Dani’s hours of sleep)\nEstimated intercept: \\(\\hat{b}_0\\) = 125.96\nEstimated slope: \\(\\hat{b}_1\\) = -8.94\nRegression equation: \\(\\hat{Y}_i = 125.96+(-8.94 X_i)\\)"
  },
  {
    "objectID": "slides/lec-8.html#interpreting-the-estimated-model",
    "href": "slides/lec-8.html#interpreting-the-estimated-model",
    "title": "Week 8: Regression Analysis",
    "section": "Interpreting the estimated model",
    "text": "Interpreting the estimated model\n\nWe need to understand what the estimated coefficients mean\nThe slope \\(\\hat{b}_1\\) tells us how much the dependent variable changes when the covariate increases by one unit\nThe intercept \\(\\hat{b}_0\\) tells us what the expected value of the dependent variable is when the covariate is zero"
  },
  {
    "objectID": "slides/lec-8.html#example-parenthood-data-1",
    "href": "slides/lec-8.html#example-parenthood-data-1",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\n\nDependent variable: dani.grump (Dani’s grumpiness)\nCovariate: dani.sleep (Dani’s hours of sleep)\nEstimated slope: \\(\\hat{b}_1\\) = -8.94\n\nInterpretation: Each additional hour of sleep reduces grumpiness by 8.94 points\n\nEstimated intercept: \\(\\hat{b}_0\\) = 125.96\n\nInterpretation: If Dani gets zero hours of sleep, her grumpiness will be 125.96 points"
  },
  {
    "objectID": "slides/lec-8.html#introduction",
    "href": "slides/lec-8.html#introduction",
    "title": "Week 8: Regression Analysis",
    "section": "Introduction",
    "text": "Introduction\n\nWe can use more than one predictor variable to explain the variation in the outcome variable\n\nAdd more terms to our regression equation to represent each predictor variable\n\nEach term has a coefficient that indicates how much the outcome variable changes when that predictor variable increases by one unit"
  },
  {
    "objectID": "slides/lec-8.html#example-parenthood-data-2",
    "href": "slides/lec-8.html#example-parenthood-data-2",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\n\nOutcome variable: dani.grump (Dani’s grumpiness)\nPredictor variables: dani.sleep (Dani’s hours of sleep) and baby.sleep (Baby’s hours of sleep)\n\nRegression equation: \\(Y_i=b_0+b_1X_{i1}+b_2X_{i2}+\\epsilon_i\\)\n\\(Y_i\\): Dani’s grumpiness on day \\(i\\)\n\\(X_{i1}\\): Dani’s hours of sleep on day \\(i\\)\n\\(X_{i2}\\): Baby’s hours of sleep on day \\(i\\)\n\\(b_0\\): Intercept\n\\(b_1\\): Coefficient for Dani’s sleep\n\\(b_2\\): Coefficient for Baby’s sleep\n\\(\\epsilon_i\\): Error term on day \\(i\\)"
  },
  {
    "objectID": "slides/lec-8.html#estimating-the-coefficients-in-multiple-regression",
    "href": "slides/lec-8.html#estimating-the-coefficients-in-multiple-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Estimating the coefficients in multiple regression",
    "text": "Estimating the coefficients in multiple regression\n\nWe want to find the coefficients that minimize the sum of squared residuals\nResiduals are the differences between the observed and predicted values of the outcome variable\nWe use a similar method as in simple regression, but with more terms in the equation"
  },
  {
    "objectID": "slides/lec-8.html#doing-it-in-jamovi",
    "href": "slides/lec-8.html#doing-it-in-jamovi",
    "title": "Week 8: Regression Analysis",
    "section": "Doing it in jamovi",
    "text": "Doing it in jamovi\n\n\n\n\n\njamovi can estimate multiple regression models easily\nWe just need to add more variables to the Covariates box in the analysis\njamovi will output the estimated coefficients and other statistics for each predictor variable\nThe Table shows the coefficients for dani.sleep and baby.sleep as predictors of dani.grump"
  },
  {
    "objectID": "slides/lec-8.html#interpreting-the-coefficients-in-multiple-regression",
    "href": "slides/lec-8.html#interpreting-the-coefficients-in-multiple-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Interpreting the coefficients in multiple regression",
    "text": "Interpreting the coefficients in multiple regression\n\nThe coefficients tell us how much the outcome variable changes when one predictor variable increases by one unit, holding the other predictor variables constant\nThe larger the absolute value of the coefficient, the stronger the effect of that predictor variable on the outcome variable\nThe sign of the coefficient indicates whether the effect is positive or negative"
  },
  {
    "objectID": "slides/lec-8.html#example-parenthood-data-3",
    "href": "slides/lec-8.html#example-parenthood-data-3",
    "title": "Week 8: Regression Analysis",
    "section": "Example: Parenthood data",
    "text": "Example: Parenthood data\n\nCoefficient (slope) for dani.sleep: -8.94\n\nInterpretation: Each additional hour of sleep reduces Dani’s grumpiness by 8.94 points, regardless of how much sleep the baby gets\n\nCoefficient (slope) for baby.sleep: 0.01\n\nInterpretation: Each additional hour of sleep for the baby increases Dani’s grumpiness by 0.01 points, regardless of how much sleep Dani gets"
  },
  {
    "objectID": "slides/lec-8.html#quantifying-the-fit-of-the-regression-model",
    "href": "slides/lec-8.html#quantifying-the-fit-of-the-regression-model",
    "title": "Week 8: Regression Analysis",
    "section": "Quantifying the fit of the regression model",
    "text": "Quantifying the fit of the regression model\n\nWe want to know how well our regression model predicts the outcome variable\nWe can compare the predicted values ( \\(\\hat{Y}_i\\) ) to the observed values ( \\(Y_i\\) ) using two sums of squares\n\nResidual sum of squares ( \\(SS_{res}\\) ): measures how much error there is in our predictions\nTotal sum of squares ( \\(SS_{tot}\\) ): measures how much variability there is in the outcome variable"
  },
  {
    "objectID": "slides/lec-8.html#the-r2-value-effect-size",
    "href": "slides/lec-8.html#the-r2-value-effect-size",
    "title": "Week 8: Regression Analysis",
    "section": "The \\(R^2\\) value (effect size)",
    "text": "The \\(R^2\\) value (effect size)\n\nThe \\(R^2\\) value is a proportion that tells us how much of the variability in the outcome variable is explained by our regression model\nIt is calculated as:\n\n\\[R^2=1-\\frac{SS_{res}}{SS_{tot}}\\]\n\nIt ranges from 0 to 1, with higher values indicating better fit\nIt can be interpreted as the percentage of variance explained by our regression model"
  },
  {
    "objectID": "slides/lec-8.html#the-relationship-between-regression-and-correlation",
    "href": "slides/lec-8.html#the-relationship-between-regression-and-correlation",
    "title": "Week 8: Regression Analysis",
    "section": "The relationship between regression and correlation",
    "text": "The relationship between regression and correlation\n\nRegression and correlation are both ways of measuring the strength and direction of a linear relationship between two variables\nFor a simple regression model with one predictor variable, the \\(R^2\\) value is equal to the square of the Pearson correlation coefficient (\\(r^2\\))\n\nRunning a Pearson correlation is equivalent to running a simple linear regression model"
  },
  {
    "objectID": "slides/lec-8.html#the-adjusted-r2-value",
    "href": "slides/lec-8.html#the-adjusted-r2-value",
    "title": "Week 8: Regression Analysis",
    "section": "The adjusted \\(R^2\\) value",
    "text": "The adjusted \\(R^2\\) value\n\nThe adjusted \\(R^2\\) value is a modified version of the \\(R^2\\) value that takes into account the number of predictors in the model\n\nThe adjusted \\(R^2\\) value adjusts for the degrees of freedom in the model\n\nIt increases only if adding a predictor improves the model more than expected by chance"
  },
  {
    "objectID": "slides/lec-8.html#which-one-to-report-r2-or-adjusted-r2",
    "href": "slides/lec-8.html#which-one-to-report-r2-or-adjusted-r2",
    "title": "Week 8: Regression Analysis",
    "section": "Which one to report: \\(R^2\\) or adjusted \\(R^2\\)?",
    "text": "Which one to report: \\(R^2\\) or adjusted \\(R^2\\)?\n\nThere is no definitive answer to this question\nIt depends on your preference and your research question\nSome factors to consider are:\n\nInterpretability: \\(R^2\\) is easier to understand and explain\nBias correction: Adjusted \\(R^2\\) is less likely to overestimate the model performance\nHypothesis testing: There are other ways to test if adding a predictor improves the model significantly"
  },
  {
    "objectID": "slides/lec-8.html#hypothesis-tests-for-regression-models",
    "href": "slides/lec-8.html#hypothesis-tests-for-regression-models",
    "title": "Week 8: Regression Analysis",
    "section": "Hypothesis tests for regression models",
    "text": "Hypothesis tests for regression models\n\nWe can use hypothesis tests to evaluate the significance of our regression model and its coefficients\nThere are two types of hypothesis tests for regression models:\n\nTesting the model as a whole: Is there any relationship between the predictors and the outcome?\nTesting a specific coefficient: Is a particular predictor significantly related to the outcome?"
  },
  {
    "objectID": "slides/lec-8.html#test-the-model-as-a-whole",
    "href": "slides/lec-8.html#test-the-model-as-a-whole",
    "title": "Week 8: Regression Analysis",
    "section": "Test the model as a whole",
    "text": "Test the model as a whole\n\\(H_0\\): there is no relationship between the predictors and the outcome\n\\(H_a\\): data follow the regression model\n\\[F=\\frac{(R^2/K)}{(1-R^2)/(N-K-1)}\\]\n\nwhere \\(R^2\\) is the proportion of variance explained by our model, \\(K\\) is the number of predictors, and \\(N\\) is the number of observations\nThe F-test statistic follows an F-distribution with \\(K\\) and \\(N-K-1\\) degrees of freedom\nWe can use a p-value to determine if our F-test statistic is significant\n jamovi can do this for us!"
  },
  {
    "objectID": "slides/lec-8.html#tests-for-individual-coefficients",
    "href": "slides/lec-8.html#tests-for-individual-coefficients",
    "title": "Week 8: Regression Analysis",
    "section": "Tests for Individual Coefficients",
    "text": "Tests for Individual Coefficients\n\nThe F-test checks if the model as a whole is performing better than chance\nIf the F-test is not significant, then the regression model may not be good\nHowever, passing the F-test does not imply that the model is good"
  },
  {
    "objectID": "slides/lec-8.html#example-of-multiple-linear-regression",
    "href": "slides/lec-8.html#example-of-multiple-linear-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Example of Multiple Linear Regression",
    "text": "Example of Multiple Linear Regression\n\nIn a multiple linear regression model with baby.sleep and dani.sleep as predictors:\n\nThe estimated regression coefficient for baby.sleep is small (0.01) compared to dani.sleep (-.8.95)\nThis suggests that only dani.sleep matters in predicting grumpiness"
  },
  {
    "objectID": "slides/lec-8.html#hypothesis-testing-for-regression-coefficients",
    "href": "slides/lec-8.html#hypothesis-testing-for-regression-coefficients",
    "title": "Week 8: Regression Analysis",
    "section": "Hypothesis Testing for Regression Coefficients",
    "text": "Hypothesis Testing for Regression Coefficients\n\nA t-test can be used to test if a regression coefficient is significantly different from zero\n\n\\(H_0\\): b = 0 (the true regression coefficient is zero)\n\\(H_0\\): b ≠ 0 (the true regression coefficient is not zero)"
  },
  {
    "objectID": "slides/lec-8.html#running-hypothesis-tests-in-jamovi",
    "href": "slides/lec-8.html#running-hypothesis-tests-in-jamovi",
    "title": "Week 8: Regression Analysis",
    "section": "Running Hypothesis Tests in Jamovi",
    "text": "Running Hypothesis Tests in Jamovi\n\nTo compute statistics, check relevant options and run regression in jamovi\nSee result in the next slide"
  },
  {
    "objectID": "slides/lec-8.html#output",
    "href": "slides/lec-8.html#output",
    "title": "Week 8: Regression Analysis",
    "section": "Output",
    "text": "Output\n\n\nModel Coefficients\n\nLocated at bottom of jamovi analysis results\nEach row refers to one coefficient in regression model\nFirst row is intercept term; later rows look at each predictor\n\nCoefficient Information\n\nFirst column: estimate of b\nSecond column: standard error estimate\nThird and fourth columns: lower and upper values for 95% confidence interval around b estimate\nFifth column: t-statistic ( \\(t = b / se(b)\\) )\nLast column: p-value for each test\n\nDegrees of Freedom\n\nNot listed in coefficients table itself\nAlways N - K - 1\nListed in table at top of output"
  },
  {
    "objectID": "slides/lec-8.html#interpretation",
    "href": "slides/lec-8.html#interpretation",
    "title": "Week 8: Regression Analysis",
    "section": "Interpretation",
    "text": "Interpretation\n\n\n\nConclusion\n\nThe current regression model may not be the best fit for the data\nDropping baby.sleep predictor entirely may improve the model\n\n\n\nThe model performs significantly better than chance\n\n\\(F(2,97) = 215.24\\), \\(p&lt; .001\\)\n\\(R^2 = .81\\) value indicates that the regression model accounts for 81% of the variability in the outcome measure\n\nIndividual Coefficients\n\nbaby.sleep variable has no significant effect\nAll work in this model is being done by the dani.sleep variable"
  },
  {
    "objectID": "slides/lec-8.html#assumptions-of-regression",
    "href": "slides/lec-8.html#assumptions-of-regression",
    "title": "Week 8: Regression Analysis",
    "section": "Assumptions of Regression",
    "text": "Assumptions of Regression\nThe linear regression model relies on several assumptions.\n\nLinearity: The relationship between X and Y is assumed to be linear.\nIndependence: Residuals are assumed to be independent of each other.\nNormality: The residuals are assumed to be normally distributed.\nEquality of Variance: The standard deviation of the residual is assumed to be the same for all values of Y-hat."
  },
  {
    "objectID": "slides/lec-8.html#assumptions-of-regression-cont.",
    "href": "slides/lec-8.html#assumptions-of-regression-cont.",
    "title": "Week 8: Regression Analysis",
    "section": "Assumptions of Regression, cont.",
    "text": "Assumptions of Regression, cont.\nAlso…\n\nUncorrelated Predictors: In a multiple regression model, predictors should not be too strongly correlated with each other.\n\nStrongly correlated predictors (collinearity) can cause problems when evaluating the model.\n\nNo “Bad” Outliers: The regression model should not be too strongly influenced by one or two anomalous data points.\n\nAnomalous data points can raise questions about the adequacy of the model and trustworthiness of data."
  },
  {
    "objectID": "slides/lec-8.html#checking-for-linearity",
    "href": "slides/lec-8.html#checking-for-linearity",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for linearity",
    "text": "Checking for linearity\n\n\n\n\nChecking Linearity\n\nIt is important to check for the linearity of relationships between predictors and outcomes.\n\nPlotting Relationships\n\nOne way to check for linearity is to plot the relationship between predicted values and observed values for the outcome variable.\n\nUsing Jamovi\n\nIn Jamovi, you can save predicted values to the dataset and then draw a scatterplot of observed against predicted (fitted) values.\n\nInterpreting Results\n\nIf the plot looks approximately linear, then it suggests that your model is not doing too badly. However, if there are big departures from linearity, it suggests that changes need to be made."
  },
  {
    "objectID": "slides/lec-8.html#checking-for-linearity-cont.",
    "href": "slides/lec-8.html#checking-for-linearity-cont.",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for linearity, cont.",
    "text": "Checking for linearity, cont.\n\n\n\n\nTo get a more detailed picture of linearity, it can be helpful to look at the relationship between predicted values and residuals.\nUsing Jamovi\n\nIn Jamovi, you can save residuals to the dataset and then draw a scatterplot of predicted values against residual values.\n\nInterpreting Results\n\nIdeally, the relationship between predicted values and residuals should be a straight, perfectly horizontal line. In practice, we’re looking for a reasonably straight or flat line. This is a matter of judgement."
  },
  {
    "objectID": "slides/lec-8.html#checking-for-normality-residuals",
    "href": "slides/lec-8.html#checking-for-normality-residuals",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for normality (residuals)",
    "text": "Checking for normality (residuals)\n\n\n\n\nRegression models rely on a normality assumption: the residuals should be normally distributed.\nUsing Jamovi\n\nIn Jamovi, you can draw a QQ-plot via the ‘Assumption Checks’ - ‘Assumption Checks’ - ‘Q-Q plot of residuals’ option.\n\nInterpreting Results\n\nThe output shows the standardized residuals plotted as a function of their theoretical quantiles according to the regression model. The dots should be somewhat near the line."
  },
  {
    "objectID": "slides/lec-8.html#checking-for-normality-residuals-cont.",
    "href": "slides/lec-8.html#checking-for-normality-residuals-cont.",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for normality (residuals), cont.",
    "text": "Checking for normality (residuals), cont.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChecking Relationship between Predicted Values and Residuals\n\nIn Jamovi, you can use the ‘Residuals Plots’ option to check the relationship between predicted values and residuals.\nThe output provides a scatterplot for each predictor variable, the outcome variable, and the predicted values against residuals.\n\nInterpreting Results\n\nWe are looking for a fairly uniform distribution of dots with no clear bunching or patterning.\n\nThe dots are fairly evenly spread across the whole plot \n\nIssues with the relationship between predicted values and residuals? \n\nTransform one or more of the variables (Box-Cox Transform in jamovi)"
  },
  {
    "objectID": "slides/lec-8.html#checking-for-equality-of-variance",
    "href": "slides/lec-8.html#checking-for-equality-of-variance",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for equality of variance",
    "text": "Checking for equality of variance\n\n\n\n\nRegression models make an assumption of equality (homogeneity) of variance.\n\nThis means that the variance of the residuals is assumed to be constant.\n\nPlotting Equality of Variance in Jamovi\n\nTo check this assumption in Jamovi, first calculate the square root of the absolute size of the residual.\n\nCompute this new variable using the formula SQRT(ABS(Residuals))\n\nThen plot this against the predicted values.\nThe plot should show a straight horizontal line running through the middle."
  },
  {
    "objectID": "slides/lec-8.html#checking-for-collineary",
    "href": "slides/lec-8.html#checking-for-collineary",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for Collineary",
    "text": "Checking for Collineary\n\n\n\n\n\nVariance Inflation Factors (VIFs) can be used to determine if predictors in a regression model are too highly correlated with each other.\n\nEach predictor has an associated VIF.\n\nIn Jamovi, click on the ‘Collinearity’ checkbox in the ‘Regression’ - ‘Assumptions’ options to see VIF values.\nInterpreting VIF\n\nA VIF of 1 means no correlation among the predictor and the remaining predictor variables\nVIFs exceeding 4 warrant further investigation\nVIFs exceeding 10 are signs of serious multicollinearity requiring correction"
  },
  {
    "objectID": "slides/lec-8.html#checking-for-outliers",
    "href": "slides/lec-8.html#checking-for-outliers",
    "title": "Week 8: Regression Analysis",
    "section": "Checking for outliers",
    "text": "Checking for outliers\n\n\n\n\n\nUsed in regression analysis to identify influential data points that may negatively affect your regression model\nDatasets with a large number of highly influential points might not be suitable for linear regression without further processing such as outlier removal or imputation\nIdentifying Outliers\n\nA general rule of thumb: Cook’s distance greater than 1 is often considered large\n\nWhat if the value is greater than 1?\n\nremove the outlier and run the regression again\nHow? In jamovi you can save the Cook’s distance values to the dataset, then draw a boxplot of the Cook’s distance values to identify the specific outliers."
  },
  {
    "objectID": "slides/lec-10.html#intro-to-one-way-anova",
    "href": "slides/lec-10.html#intro-to-one-way-anova",
    "title": "Week 12: One-way ANOVA",
    "section": "Intro to One-way ANOVA",
    "text": "Intro to One-way ANOVA\nOne-way Analysis of Variance (ANOVA) is a statistical technique used to compare the means of three or more groups. It is an extension of the t-test, which can only compare the means of two groups. The main purpose of one-way ANOVA is to determine if there are any significant differences among the group means."
  },
  {
    "objectID": "slides/lec-10.html#hypotheses-in-one-way-anova",
    "href": "slides/lec-10.html#hypotheses-in-one-way-anova",
    "title": "Week 12: One-way ANOVA",
    "section": "Hypotheses in One-way ANOVA",
    "text": "Hypotheses in One-way ANOVA\n\nNull Hypothesis (H0): All group means are equal.\nAlternative Hypothesis (H1): At least one group mean is different."
  },
  {
    "objectID": "slides/lec-10.html#one-way-anova-process",
    "href": "slides/lec-10.html#one-way-anova-process",
    "title": "Week 12: One-way ANOVA",
    "section": "One-way ANOVA Process",
    "text": "One-way ANOVA Process\n\nState the null and alternative hypotheses.\nCalculate the test statistic (F-statistic) using the ANOVA table.\nDetermine the critical value based on the chosen significance level (alpha) and degrees of freedom.\nCompare the test statistic to the critical value.\nMake a decision about the null hypothesis."
  },
  {
    "objectID": "slides/lec-10.html#post-hoc-tests",
    "href": "slides/lec-10.html#post-hoc-tests",
    "title": "Week 12: One-way ANOVA",
    "section": "Post-hoc Tests",
    "text": "Post-hoc Tests\nIf the null hypothesis is rejected, post-hoc tests can be conducted to identify the specific group differences."
  },
  {
    "objectID": "slides/lec-10.html#sum-of-squares-between-groups-ssb",
    "href": "slides/lec-10.html#sum-of-squares-between-groups-ssb",
    "title": "Week 12: One-way ANOVA",
    "section": "Sum of Squares Between groups (SSB)",
    "text": "Sum of Squares Between groups (SSB)\n\nMeasures the variability between the group means\nQuantifies differences in the means of different groups compared to the grand mean\nLarger SSB value indicates greater difference between group means\nSuggests factor being studied may have significant impact on the outcome"
  },
  {
    "objectID": "slides/lec-10.html#sum-of-squares-within-groups-ssw",
    "href": "slides/lec-10.html#sum-of-squares-within-groups-ssw",
    "title": "Week 12: One-way ANOVA",
    "section": "Sum of Squares Within groups (SSW)",
    "text": "Sum of Squares Within groups (SSW)\n\nMeasures the variability within each group\nRepresents dispersion of individual data points around their respective group means\nLarger SSW value indicates more variability within the groups\nMay be due to random errors or other factors not accounted for in the study"
  },
  {
    "objectID": "slides/lec-10.html#key-differences-between-ssb-and-ssw",
    "href": "slides/lec-10.html#key-differences-between-ssb-and-ssw",
    "title": "Week 12: One-way ANOVA",
    "section": "Key Differences Between SSB and SSW",
    "text": "Key Differences Between SSB and SSW\n\nSSB: concerned with variability between group means\nSSW: focuses on variability within each group\nSSB: identifies the effect of the factor being studied\nSSW: accounts for random errors and other unexplained factors"
  },
  {
    "objectID": "slides/lec-10.html#f-ratio-in-one-way-anova",
    "href": "slides/lec-10.html#f-ratio-in-one-way-anova",
    "title": "Week 12: One-way ANOVA",
    "section": "F-Ratio in One-Way ANOVA",
    "text": "F-Ratio in One-Way ANOVA\n\nTest statistic for determining statistically significant differences between group means\nF-ratio = Mean Square Between groups (MSB) / Mean Square Within groups (MSW)\nMSB = SSB / degrees of freedom between groups\nMSW = SSW / degrees of freedom within groups\nLarger F-ratio indicates greater between-group variability than within-group variability\nSuggests differences between group means are statistically significant"
  },
  {
    "objectID": "slides/lec-10.html#calculate-the-sum-of-squares",
    "href": "slides/lec-10.html#calculate-the-sum-of-squares",
    "title": "Week 12: One-way ANOVA",
    "section": "Calculate the sum of squares:",
    "text": "Calculate the sum of squares:\nSum of squares is calculated using the following components:\n\nSum of squares between groups (SSB): It measures the variability among group means.\n\\[\nSSB = Σk(Ŷi. - Ŷ..)² / ni\n\\]\nwhere k is the number of groups, Ŷi. is the mean of group i, Ŷ.. is the grand mean, and ni is the number of observations in group i.\nSum of squares within groups (SSW): It measures the variability within each group.\n\\[\nSSW = ΣΣ(Yij - Ŷi.)²\n\\]\nwhere Yij is the observation j in group i, and Ŷi. is the mean of group i.\nTotal sum of squares (SST): It measures the total variability in the data.\n\\[\nSST = ΣΣ(Yij - Ŷ..)²\n\\]"
  },
  {
    "objectID": "slides/lec-10.html#calculate-the-f-ratio",
    "href": "slides/lec-10.html#calculate-the-f-ratio",
    "title": "Week 12: One-way ANOVA",
    "section": "Calculate the F-ratio",
    "text": "Calculate the F-ratio\nThe F-ratio is calculated using the mean squares, which are obtained by dividing the sum of squares by their respective degrees of freedom.\n\nMean squares between groups (MSB):\n\\[\nMSB = SSB / (k - 1)\n\\]\nwhere k is the number of groups.\nMean squares within groups (MSW):\n\\[\nMSW = SSW / (N - k)\n\\]\nwhere N is the total number of observations.\nF-ratio:\n\\[\nF = MSB / MSW\n\\]\n\nThe F-ratio follows an F-distribution with (k - 1) and (N - k) degrees of freedom. The F-ratio is then compared to the critical value from the F-distribution table at a given significance level (usually α = 0.05) to determine if the null hypothesis can be rejected."
  },
  {
    "objectID": "slides/lec-10.html#intro",
    "href": "slides/lec-10.html#intro",
    "title": "Week 12: One-way ANOVA",
    "section": "Intro",
    "text": "Intro\nThe F distribution, also known as the Fisher-Snedecor distribution, is a continuous probability distribution that is widely used in statistical hypothesis testing, particularly in the analysis of variance (ANOVA). It is named after Ronald A. Fisher and George W. Snedecor, two prominent statisticians who contributed significantly to its development."
  },
  {
    "objectID": "slides/lec-10.html#characteristics-of-the-f-distribution",
    "href": "slides/lec-10.html#characteristics-of-the-f-distribution",
    "title": "Week 12: One-way ANOVA",
    "section": "Characteristics of the F Distribution",
    "text": "Characteristics of the F Distribution\n\n\n\n\n\n\n\n\n\nThe F distribution has two important parameters: degrees of freedom for the numerator (df1) and degrees of freedom for the denominator (df2). These parameters define the shape of the distribution. Some key characteristics of the F distribution are:\nIt is always non-negative, as it represents the ratio of two chi-square distributions.\nIt is asymmetric and positively skewed, with a longer tail on the right side.\nThe peak of the distribution shifts to the right as the degrees of freedom increase.\nAs both degrees of freedom approach infinity, the F distribution converges to a normal distribution."
  },
  {
    "objectID": "slides/lec-10.html#applications-of-the-f-distribution-in-anova",
    "href": "slides/lec-10.html#applications-of-the-f-distribution-in-anova",
    "title": "Week 12: One-way ANOVA",
    "section": "Applications of the F Distribution in ANOVA",
    "text": "Applications of the F Distribution in ANOVA\nThe F distribution is central to the analysis of variance (ANOVA) and other statistical tests that involve comparing variances or assessing the effects of different factors on a response variable. In these applications, an F statistic is calculated as the ratio of two mean square values (MS), which are derived from sums of squares (SS) and degrees of freedom:\nF = (MS_between groups) / (MS_within groups)\n\nThe numerator (MS_between groups) represents the variability between the groups\nThe denominator (MS_within groups) represents the variability within the groups\nF statistic is used in ANOVA (Analysis of Variance) to compare variances between groups\nIt measures the ratio of variability between groups to the variability within groups\n\nF Statistic and Group Differences\n\nF statistic close to 1: No significant difference between groups\nF statistic much greater than 1: Significant effect of the factor being tested\n\nHypothesis Testing with F Statistic\n\nCompare the calculated F statistic to a critical value from the F distribution\nUse appropriate degrees of freedom\nIf F statistic &gt; critical value, reject the null hypothesis\nA significant F statistic suggests a significant effect of the factor being tested"
  },
  {
    "objectID": "slides/lec-10.html#eta-squared-eta2",
    "href": "slides/lec-10.html#eta-squared-eta2",
    "title": "Week 12: One-way ANOVA",
    "section": "Eta-squared (\\(\\eta^2\\))",
    "text": "Eta-squared (\\(\\eta^2\\))\n\nProportion of variance in the dependent variable explained by the independent variable.\nRanges from 0 to 1.\nEquation: \\(\\eta^2 = \\frac{SS_{between}}{SS_{total}}\\)\nRule of thumb: 0.01 (small), 0.06 (medium), 0.14 (large) effect sizes."
  },
  {
    "objectID": "slides/lec-10.html#partial-eta-squared-eta_p2",
    "href": "slides/lec-10.html#partial-eta-squared-eta_p2",
    "title": "Week 12: One-way ANOVA",
    "section": "Partial eta-squared (\\(\\eta_p^2\\))",
    "text": "Partial eta-squared (\\(\\eta_p^2\\))\n\nVariation of eta-squared that takes into account the degrees of freedom associated with the residual error term.\nCan be less biased in certain situations.\nEquation: \\(\\eta_p^2 = \\frac{SS_{between}}{SS_{between} + SS_{error}}\\)\nSame rule of thumb as eta-squared."
  },
  {
    "objectID": "slides/lec-10.html#omega-squared-omega2",
    "href": "slides/lec-10.html#omega-squared-omega2",
    "title": "Week 12: One-way ANOVA",
    "section": "Omega-squared (\\(\\omega^2\\))",
    "text": "Omega-squared (\\(\\omega^2\\))\n\nEstimates the true population effect size.\nTypically used when the sample size is small and/or the population effect size is unknown.\nEquation: \\(\\omega^2 = \\frac{SS_{between} - (df_{between} \\times MS_{error})}{SS_{total} + MS_{error}}\\)\nSlightly different rule of thumb: 0.01 (small), 0.06 (medium), 0.14 (large) effect sizes.\n\nNote: In these equations, \\(SS_{between}\\) represents the sum of squares between groups, \\(SS_{total}\\) represents the total sum of squares, \\(SS_{error}\\) represents the sum of squares error (also known as the residual sum of squares), \\(df_{between}\\) represents the degrees of freedom between groups, and \\(MS_{error}\\) represents the mean square error (calculated as \\(SS_{error} / df_{error}\\))."
  },
  {
    "objectID": "slides/lec-10.html#common-post-hoc-tests",
    "href": "slides/lec-10.html#common-post-hoc-tests",
    "title": "Week 12: One-way ANOVA",
    "section": "Common Post-hoc Tests",
    "text": "Common Post-hoc Tests\nTukey’s HSD Test\n\nWidely used for pairwise comparisons with equal variances.\nControls experiment-wise Type I error rate.\nMost powerful test with equal sample sizes.\n\nBonferroni Test\n\nAdjusts significance level by the number of pairwise comparisons.\nMore conservative than Tukey’s HSD.\nCan be used with equal or unequal sample sizes.\n\nScheffé’s Test\n\nMore conservative than Tukey’s HSD and Bonferroni.\nAllows any linear combination of means (not just pairwise comparisons).\nSuitable for complex planned comparisons.\n\nGames-Howell Test\n\nDesigned for unequal variances.\nUses Welch-Satterthwaite degrees of freedom.\nSuitable for unequal sample sizes."
  },
  {
    "objectID": "slides/lec-10.html#factors-to-consider",
    "href": "slides/lec-10.html#factors-to-consider",
    "title": "Week 12: One-way ANOVA",
    "section": "Factors to Consider",
    "text": "Factors to Consider\nAssumption of Equal Variances\n\nTukey’s HSD, Bonferroni, or Scheffé’s if met.\nGames-Howell if not met.\n\nSample Sizes\n\nTukey’s HSD for equal sample sizes.\nBonferroni or Games-Howell for unequal sample sizes.\n\nConservativeness vs. Power\n\nTukey’s HSD is more powerful but less conservative.\nBonferroni and Scheffé’s are more conservative but less powerful.\nBalance trade-off between Type I and Type II error rates."
  },
  {
    "objectID": "slides/lec-10.html#anova-output-includes",
    "href": "slides/lec-10.html#anova-output-includes",
    "title": "Week 12: One-way ANOVA",
    "section": "ANOVA output includes:",
    "text": "ANOVA output includes:\n\nDegrees of freedom for the between-group factor and the residual error term\nSum of squares for the between-group factor and the residual error term\nMean squares for the between-group factor and the residual error term\nF-statistic and p-value associated with the F-statistic"
  },
  {
    "objectID": "slides/lec-10.html#to-interpret-the-results-consider-both-the-f-statistic-and-p-value",
    "href": "slides/lec-10.html#to-interpret-the-results-consider-both-the-f-statistic-and-p-value",
    "title": "Week 12: One-way ANOVA",
    "section": "To interpret the results, consider both the F-statistic and p-value:",
    "text": "To interpret the results, consider both the F-statistic and p-value:\n\nF-statistic indicates significant differences between group means\nP-value tells you whether those differences are statistically significant\nIf p-value &lt; alpha level, then evidence of significant difference between at least 2 group means"
  },
  {
    "objectID": "slides/lec-10.html#examining-effect-size",
    "href": "slides/lec-10.html#examining-effect-size",
    "title": "Week 12: One-way ANOVA",
    "section": "Examining effect size:",
    "text": "Examining effect size:\n\nCommon measures: eta-squared (\\(\\eta^2\\)), partial eta-squared (\\(\\eta_p^2\\)), and omega-squared (\\(\\omega^2\\))\nLarger effect sizes indicate more meaningful differences between groups"
  },
  {
    "objectID": "slides/lec-10.html#research-question",
    "href": "slides/lec-10.html#research-question",
    "title": "Week 12: One-way ANOVA",
    "section": "Research question",
    "text": "Research question\n\nIs there a significant difference in flexibility among participants in the three different exercise programs (A, B, and C)?"
  },
  {
    "objectID": "slides/lec-10.html#hypothesis-statements",
    "href": "slides/lec-10.html#hypothesis-statements",
    "title": "Week 12: One-way ANOVA",
    "section": "Hypothesis Statements",
    "text": "Hypothesis Statements\n\nNull Hypothesis (H0): \\(\\mu_{A} = \\mu_{B} = \\mu_{C}\\)\n\nThere is no significant difference in flexibility among the three exercise programs.\n\nAlternative Hypothesis (H1): \\(\\mu_{A} \\neq \\mu_{B} \\text{ or } \\mu_{A} \\neq \\mu_{C} \\text{ or } \\mu_{B} \\neq \\mu_{C}\\)\n\nThere is a significant difference in flexibility among at least two of the exercise programs."
  },
  {
    "objectID": "slides/lec-10.html#anova-test-results",
    "href": "slides/lec-10.html#anova-test-results",
    "title": "Week 12: One-way ANOVA",
    "section": "ANOVA Test Results",
    "text": "ANOVA Test Results\n\nThe one-way ANOVA test was conducted with a significance level of \\(\\alpha = 0.05\\).\nThe test statistic value was F(2, 27) = 4.98, and the p-value was 0.014.\nSince the p-value is less than the significance level, we reject the null hypothesis.\nWe can conclude that there is a significant difference in flexibility among at least two of the exercise programs."
  },
  {
    "objectID": "slides/lec-10.html#post-hoc-tests-1",
    "href": "slides/lec-10.html#post-hoc-tests-1",
    "title": "Week 12: One-way ANOVA",
    "section": "Post Hoc Tests",
    "text": "Post Hoc Tests\n\nSince the one-way ANOVA test indicated a significant difference, we can conduct post hoc tests to determine which pairs of exercise programs have a significant difference in flexibility.\nTukey’s HSD test was conducted with a significance level of \\(\\alpha = 0.05\\).\nThe test results indicated a significant difference in flexibility between exercise programs A and C, with a p-value of 0.013.\nNo other pairs of exercise programs had a significant difference in flexibility."
  },
  {
    "objectID": "slides/lec-10.html#jamovi",
    "href": "slides/lec-10.html#jamovi",
    "title": "Week 12: One-way ANOVA",
    "section": "jamovi",
    "text": "jamovi"
  },
  {
    "objectID": "slides/lec-10.html#jamovi---post-hoc",
    "href": "slides/lec-10.html#jamovi---post-hoc",
    "title": "Week 12: One-way ANOVA",
    "section": "jamovi - post hoc",
    "text": "jamovi - post hoc"
  },
  {
    "objectID": "slides/lec-10.html#interpreting-the-results",
    "href": "slides/lec-10.html#interpreting-the-results",
    "title": "Week 12: One-way ANOVA",
    "section": "Interpreting the results",
    "text": "Interpreting the results\n\nOne-way ANOVA results\n\nStatistically significant difference in flexibility scores between the three groups\nF-value of 53.65 and p-value of 2.71e-12\nAt least one group mean is significantly different from the others\n\nTukey HSD test results\n\nDifference in flexibility scores between groups A and B is significantly different from 0\n95% confidence interval: 5.97 to 10.96, p-value of 0\nGroup B has significantly higher flexibility score than group A\n\nNo significant difference between groups A and C\n\nConfidence interval (-3.83 to 1.16) includes 0, p-value of 0.40\nComparison between groups B and C shows significant difference\nGroup B has significantly higher flexibility score than group C\nConfidence interval: -12.29 to -7.31, p-value of 0\n\nConclusion\n\nSignificant differences in flexibility scores between at least two of the three groups\nGroup B has significantly higher flexibility score than both groups A and C\nNo significant difference in flexibility scores between groups A and C."
  },
  {
    "objectID": "slides/lec-10.html#results-of-one-way-anova-on-flexibility-scores",
    "href": "slides/lec-10.html#results-of-one-way-anova-on-flexibility-scores",
    "title": "Week 12: One-way ANOVA",
    "section": "Results of One-Way ANOVA on Flexibility Scores",
    "text": "Results of One-Way ANOVA on Flexibility Scores\n\nA one-way analysis of variance (ANOVA) was conducted to determine whether there were significant differences in flexibility scores among three groups. Results revealed a significant main effect of group on flexibility scores, \\(F(2, 42) = 53.65, p &lt; .001, \\eta_{p}^{2} = .72\\). Post hoc pairwise comparisons using Tukey’s HSD test showed that group B had significantly higher flexibility scores compared to both groups A (\\(p &lt; .001\\)) and C (\\(p &lt; .001\\)). However, no significant difference was found between groups A and C (\\(p = .40\\)). These findings suggest that group B had significantly better flexibility scores than groups A and C, while groups A and C did not differ significantly in terms of their flexibility scores."
  },
  {
    "objectID": "slides/lec-10.html#intro-1",
    "href": "slides/lec-10.html#intro-1",
    "title": "Week 12: One-way ANOVA",
    "section": "Intro",
    "text": "Intro\nThe nonparametric equivalent to the one-way ANOVA is the Kruskal-Wallis test. It is used when the assumptions of normality and homogeneity of variance are not met.\nThe Kruskal-Wallis test ranks the data and compares the medians of the groups instead of the means.\nLike the one-way ANOVA, it tests the null hypothesis that there is no difference between the groups, and the alternative hypothesis that at least one group differs from the others."
  },
  {
    "objectID": "slides/lec-10.html#jamovi-1",
    "href": "slides/lec-10.html#jamovi-1",
    "title": "Week 12: One-way ANOVA",
    "section": "Jamovi",
    "text": "Jamovi\n\nOpen the data set in jamovi.\nClick on the “ANOVA” button and under “Nonparametric Tests”, select One-way ANOVA Kruskal-Wallis.\nDrag the dependent variable to the “Test Variable” box and the grouping variable to the “Factor” box.\nClick “Run” to obtain the test results."
  },
  {
    "objectID": "slides/lec-10.html#spss",
    "href": "slides/lec-10.html#spss",
    "title": "Week 12: One-way ANOVA",
    "section": "SPSS",
    "text": "SPSS\n\nOpen the data set in SPSS.\nClick on “Analyze” and select “Nonparametric Tests” from the drop-down menu.\nSelect “Independent Samples” from the list of available tests.\nMove the dependent variable to the “Test Variable List” box and the grouping variable to the “Grouping Variable” box.\nClick on the “Options” button and select “Kruskal-Wallis H” from the list of available tests.\nClick “Continue” and then “OK” to run the test."
  },
  {
    "objectID": "slides/lec-10.html#r",
    "href": "slides/lec-10.html#r",
    "title": "Week 12: One-way ANOVA",
    "section": "R",
    "text": "R\n\nOpen R and load the necessary packages (e.g., “tidyverse”, “rstatix”).\nLoad the data set into R using the read.csv() or read.table() function.\nUse the kruskal.test() function to conduct the Kruskal-Wallis test, specifying the dependent variable and grouping variable.\nUse the summary() function to obtain the test results.\n(Optional) Use the dunn_test() function from the “rstatix” package to conduct post-hoc pairwise comparisons."
  },
  {
    "objectID": "slides/lec-10.html#references",
    "href": "slides/lec-10.html#references",
    "title": "Week 12: One-way ANOVA",
    "section": "References",
    "text": "References\n\n\n\nhttps://drfurtado.github.io/kin610/\n\n\n\nFurtado, Ovande. 2023. “RandomStats - One-Way ANOVA.” Blog. RandomStats. April 8, 2023. https://drfurtado.github.io/randomstats/posts/04082023-one-way-anova/."
  },
  {
    "objectID": "slides/lec-6.html#credits",
    "href": "slides/lec-6.html#credits",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Credits",
    "text": "Credits\nTBA"
  },
  {
    "objectID": "slides/lec-6.html#descriptive-vs-inferential-statistics",
    "href": "slides/lec-6.html#descriptive-vs-inferential-statistics",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Descriptive vs Inferential Statistics",
    "text": "Descriptive vs Inferential Statistics\n\nDescriptive statistics summarize and visualize data (means, standard deviations, graphs)\nInferential statistics make predictions and inferences about the population based on sample data\nHypothesis testing is a key component of inferential statistics"
  },
  {
    "objectID": "slides/lec-6.html#fundamentals-of-inferential-statistics",
    "href": "slides/lec-6.html#fundamentals-of-inferential-statistics",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Fundamentals of Inferential Statistics",
    "text": "Fundamentals of Inferential Statistics\n\nStatistics plays a crucial role in analyzing and interpreting collected data\nEstimation: using sample statistics to estimate population parameters\nHypothesis testing: determining whether observed differences in sample data are statistically significant\nExample: evaluating the effectiveness of a new exercise program for the larger population"
  },
  {
    "objectID": "slides/lec-6.html#introduction-to-probability-theory",
    "href": "slides/lec-6.html#introduction-to-probability-theory",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Introduction to Probability Theory",
    "text": "Introduction to Probability Theory\n\n\nSample Space: {1, 2, 3, 4, 5, 6}\nEvent: odd # {1, 3, 5} and even # {2, 4, 6}\n\n\n\nProbability theory deals with the analysis of random events and their associated outcomes\nThe sample space is the set of all possible outcomes of an experiment or trial\nThe sample space helps in identifying the range of potential outcomes that could arise from a trial\nAn event is a subset of the sample space that comprises a group of outcomes with a common characteristic\nProbabilities are numerical values assigned to events, representing the likelihood of those events occurring\nProbabilities range from 0 to 1, with 0 indicating that an event cannot occur and 1 indicating that the event is certain to occur\nWhen flipping a coin, what is the sample space?"
  },
  {
    "objectID": "slides/lec-6.html#introduction-1",
    "href": "slides/lec-6.html#introduction-1",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n# Set the seed for reproducibility\nset.seed(123)\n\n# Generate a random sample from a normal distribution with mean 0 and sd 1\nx &lt;- rnorm(10000, mean = 0, sd = 1)\n\n# Create a histogram of the data\nhist(x, main = \"Normal Distribution with mean = 0 and sd = 1\")\n\n\n\n\n\n\nProbability distributions allow researchers to infer population parameters based on sample statistics\nThere are many types of probability distributions, we will focus on the most common ones\n\nnormal distribution\nt-distribution\nchi-square distribution\nF-distribution\nBinomial distribution"
  },
  {
    "objectID": "slides/lec-6.html#types",
    "href": "slides/lec-6.html#types",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Types",
    "text": "Types\nDiscrete Probability Distributions\n\nDescribes probabilities of different outcomes of a discrete variable\nCan only take certain values\nExamples: Binomial, Poisson, Discrete uniform\n\nContinuous Probability Distributions\n\nDescribes probabilities of different outcomes of a continuous variable\nCan take any value within a certain range\nExamples: Normal, t-distribution, and chi-square distribution"
  },
  {
    "objectID": "slides/lec-6.html#null-distributions",
    "href": "slides/lec-6.html#null-distributions",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Null Distributions",
    "text": "Null Distributions\n\nHypothesis testing relies heavily on null distributions\nNull distributions are probability distributions of a test statistic under the assumption of a true null hypothesis\nA test statistic is a summary of a sample expressed as a single number\n\nExamples of test statistics include z, t, F, and chi-square\n\nTo determine a p-value, the test statistic is compared to the corresponding null distribution\nThe p-value represents the probability of obtaining a test statistic value as extreme or more extreme than the sample’s value, assuming the null hypothesis is true"
  },
  {
    "objectID": "slides/lec-6.html#example",
    "href": "slides/lec-6.html#example",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Example",
    "text": "Example\n\n\n\n\nTitle: The Effect of a Modified Basketball Program on Motor Skills and Cognitive Function in Older Adults\nThis study used a test statistic (t-test) to compare the mean scores of motor skills and cognitive function between two groups of older adults: one group that participated in a modified basketball program and one group that did not. The results showed a significant difference in both motor skills and cognitive function between the two groups, with the basketball group performing better. The t-test was used to determine the probability of obtaining such a difference by chance alone and to determine the statistical significance of the findings."
  },
  {
    "objectID": "slides/lec-6.html#pd-examples",
    "href": "slides/lec-6.html#pd-examples",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "PD Examples",
    "text": "PD Examples\n\n\n\n\n\n\n\n\nDistribution\nDescription\nStatistical tests\n\n\n\n\nStandard Normal\nNormal distribution with mean = 0 and standard deviation = 1\nZ-tests\n\n\nBinomial\nDiscrete distribution, number of successes in n independent trials\nChi-squared test, goodness of fit\n\n\nPoisson\nDiscrete distribution, number of events in a fixed interval of time or space\nChi-squared test, goodness of fit\n\n\nExponential\nContinuous distribution, time between successive events in a Poisson process\nSurvival analysis\n\n\nt-distribution\nContinuous distribution, used for small sample sizes\nt-tests\n\n\nF-distribution\nContinuous distribution, used in ANOVA to test equality of variances\nANOVA\n\n\nChi-Square\nProbability distribution used to test hypotheses about the relationship between two categorical variables\nChi-square goodness of fit test, chi-square test of independence"
  },
  {
    "objectID": "slides/lec-6.html#from-sample-to-population",
    "href": "slides/lec-6.html#from-sample-to-population",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "From sample to population",
    "text": "From sample to population\n\nInferential statistics uses samples from a population to make conclusions about the population.\nSampling error is the potential for error due to inherent variability in the sample."
  },
  {
    "objectID": "slides/lec-6.html#techniques-to-reduce-sampling-error",
    "href": "slides/lec-6.html#techniques-to-reduce-sampling-error",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Techniques to Reduce Sampling Error",
    "text": "Techniques to Reduce Sampling Error\n\nRandom sampling involves randomly selecting participants without bias or preference.\nStratified sampling involves dividing the population into subgroups based on certain characteristics and selecting a random sample from each subgroup.\nIncreasing the sample size can reduce random sampling error by providing a more representative sample of the population."
  },
  {
    "objectID": "slides/lec-6.html#levels-of-confidence-in-inferential-statistics",
    "href": "slides/lec-6.html#levels-of-confidence-in-inferential-statistics",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Levels of Confidence in Inferential Statistics",
    "text": "Levels of Confidence in Inferential Statistics\n\nLevels of confidence measure the uncertainty or variability in estimates when making inferences about a population based on a sample.\nLevels of confidence represent the degree of certainty that the true population parameter falls within a certain range of values.\nFor example, a 95% level of confidence means that 95% of the resulting confidence intervals would contain the true population parameter if the study were repeated many times.\nAn example can be found here."
  },
  {
    "objectID": "slides/lec-6.html#factors-affecting-the-choice-of-levels-of-confidence",
    "href": "slides/lec-6.html#factors-affecting-the-choice-of-levels-of-confidence",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Factors Affecting the Choice of Levels of Confidence",
    "text": "Factors Affecting the Choice of Levels of Confidence\n\nThe level of confidence chosen by a researcher depends on the level of risk associated with making an incorrect inference, the sample size, and the data’s variability.\nHigher levels of confidence, such as 99%, require larger sample sizes and lead to wider confidence intervals.\nLevels of confidence do not guarantee that the true population parameter falls within the confidence interval, but rather provide a measure of the likelihood that it does.\nLevels of confidence do not provide information about the precision of the estimate, only the degree of certainty in the range of values."
  },
  {
    "objectID": "slides/lec-6.html#table",
    "href": "slides/lec-6.html#table",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Table",
    "text": "Table\nThis table shows the corresponding values for the level of confidence (LOC), Z-value, and probability (p) in a standard normal distribution for the most commonly used levels of confidence in inferential statistics: 68%, 90%, 95%, and 99%. The values in the table can be used to calculate confidence intervals and perform hypothesis tests.\n\n\n\nLevel of Confidence (LOC)\nZ-Value\nProbability (p)\n\n\n\n\n68%\n1.00\n0.32\n\n\n90%\n1.64\n0.10\n\n\n95%\n1.96\n0.05\n\n\n99%\n2.58\n0.01"
  },
  {
    "objectID": "slides/lec-6.html#point-estimation",
    "href": "slides/lec-6.html#point-estimation",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Point Estimation",
    "text": "Point Estimation\n\nMethod of statistical inference used to estimate an unknown population parameter using a single value called the point estimator.\nUsed in Kinesiology to estimate parameters such as mean height, weight, or strength of a population based on a sample.\nSample mean is a good estimator of the population mean because it is unbiased and has an expected value equal to it.\nA biased estimator would be systematically off from the true population parameter.\nPoint estimators can vary from sample to sample, leading to sampling error."
  },
  {
    "objectID": "slides/lec-6.html#properties-of-a-good-point-estimator",
    "href": "slides/lec-6.html#properties-of-a-good-point-estimator",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Properties of a Good Point Estimator",
    "text": "Properties of a Good Point Estimator\n\nUnbiasedness: the estimator has an expected value equal to the population parameter.\nEfficiency: the estimator has a small variance and is more precise than other estimators.\nConsistency: the estimator becomes closer to the population parameter as the sample size increases."
  },
  {
    "objectID": "slides/lec-6.html#example-of-point-estimation-in-kinesiology",
    "href": "slides/lec-6.html#example-of-point-estimation-in-kinesiology",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Example of Point Estimation in Kinesiology",
    "text": "Example of Point Estimation in Kinesiology\n\nEstimating maximum oxygen uptake (VO2max) of all collegiate athletes in the United States using a sample of 100 athletes.\nSample mean VO2max of the athletes is calculated as 60 ml/kg/min.\nSample mean used as the point estimator of the population mean VO2max.\nMean of all means will converge to the population mean VO2max as the sample size increases."
  },
  {
    "objectID": "slides/lec-6.html#interval-estimation",
    "href": "slides/lec-6.html#interval-estimation",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Interval Estimation",
    "text": "Interval Estimation\n\nMethod of statistical inference used to estimate an unknown population parameter using an interval of values called the confidence interval.\nIn Kinesiology, confidence intervals can be used to estimate various parameters, such as the difference in means between two groups or the effect size of an intervention.\nAn example can be found here."
  },
  {
    "objectID": "slides/lec-6.html#significance-testing-using-confidence-intervals",
    "href": "slides/lec-6.html#significance-testing-using-confidence-intervals",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Significance testing using confidence intervals",
    "text": "Significance testing using confidence intervals\n\nConfidence intervals can test hypotheses about the population parameter by checking whether the hypothesized value falls within the interval.\nFor instance, if the null hypothesis is that there is no difference in mean jump height between male and female athletes, we can check whether the hypothesized value of zero falls within the 95% confidence interval.\nIf it does not, we can reject the null hypothesis at the specified level of significance."
  },
  {
    "objectID": "slides/lec-6.html#introduction-2",
    "href": "slides/lec-6.html#introduction-2",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Introduction",
    "text": "Introduction\n\nMethod of statistical inference used to make decisions about population parameter based on sample data.\nCommonly used in Kinesiology to test efficacy of interventions, compare groups of athletes/patients, and examine relationships between variables."
  },
  {
    "objectID": "slides/lec-6.html#null-and-alternative-hypotheses",
    "href": "slides/lec-6.html#null-and-alternative-hypotheses",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Null and Alternative Hypotheses",
    "text": "Null and Alternative Hypotheses\n\nNull hypothesis (H0): Statement that assumes the population parameter is equal to a specific value or falls within a specific range.\nAlternative hypothesis (Ha): Statement that contradicts the null hypothesis and assumes that the population parameter is different from the value or range specified by the null hypothesis."
  },
  {
    "objectID": "slides/lec-6.html#example-1",
    "href": "slides/lec-6.html#example-1",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Example:",
    "text": "Example:\n\nTesting whether new training program increases mean strength of athletes.\nNull hypothesis: Mean strength of athletes who follow program is equal to that of athletes who do not - hypothesis being tested\nAlternative hypothesis: Mean strength of athletes who follow program is greater than that of athletes who do not."
  },
  {
    "objectID": "slides/lec-6.html#test-statistics-and-p-values",
    "href": "slides/lec-6.html#test-statistics-and-p-values",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Test Statistics and p-values",
    "text": "Test Statistics and p-values\n\nTest statistics: Measure the distance between sample statistic and hypothesized population parameter under null hypothesis.\n\nt-test: Most commonly used test statistic, compares means of two groups.\n\np-value: Probability of observing a test statistic as extreme or more extreme than the one obtained from the sample data, assuming the null hypothesis is true."
  },
  {
    "objectID": "slides/lec-6.html#example-2",
    "href": "slides/lec-6.html#example-2",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Example:",
    "text": "Example:\n\nTesting effect of new exercise program on reducing knee pain in patients with osteoarthritis.\nt-value of 2.5 and p-value of 0.01.\np-value less than 0.05, reject null hypothesis and conclude that exercise program effectively reduces knee pain."
  },
  {
    "objectID": "slides/lec-6.html#type-i-and-type-ii-errors",
    "href": "slides/lec-6.html#type-i-and-type-ii-errors",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Type I and Type II Errors",
    "text": "Type I and Type II Errors\n\nHypothesis testing involves making two types of errors: type I and type II.\nType I error: Null hypothesis is rejected even though it is true. False positive.\nType II error: Null hypothesis is not rejected even though it is false. False negative.\nType I errors can be particularly concerning in Kinesiology when testing efficacy of a new treatment or intervention.\nType II errors can lead to missed opportunity to identify effective treatment or intervention."
  },
  {
    "objectID": "slides/lec-6.html#causes-of-error",
    "href": "slides/lec-6.html#causes-of-error",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Causes of error",
    "text": "Causes of error\n\n\nType I Errors\n\nMeasurement error\nLack of random sample\nα value too liberal (α = .10)\nInvestigator bias\nImproper use of one-tailed test\n\n\nType II Errors\n\nMeasurement error\nLack of sufficient power (N too small)\nα value too conservative (α = .01)\nTreatment effect not properly applied\n\n\n\nCredit: Weir and Vincent (2021)"
  },
  {
    "objectID": "slides/lec-6.html#decision-table",
    "href": "slides/lec-6.html#decision-table",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Decision Table",
    "text": "Decision Table\nThis table shows the possible outcomes of a hypothesis test based on whether the null hypothesis is true or false and whether the test correctly rejects or fails to reject the null hypothesis. A Type I error occurs when the null hypothesis is actually true, but the test incorrectly rejects it. A Type II error occurs when the null hypothesis is actually false, but the test incorrectly fails to reject it.\n\n\n\n\n\n\n\n\n\nNull Hypothesis is True\nNull Hypothesis is False\n\n\n\n\nReject Null Hypothesis\nType I Error (False Positive)\nCorrect Decision (True Positive)\n\n\nFail to Reject Null Hypothesis\nCorrect Decision (True Negative)\nType II Error (False Negative)"
  },
  {
    "objectID": "slides/lec-6.html#effect-size-and-power-analysis",
    "href": "slides/lec-6.html#effect-size-and-power-analysis",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Effect Size and Power Analysis",
    "text": "Effect Size and Power Analysis\n\nEffect size measures strength of relationship between two variables or magnitude of difference between two groups.\nUsed in hypothesis testing to supplement p-value and provide more meaningful interpretation of results.\nIn Kinesiology, effect size can be used to determine practical significance of study’s findings.\nPower analysis is statistical technique used to determine sample size needed to detect certain effect size with certain level of statistical power.\nStatistical power is probability of correctly rejecting null hypothesis when it is false.\nIn Kinesiology, power analysis can be used to plan sample size for a study to ensure adequate statistical power and reduce risk of type II errors."
  },
  {
    "objectID": "slides/lec-6.html#one-tailed-and-two-tailed-statistical-tests",
    "href": "slides/lec-6.html#one-tailed-and-two-tailed-statistical-tests",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "One-Tailed and Two-Tailed Statistical Tests",
    "text": "One-Tailed and Two-Tailed Statistical Tests\nResearchers choose between one-tailed or two-tailed tests based on the research question and hypotheses.\n\nA one-tailed test is used when the research question involves a specific directional prediction about the relationship between the variables.\nA two-tailed test is used when the research question involves a non-specific directional prediction about the relationship between the variables."
  },
  {
    "objectID": "slides/lec-6.html#one-tailed-test",
    "href": "slides/lec-6.html#one-tailed-test",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "One-Tailed Test",
    "text": "One-Tailed Test\n\nThe critical region for rejecting the null hypothesis is located in only one tail of the distribution, either the upper or the lower tail, depending on the direction of the prediction.\nOne-tailed tests are used when the research question involves a specific directional prediction.\nA one-tailed test has more power to detect a significant effect in a specific direction, but it also has a higher risk of a Type I error if the direction of the effect is incorrect."
  },
  {
    "objectID": "slides/lec-6.html#example-3",
    "href": "slides/lec-6.html#example-3",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Example",
    "text": "Example\n\n# set mean and standard deviation\nmu &lt;- 0\nsigma &lt;- 1\n\n# create x-axis values\nx &lt;- seq(-4, 4, by = 0.01)\n\n# create normal distribution\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# plot normal distribution\nplot(x, y, type = \"l\", xlab = \"x\", ylab = \"Density\", main = \"Normal Distribution\")\n\n# shade rejection region\nx_reject &lt;- seq(1.65, 4, by = 0.01)\ny_reject &lt;- dnorm(x_reject, mean = mu, sd = sigma)\npolygon(c(x_reject, 4, 4, x_reject[1]), c(y_reject, 0, dnorm(4, mean = mu, sd = sigma), 0), col = \"red\", border = NA)\n\n# indicate z-score for rejection region\nabline(v = 1.65, col = \"blue\", lty = 2)\ntext(1.7, 0.25, \"z = 1.65\", col = \"blue\")\n\n\nFigure 1: Distribution of α rejection area for a One-tailed test."
  },
  {
    "objectID": "slides/lec-6.html#two-tailed-test",
    "href": "slides/lec-6.html#two-tailed-test",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Two-Tailed Test",
    "text": "Two-Tailed Test\n\nThe critical region for rejecting the null hypothesis is located in both tails of the distribution, representing extreme values in either direction.\nTwo-tailed tests are used when the research question involves a non-specific directional prediction.\nA two-tailed test has less power to detect a significant effect but is more conservative and less likely to make a Type I error."
  },
  {
    "objectID": "slides/lec-6.html#example-4",
    "href": "slides/lec-6.html#example-4",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Example",
    "text": "Example\n\n# Define mean and standard deviation\nmu &lt;- 0\nsigma &lt;- 1\n\n# Create x-axis values\nx &lt;- seq(-4, 4, length.out = 1000)\n\n# Calculate y-axis values using probability density function\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot normal distribution\nplot(x, y, type = \"l\", xlab = \"Z-score\", ylab = \"Probability Density\",\n     main = \"Normal Distribution with Rejection Regions (Two-tailed Test)\")\n\n# Define alpha level\nalpha &lt;- 0.05\n\n# Define rejection regions\nlower_reject &lt;- qnorm(alpha/2, mean = mu, sd = sigma)\nupper_reject &lt;- qnorm(1-alpha/2, mean = mu, sd = sigma)\n\n# Shade rejection regions\npolygon(c(lower_reject, seq(lower_reject, upper_reject, length.out = 100), upper_reject),\n        c(0, dnorm(seq(lower_reject, upper_reject, length.out = 100), mean = mu, sd = sigma), 0),\n        col = \"gray\", border = NA)\n\n# Add text labels for rejection regions\ntext(lower_reject - 0.15, 0.05, expression(alpha/2))\ntext(upper_reject + 0.15, 0.05, expression(alpha/2))\n\n# Add text label for non-rejection region\ntext((lower_reject + upper_reject)/2, 0.1, expression(1-alpha), cex = 1.5)\n\n\nFigure 2: Distribution of α rejection area for a two-tailed test"
  },
  {
    "objectID": "slides/lec-6.html#choosing-between-one-tailed-and-two-tailed-tests",
    "href": "slides/lec-6.html#choosing-between-one-tailed-and-two-tailed-tests",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "Choosing between one-tailed and two-tailed tests",
    "text": "Choosing between one-tailed and two-tailed tests\n\nThe choice between a one-tailed and two-tailed test depends on the research question and the hypothesis being tested.\nWhen the research question is directional, or the hypothesis specifies the direction of the effect, a one-tailed test is appropriate.\nWhen the research question is non-directional, or the hypothesis does not specify the direction of the effect, a two-tailed test is appropriate.\nIt is important to choose the appropriate test to ensure the validity and accuracy of the results."
  },
  {
    "objectID": "slides/lec-6.html#references",
    "href": "slides/lec-6.html#references",
    "title": "Week 6: Fundamentals of Inferential Statistics",
    "section": "References",
    "text": "References\n\n\n\nhttps://drfurtado.github.io/kin610/\n\n\n\nWeir, Joseph P., and William J. Vincent. 2021. Statistics in Kinesiology. Human Kinetics. https://us.humankinetics.com/products/statistics-in-kinesiology-5th-edition-with-web-resource."
  },
  {
    "objectID": "slides/lec-7.html#intro",
    "href": "slides/lec-7.html#intro",
    "title": "Week 7: Bivariate Correlation",
    "section": "Intro",
    "text": "Intro\n\nBivariate correlation analysis is a statistical technique to measure the strength and direction of the linear relationship between two variables\nIt helps identify the impact of variables on human health and physical activity"
  },
  {
    "objectID": "slides/lec-7.html#the-correlation-coefficient",
    "href": "slides/lec-7.html#the-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "The correlation coefficient",
    "text": "The correlation coefficient\n\nA correlation coefficient is a statistical measure used to determine the strength and direction of the linear relationship between two variables.\nCorrelation coefficients range from -1 to +1 and provide a numerical value that summarizes the degree to which two variables are related.\nCorrelation coefficients are denoted by different symbols depending on their type."
  },
  {
    "objectID": "slides/lec-7.html#properties-of-correlation-coefficient",
    "href": "slides/lec-7.html#properties-of-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Properties of Correlation Coefficient",
    "text": "Properties of Correlation Coefficient\n\nAre symmetric, meaning that the order of the variables does not affect the value of the coefficient.\nOutliers are extreme values that can disproportionately influence the analysis results\n\nOutliers should be carefully examined and, if necessary, removed from the analysis to ensure that they are not unduly influencing the results\n\nAre a unitless measure of association\nNot affected by changes in the units of measurement of the variables\n\nUseful for comparing the strength of relationships between variables measured in different units"
  },
  {
    "objectID": "slides/lec-7.html#properties-of-correlation-coefficient-cont",
    "href": "slides/lec-7.html#properties-of-correlation-coefficient-cont",
    "title": "Week 7: Bivariate Correlation",
    "section": "Properties of Correlation Coefficient, cont",
    "text": "Properties of Correlation Coefficient, cont\n\nThe correlation coefficient is always between -1 and +1\nProvides a standardized measure of association that can be easily interpreted\nCloser the correlation coefficient is to -1 or +1, stronger the relationship is between the variables"
  },
  {
    "objectID": "slides/lec-7.html#criteria-for-interpretation",
    "href": "slides/lec-7.html#criteria-for-interpretation",
    "title": "Week 7: Bivariate Correlation",
    "section": "Criteria for interpretation",
    "text": "Criteria for interpretation\nThis table is used to interpret the strength of association between two variables based on the magnitude of their correlation coefficient.\nHowever, it’s important to keep in mind that these are just guidelines, and the strength of association may depend on the context and specific research question.\n\n\n\nCorrelation coefficient\nCorrelation strength\nCorrelation type\n\n\n\n\n-.7 to -1\nVery strong\nNegative\n\n\n-.5 to -.7\nStrong\nNegative\n\n\n-.3 to -.5\nModerate\nNegative\n\n\n0 to -.3\nWeak\nNegative\n\n\n0\nNone\nZero\n\n\n0 to .3\nWeak\nPositive\n\n\n.3 to .5\nModerate\nPositive\n\n\n.5 to .7\nStrong\nPositive\n\n\n.7 to 1\nVery strong\nPositive"
  },
  {
    "objectID": "slides/lec-7.html#types-of-correlation-coefficient",
    "href": "slides/lec-7.html#types-of-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Types of Correlation Coefficient",
    "text": "Types of Correlation Coefficient\n\nThere are several types of correlation coefficients that can be used in bivariate correlation analysis, each with its strengths and limitations.\nMost common: Pearson's correlation coefficient (\\(r\\)), which measures the strength and direction of the linear relationship between two variables.\nRanges from -1 to +1, with a value of -1 indicating a perfect negative correlation, a value of 0 indicating no correlation, and a value of +1 indicating a perfect positive correlation."
  },
  {
    "objectID": "slides/lec-7.html#comparison-table",
    "href": "slides/lec-7.html#comparison-table",
    "title": "Week 7: Bivariate Correlation",
    "section": "Comparison table",
    "text": "Comparison table\n\n\n\n\n\n\n\n\nCorrelation Coefficient\nSymbol\nScales\n\n\n\n\nPearson\n\\(r\\)\nBoth scales interval (or ratio)\n\n\nSpearman\n\\(\\rho\\) (rho)\nBoth scales ordinal\n\n\nKendall\n\\(\\tau\\) (tau)\nBoth scales ordinal\n\n\nPoint-Biserial\nrpbi\nOne scale naturally dichotomous (nominal), one scale interval (or ratio)\n\n\nPhi\n\\(\\phi\\) (phi)\nBoth scales are naturally dichotomous (nominal)\n\n\nGamma\n\\(\\gamma\\) (gamma)\nOne scale nominal, one scale ordinal"
  },
  {
    "objectID": "slides/lec-7.html#pearson-correlation-coefficient",
    "href": "slides/lec-7.html#pearson-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Pearson correlation coefficient",
    "text": "Pearson correlation coefficient\n\nUsed in research studies with interval or ratio scale variables\nMeasures strength and direction of linear relationship between two continuous variables\nWidely recognized and accepted, many statistical software packages include functions for calculating it\nAssumes linear and normally distributed relationship, sensitive to outliers and extreme values"
  },
  {
    "objectID": "slides/lec-7.html#spearmans-rank-correlation-coefficient",
    "href": "slides/lec-7.html#spearmans-rank-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Spearman’s rank correlation coefficient",
    "text": "Spearman’s rank correlation coefficient\n\nUsed when data is not normally distributed or there are outliers\nBased on ranks of data, measures monotonic relationship between two variables\nMonotonic relationship means variables move in same direction but not necessarily at constant rate"
  },
  {
    "objectID": "slides/lec-7.html#kendalls-tau-correlation-coefficient",
    "href": "slides/lec-7.html#kendalls-tau-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Kendall’s tau correlation coefficient",
    "text": "Kendall’s tau correlation coefficient\n\nAlso based on ranks of data, more robust than Spearman’s rank correlation coefficient\nUsed when sample size is small or there are tied ranks in the data"
  },
  {
    "objectID": "slides/lec-7.html#point-biserial-correlation-coefficient",
    "href": "slides/lec-7.html#point-biserial-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Point-biserial correlation coefficient",
    "text": "Point-biserial correlation coefficient\n\nUsed when one variable is dichotomous and the other is continuous\nMeasures association between dichotomous and continuous variables"
  },
  {
    "objectID": "slides/lec-7.html#phi-correlation-coefficient",
    "href": "slides/lec-7.html#phi-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Phi correlation coefficient",
    "text": "Phi correlation coefficient\n\nUsed when both variables are dichotomous\nMeasures association between two dichotomous variables"
  },
  {
    "objectID": "slides/lec-7.html#gamma-correlation-coefficient",
    "href": "slides/lec-7.html#gamma-correlation-coefficient",
    "title": "Week 7: Bivariate Correlation",
    "section": "Gamma correlation coefficient",
    "text": "Gamma correlation coefficient\n\nNon-parametric measure of association between two variables (one nominal and one ordinal)\nMeasures strength and direction of monotonic relationship\nUsed in research studies with categorical data or healthcare research\nDoes not assume linear relationship between variables"
  },
  {
    "objectID": "slides/lec-7.html#graphical-representation-of-correlation",
    "href": "slides/lec-7.html#graphical-representation-of-correlation",
    "title": "Week 7: Bivariate Correlation",
    "section": "Graphical Representation of Correlation",
    "text": "Graphical Representation of Correlation\n\nGraphical representation of correlation can provide valuable insights into the relationship between two variables.\nScatterplots\n\nare a common method of graphical representation of correlation.\ncan also be used to identify outliers and nonlinear relationships between variables."
  },
  {
    "objectID": "slides/lec-7.html#scale-of-measurement-of-variables",
    "href": "slides/lec-7.html#scale-of-measurement-of-variables",
    "title": "Week 7: Bivariate Correlation",
    "section": "Scale of measurement of variables",
    "text": "Scale of measurement of variables\n\nCorrelation coefficient is affected by the scale of measurement of the variables\nIf one variable is measured on a larger scale than the other, the correlation coefficient may be artificially inflated\nScale of measurement should be considered when interpreting the correlation coefficient"
  },
  {
    "objectID": "slides/lec-7.html#graphical-representation-of-correlation-1",
    "href": "slides/lec-7.html#graphical-representation-of-correlation-1",
    "title": "Week 7: Bivariate Correlation",
    "section": "Graphical representation of correlation",
    "text": "Graphical representation of correlation\n\nScatter plot is a graph displaying the relationship between two continuous variables as points\nThe horizontal axis represents one variable, and the vertical axis represents another variable\nScatter plot can identify the presence and strength of a linear relationship between the two variables"
  },
  {
    "objectID": "slides/lec-7.html#correlation-vs.-causation",
    "href": "slides/lec-7.html#correlation-vs.-causation",
    "title": "Week 7: Bivariate Correlation",
    "section": "Correlation vs. Causation",
    "text": "Correlation vs. Causation\n\nCorrelation does not imply causation.\nTwo variables may be correlated, but other factors may be influencing their relationship."
  },
  {
    "objectID": "slides/lec-7.html#limitations-of-bivariate-correlation",
    "href": "slides/lec-7.html#limitations-of-bivariate-correlation",
    "title": "Week 7: Bivariate Correlation",
    "section": "Limitations of Bivariate Correlation",
    "text": "Limitations of Bivariate Correlation\n\nOnly examines the relationship between two variables and does not consider the influence of other variables.\nDoes not provide information about causation.\nAssumes a linear relationship and normality, which may not always be appropriate - there is fix"
  },
  {
    "objectID": "slides/lec-7.html#steps-for-conducting-bivariate-correlation",
    "href": "slides/lec-7.html#steps-for-conducting-bivariate-correlation",
    "title": "Week 7: Bivariate Correlation",
    "section": "Steps for Conducting Bivariate Correlation",
    "text": "Steps for Conducting Bivariate Correlation\n\nCheck for normality.\nCheck for outliers.\nCalculate the correlation coefficient.\nTest for statistical significance.\nInterpret the results."
  },
  {
    "objectID": "slides/lec-7.html#example",
    "href": "slides/lec-7.html#example",
    "title": "Week 7: Bivariate Correlation",
    "section": "Example",
    "text": "Example\n\nStudy on the relationship between exercise intensity and heart rate.\nNormality and outlier checks performed.\nCorrelation coefficient calculated (r = 0.80).\nStatistical significance tested (p &lt; 0.05).\nInterpretation: Strong positive relationship between exercise intensity and heart rate."
  },
  {
    "objectID": "slides/lec-7.html#hypothesis-testing-in-bivariate-correlation-analysis",
    "href": "slides/lec-7.html#hypothesis-testing-in-bivariate-correlation-analysis",
    "title": "Week 7: Bivariate Correlation",
    "section": "Hypothesis Testing in Bivariate Correlation Analysis",
    "text": "Hypothesis Testing in Bivariate Correlation Analysis\n\nBivariate correlation analysis involves hypothesis testing to determine if there is a significant correlation between the variables of interest.\nHypothesis testing determines the probability that the correlation coefficient calculated from the sample data is statistically significant, indicating that it is unlikely to have occurred by chance."
  },
  {
    "objectID": "slides/lec-7.html#null-alternative-hypotheses",
    "href": "slides/lec-7.html#null-alternative-hypotheses",
    "title": "Week 7: Bivariate Correlation",
    "section": "Null & Alternative Hypotheses",
    "text": "Null & Alternative Hypotheses\n\nThe null hypothesis for a bivariate correlation analysis is that there is no significant correlation between the two variables.\nThe alternative hypothesis is that there is a significant correlation between the two variables.\nThe significance level, denoted by α, is the probability of rejecting the null hypothesis when it is true.\nFollow the example below when stating the null (𝐻0) and alternative (𝐻𝑎) hypotheses."
  },
  {
    "objectID": "slides/lec-7.html#stating-the-null-and-alternative-hypotheses",
    "href": "slides/lec-7.html#stating-the-null-and-alternative-hypotheses",
    "title": "Week 7: Bivariate Correlation",
    "section": "Stating the Null and Alternative Hypotheses",
    "text": "Stating the Null and Alternative Hypotheses\nH0: There is no linear correlation between the two variables, or the correlation coefficient is zero.\nH1: There is a linear correlation between the two variables, or the correlation coefficient is not zero.\nMathematically, we can represent the null and alternative hypotheses as:\nH0: 𝜌 = 0\nH1: 𝜌 ≠ 0\n𝜌 is the population correlation coefficient."
  },
  {
    "objectID": "slides/lec-7.html#steps-to-conduct-hypothesis-testing",
    "href": "slides/lec-7.html#steps-to-conduct-hypothesis-testing",
    "title": "Week 7: Bivariate Correlation",
    "section": "Steps to Conduct Hypothesis Testing",
    "text": "Steps to Conduct Hypothesis Testing\n\nCalculate the correlation coefficient (r) using the sample data. Determine the degrees of freedom (df) equal to the sample size minus two (two variables).\nUse a table or statistical software to determine the critical value of r for the given significance level (i.e., alpha = 0.05) and degrees of freedom.\nCompare the calculated correlation coefficient to the critical value.\nIf the calculated correlation coefficient is greater than the critical value, reject the null hypothesis and conclude that there is a significant correlation between the two variables.\nIf the calculated correlation coefficient is less than the critical value, fail to reject the null hypothesis and conclude that there is no significant correlation between the two variables."
  },
  {
    "objectID": "slides/lec-7.html#assumptions-and-interpretation",
    "href": "slides/lec-7.html#assumptions-and-interpretation",
    "title": "Week 7: Bivariate Correlation",
    "section": "Assumptions and Interpretation",
    "text": "Assumptions and Interpretation\n\nThe correlation of two interval (or ratio) variables assumes that the data meet the assumptions of normality and linearity.\nNormality refers to the assumption that the distribution of the variables being studied is approximately normal.\nLinearity is the assumption that the relationship between the two variables is linear.\n\nIf these assumptions are not met, it may be necessary to use non-parametric correlation coefficients or transform the data to meet these assumptions.\n\nInterpret the results of hypothesis testing in the context of the research question and consider other factors that may influence the relationship between the variables.\nControlling for confounding variables or conducting subgroup analyses to explore potential interactions may be necessary.\n\nPartial correlation measures the strength of a relationship between two variables, while controlling for the effect of one or more other variables. \nFor example, you might want to see if there is a correlation between amount of food eaten and blood pressure, while controlling for weight or amount of exercise."
  },
  {
    "objectID": "slides/lec-7.html#correlation-and-jamovi",
    "href": "slides/lec-7.html#correlation-and-jamovi",
    "title": "Week 7: Bivariate Correlation",
    "section": "Correlation and jamovi",
    "text": "Correlation and jamovi\n\nesci module - Pearson correlation\n\nData: lsj - Parenthood\n\nCorrelation matrix (Pearson, Spearman, Kendall’s tau\n\nData: lsj - Anscombe"
  },
  {
    "objectID": "slides/lec-7.html#references",
    "href": "slides/lec-7.html#references",
    "title": "Week 7: Bivariate Correlation",
    "section": "References",
    "text": "References\n\n\n\nhttps://drfurtado.github.io/kin610/"
  },
  {
    "objectID": "slides/lec-5.html#credits",
    "href": "slides/lec-5.html#credits",
    "title": "Week 5: Descriptive Statistics",
    "section": "Credits",
    "text": "Credits\n(furtadoDescriptiveStatistics2023?)"
  },
  {
    "objectID": "slides/lec-5.html#the-mean",
    "href": "slides/lec-5.html#the-mean",
    "title": "Week 5: Descriptive Statistics",
    "section": "The Mean",
    "text": "The Mean\n\nThe mean is the most commonly used measure of central tendency in Kinesiology research.\nIt is the arithmetic average of a data set.\nCalculated by adding up all the values and dividing by the total number of values."
  },
  {
    "objectID": "slides/lec-5.html#why-mean",
    "href": "slides/lec-5.html#why-mean",
    "title": "Week 5: Descriptive Statistics",
    "section": "Why Mean?",
    "text": "Why Mean?\n\nThe mean considers all the values in a data set.\nSensitive to small changes in the data.\nAppropriate for continuous (normal) data"
  },
  {
    "objectID": "slides/lec-5.html#limitations-of-mean",
    "href": "slides/lec-5.html#limitations-of-mean",
    "title": "Week 5: Descriptive Statistics",
    "section": "Limitations of Mean",
    "text": "Limitations of Mean\n\n\n\nNot always the most appropriate measure of central tendency.\nExtreme outliers or skewed data can influence the mean.\n\n\n\nlibrary(stats)\n\n# Generate a gamma distributed random variable\nx &lt;- rgamma(n = 1000, shape = 2, rate = 1)\n\n# Create a skewed distribution by taking the square root of the gamma variable\ny &lt;- sqrt(x)\n\n# Plot the histogram of the skewed distribution\nhist(y, breaks = 20, col = \"lightblue\", main = \"Skewed Distribution\")"
  },
  {
    "objectID": "slides/lec-5.html#median-as-an-alternative",
    "href": "slides/lec-5.html#median-as-an-alternative",
    "title": "Week 5: Descriptive Statistics",
    "section": "Median as an alternative",
    "text": "Median as an alternative\n\nIf data are continuous but deviating from normality\nThe median is not as sensitive to extreme values as the mean.\nAppropriate with skewed data or data with outliers.\n\n\nset.seed(123)  # for reproducibility\n\n# Generate 1000 samples from a chi-squared distribution with 2 degrees of freedom\nx &lt;- rchisq(1000, df = 2)\n\n# Plot the histogram of x\nhist(x, breaks = 20, col = \"skyblue\", main = \"Badly skewed distribution\")"
  },
  {
    "objectID": "slides/lec-5.html#calculating-the-mean---steps",
    "href": "slides/lec-5.html#calculating-the-mean---steps",
    "title": "Week 5: Descriptive Statistics",
    "section": "Calculating the Mean - Steps",
    "text": "Calculating the Mean - Steps\n\nAdd up all the values in the dataset.\nCount the number of observations in the dataset.\nDivide the total sum by the number of observations."
  },
  {
    "objectID": "slides/lec-5.html#calculating-the-mean---example",
    "href": "slides/lec-5.html#calculating-the-mean---example",
    "title": "Week 5: Descriptive Statistics",
    "section": "Calculating the Mean - Example",
    "text": "Calculating the Mean - Example\nData set: 12.5, 10.8, 11.2, 13.1, 12.9, 11.7, 12.3\n\nStep 1: 12.5 + 10.8 + 11.2 + 13.1 + 12.9 + 11.7 + 12.3 = 84.5\nStep 2: 7\nStep 3: 84.5 / 7 = 12.07 seconds"
  },
  {
    "objectID": "slides/lec-5.html#calculating-the-mean---equation",
    "href": "slides/lec-5.html#calculating-the-mean---equation",
    "title": "Week 5: Descriptive Statistics",
    "section": "Calculating the Mean - Equation",
    "text": "Calculating the Mean - Equation\n\\[\n\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\n\\]\nwhere, \\(n\\) is the total number of values in the set, \\(x_i\\) is the \\(i\\)th value in the set, and \\(\\sum_{i=1}^{n}\\) represents the sum of all the values from \\(i=1\\) to \\(i=n\\)."
  },
  {
    "objectID": "slides/lec-5.html#displaying-data1",
    "href": "slides/lec-5.html#displaying-data1",
    "title": "Week 5: Descriptive Statistics",
    "section": "Displaying data1",
    "text": "Displaying data1\n\nlibrary(ggplot2)\n\n# Create a data frame with 3 group means\ngroup_means &lt;- data.frame(group = c(\"Group 1\", \"Group 2\", \"Group 3\"),\n                          mean = c(10, 15, 12))\n\n# Create a bar chart with custom colors and labels\nggplot(group_means, aes(x = group, y = mean, fill = group)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"#FFA07A\", \"#87CEEB\", \"#90EE90\")) +  # custom colors\n  labs(title = \"Comparison of Group Means in Kinesiology\",\n       x = \"Groups\", y = \"Mean Values\")\n\n\n\n\nBar chart created in RStudio."
  },
  {
    "objectID": "slides/lec-5.html#median",
    "href": "slides/lec-5.html#median",
    "title": "Week 5: Descriptive Statistics",
    "section": "Median",
    "text": "Median\n\nDefinition of Median\nMedian is not influenced by extreme values\nMedian may not be as sensitive to small changes in the data as the mean\nBoth case below the median is 7\ndata1: 1, 3, 7, 7, 8, 99\ndata2: 1, 3, 7, 7, 8, 9"
  },
  {
    "objectID": "slides/lec-5.html#median-calculation",
    "href": "slides/lec-5.html#median-calculation",
    "title": "Week 5: Descriptive Statistics",
    "section": "Median Calculation",
    "text": "Median Calculation\n\nFirst step is arranging the data in order of magnitude\nMedian is the middle value if the number of observations is odd\nMedian is the average of two middle values if the number of observations is even\nUse of median when data contains extreme values or is ordinal\nHelps to understand the group’s typical value or performance\nExample in the next slide"
  },
  {
    "objectID": "slides/lec-5.html#mode",
    "href": "slides/lec-5.html#mode",
    "title": "Week 5: Descriptive Statistics",
    "section": "Mode",
    "text": "Mode\n\nDefinition of Mode\nMode is the value that occurs most frequently in a data set\nMode is often used with categorical or nominal data"
  },
  {
    "objectID": "slides/lec-5.html#mode-calculation",
    "href": "slides/lec-5.html#mode-calculation",
    "title": "Week 5: Descriptive Statistics",
    "section": "Mode Calculation",
    "text": "Mode Calculation\n\nIdentify the value or category that occurs most frequently in the data set\nHelps researchers identify the most common value or category in a data set"
  },
  {
    "objectID": "slides/lec-5.html#comparison-table",
    "href": "slides/lec-5.html#comparison-table",
    "title": "Week 5: Descriptive Statistics",
    "section": "Comparison table",
    "text": "Comparison table\n\n\n\n\n\n\n\n\n\nMeasure of Central Tendency\nDefinition\nCalculation\nUsefulness\n\n\n\n\nMean\nThe average of a set of numbers\nSum of values divided by number of values\nUseful for data that are normally distributed and have no extreme values\n\n\nMedian\nThe middle value in a set of numbers\nOrder values and find the middle value\nUseful for data with extreme values or that are not normally distributed\n\n\nMode\nThe value that occurs most frequently in a set of numbers\nIdentify the value that appears most often\nUseful for categorical or nominal data"
  },
  {
    "objectID": "slides/lec-5.html#introduction",
    "href": "slides/lec-5.html#introduction",
    "title": "Week 5: Descriptive Statistics",
    "section": "Introduction",
    "text": "Introduction\n\nUnderstanding how much individual data points in a data set vary from one another\nTypes: variance, standard deviation, range, and interquartile range\nImportance\n\nunderstanding data sets\ncan help researchers understand the precision and accuracy of their results\nto draw meaningful conclusions"
  },
  {
    "objectID": "slides/lec-5.html#range",
    "href": "slides/lec-5.html#range",
    "title": "Week 5: Descriptive Statistics",
    "section": "Range",
    "text": "Range\n\nDifference between the largest and smallest values in a data set\nLimitations of range due to sensitivity to outliers or extreme values\nCaution in interpreting the range especially when there are outliers\nThe need to use range in conjunction with other measures of variability"
  },
  {
    "objectID": "slides/lec-5.html#calculating-range",
    "href": "slides/lec-5.html#calculating-range",
    "title": "Week 5: Descriptive Statistics",
    "section": "Calculating Range",
    "text": "Calculating Range\n\nUse of jamovi to obtain the minimum and maximum values for a data set\nCalculation of the range by subtracting the minimum from the maximum value"
  },
  {
    "objectID": "slides/lec-5.html#interquartile-range",
    "href": "slides/lec-5.html#interquartile-range",
    "title": "Week 5: Descriptive Statistics",
    "section": "Interquartile Range",
    "text": "Interquartile Range\n\nDefinition of interquartile range as a measure of variability that is less sensitive to outliers\nUse of quartiles to divide a data set into four equal parts\nCalculation of interquartile range as the difference between the upper and lower quartiles\nImportance of interquartile range in providing information about the range of the middle 50% of the data"
  },
  {
    "objectID": "slides/lec-5.html#calculating-interquartile-range",
    "href": "slides/lec-5.html#calculating-interquartile-range",
    "title": "Week 5: Descriptive Statistics",
    "section": "Calculating Interquartile Range",
    "text": "Calculating Interquartile Range\n\nCalculation: Q3 - Q1\nInterpretation: the range between the first quartile and the third quartile\nAdvantages: Resistant to outliers\nDisadvantages: Not sensitive to extreme values that fall outside the range of the interquartile"
  },
  {
    "objectID": "slides/lec-5.html#variance",
    "href": "slides/lec-5.html#variance",
    "title": "Week 5: Descriptive Statistics",
    "section": "Variance",
    "text": "Variance\n\n\n\\(s^2 = \\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\)\n\n\nInterpretation: A measure of how much the data deviates from the mean\nAdvantages: Widely used and well known\nDisadvantages: Can be sensitive to outliers"
  },
  {
    "objectID": "slides/lec-5.html#standard-deviation",
    "href": "slides/lec-5.html#standard-deviation",
    "title": "Week 5: Descriptive Statistics",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\nCalculation: \\(s = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}}\\)\nInterpretation: A measure of the amount of variation or dispersion of a set of values from the mean\nAdvantages: Widely used and well known\nDisadvantages: Can be sensitive to outliers; more difficult to interpret than the range or IQR"
  },
  {
    "objectID": "slides/lec-5.html#coefficient-of-variation",
    "href": "slides/lec-5.html#coefficient-of-variation",
    "title": "Week 5: Descriptive Statistics",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nCalculation: CV = \\(\\frac{s}{\\bar{x}} \\times 100%\\)\nInterpretation: A measure of the relative variation or dispersion of a data set, particularly useful for comparing the variability of data sets with different units or scales\nAdvantages: Allows for comparison of the relative variability of data sets with different scales or units\nDisadvantages: Not suitable for data sets with negative or zero mean values"
  },
  {
    "objectID": "slides/lec-5.html#comparing-measures-of-variability",
    "href": "slides/lec-5.html#comparing-measures-of-variability",
    "title": "Week 5: Descriptive Statistics",
    "section": "Comparing Measures of Variability",
    "text": "Comparing Measures of Variability\n\nIt is essential to consider the characteristics of the data and the research question when comparing measures of variability.\nRange and IQR are useful for non-normally distributed data or when identifying outliers.\nVariance and standard deviation are useful for normally distributed data and can provide more information about the spread of the distribution.\nCoefficient of variation is suitable for comparing the spread of two sets of data with different units."
  },
  {
    "objectID": "slides/lec-5.html#comparison-table-1",
    "href": "slides/lec-5.html#comparison-table-1",
    "title": "Week 5: Descriptive Statistics",
    "section": "Comparison table",
    "text": "Comparison table\n\n\n\n\n\n\n\n\n\n\nMeasure of Variability\nCalculation\nInterpretation\nAdvantages\nDisadvantages\n\n\n\n\nRange\nMaximum value - Minimum value\nThe spread of the data from the smallest to the largest value\nEasy to understand\nSensitive to outliers\n\n\nInterquartile Range\nQ3 - Q1\nThe range between the first quartile and the third quartile\nResistant to outliers\nNot sensitive to extreme values that fall outside the range of the interquartile\n\n\nVariance\n\\(s^2 = \\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\)\nA measure of how much the data deviates from the mean\nWidely used and well known\nCan be sensitive to outliers\n\n\nStandard Deviation\n\\(s = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}}\\)\nA measure of the amount of variation or dispersion of a set of values from the mean\nWidely used and well known\nCan be sensitive to outliers; more difficult to interpret than the range or IQR"
  },
  {
    "objectID": "slides/lec-5.html#using-jamovi",
    "href": "slides/lec-5.html#using-jamovi",
    "title": "Week 5: Descriptive Statistics",
    "section": "Using jamovi",
    "text": "Using jamovi\n\n\n\n\n\nOpen jamovi, click Exploration, then Descriptives\nMove DVs under Variables and IVs under Split by\nSelect Variables across rows under Descriptives (horizontal format)\njamovi will create a Descriptives Table - see next slide."
  },
  {
    "objectID": "slides/lec-5.html#descriptives-table",
    "href": "slides/lec-5.html#descriptives-table",
    "title": "Week 5: Descriptive Statistics",
    "section": "Descriptives Table",
    "text": "Descriptives Table"
  },
  {
    "objectID": "slides/lec-5.html#summary",
    "href": "slides/lec-5.html#summary",
    "title": "Week 5: Descriptive Statistics",
    "section": "Summary",
    "text": "Summary\n\nDescriptive statistics help in summarizing and describing a dataset’s features.\nMeasures of variability are used to understand how spread out the data is.\nThe range, interquartile range, variance, standard deviation, and coefficient of variation are measures of variability that have their advantages and disadvantages.\nThe choice of measure depends on the characteristics of the data and the research question."
  },
  {
    "objectID": "slides/lec-4.html#credits",
    "href": "slides/lec-4.html#credits",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Credits",
    "text": "Credits\n(furtado2022?); Navarro and Foxcroft (2022)"
  },
  {
    "objectID": "slides/lec-4.html#percentile-and-percentile-rank",
    "href": "slides/lec-4.html#percentile-and-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Percentile and Percentile Rank",
    "text": "Percentile and Percentile Rank\nPercentiles and percentile rank are related concepts, but they have slightly different meanings.\nA percentile is a specific value that indicates the percentage of values that are equal to or below a given value in a dataset. For example, the 75th percentile is the value below which 75% of the values in a dataset fall.\nPercentile rank, on the other hand, is a measure of the relative position of a score within a distribution of scores. It indicates the percentage of scores that are equal to or below a given score. For example, if a score has a percentile rank of 75, it means that 75% of the scores in the distribution are equal to or below that score.\nIn essence, percentile rank uses percentiles to determine the relative position of a score within a dataset. While percentiles focus on specific values in a dataset, percentile rank focuses on the relative position of a score within the distribution of scores."
  },
  {
    "objectID": "slides/lec-4.html#definition-of-percentiles",
    "href": "slides/lec-4.html#definition-of-percentiles",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Definition of Percentiles",
    "text": "Definition of Percentiles\n\nA measure used in statistics\nIndicates the value below which a certain percentage of observations in a group fall"
  },
  {
    "objectID": "slides/lec-4.html#example-20th-percentile",
    "href": "slides/lec-4.html#example-20th-percentile",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example: 20th Percentile",
    "text": "Example: 20th Percentile\n\nThe value below which 20% of the observations may be found\nCan be used to compare the relative standing of a value within a dataset (Percentile Rank)"
  },
  {
    "objectID": "slides/lec-4.html#example-90th-percentile",
    "href": "slides/lec-4.html#example-90th-percentile",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example: 90th Percentile",
    "text": "Example: 90th Percentile\n\nIf a student’s test score is in the 90th percentile, it means that the student scored higher than 90% of the other students who took the test"
  },
  {
    "objectID": "slides/lec-4.html#determining-distribution",
    "href": "slides/lec-4.html#determining-distribution",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Determining Distribution",
    "text": "Determining Distribution\n\nPercentiles can be used to determine the distribution of values within a dataset\nIf the majority of scores fall within the lower percentiles, it may indicate that the scores are generally lower\nIf the majority of scores fall within the higher percentiles, it may indicate that the scores are generally higher"
  },
  {
    "objectID": "slides/lec-4.html#in-a-nutshell",
    "href": "slides/lec-4.html#in-a-nutshell",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "In a nutshell…",
    "text": "In a nutshell…\n\nPercentiles can be calculated using a variety of methods\nOne common method is to first arrange the data in order from smallest to largest\nThen identify the value that corresponds to the desired percentile"
  },
  {
    "objectID": "slides/lec-4.html#doing-it-by-hand",
    "href": "slides/lec-4.html#doing-it-by-hand",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Doing it by hand",
    "text": "Doing it by hand\n\nArrange the data set in numerical order\nDetermine the position of the percentile you want to calculate in the data set\nE.g. 50th percentile is also known as the median\nCalculate the percentile by multiplying the position of the percentile by the total number of values in the data set and then dividing that number by 100\nE.g. (5 * 10) / 100 = 0.5 for the 50th percentile of a data set with 10 values\nTo find the value at the percentile you calculated, go to the position in the data set that corresponds to the percentile value"
  },
  {
    "objectID": "slides/lec-4.html#example-1",
    "href": "slides/lec-4.html#example-1",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example 1:",
    "text": "Example 1:\n\nData set: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nFind 50th percentile (median)\nPosition: 50th percentile = (50 / 100) * 10 = 5\nValue: 5"
  },
  {
    "objectID": "slides/lec-4.html#example-2",
    "href": "slides/lec-4.html#example-2",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Example 2:",
    "text": "Example 2:\n\nData set: {5, 7, 8, 12, 14, 15, 16, 17, 18, 20}\nFind 75th percentile\nPosition: 75th percentile = (75 / 100) * 10 = 7.5\nValue: average of 7th and 8th values = (16 + 17) / 2 = 16.5"
  },
  {
    "objectID": "slides/lec-4.html#understanding-the-distribution-of-data",
    "href": "slides/lec-4.html#understanding-the-distribution-of-data",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Understanding the distribution of data",
    "text": "Understanding the distribution of data\n\nPercentile can be used to understand the distribution of data.\nIt indicates the value below which a certain percentage of data falls.\nFor example, if the 50th percentile of a dataset is 50, it means that 50% of the data falls below that value."
  },
  {
    "objectID": "slides/lec-4.html#interpreting-percentile-values",
    "href": "slides/lec-4.html#interpreting-percentile-values",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Interpreting percentile values",
    "text": "Interpreting percentile values\nExample 1: If the 10th percentile is 20 and the 90th percentile is 80, it means that 10% of the data falls below 20 and 90% of the data falls below 80.\n\nThis indicates that the data is distributed relatively evenly, with a few outliers on either side.\n\nExample 2: If the 10th percentile is 20 and the 90th percentile is 90, it means that there is a larger concentration of data towards the higher end of the scale."
  },
  {
    "objectID": "slides/lec-4.html#using-percentile-to-understand-data",
    "href": "slides/lec-4.html#using-percentile-to-understand-data",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Using percentile to understand data",
    "text": "Using percentile to understand data\n\nUsing percentile can help us understand the distribution of data and identify patterns or trends in the data.\nIt can also be used to compare different datasets and see how they differ in terms of distribution."
  },
  {
    "objectID": "slides/lec-4.html#comparing-data-sets",
    "href": "slides/lec-4.html#comparing-data-sets",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Comparing Data Sets",
    "text": "Comparing Data Sets\n\nComparing data sets can be useful to understand how a particular value in one data set compares to values in another data set.\nPercentiles can be used for comparing data sets, especially when they have different scales or units of measurement."
  },
  {
    "objectID": "slides/lec-4.html#definition-of-percentile-rank",
    "href": "slides/lec-4.html#definition-of-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Definition of Percentile Rank",
    "text": "Definition of Percentile Rank\n\nPercentile rank is a measure of the relative standing of a value in a dataset\nIndicates the percentage of values in the dataset that are equal to or less than the value in question\nExample: if a value has a percentile rank of 75, it means that 75% of the values in the dataset are equal to or less than that value."
  },
  {
    "objectID": "slides/lec-4.html#application-of-percentile-rank",
    "href": "slides/lec-4.html#application-of-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Application of Percentile Rank",
    "text": "Application of Percentile Rank\n\nPercentile ranks are commonly used to describe how well a person has performed on a test or assessment relative to a group of people\nExample: a person scores in the 75th percentile on a test, it means that they scored higher than 75% of the people who took the test\nPercentile ranks can also be used to compare the scores of different groups of people, such as comparing the scores of students in different schools or at different grade levels."
  },
  {
    "objectID": "slides/lec-4.html#difference-between-percentile-rank-and-percentage",
    "href": "slides/lec-4.html#difference-between-percentile-rank-and-percentage",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Difference between Percentile Rank and Percentage",
    "text": "Difference between Percentile Rank and Percentage\n\nIt’s important to note that percentile rank is different from percentage\nPercentile rank describes the relative standing of a value within a dataset\nPercentage is a measure of the number of items in a set relative to the total number of items."
  },
  {
    "objectID": "slides/lec-4.html#how-to-calculate-percentile-rank",
    "href": "slides/lec-4.html#how-to-calculate-percentile-rank",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "How to Calculate Percentile Rank",
    "text": "How to Calculate Percentile Rank\n\nOrganize the scores in ascending order.\nThe lowest score should be at the bottom.\nIdentify the position of the score in the ordered distribution."
  },
  {
    "objectID": "slides/lec-4.html#calculate-the-percentile-rank-as-a-percentage.",
    "href": "slides/lec-4.html#calculate-the-percentile-rank-as-a-percentage.",
    "title": "Week 4: Organizing and Displyain Data & Percentiles",
    "section": "Calculate the percentile rank as a percentage.",
    "text": "Calculate the percentile rank as a percentage.\n\nDivide the position of the score by the total number of scores.\nMultiply the result by 100 to get the percentile rank as a percentage.\n\nExample: Let’s say we have the following distribution of scores: 60, 70, 75, 80, 85, 90, 95, 100. The percentile rank for a score of 80 would be:\n\nOrganize the scores in ascending order: 60, 70, 75, 80, 85, 90, 95, 100.\nDetermine the position of the score in question: The score of 80 is the 4th score in the distribution.\nCalculate the percentile rank as a percentage: 4/8 * 100 = 50%. The score of 80 is at the 50th percentile."
  },
  {
    "objectID": "slides/lec-0.html#meet-each-other",
    "href": "slides/lec-0.html#meet-each-other",
    "title": "Welcome to KIN 610!",
    "section": "Meet each other!",
    "text": "Meet each other!\nIn breakout rooms:\n\nName, year, major, hometown\nWhat did you do over the winter break?\nWhat do you hope to get out of this course?\nAnything else you want to share/ask?\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lec-0.html#what-to-expect-in-class",
    "href": "slides/lec-0.html#what-to-expect-in-class",
    "title": "Welcome to KIN 610!",
    "section": "What to expect in class",
    "text": "What to expect in class\n\n\n\nTry to arrive 10 minutes before class begins to set up the computer, open lecture notes, etc.\nI will go over any announcements and begin the lecture shortly after\nA PDF version of the lecture notes will be provide to students, which can used for note taking purposes - electronically1 or hand writing2\nWhen covering jamovi, students are expected to follow along and turn in the generated output at the end of class - will count toward participation points\n\n\n\nUse Acrobat Reader for this purpose.The computer lab has a printer."
  },
  {
    "objectID": "slides/lec-0.html#wrap-up",
    "href": "slides/lec-0.html#wrap-up",
    "title": "Welcome to KIN 610!",
    "section": "Wrap up",
    "text": "Wrap up\nAre there any questions \n\n\n\nhttps://drfurtado.github.io/kin610/"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-professor",
    "href": "slides/lec-1.html#meet-the-professor",
    "title": "Welcome to KIN 610!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\nDr. Furtado - Cal State Northridge\n\n\n\n\nAssociate Professor in Motor Behavior, Department Kinesiology, Cal State Northridge\nFind out more at my academic site"
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to KIN 610!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Introductory statistics or probability course.\nWill we be doing computing? Yes. We will use jamovi."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to KIN 610!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to KIN 610!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching mini lecture videos)\nParticipate: Attend and actively participate in lectures and labs\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you’ve learned to analyze real-world data\n\nLab assignments x 6\nExam 1 and Exam 2"
  },
  {
    "objectID": "slides/lec-1.html#cadence",
    "href": "slides/lec-1.html#cadence",
    "title": "Welcome to KIN 610!",
    "section": "Cadence",
    "text": "Cadence\n\n\nActivities: Start and complete in class (completed/not completed)\nLabs: Start and make large progress on Friday-Saturday-Sunday and, finish it up by Thursday 4 pm of that week\nExams: Start and make large progress during the first two hours, then use the remaining time (~45 min) to check your answers"
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to KIN 610!",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions using our mailing list email address\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to KIN 610!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email (course mailing list), be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to KIN 610!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official CSUN records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to KIN 610!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times! \nRead and follow university guidance"
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to KIN 610!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to KIN 610!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nLabs must be completed individually. You may not directly share answers with others; however, you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to KIN 610!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the CSUN Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to KIN 610!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to KIN 610!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class\nAsk questions\nDo the readings\nDo the and labs\nDon’t procrastinate and don’t let a week pass by with lingering questions"
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic",
    "href": "slides/lec-1.html#learning-during-a-pandemic",
    "title": "Welcome to KIN 610!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this ongoing crisis."
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to KIN 610!",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nPrepare for next week by clicking here\nRe-read the syllabus\nWatch out for next week’s announcement email, in your inbox sometime tomorrow"
  },
  {
    "objectID": "slides/lec-1.html#bi-question-any-questions",
    "href": "slides/lec-1.html#bi-question-any-questions",
    "title": "Welcome to KIN 610!",
    "section": " Any Questions",
    "text": "Any Questions\n\n\n\nhttps://drfurtado.github.io/kin610/"
  },
  {
    "objectID": "slides/lec-3.html#credits",
    "href": "slides/lec-3.html#credits",
    "title": "Week 3: Intro to Stats",
    "section": "Credits",
    "text": "Credits\n(furtado2023?)"
  },
  {
    "objectID": "slides/lec-3.html#introduction-to-measurement-in-kinesiology",
    "href": "slides/lec-3.html#introduction-to-measurement-in-kinesiology",
    "title": "Week 3: Intro to Stats",
    "section": "Introduction to Measurement in Kinesiology",
    "text": "Introduction to Measurement in Kinesiology\n\nThe importance of measurement in Kinesiology\nMeasurement as the process of determining the value of a characteristic or quantity"
  },
  {
    "objectID": "slides/lec-3.html#why-measurement-is-important-in-kinesiology",
    "href": "slides/lec-3.html#why-measurement-is-important-in-kinesiology",
    "title": "Week 3: Intro to Stats",
    "section": "Why Measurement is Important in Kinesiology",
    "text": "Why Measurement is Important in Kinesiology\n\nMeasurement provides objective data\nMeasurement allows for comparison"
  },
  {
    "objectID": "slides/lec-3.html#evaluation-of-interventions",
    "href": "slides/lec-3.html#evaluation-of-interventions",
    "title": "Week 3: Intro to Stats",
    "section": "Evaluation of Interventions",
    "text": "Evaluation of Interventions\n\nMeasurement is essential for evaluating the effectiveness of interventions\nMeasurement can help to identify patterns or trends in large amounts of data"
  },
  {
    "objectID": "slides/lec-3.html#intro",
    "href": "slides/lec-3.html#intro",
    "title": "Week 3: Intro to Stats",
    "section": "Intro",
    "text": "Intro\n\nStatistics plays a crucial role in Kinesiology\nAllows researchers and practitioners to analyze and interpret data related to human movement, physical activity, and exercise"
  },
  {
    "objectID": "slides/lec-3.html#data-analysis-techniques",
    "href": "slides/lec-3.html#data-analysis-techniques",
    "title": "Week 3: Intro to Stats",
    "section": "Data Analysis Techniques",
    "text": "Data Analysis Techniques\n\nOne of the most common uses of statistics in Kinesiology is for data analyses This includes:\nDescriptive statistics: summarize and describe the main characteristics of a dataset\nInferential statistics: infer about a specific population based on a sample of data\nDescriptive statistics: mean, median, standard deviation, range\nInferential statistics: t-tests, ANOVA, regression analysis"
  },
  {
    "objectID": "slides/lec-3.html#design-and-analysis-of-experiments-and-studies",
    "href": "slides/lec-3.html#design-and-analysis-of-experiments-and-studies",
    "title": "Week 3: Intro to Stats",
    "section": "Design and Analysis of Experiments and Studies",
    "text": "Design and Analysis of Experiments and Studies\n\nStatistics used to design and analyze experiments and studies in Kinesiology\nStatistical tests: determine if there is a significant difference between groups or if an intervention has an effect\nExamples: t-test, ANOVA"
  },
  {
    "objectID": "slides/lec-3.html#correlation-and-causal-inference",
    "href": "slides/lec-3.html#correlation-and-causal-inference",
    "title": "Week 3: Intro to Stats",
    "section": "Correlation and Causal Inference",
    "text": "Correlation and Causal Inference\n\nCorrelation: measures the association between two variables\nCausal inference: determines if an observed association is due to a causal relationship"
  },
  {
    "objectID": "slides/lec-3.html#interpreting-results",
    "href": "slides/lec-3.html#interpreting-results",
    "title": "Week 3: Intro to Stats",
    "section": "Interpreting Results",
    "text": "Interpreting Results\n\nConsider level of significance: probability that results occurred by chance (p &lt; 0.05)\nConsider practical significance: meaningful results in the real world"
  },
  {
    "objectID": "slides/lec-3.html#visualizing-data",
    "href": "slides/lec-3.html#visualizing-data",
    "title": "Week 3: Intro to Stats",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nGraphical methods used to visualize data: histograms, scatter plots, box plots\nHelp identify patterns, outliers, and communicate results in an easily understandable format"
  },
  {
    "objectID": "slides/lec-3.html#variables",
    "href": "slides/lec-3.html#variables",
    "title": "Week 3: Intro to Stats",
    "section": "Variables",
    "text": "Variables\n\nA variable is a characteristic or factor that can change or take on different values within a study or experiment.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the variable of interest would be muscle strength."
  },
  {
    "objectID": "slides/lec-3.html#constants",
    "href": "slides/lec-3.html#constants",
    "title": "Week 3: Intro to Stats",
    "section": "Constants",
    "text": "Constants\n\nA constant is a characteristic or factor that remains unchanged or fixed within a study or experiment.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the age of the participants could be considered a constant."
  },
  {
    "objectID": "slides/lec-3.html#benefits-of-controlling-constants",
    "href": "slides/lec-3.html#benefits-of-controlling-constants",
    "title": "Week 3: Intro to Stats",
    "section": "Benefits of Controlling Constants",
    "text": "Benefits of Controlling Constants\n\nAllows researchers to isolate the effects of a particular variable of interest.\nConfidence that any changes observed are due to the variable of interest and not other factors."
  },
  {
    "objectID": "slides/lec-3.html#summary",
    "href": "slides/lec-3.html#summary",
    "title": "Week 3: Intro to Stats",
    "section": "Summary",
    "text": "Summary\n\nVariables and constants are important concepts in scientific research.\nVariables are factors that can change, while constants are factors that remain unchanged.\nUnderstanding and controlling constants is important to isolate the effects of the variables of interest."
  },
  {
    "objectID": "slides/lec-3.html#continuous-variables",
    "href": "slides/lec-3.html#continuous-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Continuous Variables",
    "text": "Continuous Variables\n\nA continuous variable is a variable that can take on any value within a specific range.\nExamples: height, weight, time\nCan be measured to an infinite number of decimal places."
  },
  {
    "objectID": "slides/lec-3.html#discrete-variables",
    "href": "slides/lec-3.html#discrete-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Discrete Variables",
    "text": "Discrete Variables\n\nA discrete variable is a variable that can only take on specific values.\nExamples: number of children in a household\nDiscrete variables are countable, usually measured by counting."
  },
  {
    "objectID": "slides/lec-3.html#difference-between-continuous-and-discrete-variables",
    "href": "slides/lec-3.html#difference-between-continuous-and-discrete-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Difference between Continuous and Discrete Variables",
    "text": "Difference between Continuous and Discrete Variables\n\nThe main difference between continuous and discrete variables is how data is collected and analyzed.\nExample 1: Study investigating the relationship between weight and blood pressure, weight is a continuous variable, and blood pressure is also continuous. Pearson Correlation Coefficient would be used to investigate the relationship.\nExample 2: Study investigating the relationship between the number of hours of sleep and the number of absenteeism in a company, hours of sleep are continuous and can have an infinite number of values, while absenteeism is discrete. Spearman Rho would be used to investigate the correlation."
  },
  {
    "objectID": "slides/lec-3.html#importance-of-understanding-continuous-vs.-discrete-variables",
    "href": "slides/lec-3.html#importance-of-understanding-continuous-vs.-discrete-variables",
    "title": "Week 3: Intro to Stats",
    "section": "Importance of Understanding Continuous vs. Discrete Variables",
    "text": "Importance of Understanding Continuous vs. Discrete Variables\n\nAffects the methods used to collect and analyze data.\nResearchers must use the appropriate statistical techniques for their specific type of variables to draw valid conclusions from their data."
  },
  {
    "objectID": "slides/lec-3.html#summary-1",
    "href": "slides/lec-3.html#summary-1",
    "title": "Week 3: Intro to Stats",
    "section": "Summary",
    "text": "Summary\n\nContinuous and discrete variables are two types of variables used in research.\nContinuous variables can take on any value within a specific range, while discrete variables can only take on specific values.\nUnderstanding the difference between these two types of variables is important because it can affect the methods used to collect and analyze data."
  },
  {
    "objectID": "slides/lec-3.html#intro-1",
    "href": "slides/lec-3.html#intro-1",
    "title": "Week 3: Intro to Stats",
    "section": "Intro",
    "text": "Intro\n\nNumerical data is classified into four types based on their level of measurement and the types of statistical analysis that can be used.\nNominal, ordinal, interval, and ratio data are different types of numerical data."
  },
  {
    "objectID": "slides/lec-3.html#nominal-data",
    "href": "slides/lec-3.html#nominal-data",
    "title": "Week 3: Intro to Stats",
    "section": "Nominal Data",
    "text": "Nominal Data\n\nNominal data is a non-numeric type of data that can be placed into categories but cannot be meaningfully ordered or quantified.\nExamples: color, gender, religion\nAnalysis methods: frequency distributions, chi-squared tests, contingency tables"
  },
  {
    "objectID": "slides/lec-3.html#ordinal-data",
    "href": "slides/lec-3.html#ordinal-data",
    "title": "Week 3: Intro to Stats",
    "section": "Ordinal Data",
    "text": "Ordinal Data\n\nOrdinal data is a type of data that can be placed into categories and can be meaningfully ordered, but the difference between the data points is not necessarily equal.\nExamples: education level, socioeconomic status, satisfaction level\nAnalysis methods: medians, quartiles, percentiles"
  },
  {
    "objectID": "slides/lec-3.html#interval-data",
    "href": "slides/lec-3.html#interval-data",
    "title": "Week 3: Intro to Stats",
    "section": "Interval Data",
    "text": "Interval Data\n\nInterval data is a type of data that has equal intervals between the data points but does not have an absolute zero point.\nExamples: temperature measured in Celsius or Fahrenheit\nAnalysis methods: central tendency and variability measures"
  },
  {
    "objectID": "slides/lec-3.html#ratio-data",
    "href": "slides/lec-3.html#ratio-data",
    "title": "Week 3: Intro to Stats",
    "section": "Ratio Data",
    "text": "Ratio Data\n\nRatio data is a type of data with equal intervals between the data points and an absolute zero point.\nExamples: weight, height, time\nAnalysis methods: central tendency and variability measures, correlation, and regression analysis"
  },
  {
    "objectID": "slides/lec-3.html#conclusion",
    "href": "slides/lec-3.html#conclusion",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nUnderstanding the differences between nominal, ordinal, interval, and ratio data is crucial because it affects the statistical methods used to analyze and interpret the data.\nChoosing the appropriate type of data and analysis is important to draw meaningful and accurate conclusions."
  },
  {
    "objectID": "slides/lec-3.html#independent-variable",
    "href": "slides/lec-3.html#independent-variable",
    "title": "Week 3: Intro to Stats",
    "section": "Independent Variable",
    "text": "Independent Variable\n\nIndependent variable (IV) is the variable that is manipulated or changed in an experiment.\nThe IV is the factor the researcher is interested in studying.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the IV would be the exercise program itself."
  },
  {
    "objectID": "slides/lec-3.html#dependent-variable",
    "href": "slides/lec-3.html#dependent-variable",
    "title": "Week 3: Intro to Stats",
    "section": "Dependent Variable",
    "text": "Dependent Variable\n\nDependent variable (DV) is the factor affected by the independent variable.\nThe DV is the variable that is measured or observed in response to the manipulation of the independent variable.\nExample: In a study investigating the effects of a new exercise program on muscle strength, the DV would be muscle strength, measured before and after the exercise program to see if there is an improvement."
  },
  {
    "objectID": "slides/lec-3.html#the-relationship-between-iv-and-dv",
    "href": "slides/lec-3.html#the-relationship-between-iv-and-dv",
    "title": "Week 3: Intro to Stats",
    "section": "The Relationship between IV and DV",
    "text": "The Relationship between IV and DV\n\nThe independent variable is manipulated or controlled by the researcher.\nThe dependent variable is measured or observed.\nUnderstanding the relationship between these two variables allows researchers to establish a cause-and-effect relationship and draw valid conclusions from their research."
  },
  {
    "objectID": "slides/lec-3.html#another-example",
    "href": "slides/lec-3.html#another-example",
    "title": "Week 3: Intro to Stats",
    "section": "Another Example",
    "text": "Another Example\n\nA study investigating the effect of a specific training program on running performance.\nIndependent variable: The training program\nDependent variable: Running performance, measured before and after the program."
  },
  {
    "objectID": "slides/lec-3.html#conclusion-1",
    "href": "slides/lec-3.html#conclusion-1",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nDependent and independent variables are important concepts in scientific research.\nThe researcher manipulates independent variables and dependent variables are measured or observed.\nUnderstanding the relationship between these two variables is crucial to establish a cause-and-effect relationship and draw valid conclusions from research."
  },
  {
    "objectID": "slides/lec-3.html#intro-2",
    "href": "slides/lec-3.html#intro-2",
    "title": "Week 3: Intro to Stats",
    "section": "Intro",
    "text": "Intro\n\nResearch is a systematic and scientific inquiry into a subject or phenomenon\nIt involves a process of discovering new knowledge, understanding complex issues, and making informed decisions"
  },
  {
    "objectID": "slides/lec-3.html#three-common-types-of-research",
    "href": "slides/lec-3.html#three-common-types-of-research",
    "title": "Week 3: Intro to Stats",
    "section": "Three Common Types of Research",
    "text": "Three Common Types of Research\n\nHistorical Research\nObservational Research\nExperimental Research"
  },
  {
    "objectID": "slides/lec-3.html#historical-research",
    "href": "slides/lec-3.html#historical-research",
    "title": "Week 3: Intro to Stats",
    "section": "Historical Research",
    "text": "Historical Research\n\nInvolves the collection and analysis of primary and secondary sources\nInvestigates events, phenomena, or people in the past\nRelying on written documents, photographs, and other artifacts to reconstruct the past\nUnderstanding the origin of events, historical trends, and the development of ideas, institutions, or societies\nObservational Research\nThe researcher observes but does not manipulate the phenomenon of interest\nMay involve collecting both quantitative and qualitative data\nTypically does not involve manipulation of independent variables\nCan be conducted in natural settings, such as in the field or controlled laboratory settings\nExample: studying athletes’ natural movement patterns or assessing the effectiveness of rehabilitation programs"
  },
  {
    "objectID": "slides/lec-3.html#experimental-research",
    "href": "slides/lec-3.html#experimental-research",
    "title": "Week 3: Intro to Stats",
    "section": "Experimental Research",
    "text": "Experimental Research\n\nThe researcher manipulates one or more independent variables and measures their effects on one or more dependent variables\nEstablishes cause-and-effect relationships between variables\nInvolves using control groups and randomly assigning participants to treatment or control groups\nExample: investigating the effects of different training protocols on physical performance or testing the effectiveness of different therapeutic interventions"
  },
  {
    "objectID": "slides/lec-3.html#conclusion-2",
    "href": "slides/lec-3.html#conclusion-2",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nResearch is a systematic and scientific inquiry into a particular subject or phenomenon\nHistorical research, observational research, and experimental research are three common types of research\nEach type of research has its strengths, limitations, and purposes\nThe choice of which type to use will depend on the research question and the study’s goals."
  },
  {
    "objectID": "slides/lec-3.html#introduction",
    "href": "slides/lec-3.html#introduction",
    "title": "Week 3: Intro to Stats",
    "section": "Introduction",
    "text": "Introduction\n\nResearch is a systematic and scientific inquiry into a particular subject or phenomenon\nTwo critical concepts in research: internal and external validity"
  },
  {
    "objectID": "slides/lec-3.html#internal-validity",
    "href": "slides/lec-3.html#internal-validity",
    "title": "Week 3: Intro to Stats",
    "section": "Internal Validity",
    "text": "Internal Validity\n\nDefinition: degree to which the results of a study can be attributed to the manipulation of the independent variable\nImportance in Kinesiology: ensuring that the results of a study can be attributed to the specific training protocol or intervention tested\nExample: investigating the effects of a specific strength training program on muscle mass"
  },
  {
    "objectID": "slides/lec-3.html#external-validity",
    "href": "slides/lec-3.html#external-validity",
    "title": "Week 3: Intro to Stats",
    "section": "External Validity",
    "text": "External Validity\n\nDefinition: degree to which the results of a study can be generalized to other populations, settings, and periods\nImportance in Kinesiology: ensuring that the results of a study can be applied to real-world situations and other populations\nExample: investigating the effects of a specific strength training program on muscle mass in young men"
  },
  {
    "objectID": "slides/lec-3.html#internal-and-external-validity-1",
    "href": "slides/lec-3.html#internal-and-external-validity-1",
    "title": "Week 3: Intro to Stats",
    "section": "Internal and External Validity",
    "text": "Internal and External Validity\n\nSeparate concepts, but related\nResearchers should strive to achieve high internal and external validity\nTrade-offs between the two may be necessary"
  },
  {
    "objectID": "slides/lec-3.html#conclusion-3",
    "href": "slides/lec-3.html#conclusion-3",
    "title": "Week 3: Intro to Stats",
    "section": "Conclusion",
    "text": "Conclusion\n\nStatistics is a critical component of kinesiology\nUnderstanding and applying statistical concepts and methods is crucial for informed decision-making\nKey concepts like measurement, variables, and research types must be understood and applied properly\nUnderstanding and applying concepts like internal and external validity is essential for drawing valid conclusions from research findings."
  },
  {
    "objectID": "slides/pe.html",
    "href": "slides/pe.html",
    "title": "Practice Exercises",
    "section": "",
    "text": "Visit the the link below take the quiz to test your knowledge on this topic.\nhttps://drfurtado.shinyapps.io/Practice-Questions/\n\n\n\n\n\n\nWarning\n\n\n\nThe studies below are fictitious.\n\n\n\n\n\nBelow are several practice exercises for Week 5. Write down your answers, then click Tip at the end of each exercise to review the answers.\nFor exercises 1-3, fill the blank with wither Mean, Median, or Mode.\n\n\nA study titled “Symptoms and Quality of Life in Patients with Fibromyalgia: A Cross-Sectional Study” used the ___________ to report the most frequently experienced symptoms by patients with fibromyalgia. The study surveyed 200 patients with fibromyalgia and asked them to report their symptoms using a questionnaire. The questionnaire included questions about 19 different symptoms commonly associated with fibromyalgia, such as pain, fatigue, sleep disturbances, depression, and anxiety.\nWhen reporting the results, the authors used the _________ to describe the most common symptoms experienced by the patients. For example, they reported that the __________ for pain intensity was 7 (on a scale of 0 to 10), indicating that a pain intensity score of 7 was the most frequently reported by patients. The authors also reported the ___________ for each of the other 18 symptoms, such as the ___________ for fatigue severity, sleep quality, and anxiety level.\nUsing the ___________ in this study allowed the researchers to identify the symptoms that were most commonly reported by patients with fibromyalgia, which could help clinicians to better understand and manage the condition. The ___________ is an appropriate measure of central tendency in this study because it is useful for identifying the most frequently occurring value in a dataset, which can be important information for clinical decision-making.\n\n\n\n\n\n\nTip\n\n\n\nmode\n\n\n\n\n\nIn this study, the authors aimed to investigate the associations between physical activity, adiposity, cardiorespiratory fitness, and academic performance in a sample of Spanish youth. The authors used a cross-sectional design and recruited 1,700 children aged 6 to 18 years. The authors measured the children’s physical activity using self-report questionnaires, and they measured their adiposity using body mass index (BMI), waist circumference, and skinfold thickness. The authors also assessed the children’s cardiorespiratory fitness using a 20-m shuttle run test, and they measured academic performance using grade point averages.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the distribution of the physical activity and adiposity measures. For example, they reported the ___________ minutes per day spent in moderate-to-vigorous physical activity (MVPA) instead of the ___________ MVPA. The authors chose to use the ___________ because the distributions of the physical activity and adiposity measures were skewed, meaning that a few extreme values could heavily influence the ___________.\nOverall, the study found that higher levels of physical activity, lower levels of adiposity, and higher levels of cardiorespiratory fitness were all positively associated with better academic performance in youth. The authors also found evidence to suggest that cardiorespiratory fitness mediated the relationship between physical activity and academic performance.\n\n\n\n\n\n\nTip\n\n\n\nmedian, mean, median, mean, median, mean\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of caffeine ingestion on tennis skill performance. The authors used a randomized, double-blind, crossover design and recruited 16 male tennis players. The players consumed either caffeine or a placebo before performing a tennis skill test, which consisted of serving, forehand, backhand, and volley. The authors measured the time to complete the skill test, the accuracy of the shots, and the total score of the test.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the central tendency of the data. For example, they reported the ___________ time to complete the skill test instead of the ___________ time. The authors chose to use the ___________ because the distributions of the skill test measures were approximately normal, meaning that the ___________ was a representative value of the data.\nOverall, the study found that caffeine ingestion improved tennis skill performance compared to the placebo condition. The authors found significant improvements in the time to complete the skill test, the accuracy of the shots, and the total score of the test. The authors concluded that caffeine ingestion may enhance tennis skill performance and could be used as an ergogenic aid in tennis.\n\n\n\n\n\n\nTip\n\n\n\nmean, median, mean, median, mean, mean\n\n\n\n\n\n\nFor exercises 4-6, fill the blank with either the Interquartile Range, Variance, Range, or Standard Deviation.\n\n\nn this study, the authors aimed to investigate the effect of protein supplementation combined with resistance training on muscle mass, strength, and function in individuals with chronic obstructive pulmonary disease (COPD). The authors conducted a systematic review and meta-analysis of randomized controlled trials that evaluated the effect of protein supplementation and resistance training on COPD patients. The authors extracted data on muscle mass, strength, and function outcomes and calculated effect sizes using Hedges’ g.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the dispersion of the effect sizes. The authors chose to use the __________ because the effect size distributions were not normally distributed and contained outliers, which could heavily influence the _________ . The _________ is a more robust measure of dispersion that is less affected by outliers.\nOverall, the meta-analysis found that protein supplementation combined with resistance training was effective in improving muscle mass, strength, and function in individuals with COPD. The authors found significant improvements in the outcomes of muscle mass, strength, and function in the protein supplementation group compared to the control group. The authors concluded that protein supplementation combined with resistance training could be a promising intervention for improving muscle health in individuals with COPD.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR\nRecall that the SD should be reported instead of the variance since the former is aligned to the scale of the original data.\n\n\n\n\n\nIn this study, the authors aimed to investigate the relationship between physical activity and depressive symptoms in older women. The authors used a cross-sectional design and recruited 198 women aged 65 years and older. The authors measured the women’s physical activity using self-report questionnaires, and they assessed their depressive symptoms using the Geriatric Depression Scale.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the variability of the data. For example, they reported the ___________ of the physical activity levels instead of the ____________ of the physical activity levels. The authors chose to use the ___________ because the distributions of the physical activity levels and the depressive symptoms scores were skewed and had outliers, which could heavily influence the ____________.\nOverall, the study found a significant negative relationship between physical activity levels and depressive symptoms scores in older women. The authors also found that the relationship was strongest for moderate-intensity physical activity. The authors concluded that physical activity could be an effective non-pharmacological intervention for preventing and treating depressive symptoms in older women.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR, Standard Deviation\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of resistance training frequency on neuromuscular performance and muscle morphology in trained men. The authors used a randomized controlled trial design and recruited 28 trained men. The men were randomly assigned to either a high-frequency resistance training group (six sessions per week) or a low-frequency resistance training group (three sessions per week). The authors measured the men’s neuromuscular performance using maximal isometric and dynamic strength tests, and they assessed the muscle morphology using muscle biopsies.\nWhen reporting the results, the authors used the ____________ instead of the ___________ to describe the variability of the data. For example, they reported the ____________ of the maximal isometric strength instead of the ___________ of the maximal isometric strength. The authors chose to use the ____________ because the distributions of the neuromuscular performance measures and the muscle morphology measures were approximately normal, meaning that the ____________ was a representative value of the data.\nOverall, the study found that the high-frequency resistance training group had greater improvements in neuromuscular performance and muscle morphology compared to the low-frequency resistance training group. The authors found significant increases in maximal isometric and dynamic strength, muscle cross-sectional area, and myofibrillar protein content in the high-frequency group. The authors concluded that high-frequency resistance training could be a superior training strategy for enhancing neuromuscular performance and muscle morphology in trained men.\n\n\n\n\n\n\nTip\n\n\n\nStandard Deviation, IQR or Range, Standard Deviation, IQR, Standard Deviation, Standard Deviation"
  },
  {
    "objectID": "slides/pe.html#practice-questions",
    "href": "slides/pe.html#practice-questions",
    "title": "Practice Exercises",
    "section": "",
    "text": "Visit the the link below take the quiz to test your knowledge on this topic.\nhttps://drfurtado.shinyapps.io/Practice-Questions/\n\n\n\n\n\n\nWarning\n\n\n\nThe studies below are fictitious."
  },
  {
    "objectID": "slides/pe.html#practice-exercises---measures-of-central-tendency",
    "href": "slides/pe.html#practice-exercises---measures-of-central-tendency",
    "title": "Practice Exercises",
    "section": "",
    "text": "Below are several practice exercises for Week 5. Write down your answers, then click Tip at the end of each exercise to review the answers.\nFor exercises 1-3, fill the blank with wither Mean, Median, or Mode.\n\n\nA study titled “Symptoms and Quality of Life in Patients with Fibromyalgia: A Cross-Sectional Study” used the ___________ to report the most frequently experienced symptoms by patients with fibromyalgia. The study surveyed 200 patients with fibromyalgia and asked them to report their symptoms using a questionnaire. The questionnaire included questions about 19 different symptoms commonly associated with fibromyalgia, such as pain, fatigue, sleep disturbances, depression, and anxiety.\nWhen reporting the results, the authors used the _________ to describe the most common symptoms experienced by the patients. For example, they reported that the __________ for pain intensity was 7 (on a scale of 0 to 10), indicating that a pain intensity score of 7 was the most frequently reported by patients. The authors also reported the ___________ for each of the other 18 symptoms, such as the ___________ for fatigue severity, sleep quality, and anxiety level.\nUsing the ___________ in this study allowed the researchers to identify the symptoms that were most commonly reported by patients with fibromyalgia, which could help clinicians to better understand and manage the condition. The ___________ is an appropriate measure of central tendency in this study because it is useful for identifying the most frequently occurring value in a dataset, which can be important information for clinical decision-making.\n\n\n\n\n\n\nTip\n\n\n\nmode\n\n\n\n\n\nIn this study, the authors aimed to investigate the associations between physical activity, adiposity, cardiorespiratory fitness, and academic performance in a sample of Spanish youth. The authors used a cross-sectional design and recruited 1,700 children aged 6 to 18 years. The authors measured the children’s physical activity using self-report questionnaires, and they measured their adiposity using body mass index (BMI), waist circumference, and skinfold thickness. The authors also assessed the children’s cardiorespiratory fitness using a 20-m shuttle run test, and they measured academic performance using grade point averages.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the distribution of the physical activity and adiposity measures. For example, they reported the ___________ minutes per day spent in moderate-to-vigorous physical activity (MVPA) instead of the ___________ MVPA. The authors chose to use the ___________ because the distributions of the physical activity and adiposity measures were skewed, meaning that a few extreme values could heavily influence the ___________.\nOverall, the study found that higher levels of physical activity, lower levels of adiposity, and higher levels of cardiorespiratory fitness were all positively associated with better academic performance in youth. The authors also found evidence to suggest that cardiorespiratory fitness mediated the relationship between physical activity and academic performance.\n\n\n\n\n\n\nTip\n\n\n\nmedian, mean, median, mean, median, mean\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of caffeine ingestion on tennis skill performance. The authors used a randomized, double-blind, crossover design and recruited 16 male tennis players. The players consumed either caffeine or a placebo before performing a tennis skill test, which consisted of serving, forehand, backhand, and volley. The authors measured the time to complete the skill test, the accuracy of the shots, and the total score of the test.\nWhen reporting the results, the authors used the ___________ instead of the ___________ to describe the central tendency of the data. For example, they reported the ___________ time to complete the skill test instead of the ___________ time. The authors chose to use the ___________ because the distributions of the skill test measures were approximately normal, meaning that the ___________ was a representative value of the data.\nOverall, the study found that caffeine ingestion improved tennis skill performance compared to the placebo condition. The authors found significant improvements in the time to complete the skill test, the accuracy of the shots, and the total score of the test. The authors concluded that caffeine ingestion may enhance tennis skill performance and could be used as an ergogenic aid in tennis.\n\n\n\n\n\n\nTip\n\n\n\nmean, median, mean, median, mean, mean"
  },
  {
    "objectID": "slides/pe.html#practice-exercises---measures-of-variability",
    "href": "slides/pe.html#practice-exercises---measures-of-variability",
    "title": "Practice Exercises",
    "section": "",
    "text": "For exercises 4-6, fill the blank with either the Interquartile Range, Variance, Range, or Standard Deviation.\n\n\nn this study, the authors aimed to investigate the effect of protein supplementation combined with resistance training on muscle mass, strength, and function in individuals with chronic obstructive pulmonary disease (COPD). The authors conducted a systematic review and meta-analysis of randomized controlled trials that evaluated the effect of protein supplementation and resistance training on COPD patients. The authors extracted data on muscle mass, strength, and function outcomes and calculated effect sizes using Hedges’ g.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the dispersion of the effect sizes. The authors chose to use the __________ because the effect size distributions were not normally distributed and contained outliers, which could heavily influence the _________ . The _________ is a more robust measure of dispersion that is less affected by outliers.\nOverall, the meta-analysis found that protein supplementation combined with resistance training was effective in improving muscle mass, strength, and function in individuals with COPD. The authors found significant improvements in the outcomes of muscle mass, strength, and function in the protein supplementation group compared to the control group. The authors concluded that protein supplementation combined with resistance training could be a promising intervention for improving muscle health in individuals with COPD.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR\nRecall that the SD should be reported instead of the variance since the former is aligned to the scale of the original data.\n\n\n\n\n\nIn this study, the authors aimed to investigate the relationship between physical activity and depressive symptoms in older women. The authors used a cross-sectional design and recruited 198 women aged 65 years and older. The authors measured the women’s physical activity using self-report questionnaires, and they assessed their depressive symptoms using the Geriatric Depression Scale.\nWhen reporting the results, the authors used the ___________ instead of the ____________ to describe the variability of the data. For example, they reported the ___________ of the physical activity levels instead of the ____________ of the physical activity levels. The authors chose to use the ___________ because the distributions of the physical activity levels and the depressive symptoms scores were skewed and had outliers, which could heavily influence the ____________.\nOverall, the study found a significant negative relationship between physical activity levels and depressive symptoms scores in older women. The authors also found that the relationship was strongest for moderate-intensity physical activity. The authors concluded that physical activity could be an effective non-pharmacological intervention for preventing and treating depressive symptoms in older women.\n\n\n\n\n\n\nTip\n\n\n\nIQR, Standard Deviation, IQR, Standard Deviation, IQR, Standard Deviation\n\n\n\n\n\nIn this study, the authors aimed to investigate the effect of resistance training frequency on neuromuscular performance and muscle morphology in trained men. The authors used a randomized controlled trial design and recruited 28 trained men. The men were randomly assigned to either a high-frequency resistance training group (six sessions per week) or a low-frequency resistance training group (three sessions per week). The authors measured the men’s neuromuscular performance using maximal isometric and dynamic strength tests, and they assessed the muscle morphology using muscle biopsies.\nWhen reporting the results, the authors used the ____________ instead of the ___________ to describe the variability of the data. For example, they reported the ____________ of the maximal isometric strength instead of the ___________ of the maximal isometric strength. The authors chose to use the ____________ because the distributions of the neuromuscular performance measures and the muscle morphology measures were approximately normal, meaning that the ____________ was a representative value of the data.\nOverall, the study found that the high-frequency resistance training group had greater improvements in neuromuscular performance and muscle morphology compared to the low-frequency resistance training group. The authors found significant increases in maximal isometric and dynamic strength, muscle cross-sectional area, and myofibrillar protein content in the high-frequency group. The authors concluded that high-frequency resistance training could be a superior training strategy for enhancing neuromuscular performance and muscle morphology in trained men.\n\n\n\n\n\n\nTip\n\n\n\nStandard Deviation, IQR or Range, Standard Deviation, IQR, Standard Deviation, Standard Deviation"
  },
  {
    "objectID": "supplemental/CopyOftables.html",
    "href": "supplemental/CopyOftables.html",
    "title": "Statistical Tables",
    "section": "",
    "text": "Tablesz-tablecorrelation\n\n\nasasas\n\n\nThe table shows the probabilities associated with various z-scores. Each row represents a different z-score, while the columns show the z-score value and the probability (rounded to two decimal places) of getting a z-score less than or equal to that value.\nFor example, if we look at the row where z is equal to 1.96, we see that the probability of getting a z-score less than or equal to 1.96 is 0.025 (1 - 0.9750). This means that if we have a normally distributed variable, and we want to find the probability of getting a z-score less than or equal to 1.96, we can look up that value in the table and find the corresponding probability. In this case, the probability is 0.9750, then subtract from 1. The result is the probability value.\nConversely, if we have a probability and we want to find the z-score associated with it, we can use the table by looking for the probability in the second column and then reading the corresponding z-score from the first column. For example, if we have a probability of 0.9985, we can look for that value in the second column and find the corresponding z-score of 2.81 in the first column. Overall, this table can be a useful tool for working with the standard normal distribution, particularly when calculating probabilities or finding critical values for hypothesis tests.\n\n\n       z probabilities\n1   0.00        0.5000\n2   0.01        0.5040\n3   0.02        0.5080\n4   0.03        0.5120\n5   0.04        0.5160\n6   0.05        0.5199\n7   0.06        0.5239\n8   0.07        0.5279\n9   0.08        0.5319\n10  0.09        0.5359\n11  0.10        0.5398\n12  0.11        0.5438\n13  0.12        0.5478\n14  0.13        0.5517\n15  0.14        0.5557\n16  0.15        0.5596\n17  0.16        0.5636\n18  0.17        0.5675\n19  0.18        0.5714\n20  0.19        0.5753\n21  0.20        0.5793\n22  0.21        0.5832\n23  0.22        0.5871\n24  0.23        0.5910\n25  0.24        0.5948\n26  0.25        0.5987\n27  0.26        0.6026\n28  0.27        0.6064\n29  0.28        0.6103\n30  0.29        0.6141\n31  0.30        0.6179\n32  0.31        0.6217\n33  0.32        0.6255\n34  0.33        0.6293\n35  0.34        0.6331\n36  0.35        0.6368\n37  0.36        0.6406\n38  0.37        0.6443\n39  0.38        0.6480\n40  0.39        0.6517\n41  0.40        0.6554\n42  0.41        0.6591\n43  0.42        0.6628\n44  0.43        0.6664\n45  0.44        0.6700\n46  0.45        0.6736\n47  0.46        0.6772\n48  0.47        0.6808\n49  0.48        0.6844\n50  0.49        0.6879\n51  0.50        0.6915\n52  0.51        0.6950\n53  0.52        0.6985\n54  0.53        0.7019\n55  0.54        0.7054\n56  0.55        0.7088\n57  0.56        0.7123\n58  0.57        0.7157\n59  0.58        0.7190\n60  0.59        0.7224\n61  0.60        0.7257\n62  0.61        0.7291\n63  0.62        0.7324\n64  0.63        0.7357\n65  0.64        0.7389\n66  0.65        0.7422\n67  0.66        0.7454\n68  0.67        0.7486\n69  0.68        0.7517\n70  0.69        0.7549\n71  0.70        0.7580\n72  0.71        0.7611\n73  0.72        0.7642\n74  0.73        0.7673\n75  0.74        0.7704\n76  0.75        0.7734\n77  0.76        0.7764\n78  0.77        0.7794\n79  0.78        0.7823\n80  0.79        0.7852\n81  0.80        0.7881\n82  0.81        0.7910\n83  0.82        0.7939\n84  0.83        0.7967\n85  0.84        0.7995\n86  0.85        0.8023\n87  0.86        0.8051\n88  0.87        0.8078\n89  0.88        0.8106\n90  0.89        0.8133\n91  0.90        0.8159\n92  0.91        0.8186\n93  0.92        0.8212\n94  0.93        0.8238\n95  0.94        0.8264\n96  0.95        0.8289\n97  0.96        0.8315\n98  0.97        0.8340\n99  0.98        0.8365\n100 0.99        0.8389\n101 1.00        0.8413\n102 1.01        0.8438\n103 1.02        0.8461\n104 1.03        0.8485\n105 1.04        0.8508\n106 1.05        0.8531\n107 1.06        0.8554\n108 1.07        0.8577\n109 1.08        0.8599\n110 1.09        0.8621\n111 1.10        0.8643\n112 1.11        0.8665\n113 1.12        0.8686\n114 1.13        0.8708\n115 1.14        0.8729\n116 1.15        0.8749\n117 1.16        0.8770\n118 1.17        0.8790\n119 1.18        0.8810\n120 1.19        0.8830\n121 1.20        0.8849\n122 1.21        0.8869\n123 1.22        0.8888\n124 1.23        0.8907\n125 1.24        0.8925\n126 1.25        0.8944\n127 1.26        0.8962\n128 1.27        0.8980\n129 1.28        0.8997\n130 1.29        0.9015\n131 1.30        0.9032\n132 1.31        0.9049\n133 1.32        0.9066\n134 1.33        0.9082\n135 1.34        0.9099\n136 1.35        0.9115\n137 1.36        0.9131\n138 1.37        0.9147\n139 1.38        0.9162\n140 1.39        0.9177\n141 1.40        0.9192\n142 1.41        0.9207\n143 1.42        0.9222\n144 1.43        0.9236\n145 1.44        0.9251\n146 1.45        0.9265\n147 1.46        0.9279\n148 1.47        0.9292\n149 1.48        0.9306\n150 1.49        0.9319\n151 1.50        0.9332\n152 1.51        0.9345\n153 1.52        0.9357\n154 1.53        0.9370\n155 1.54        0.9382\n156 1.55        0.9394\n157 1.56        0.9406\n158 1.57        0.9418\n159 1.58        0.9429\n160 1.59        0.9441\n161 1.60        0.9452\n162 1.61        0.9463\n163 1.62        0.9474\n164 1.63        0.9484\n165 1.64        0.9495\n166 1.65        0.9505\n167 1.66        0.9515\n168 1.67        0.9525\n169 1.68        0.9535\n170 1.69        0.9545\n171 1.70        0.9554\n172 1.71        0.9564\n173 1.72        0.9573\n174 1.73        0.9582\n175 1.74        0.9591\n176 1.75        0.9599\n177 1.76        0.9608\n178 1.77        0.9616\n179 1.78        0.9625\n180 1.79        0.9633\n181 1.80        0.9641\n182 1.81        0.9649\n183 1.82        0.9656\n184 1.83        0.9664\n185 1.84        0.9671\n186 1.85        0.9678\n187 1.86        0.9686\n188 1.87        0.9693\n189 1.88        0.9699\n190 1.89        0.9706\n191 1.90        0.9713\n192 1.91        0.9719\n193 1.92        0.9726\n194 1.93        0.9732\n195 1.94        0.9738\n196 1.95        0.9744\n197 1.96        0.9750\n198 1.97        0.9756\n199 1.98        0.9761\n200 1.99        0.9767\n201 2.00        0.9772\n202 2.01        0.9778\n203 2.02        0.9783\n204 2.03        0.9788\n205 2.04        0.9793\n206 2.05        0.9798\n207 2.06        0.9803\n208 2.07        0.9808\n209 2.08        0.9812\n210 2.09        0.9817\n211 2.10        0.9821\n212 2.11        0.9826\n213 2.12        0.9830\n214 2.13        0.9834\n215 2.14        0.9838\n216 2.15        0.9842\n217 2.16        0.9846\n218 2.17        0.9850\n219 2.18        0.9854\n220 2.19        0.9857\n221 2.20        0.9861\n222 2.21        0.9864\n223 2.22        0.9868\n224 2.23        0.9871\n225 2.24        0.9875\n226 2.25        0.9878\n227 2.26        0.9881\n228 2.27        0.9884\n229 2.28        0.9887\n230 2.29        0.9890\n231 2.30        0.9893\n232 2.31        0.9896\n233 2.32        0.9898\n234 2.33        0.9901\n235 2.34        0.9904\n236 2.35        0.9906\n237 2.36        0.9909\n238 2.37        0.9911\n239 2.38        0.9913\n240 2.39        0.9916\n241 2.40        0.9918\n242 2.41        0.9920\n243 2.42        0.9922\n244 2.43        0.9925\n245 2.44        0.9927\n246 2.45        0.9929\n247 2.46        0.9931\n248 2.47        0.9932\n249 2.48        0.9934\n250 2.49        0.9936\n251 2.50        0.9938\n252 2.51        0.9940\n253 2.52        0.9941\n254 2.53        0.9943\n255 2.54        0.9945\n256 2.55        0.9946\n257 2.56        0.9948\n258 2.57        0.9949\n259 2.58        0.9951\n260 2.59        0.9952\n261 2.60        0.9953\n262 2.61        0.9955\n263 2.62        0.9956\n264 2.63        0.9957\n265 2.64        0.9959\n266 2.65        0.9960\n267 2.66        0.9961\n268 2.67        0.9962\n269 2.68        0.9963\n270 2.69        0.9964\n271 2.70        0.9965\n272 2.71        0.9966\n273 2.72        0.9967\n274 2.73        0.9968\n275 2.74        0.9969\n276 2.75        0.9970\n277 2.76        0.9971\n278 2.77        0.9972\n279 2.78        0.9973\n280 2.79        0.9974\n281 2.80        0.9974\n282 2.81        0.9975\n283 2.82        0.9976\n284 2.83        0.9977\n285 2.84        0.9977\n286 2.85        0.9978\n287 2.86        0.9979\n288 2.87        0.9979\n289 2.88        0.9980\n290 2.89        0.9981\n291 2.90        0.9981\n292 2.91        0.9982\n293 2.92        0.9982\n294 2.93        0.9983\n295 2.94        0.9984\n296 2.95        0.9984\n297 2.96        0.9985\n298 2.97        0.9985\n299 2.98        0.9986\n300 2.99        0.9986\n301 3.00        0.9987\n302 3.01        0.9987\n303 3.02        0.9987\n304 3.03        0.9988\n305 3.04        0.9988\n306 3.05        0.9989\n307 3.06        0.9989\n308 3.07        0.9989\n309 3.08        0.9990\n310 3.09        0.9990\n311 3.10        0.9990\n312 3.11        0.9991\n313 3.12        0.9991\n314 3.13        0.9991\n315 3.14        0.9992\n316 3.15        0.9992\n317 3.16        0.9992\n318 3.17        0.9992\n319 3.18        0.9993\n320 3.19        0.9993\n321 3.20        0.9993\n322 3.21        0.9993\n323 3.22        0.9994\n324 3.23        0.9994\n325 3.24        0.9994\n326 3.25        0.9994\n327 3.26        0.9994\n328 3.27        0.9995\n329 3.28        0.9995\n330 3.29        0.9995\n331 3.30        0.9995\n332 3.31        0.9995\n333 3.32        0.9995\n334 3.33        0.9996\n335 3.34        0.9996\n336 3.35        0.9996\n337 3.36        0.9996\n338 3.37        0.9996\n339 3.38        0.9996\n340 3.39        0.9997\n341 3.40        0.9997\n\n\n\n\n\n\n       df alpha=0.1 alpha=0.05 alpha=0.025 alpha=0.01\n  [1,]  1     6.314     12.706      25.452     63.657\n  [2,]  2     2.920      4.303       6.205      9.925\n  [3,]  3     2.353      3.182       4.177      5.841\n  [4,]  4     2.132      2.776       3.495      4.604\n  [5,]  5     2.015      2.571       3.163      4.032\n  [6,]  6     1.943      2.447       2.969      3.707\n  [7,]  7     1.895      2.365       2.841      3.499\n  [8,]  8     1.860      2.306       2.752      3.355\n  [9,]  9     1.833      2.262       2.685      3.250\n [10,] 10     1.812      2.228       2.634      3.169\n [11,] 11     1.796      2.201       2.593      3.106\n [12,] 12     1.782      2.179       2.560      3.055\n [13,] 13     1.771      2.160       2.533      3.012\n [14,] 14     1.761      2.145       2.510      2.977\n [15,] 15     1.753      2.131       2.490      2.947\n [16,] 16     1.746      2.120       2.473      2.921\n [17,] 17     1.740      2.110       2.458      2.898\n [18,] 18     1.734      2.101       2.445      2.878\n [19,] 19     1.729      2.093       2.433      2.861\n [20,] 20     1.725      2.086       2.423      2.845\n [21,] 21     1.721      2.080       2.414      2.831\n [22,] 22     1.717      2.074       2.405      2.819\n [23,] 23     1.714      2.069       2.398      2.807\n [24,] 24     1.711      2.064       2.391      2.797\n [25,] 25     1.708      2.060       2.385      2.787\n [26,] 26     1.706      2.056       2.379      2.779\n [27,] 27     1.703      2.052       2.373      2.771\n [28,] 28     1.701      2.048       2.368      2.763\n [29,] 29     1.699      2.045       2.364      2.756\n [30,] 30     1.697      2.042       2.360      2.750\n [31,] 31     1.696      2.040       2.356      2.744\n [32,] 32     1.694      2.037       2.352      2.738\n [33,] 33     1.692      2.035       2.348      2.733\n [34,] 34     1.691      2.032       2.345      2.728\n [35,] 35     1.690      2.030       2.342      2.724\n [36,] 36     1.688      2.028       2.339      2.719\n [37,] 37     1.687      2.026       2.336      2.715\n [38,] 38     1.686      2.024       2.334      2.712\n [39,] 39     1.685      2.023       2.331      2.708\n [40,] 40     1.684      2.021       2.329      2.704\n [41,] 41     1.683      2.020       2.327      2.701\n [42,] 42     1.682      2.018       2.325      2.698\n [43,] 43     1.681      2.017       2.323      2.695\n [44,] 44     1.680      2.015       2.321      2.692\n [45,] 45     1.679      2.014       2.319      2.690\n [46,] 46     1.679      2.013       2.317      2.687\n [47,] 47     1.678      2.012       2.315      2.685\n [48,] 48     1.677      2.011       2.314      2.682\n [49,] 49     1.677      2.010       2.312      2.680\n [50,] 50     1.676      2.009       2.311      2.678\n [51,] 51     1.675      2.008       2.310      2.676\n [52,] 52     1.675      2.007       2.308      2.674\n [53,] 53     1.674      2.006       2.307      2.672\n [54,] 54     1.674      2.005       2.306      2.670\n [55,] 55     1.673      2.004       2.304      2.668\n [56,] 56     1.673      2.003       2.303      2.667\n [57,] 57     1.672      2.002       2.302      2.665\n [58,] 58     1.672      2.002       2.301      2.663\n [59,] 59     1.671      2.001       2.300      2.662\n [60,] 60     1.671      2.000       2.299      2.660\n [61,] 61     1.670      2.000       2.298      2.659\n [62,] 62     1.670      1.999       2.297      2.657\n [63,] 63     1.669      1.998       2.296      2.656\n [64,] 64     1.669      1.998       2.295      2.655\n [65,] 65     1.669      1.997       2.295      2.654\n [66,] 66     1.668      1.997       2.294      2.652\n [67,] 67     1.668      1.996       2.293      2.651\n [68,] 68     1.668      1.995       2.292      2.650\n [69,] 69     1.667      1.995       2.291      2.649\n [70,] 70     1.667      1.994       2.291      2.648\n [71,] 71     1.667      1.994       2.290      2.647\n [72,] 72     1.666      1.993       2.289      2.646\n [73,] 73     1.666      1.993       2.289      2.645\n [74,] 74     1.666      1.993       2.288      2.644\n [75,] 75     1.665      1.992       2.287      2.643\n [76,] 76     1.665      1.992       2.287      2.642\n [77,] 77     1.665      1.991       2.286      2.641\n [78,] 78     1.665      1.991       2.285      2.640\n [79,] 79     1.664      1.990       2.285      2.640\n [80,] 80     1.664      1.990       2.284      2.639\n [81,] 81     1.664      1.990       2.284      2.638\n [82,] 82     1.664      1.989       2.283      2.637\n [83,] 83     1.663      1.989       2.283      2.636\n [84,] 84     1.663      1.989       2.282      2.636\n [85,] 85     1.663      1.988       2.282      2.635\n [86,] 86     1.663      1.988       2.281      2.634\n [87,] 87     1.663      1.988       2.281      2.634\n [88,] 88     1.662      1.987       2.280      2.633\n [89,] 89     1.662      1.987       2.280      2.632\n [90,] 90     1.662      1.987       2.280      2.632\n [91,] 91     1.662      1.986       2.279      2.631\n [92,] 92     1.662      1.986       2.279      2.630\n [93,] 93     1.661      1.986       2.278      2.630\n [94,] 94     1.661      1.986       2.278      2.629\n [95,] 95     1.661      1.985       2.277      2.629\n [96,] 96     1.661      1.985       2.277      2.628\n [97,] 97     1.661      1.985       2.277      2.627\n [98,] 98     1.661      1.984       2.276      2.627\n [99,] 99     1.660      1.984       2.276      2.626\n\n\nasasas\n\n\n\n\nThe correlation table\n\n\nThe \\(z\\) table\n\n# Set up a vector of z-scores\nz &lt;- seq(-3.4, 3.4, 0.1)\n\n# Calculate the corresponding probabilities using pnorm()\nprob &lt;- round(pnorm(z), 4)\n\n# Combine the z-scores and probabilities into a data frame\ntable &lt;- data.frame(z, prob)\n\n# Print the table\nprint(table)\n\n               z   prob\n1  -3.400000e+00 0.0003\n2  -3.300000e+00 0.0005\n3  -3.200000e+00 0.0007\n4  -3.100000e+00 0.0010\n5  -3.000000e+00 0.0013\n6  -2.900000e+00 0.0019\n7  -2.800000e+00 0.0026\n8  -2.700000e+00 0.0035\n9  -2.600000e+00 0.0047\n10 -2.500000e+00 0.0062\n11 -2.400000e+00 0.0082\n12 -2.300000e+00 0.0107\n13 -2.200000e+00 0.0139\n14 -2.100000e+00 0.0179\n15 -2.000000e+00 0.0228\n16 -1.900000e+00 0.0287\n17 -1.800000e+00 0.0359\n18 -1.700000e+00 0.0446\n19 -1.600000e+00 0.0548\n20 -1.500000e+00 0.0668\n21 -1.400000e+00 0.0808\n22 -1.300000e+00 0.0968\n23 -1.200000e+00 0.1151\n24 -1.100000e+00 0.1357\n25 -1.000000e+00 0.1587\n26 -9.000000e-01 0.1841\n27 -8.000000e-01 0.2119\n28 -7.000000e-01 0.2420\n29 -6.000000e-01 0.2743\n30 -5.000000e-01 0.3085\n31 -4.000000e-01 0.3446\n32 -3.000000e-01 0.3821\n33 -2.000000e-01 0.4207\n34 -1.000000e-01 0.4602\n35  4.440892e-16 0.5000\n36  1.000000e-01 0.5398\n37  2.000000e-01 0.5793\n38  3.000000e-01 0.6179\n39  4.000000e-01 0.6554\n40  5.000000e-01 0.6915\n41  6.000000e-01 0.7257\n42  7.000000e-01 0.7580\n43  8.000000e-01 0.7881\n44  9.000000e-01 0.8159\n45  1.000000e+00 0.8413\n46  1.100000e+00 0.8643\n47  1.200000e+00 0.8849\n48  1.300000e+00 0.9032\n49  1.400000e+00 0.9192\n50  1.500000e+00 0.9332\n51  1.600000e+00 0.9452\n52  1.700000e+00 0.9554\n53  1.800000e+00 0.9641\n54  1.900000e+00 0.9713\n55  2.000000e+00 0.9772\n56  2.100000e+00 0.9821\n57  2.200000e+00 0.9861\n58  2.300000e+00 0.9893\n59  2.400000e+00 0.9918\n60  2.500000e+00 0.9938\n61  2.600000e+00 0.9953\n62  2.700000e+00 0.9965\n63  2.800000e+00 0.9974\n64  2.900000e+00 0.9981\n65  3.000000e+00 0.9987\n66  3.100000e+00 0.9990\n67  3.200000e+00 0.9993\n68  3.300000e+00 0.9995\n69  3.400000e+00 0.9997\n\n\nThe z-table is a statistical table that shows the values of the standard normal distribution. The standard normal distribution is a normal distribution with a mean of 0 and a standard deviation of 1.\n\n\n   z_value area_percent\n1     -3.0  0.001349898\n2     -2.9  0.001865813\n3     -2.8  0.002555130\n4     -2.7  0.003466974\n5     -2.6  0.004661188\n6     -2.5  0.006209665\n7     -2.4  0.008197536\n8     -2.3  0.010724110\n9     -2.2  0.013903448\n10    -2.1  0.017864421\n11    -2.0  0.022750132\n12    -1.9  0.028716560\n13    -1.8  0.035930319\n14    -1.7  0.044565463\n15    -1.6  0.054799292\n16    -1.5  0.066807201\n17    -1.4  0.080756659\n18    -1.3  0.096800485\n19    -1.2  0.115069670\n20    -1.1  0.135666061\n21    -1.0  0.158655254\n22    -0.9  0.184060125\n23    -0.8  0.211855399\n24    -0.7  0.241963652\n25    -0.6  0.274253118\n26    -0.5  0.308537539\n27    -0.4  0.344578258\n28    -0.3  0.382088578\n29    -0.2  0.420740291\n30    -0.1  0.460172163\n31     0.0  0.500000000\n32     0.1  0.539827837\n33     0.2  0.579259709\n34     0.3  0.617911422\n35     0.4  0.655421742\n36     0.5  0.691462461\n37     0.6  0.725746882\n38     0.7  0.758036348\n39     0.8  0.788144601\n40     0.9  0.815939875\n41     1.0  0.841344746\n42     1.1  0.864333939\n43     1.2  0.884930330\n44     1.3  0.903199515\n45     1.4  0.919243341\n46     1.5  0.933192799\n47     1.6  0.945200708\n48     1.7  0.955434537\n49     1.8  0.964069681\n50     1.9  0.971283440\n51     2.0  0.977249868\n52     2.1  0.982135579\n53     2.2  0.986096552\n54     2.3  0.989275890\n55     2.4  0.991802464\n56     2.5  0.993790335\n57     2.6  0.995338812\n58     2.7  0.996533026\n59     2.8  0.997444870\n60     2.9  0.998134187\n61     3.0  0.998650102\n\n\n\nlibrary(stats)\n\nf_table &lt;- data.frame(df1=rep(1:30, each=30), df2=rep(1:30, 30), \n                      p=qf(seq(0.01, 0.99, 0.01), df1=rep(1:30, each=30), df2=rep(1:30, 30)))\n\nprint(f_table)\n\n    df1 df2            p\n1     1   1 2.467807e-04\n2     1   2 8.003201e-04\n3     1   3 1.666730e-03\n4     1   4 2.847820e-03\n5     1   5 4.344768e-03\n6     1   6 6.158721e-03\n7     1   7 8.290949e-03\n8     1   8 1.074289e-02\n9     1   9 1.351619e-02\n10    1  10 1.661268e-02\n11    1  11 2.003441e-02\n12    1  12 2.378365e-02\n13    1  13 2.786290e-02\n14    1  14 3.227486e-02\n15    1  15 3.702251e-02\n16    1  16 4.210904e-02\n17    1  17 4.753789e-02\n18    1  18 5.331278e-02\n19    1  19 5.943768e-02\n20    1  20 6.591684e-02\n21    1  21 7.275479e-02\n22    1  22 7.995635e-02\n23    1  23 8.752666e-02\n24    1  24 9.547119e-02\n25    1  25 1.037957e-01\n26    1  26 1.125064e-01\n27    1  27 1.216096e-01\n28    1  28 1.311124e-01\n29    1  29 1.410220e-01\n30    1  30 1.513461e-01\n31    2   1 5.501995e-01\n32    2   2 4.705882e-01\n33    2   3 4.590314e-01\n34    2   4 4.618298e-01\n35    2   5 4.701246e-01\n36    2   6 4.811916e-01\n37    2   7 4.939196e-01\n38    2   8 5.077733e-01\n39    2   9 5.224659e-01\n40    2  10 5.378317e-01\n41    2  11 5.537706e-01\n42    2  12 5.702201e-01\n43    2  13 5.871410e-01\n44    2  14 6.045090e-01\n45    2  15 6.223102e-01\n46    2  16 6.405377e-01\n47    2  17 6.591898e-01\n48    2  18 6.782691e-01\n49    2  19 6.977813e-01\n50    2  20 7.177346e-01\n51    2  21 7.381399e-01\n52    2  22 7.590099e-01\n53    2  23 7.803592e-01\n54    2  24 8.022045e-01\n55    2  25 8.245641e-01\n56    2  26 8.474584e-01\n57    2  27 8.709095e-01\n58    2  28 8.949415e-01\n59    2  29 9.195807e-01\n60    2  30 9.448557e-01\n61    3   1 3.103835e+00\n62    3   2 1.776235e+00\n63    3   3 1.517822e+00\n64    3   4 1.422547e+00\n65    3   5 1.381678e+00\n66    3   6 1.365706e+00\n67    3   7 1.363397e+00\n68    3   8 1.369572e+00\n69    3   9 1.381530e+00\n70    3  10 1.397742e+00\n71    3  11 1.417290e+00\n72    3  12 1.439607e+00\n73    3  13 1.464335e+00\n74    3  14 1.491255e+00\n75    3  15 1.520241e+00\n76    3  16 1.551235e+00\n77    3  17 1.584233e+00\n78    3  18 1.619273e+00\n79    3  19 1.656434e+00\n80    3  20 1.695833e+00\n81    3  21 1.737624e+00\n82    3  22 1.782007e+00\n83    3  23 1.829224e+00\n84    3  24 1.879580e+00\n85    3  25 1.933443e+00\n86    3  26 1.991271e+00\n87    3  27 2.053632e+00\n88    3  28 2.121236e+00\n89    3  29 2.194991e+00\n90    3  30 2.276071e+00\n91    4   1 6.902748e+01\n92    4   2 1.174479e+01\n93    4   3 7.068554e+00\n94    4   4 5.710646e+00\n95    4   5 5.192168e+00\n96    4   6 5.037634e+00\n97    4   7 5.127216e+00\n98    4   8 5.488919e+00\n99    4   9 6.422085e+00\n100   4  10 6.874789e-02\n101   4  11 1.005671e-01\n102   4  12 1.264667e-01\n103   4  13 1.493282e-01\n104   4  14 1.702607e-01\n105   4  15 1.898332e-01\n106   4  16 2.083852e-01\n107   4  17 2.261397e-01\n108   4  18 2.432533e-01\n109   4  19 2.598411e-01\n110   4  20 2.759913e-01\n111   4  21 2.917734e-01\n112   4  22 3.072433e-01\n113   4  23 3.224471e-01\n114   4  24 3.374236e-01\n115   4  25 3.522057e-01\n116   4  26 3.668215e-01\n117   4  27 3.812960e-01\n118   4  28 3.956509e-01\n119   4  29 4.099055e-01\n120   4  30 4.240774e-01\n121   5   1 5.091590e-01\n122   5   2 4.999058e-01\n123   5   3 5.129588e-01\n124   5   4 5.283505e-01\n125   5   5 5.438409e-01\n126   5   6 5.590668e-01\n127   5   7 5.740021e-01\n128   5   8 5.886885e-01\n129   5   9 6.031761e-01\n130   5  10 6.175103e-01\n131   5  11 6.317295e-01\n132   5  12 6.458658e-01\n133   5  13 6.599461e-01\n134   5  14 6.739933e-01\n135   5  15 6.880274e-01\n136   5  16 7.020657e-01\n137   5  17 7.161240e-01\n138   5  18 7.302164e-01\n139   5  19 7.443563e-01\n140   5  20 7.585559e-01\n141   5  21 7.728270e-01\n142   5  22 7.871810e-01\n143   5  23 8.016288e-01\n144   5  24 8.161813e-01\n145   5  25 8.308491e-01\n146   5  26 8.456430e-01\n147   5  27 8.605737e-01\n148   5  28 8.756523e-01\n149   5  29 8.908898e-01\n150   5  30 9.062976e-01\n151   6   1 2.142680e+00\n152   6   2 1.414313e+00\n153   6   3 1.258411e+00\n154   6   4 1.199063e+00\n155   6   5 1.172888e+00\n156   6   6 1.162038e+00\n157   6   7 1.159581e+00\n158   6   8 1.162277e+00\n159   6   9 1.168415e+00\n160   6  10 1.177012e+00\n161   6  11 1.187468e+00\n162   6  12 1.199398e+00\n163   6  13 1.212549e+00\n164   6  14 1.226750e+00\n165   6  15 1.241887e+00\n166   6  16 1.257883e+00\n167   6  17 1.274688e+00\n168   6  18 1.292274e+00\n169   6  19 1.310628e+00\n170   6  20 1.329752e+00\n171   6  21 1.349656e+00\n172   6  22 1.370364e+00\n173   6  23 1.391907e+00\n174   6  24 1.414327e+00\n175   6  25 1.437674e+00\n176   6  26 1.462011e+00\n177   6  27 1.487411e+00\n178   6  28 1.513961e+00\n179   6  29 1.541761e+00\n180   6  30 1.570932e+00\n181   7   1 1.791611e+01\n182   7   2 5.225245e+00\n183   7   3 3.602058e+00\n184   7   4 3.035693e+00\n185   7   5 2.768198e+00\n186   7   6 2.626216e+00\n187   7   7 2.549944e+00\n188   7   8 2.513765e+00\n189   7   9 2.505313e+00\n190   7  10 2.518389e+00\n191   7  11 2.550194e+00\n192   7  12 2.600247e+00\n193   7  13 2.670169e+00\n194   7  14 2.764199e+00\n195   7  15 2.890905e+00\n196   7  16 3.067892e+00\n197   7  17 3.337117e+00\n198   7  18 3.840639e+00\n199   7  19 1.617909e-01\n200   7  20 2.066421e-01\n201   7  21 2.400607e-01\n202   7  22 2.679894e-01\n203   7  23 2.925733e-01\n204   7  24 3.148643e-01\n205   7  25 3.354679e-01\n206   7  26 3.547695e-01\n207   7  27 3.730320e-01\n208   7  28 3.904446e-01\n209   7  29 4.071483e-01\n210   7  30 4.232523e-01\n211   8   1 3.511928e-01\n212   8   2 3.938170e-01\n213   8   3 4.279724e-01\n214   8   4 4.559084e-01\n215   8   5 4.798862e-01\n216   8   6 5.012053e-01\n217   8   7 5.206408e-01\n218   8   8 5.386830e-01\n219   8   9 5.556596e-01\n220   8  10 5.717991e-01\n221   8  11 5.872670e-01\n222   8  12 6.021872e-01\n223   8  13 6.166548e-01\n224   8  14 6.307444e-01\n225   8  15 6.445161e-01\n226   8  16 6.580191e-01\n227   8  17 6.712940e-01\n228   8  18 6.843754e-01\n229   8  19 6.972926e-01\n230   8  20 7.100712e-01\n231   8  21 7.227335e-01\n232   8  22 7.352994e-01\n233   8  23 7.477868e-01\n234   8  24 7.602116e-01\n235   8  25 7.725887e-01\n236   8  26 7.849315e-01\n237   8  27 7.972529e-01\n238   8  28 8.095646e-01\n239   8  29 8.218779e-01\n240   8  30 8.342035e-01\n241   9   1 1.464657e+00\n242   9   2 1.110321e+00\n243   9   3 1.034990e+00\n244   9   4 1.009445e+00\n245   9   5 1.000980e+00\n246   9   6 1.000284e+00\n247   9   7 1.003754e+00\n248   9   8 1.009726e+00\n249   9   9 1.017331e+00\n250   9  10 1.026078e+00\n251   9  11 1.035670e+00\n252   9  12 1.045921e+00\n253   9  13 1.056709e+00\n254   9  14 1.067954e+00\n255   9  15 1.079600e+00\n256   9  16 1.091611e+00\n257   9  17 1.103964e+00\n258   9  18 1.116645e+00\n259   9  19 1.129645e+00\n260   9  20 1.142963e+00\n261   9  21 1.156601e+00\n262   9  22 1.170565e+00\n263   9  23 1.184864e+00\n264   9  24 1.199510e+00\n265   9  25 1.214519e+00\n266   9  26 1.229907e+00\n267   9  27 1.245696e+00\n268   9  28 1.261910e+00\n269   9  29 1.278574e+00\n270   9  30 1.295719e+00\n271  10   1 7.937231e+00\n272  10   2 3.222103e+00\n273  10   3 2.444669e+00\n274  10   4 2.148218e+00\n275  10   5 1.999855e+00\n276  10   6 1.916225e+00\n277  10   7 1.866925e+00\n278  10   8 1.838298e+00\n279  10   9 1.823340e+00\n280  10  10 1.818130e+00\n281  10  11 1.820345e+00\n282  10  12 1.828563e+00\n283  10  13 1.841918e+00\n284  10  14 1.859914e+00\n285  10  15 1.882322e+00\n286  10  16 1.909135e+00\n287  10  17 1.940550e+00\n288  10  18 1.976980e+00\n289  10  19 2.019100e+00\n290  10  20 2.067933e+00\n291  10  21 2.125017e+00\n292  10  22 2.192699e+00\n293  10  23 2.274728e+00\n294  10  24 2.377526e+00\n295  10  25 2.513389e+00\n296  10  26 2.710532e+00\n297  10  27 3.061754e+00\n298  10  28 2.341947e-01\n299  10  29 2.830520e-01\n300  10  30 3.181824e-01\n301  11   1 1.844938e-01\n302  11   2 2.511113e-01\n303  11   3 3.000211e-01\n304  11   4 3.393016e-01\n305  11   5 3.724455e-01\n306  11   6 4.013234e-01\n307  11   7 4.270647e-01\n308  11   8 4.504066e-01\n309  11   9 4.718578e-01\n310  11  10 4.917846e-01\n311  11  11 5.104593e-01\n312  11  12 5.280899e-01\n313  11  13 5.448391e-01\n314  11  14 5.608365e-01\n315  11  15 5.761867e-01\n316  11  16 5.909760e-01\n317  11  17 6.052761e-01\n318  11  18 6.191470e-01\n319  11  19 6.326402e-01\n320  11  20 6.457996e-01\n321  11  21 6.586633e-01\n322  11  22 6.712644e-01\n323  11  23 6.836323e-01\n324  11  24 6.957928e-01\n325  11  25 7.077690e-01\n326  11  26 7.195817e-01\n327  11  27 7.312496e-01\n328  11  28 7.427898e-01\n329  11  29 7.542178e-01\n330  11  30 7.655479e-01\n331  12   1 1.012788e+00\n332  12   2 8.716379e-01\n333  12   3 8.509786e-01\n334  12   4 8.508789e-01\n335  12   5 8.570677e-01\n336  12   6 8.657150e-01\n337  12   7 8.754606e-01\n338  12   8 8.857381e-01\n339  12   9 8.962877e-01\n340  12  10 9.069830e-01\n341  12  11 9.177617e-01\n342  12  12 9.285933e-01\n343  12  13 9.394647e-01\n344  12  14 9.503723e-01\n345  12  15 9.613180e-01\n346  12  16 9.723068e-01\n347  12  17 9.833453e-01\n348  12  18 9.944418e-01\n349  12  19 1.005605e+00\n350  12  20 1.016844e+00\n351  12  21 1.028168e+00\n352  12  22 1.039588e+00\n353  12  23 1.051114e+00\n354  12  24 1.062756e+00\n355  12  25 1.074525e+00\n356  12  26 1.086434e+00\n357  12  27 1.098493e+00\n358  12  28 1.110716e+00\n359  12  29 1.123116e+00\n360  12  30 1.135706e+00\n361  13   1 4.361172e+00\n362  13   2 2.245281e+00\n363  13   3 1.834349e+00\n364  13   4 1.669849e+00\n365  13   5 1.585821e+00\n366  13   6 1.538024e+00\n367  13   7 1.509739e+00\n368  13   8 1.493265e+00\n369  13   9 1.484573e+00\n370  13  10 1.481358e+00\n371  13  11 1.482213e+00\n372  13  12 1.486241e+00\n373  13  13 1.492851e+00\n374  13  14 1.501646e+00\n375  13  15 1.512360e+00\n376  13  16 1.524819e+00\n377  13  17 1.538919e+00\n378  13  18 1.554605e+00\n379  13  19 1.571871e+00\n380  13  20 1.590749e+00\n381  13  21 1.611311e+00\n382  13  22 1.633671e+00\n383  13  23 1.657986e+00\n384  13  24 1.684470e+00\n385  13  25 1.713404e+00\n386  13  26 1.745158e+00\n387  13  27 1.780221e+00\n388  13  28 1.819250e+00\n389  13  29 1.863149e+00\n390  13  30 1.913200e+00\n391  14   1 1.702824e+02\n392  14   2 1.942438e+01\n393  14   3 1.023428e+01\n394  14   4 7.848463e+00\n395  14   5 7.155501e+00\n396  14   6 7.604897e+00\n397  14   7 2.337605e-01\n398  14   8 2.869820e-01\n399  14   9 3.271479e-01\n400  14  10 3.606293e-01\n401  14  11 3.897880e-01\n402  14  12 4.158364e-01\n403  14  13 4.395075e-01\n404  14  14 4.612897e-01\n405  14  15 4.815302e-01\n406  14  16 5.004868e-01\n407  14  17 5.183580e-01\n408  14  18 5.353002e-01\n409  14  19 5.514391e-01\n410  14  20 5.668779e-01\n411  14  21 5.817022e-01\n412  14  22 5.959839e-01\n413  14  23 6.097842e-01\n414  14  24 6.231553e-01\n415  14  25 6.361428e-01\n416  14  26 6.487862e-01\n417  14  27 6.611200e-01\n418  14  28 6.731751e-01\n419  14  29 6.849786e-01\n420  14  30 6.965549e-01\n421  15   1 6.982922e-01\n422  15   2 6.776778e-01\n423  15   3 6.933909e-01\n424  15   4 7.119283e-01\n425  15   5 7.297244e-01\n426  15   6 7.463400e-01\n427  15   7 7.618650e-01\n428  15   8 7.764714e-01\n429  15   9 7.903211e-01\n430  15  10 8.035491e-01\n431  15  11 8.162646e-01\n432  15  12 8.285554e-01\n433  15  13 8.404927e-01\n434  15  14 8.521348e-01\n435  15  15 8.635300e-01\n436  15  16 8.747185e-01\n437  15  17 8.857347e-01\n438  15  18 8.966079e-01\n439  15  19 9.073637e-01\n440  15  20 9.180244e-01\n441  15  21 9.286101e-01\n442  15  22 9.391387e-01\n443  15  23 9.496263e-01\n444  15  24 9.600880e-01\n445  15  25 9.705378e-01\n446  15  26 9.809885e-01\n447  15  27 9.914526e-01\n448  15  28 1.001942e+00\n449  15  29 1.012468e+00\n450  15  30 1.023042e+00\n451  16   1 2.681622e+00\n452  16   2 1.662933e+00\n453  16   3 1.444452e+00\n454  16   4 1.356139e+00\n455  16   5 1.311920e+00\n456  16   6 1.287861e+00\n457  16   7 1.274720e+00\n458  16   8 1.268193e+00\n459  16   9 1.266008e+00\n460  16  10 1.266858e+00\n461  16  11 1.269941e+00\n462  16  12 1.274742e+00\n463  16  13 1.280917e+00\n464  16  14 1.288231e+00\n465  16  15 1.296519e+00\n466  16  16 1.305667e+00\n467  16  17 1.315596e+00\n468  16  18 1.326252e+00\n469  16  19 1.337603e+00\n470  16  20 1.349629e+00\n471  16  21 1.362327e+00\n472  16  22 1.375703e+00\n473  16  23 1.389776e+00\n474  16  24 1.404573e+00\n475  16  25 1.420132e+00\n476  16  26 1.436504e+00\n477  16  27 1.453751e+00\n478  16  28 1.471948e+00\n479  16  29 1.491188e+00\n480  16  30 1.511583e+00\n481  17   1 2.712052e+01\n482  17   2 6.571644e+00\n483  17   3 4.236673e+00\n484  17   4 3.440831e+00\n485  17   5 3.062201e+00\n486  17   6 2.854986e+00\n487  17   7 2.736524e+00\n488  17   8 2.672213e+00\n489  17   9 2.646005e+00\n490  17  10 2.650786e+00\n491  17  11 2.685100e+00\n492  17  12 2.752919e+00\n493  17  13 2.866780e+00\n494  17  14 3.060261e+00\n495  17  15 3.452308e+00\n496  17  16 3.053600e-01\n497  17  17 3.561953e-01\n498  17  18 3.927636e-01\n499  17  19 4.226055e-01\n500  17  20 4.483593e-01\n501  17  21 4.713002e-01\n502  17  22 4.921574e-01\n503  17  23 5.113941e-01\n504  17  24 5.293267e-01\n505  17  25 5.461829e-01\n506  17  26 5.621336e-01\n507  17  27 5.773107e-01\n508  17  28 5.918193e-01\n509  17  29 6.057443e-01\n510  17  30 6.191556e-01\n511  18   1 4.655340e-01\n512  18   2 5.106141e-01\n513  18   3 5.500654e-01\n514  18   4 5.822687e-01\n515  18   5 6.093890e-01\n516  18   6 6.329213e-01\n517  18   7 6.538279e-01\n518  18   8 6.727467e-01\n519  18   9 6.901177e-01\n520  18  10 7.062554e-01\n521  18  11 7.213918e-01\n522  18  12 7.357025e-01\n523  18  13 7.493235e-01\n524  18  14 7.623621e-01\n525  18  15 7.749050e-01\n526  18  16 7.870225e-01\n527  18  17 7.987731e-01\n528  18  18 8.102059e-01\n529  18  19 8.213623e-01\n530  18  20 8.322779e-01\n531  18  21 8.429835e-01\n532  18  22 8.535061e-01\n533  18  23 8.638695e-01\n534  18  24 8.740946e-01\n535  18  25 8.842006e-01\n536  18  26 8.942044e-01\n537  18  27 9.041217e-01\n538  18  28 9.139667e-01\n539  18  29 9.237528e-01\n540  18  30 9.334922e-01\n541  19   1 1.758231e+00\n542  19   2 1.272529e+00\n543  19   3 1.166204e+00\n544  19   4 1.126133e+00\n545  19   5 1.108648e+00\n546  19   6 1.101380e+00\n547  19   7 1.099549e+00\n548  19   8 1.100945e+00\n549  19   9 1.104414e+00\n550  19  10 1.109302e+00\n551  19  11 1.115213e+00\n552  19  12 1.121898e+00\n553  19  13 1.129191e+00\n554  19  14 1.136982e+00\n555  19  15 1.145195e+00\n556  19  16 1.153779e+00\n557  19  17 1.162698e+00\n558  19  18 1.171928e+00\n559  19  19 1.181453e+00\n560  19  20 1.191265e+00\n561  19  21 1.201361e+00\n562  19  22 1.211742e+00\n563  19  23 1.222414e+00\n564  19  24 1.233385e+00\n565  19  25 1.244665e+00\n566  19  26 1.256271e+00\n567  19  27 1.268218e+00\n568  19  28 1.280529e+00\n569  19  29 1.293226e+00\n570  19  30 1.306339e+00\n571  20   1 1.042664e+01\n572  20   2 3.776288e+00\n573  20   3 2.750549e+00\n574  20   4 2.362625e+00\n575  20   5 2.165992e+00\n576  20   6 2.051799e+00\n577  20   7 1.980915e+00\n578  20   8 1.935921e+00\n579  20   9 1.907942e+00\n580  20  10 1.892036e+00\n581  20  11 1.885291e+00\n582  20  12 1.885952e+00\n583  20  13 1.892978e+00\n584  20  14 1.905820e+00\n585  20  15 1.924314e+00\n586  20  16 1.948641e+00\n587  20  17 1.979357e+00\n588  20  18 2.017495e+00\n589  20  19 2.064792e+00\n590  20  20 2.124155e+00\n591  20  21 2.200693e+00\n592  20  22 2.304322e+00\n593  20  23 2.458026e+00\n594  20  24 2.737997e+00\n595  20  25 3.516919e-01\n596  20  26 4.015074e-01\n597  20  27 4.365531e-01\n598  20  28 4.647858e-01\n599  20  29 4.889558e-01\n600  20  30 5.103762e-01\n601  21   1 2.743554e-01\n602  21   2 3.502136e-01\n603  21   3 4.048237e-01\n604  21   4 4.477589e-01\n605  21   5 4.833096e-01\n606  21   6 5.137625e-01\n607  21   7 5.404859e-01\n608  21   8 5.643666e-01\n609  21   9 5.860129e-01\n610  21  10 6.058607e-01\n611  21  11 6.242332e-01\n612  21  12 6.413767e-01\n613  21  13 6.574830e-01\n614  21  14 6.727047e-01\n615  21  15 6.871649e-01\n616  21  16 7.009647e-01\n617  21  17 7.141876e-01\n618  21  18 7.269041e-01\n619  21  19 7.391735e-01\n620  21  20 7.510469e-01\n621  21  21 7.625681e-01\n622  21  22 7.737753e-01\n623  21  23 7.847019e-01\n624  21  24 7.953774e-01\n625  21  25 8.058278e-01\n626  21  26 8.160766e-01\n627  21  27 8.261446e-01\n628  21  28 8.360507e-01\n629  21  29 8.458122e-01\n630  21  30 8.554446e-01\n631  22   1 1.193851e+00\n632  22   2 9.887137e-01\n633  22   3 9.518077e-01\n634  22   4 9.440411e-01\n635  22   5 9.454889e-01\n636  22   6 9.506882e-01\n637  22   7 9.576423e-01\n638  22   8 9.654898e-01\n639  22   9 9.738181e-01\n640  22  10 9.824155e-01\n641  22  11 9.911685e-01\n642  22  12 1.000015e+00\n643  22  13 1.008922e+00\n644  22  14 1.017873e+00\n645  22  15 1.026859e+00\n646  22  16 1.035880e+00\n647  22  17 1.044938e+00\n648  22  18 1.054037e+00\n649  22  19 1.063184e+00\n650  22  20 1.072386e+00\n651  22  21 1.081652e+00\n652  22  22 1.090989e+00\n653  22  23 1.100408e+00\n654  22  24 1.109917e+00\n655  22  25 1.119528e+00\n656  22  26 1.129251e+00\n657  22  27 1.139097e+00\n658  22  28 1.149078e+00\n659  22  29 1.159207e+00\n660  22  30 1.169497e+00\n661  23   1 5.366535e+00\n662  23   2 2.549706e+00\n663  23   3 2.024456e+00\n664  23   4 1.813931e+00\n665  23   5 1.704374e+00\n666  23   6 1.639855e+00\n667  23   7 1.599437e+00\n668  23   8 1.573534e+00\n669  23   9 1.557146e+00\n670  23  10 1.547418e+00\n671  23  11 1.542610e+00\n672  23  12 1.541614e+00\n673  23  13 1.543697e+00\n674  23  14 1.548369e+00\n675  23  15 1.555302e+00\n676  23  16 1.564284e+00\n677  23  17 1.575187e+00\n678  23  18 1.587955e+00\n679  23  19 1.602589e+00\n680  23  20 1.619150e+00\n681  23  21 1.637756e+00\n682  23  22 1.658592e+00\n683  23  23 1.681924e+00\n684  23  24 1.708123e+00\n685  23  25 1.737701e+00\n686  23  26 1.771379e+00\n687  23  27 1.810193e+00\n688  23  28 1.855686e+00\n689  23  29 1.910287e+00\n690  23  30 1.978122e+00\n691  24   1 6.924281e+02\n692  24   2 4.945666e+01\n693  24   3 2.659752e+01\n694  24   4 2.370542e-01\n695  24   5 3.001909e-01\n696  24   6 3.490371e-01\n697  24   7 3.896563e-01\n698  24   8 4.246138e-01\n699  24   9 4.553636e-01\n700  24  10 4.828454e-01\n701  24  11 5.077130e-01\n702  24  12 5.304433e-01\n703  24  13 5.513968e-01\n704  24  14 5.708526e-01\n705  24  15 5.890316e-01\n706  24  16 6.061118e-01\n707  24  17 6.222382e-01\n708  24  18 6.375310e-01\n709  24  19 6.520907e-01\n710  24  20 6.660020e-01\n711  24  21 6.793372e-01\n712  24  22 6.921581e-01\n713  24  23 7.045186e-01\n714  24  24 7.164651e-01\n715  24  25 7.280387e-01\n716  24  26 7.392754e-01\n717  24  27 7.502071e-01\n718  24  28 7.608622e-01\n719  24  29 7.712662e-01\n720  24  30 7.814420e-01\n721  25   1 8.200968e-01\n722  25   2 7.684965e-01\n723  25   3 7.759285e-01\n724  25   4 7.905547e-01\n725  25   5 8.059323e-01\n726  25   6 8.207704e-01\n727  25   7 8.348258e-01\n728  25   8 8.481181e-01\n729  25   9 8.607320e-01\n730  25  10 8.727606e-01\n731  25  11 8.842897e-01\n732  25  12 8.953933e-01\n733  25  13 9.061346e-01\n734  25  14 9.165673e-01\n735  25  15 9.267366e-01\n736  25  16 9.366815e-01\n737  25  17 9.464355e-01\n738  25  18 9.560276e-01\n739  25  19 9.654834e-01\n740  25  20 9.748253e-01\n741  25  21 9.840735e-01\n742  25  22 9.932462e-01\n743  25  23 1.002360e+00\n744  25  24 1.011430e+00\n745  25  25 1.020470e+00\n746  25  26 1.029494e+00\n747  25  27 1.038513e+00\n748  25  28 1.047541e+00\n749  25  29 1.056589e+00\n750  25  30 1.065667e+00\n751  26   1 3.184158e+00\n752  26   2 1.857056e+00\n753  26   3 1.578177e+00\n754  26   4 1.463848e+00\n755  26   5 1.404665e+00\n756  26   6 1.370572e+00\n757  26   7 1.350029e+00\n758  26   8 1.337671e+00\n759  26   9 1.330670e+00\n760  26  10 1.327399e+00\n761  26  11 1.326859e+00\n762  26  12 1.328406e+00\n763  26  13 1.331608e+00\n764  26  14 1.336170e+00\n765  26  15 1.341885e+00\n766  26  16 1.348608e+00\n767  26  17 1.356236e+00\n768  26  18 1.364701e+00\n769  26  19 1.373957e+00\n770  26  20 1.383979e+00\n771  26  21 1.394761e+00\n772  26  22 1.406309e+00\n773  26  23 1.418644e+00\n774  26  24 1.431802e+00\n775  26  25 1.445831e+00\n776  26  26 1.460799e+00\n777  26  27 1.476788e+00\n778  26  28 1.493906e+00\n779  26  29 1.512285e+00\n780  26  30 1.532093e+00\n781  27   1 4.305230e+01\n782  27   2 8.544216e+00\n783  27   3 5.171797e+00\n784  27   4 4.077014e+00\n785  27   5 3.571090e+00\n786  27   6 3.302916e+00\n787  27   7 3.159095e+00\n788  27   8 3.095428e+00\n789  27   9 3.096267e+00\n790  27  10 3.165110e+00\n791  27  11 3.333982e+00\n792  27  12 3.736435e+00\n793  27  13 3.482515e-01\n794  27  14 4.003084e-01\n795  27  15 4.380686e-01\n796  27  16 4.689518e-01\n797  27  17 4.955723e-01\n798  27  18 5.192082e-01\n799  27  19 5.406004e-01\n800  27  20 5.602260e-01\n801  27  21 5.784155e-01\n802  27  22 5.954095e-01\n803  27  23 6.113908e-01\n804  27  24 6.265019e-01\n805  27  25 6.408570e-01\n806  27  26 6.545494e-01\n807  27  27 6.676563e-01\n808  27  28 6.802428e-01\n809  27  29 6.923640e-01\n810  27  30 7.040676e-01\n811  28   1 5.542825e-01\n812  28   2 5.863048e-01\n813  28   3 6.222192e-01\n814  28   4 6.527268e-01\n815  28   5 6.787421e-01\n816  28   6 7.013957e-01\n817  28   7 7.215124e-01\n818  28   8 7.396706e-01\n819  28   9 7.562827e-01\n820  28  10 7.716499e-01\n821  28  11 7.859977e-01\n822  28  12 7.994991e-01\n823  28  13 8.122893e-01\n824  28  14 8.244761e-01\n825  28  15 8.361465e-01\n826  28  16 8.473722e-01\n827  28  17 8.582124e-01\n828  28  18 8.687174e-01\n829  28  19 8.789295e-01\n830  28  20 8.888853e-01\n831  28  21 8.986165e-01\n832  28  22 9.081508e-01\n833  28  23 9.175126e-01\n834  28  24 9.267236e-01\n835  28  25 9.358032e-01\n836  28  26 9.447692e-01\n837  28  27 9.536373e-01\n838  28  28 9.624223e-01\n839  28  29 9.711378e-01\n840  28  30 9.797963e-01\n841  29   1 2.045513e+00\n842  29   2 1.408487e+00\n843  29   3 1.267765e+00\n844  29   4 1.212027e+00\n845  29   5 1.185253e+00\n846  29   6 1.171634e+00\n847  29   7 1.165051e+00\n848  29   8 1.162661e+00\n849  29   9 1.162974e+00\n850  29  10 1.165137e+00\n851  29  11 1.168633e+00\n852  29  12 1.173131e+00\n853  29  13 1.178411e+00\n854  29  14 1.184324e+00\n855  29  15 1.190767e+00\n856  29  16 1.197667e+00\n857  29  17 1.204973e+00\n858  29  18 1.212650e+00\n859  29  19 1.220673e+00\n860  29  20 1.229027e+00\n861  29  21 1.237705e+00\n862  29  22 1.246704e+00\n863  29  23 1.256027e+00\n864  29  24 1.265681e+00\n865  29  25 1.275678e+00\n866  29  26 1.286031e+00\n867  29  27 1.296761e+00\n868  29  28 1.307891e+00\n869  29  29 1.319449e+00\n870  29  30 1.331468e+00\n871  30   1 1.385050e+01\n872  30   2 4.448169e+00\n873  30   3 3.113835e+00\n874  30   4 2.620683e+00\n875  30   5 2.372444e+00\n876  30   6 2.228125e+00\n877  30   7 2.137929e+00\n878  30   8 2.079964e+00\n879  30   9 2.043205e+00\n880  30  10 2.021604e+00\n881  30  11 2.011693e+00\n882  30  12 2.011492e+00\n883  30  13 2.020000e+00\n884  30  14 2.036960e+00\n885  30  15 2.062826e+00\n886  30  16 2.098892e+00\n887  30  17 2.147708e+00\n888  30  18 2.214068e+00\n889  30  19 2.307574e+00\n890  30  20 2.450868e+00\n891  30  21 2.719955e+00\n892  30  22 3.991164e-01\n893  30  23 4.483312e-01\n894  30  24 4.830048e-01\n895  30  25 5.109395e-01\n896  30  26 5.348283e-01\n897  30  27 5.559591e-01\n898  30  28 5.750608e-01\n899  30  29 5.925923e-01\n900  30  30 6.088646e-01\n\n\n\nx &lt;- seq(-3, 3, 0.01)\ncurve(dnorm(x, mean=0, sd=1), from=-3, to=3, xlab=\"x\", ylab=\"Probability Density\")"
  },
  {
    "objectID": "supplemental/mlr-matrix.html",
    "href": "supplemental/mlr-matrix.html",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides the details for the matrix notation for multiple linear regression. We assume the reader has familiarity with some linear algebra. Please see Chapter 1 of An Introduction to Statistical Learning for a brief review of linear algebra."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#introduction",
    "href": "supplemental/mlr-matrix.html#introduction",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation 1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation 2\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "href": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Matrix Representation for the Regression Model",
    "text": "Matrix Representation for the Regression Model\nWe can represent the Equation 1 and Equation 2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "href": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Estimating the Coefficients",
    "text": "Estimating the Coefficients\nThe least-squares model is the one that minimizes the sum of the squared residuals. Therefore, we want to find the coefficients, \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes\n\\[\n\\sum\\limits_{i=1}^{n} e_{i}^2 = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})\n\\tag{5}\\]\nwhere \\(\\mathbf{e}^T\\), the transpose of the matrix \\(\\mathbf{e}\\).\n\\[\n(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{Y}^T\\mathbf{Y} -\n\\mathbf{Y}^T \\mathbf{X}\\hat{\\boldsymbol{\\beta}} - (\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y} +\n\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}})\n\\tag{6}\\]\nNote that \\((\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Since these are both constants (i.e. \\(1\\times 1\\) vectors), \\(\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Thus, Equation 7 becomes\n\\[\n\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}}\n\\tag{7}\\]\nSince we want to find the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes Equation 5, will find the value of \\(\\hat{\\boldsymbol{\\beta}}\\) such that the derivative with respect to \\(\\hat{\\boldsymbol{\\beta}}\\) is equal to 0.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\mathbf{e}^T\\mathbf{e}}{\\partial \\hat{\\boldsymbol{\\beta}}} & = \\frac{\\partial}{\\partial \\hat{\\boldsymbol{\\beta}}}(\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^T\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = 0 \\\\\n&\\Rightarrow - 2 \\mathbf{X}^T\\mathbf{Y} + 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = 0 \\\\\n& \\Rightarrow 2 \\mathbf{X}^T\\mathbf{Y} = 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow \\mathbf{X}^T\\mathbf{Y} = \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = \\mathbf{I}\\hat{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\tag{8}\\]\nThus, the estimate of the model coefficients is \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\)."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "href": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Variance-covariance matrix of the coefficients",
    "text": "Variance-covariance matrix of the coefficients\nWe will use two properties to derive the form of the variance-covariance matrix of the coefficients:\n\n\\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\)\n\nFirst, we will show that \\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\[\n\\begin{aligned}\nE[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] &= E \\begin{bmatrix}\\epsilon_1  & \\epsilon_2 & \\dots & \\epsilon_n \\end{bmatrix}\\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}  \\\\\n& = E \\begin{bmatrix} \\epsilon_1^2  & \\epsilon_1 \\epsilon_2 & \\dots & \\epsilon_1 \\epsilon_n \\\\\n\\epsilon_2 \\epsilon_1 & \\epsilon_2^2 & \\dots & \\epsilon_2 \\epsilon_n \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\epsilon_n \\epsilon_1 & \\epsilon_n \\epsilon_2 & \\dots & \\epsilon_n^2\n\\end{bmatrix} \\\\\n& = \\begin{bmatrix} E[\\epsilon_1^2]  & E[\\epsilon_1 \\epsilon_2] & \\dots & E[\\epsilon_1 \\epsilon_n] \\\\\nE[\\epsilon_2 \\epsilon_1] & E[\\epsilon_2^2] & \\dots & E[\\epsilon_2 \\epsilon_n] \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nE[\\epsilon_n \\epsilon_1] & E[\\epsilon_n \\epsilon_2] & \\dots & E[\\epsilon_n^2]\n\\end{bmatrix}\n\\end{aligned}\n\\tag{9}\\]\nRecall, the regression assumption that the errors \\(\\epsilon_i's\\) are Normally distributed with mean 0 and variance \\(\\sigma^2\\). Thus, \\(E(\\epsilon_i^2) = Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). Additionally, recall the regression assumption that the errors are uncorrelated, i.e. \\(E(\\epsilon_i \\epsilon_j) = Cov(\\epsilon_i, \\epsilon_j) = 0\\) for all \\(i,j\\). Using these assumptions, we can write Equation 9 as\n\\[\nE[\\mathbf{\\epsilon}\\mathbf{\\epsilon}^T]  = \\begin{bmatrix} \\sigma^2  & 0 & \\dots & 0 \\\\\n0 & \\sigma^2  & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & \\sigma^2\n\\end{bmatrix} = \\sigma^2 \\mathbf{I}\n\\tag{10}\\]\nwhere \\(\\mathbf{I}\\) is the \\(n \\times n\\) identity matrix.\nNext, we show that \\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\).\nRecall that the \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\) and \\(\\mathbf{Y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}\\). Then,\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{\\beta}} &= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\\\\n&= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}) \\\\\n&= \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{\\epsilon} \\\\\n\\end{aligned}\n\\tag{11}\\]\nUsing these two properties, we derive the form of the variance-covariance matrix for the coefficients. Note that the covariance matrix is \\(E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T]\\)\n\\[\n\\begin{aligned}\nE[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] &= E[(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})^T]\\\\\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T]\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T (\\sigma^2\\mathbf{I})\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&= \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&  = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n\\end{aligned}\n\\tag{12}\\]"
  },
  {
    "objectID": "supplemental/stats-tests.html",
    "href": "supplemental/stats-tests.html",
    "title": "Statistical Tests",
    "section": "",
    "text": "Parametric tests are a class of statistical tests that make assumptions about the underlying probability distribution of the data being analyzed. These assumptions include that the data are sampled from a population that follows a normal distribution, and that the sample size is large enough to make these assumptions valid. The most commonly used parametric tests include t-tests, ANOVA (analysis of variance) and multiple regression analysis. These tests are known to have more powerful results than non-parametric tests, which makes them more useful for exploring the difference between groups or testing hypotheses about a population.\nThe assumptions of parametric tests are met when the data are approximately normal and when the sample size is large enough. Therefore, it is recommended to check for normality of the data using normality test such as the Shapiro-Wilk test and check for outliers using box plots and histograms.\nParametric tests are useful when the researcher wants to compare means of two or more groups, establish a relationship between two or more variables, or investigate the correlation between variables. Examples of parametric tests include: t-test, ANOVA, multiple regression analysis, and chi-square tests.\n\n\nSimple linear regression is a statistical method used to model the relationship between two variables, where one variable (called the independent variable or predictor variable) is used to predict the other variable (called the dependent variable or response variable). The relationship between the two variables is assumed to be linear, meaning that the change in the dependent variable is proportional to the change in the independent variable.\nThe goal of simple linear regression is to find the best-fitting line that describes the relationship between the two variables. This line is called the regression line, and it is defined by an equation of the form y = mx + b, where y is the dependent variable, x is the independent variable, m is the slope of the line, and b is the y-intercept of the line.\nTo find the values of m and b that best fit the data, simple linear regression uses a method called least squares regression. This method minimizes the sum of the squared differences between the predicted values of y and the actual values of y for each value of x. The resulting regression line can be used to predict the value of y for any given value of x within the range of the data.\nSimple linear regression is commonly used in many fields, including economics, social sciences, and engineering, to analyze the relationship between two variables and make predictions based on that relationship.\n\n\nTo conduct a hypothesis test in the context of simple linear regression, follow these steps:\n\nState the research question(s) and assess the nature of the variables (continuous, discrete), and identify the dependent (outcome) and independent variables.\nState the null and alternative hypotheses: The null hypothesis (H₀) typically states that there is no relationship between the predictor (independent) variable and the response (dependent) variable, i.e., the slope of the regression line (β₁) is equal to zero. The alternative hypothesis (H₁) states that there is a relationship between the predictor and response variables, i.e., the slope is not equal to zero.\nH₀: β₁ = 0 H₁: β₁ ≠ 0\nCollect data: Gather a sample of paired data points for the predictor and response variables.\nPrepare data (diagnostics): Ensure that the data is appropriate for linear regression (i.e., there is a linear relationship, the residuals are normally distributed, homoscedasticity is present, and extreme outliers are not present).\n\nLinearity:\n\nScatterplot: Create a scatterplot of the response variable against the predictor variable. Visually inspect the plot to determine if the relationship appears to be linear. If the data points form a pattern that roughly resembles a straight line, it suggests a linear relationship. If the pattern is curved, it indicates that the relationship may be nonlinear.\nResidual plot: After fitting the linear regression model, plot the residuals (observed values minus predicted values) against the predictor variable or the predicted values. A random scattering of residuals around the horizontal axis (zero) suggests that the linear model is appropriate. If there is a pattern or trend in the residual plot, it indicates a potential violation of the linearity assumption.\nCorrelation coefficient (Pearson’s r): Calculate the correlation coefficient between the predictor and response variables. Pearson’s r ranges from -1 to 1, with values close to -1 or 1 suggesting a strong linear relationship, and values close to 0 indicating a weak or no linear relationship. While the correlation coefficient can provide information about the strength and direction of the relationship, it doesn’t necessarily imply causation or indicate that a linear regression model is appropriate.\nPartial regression plots (added-variable plots): Partial regression plots can help assess the linearity assumption in multiple regression settings. These plots show the relationship between a response variable and a predictor variable, controlling for the effects of other predictor variables in the model. If the partial regression plots display a linear pattern, it supports the linearity assumption.\n\n\nEstimate the regression coefficients: Using the sample data, calculate the slope (β₁) and the intercept (β₀) of the regression line using the least squares method or another appropriate method.\nCalculate the test statistic: Compute the t-statistic for the hypothesis test using the following formula:\nt = (b₁ - 0) / SE(b₁)\nHere, b₁ is the estimated slope of the regression line, and SE(b₁) is the standard error of the slope.\nDetermine the degrees of freedom: Calculate the degrees of freedom for the t-distribution, which is equal to the number of data points (n) minus the number of estimated parameters (2 for simple linear regression: the slope and the intercept).\ndf = n - 2\nDetermine the critical value or p-value: Based on the chosen significance level (α, usually 0.05), determine the critical t-value from the t-distribution table, or calculate the p-value for the observed t-statistic. The p-value is the probability of observing a t-statistic as extreme or more extreme than the one calculated, assuming the null hypothesis is true.\nMake a decision: Compare the calculated t-statistic to the critical value or the p-value to the significance level:\n\nIf the absolute value of the t-statistic is greater than the critical value, or if the p-value is less than the significance level (p &lt; α), reject the null hypothesis. This suggests that there is a significant relationship between the predictor and response variables.\nIf the absolute value of the t-statistic is less than or equal to the critical value, or if the p-value is greater than or equal to the significance level (p ≥ α), fail to reject the null hypothesis. This suggests that there is no significant relationship between the predictor and response variables.\n\nInterpret the results: Based on the decision made in the previous step, interpret the results in the context of your research question or study. If you rejected the null hypothesis, you can also report the estimated regression coefficients and the coefficient of determination (R²) to describe the strength and direction of the relationship between the predictor and response variables.\n\n\n\n\n\n\n\n\n\n\nCan VO2max be predicted from BMI?\nVariables:\nV02max: predicted/dependent (continuous)\nBMI: predictor/independent (continuous)\n\n\n\nH₀: β₁ = 0; H₁: β₁ ≠ 0\n\n\n\nThe following variables have been recorded for each individual:\n\nAge (in years)\nGender (1 = Male, 2 = Female)\nResting eart Rate (RHR, in beats per minute)\nVO2 Max (in mL/kg/min)\nBody Mass Index (BMI)\n\nThe dataset can be found here: physical-fitness.csv\n\n\n\n\n\n\n\n\nIf you violate the assumption of equal variance (also known as homoscedasticity) in a simple linear regression, this can have several consequences for your model:\n\nBiased estimates: The estimated coefficients may be biased, which means that they may not accurately reflect the true relationship between the dependent variable and the independent variable.\nInaccurate standard errors: The standard errors of the estimated coefficients may be inaccurate, which means that the confidence intervals and hypothesis tests based on them may be incorrect.\nInvalid hypothesis tests: The F-test and t-tests used to assess the significance of the regression coefficients may not be valid if the assumption of equal variance is violated.\nInefficient estimates: The estimates may be less efficient than they would be under homoscedasticity, which means that you may need a larger sample size to achieve the same level of precision in your estimates.\n\nTo address this issue, you may want to consider using alternative regression techniques that are robust to heteroscedasticity, such as weighted least squares regression or generalized least squares regression. Alternatively, you may want to transform the variables or use nonparametric methods that do not assume equal variance. You can also use diagnostic plots, such as a plot of residuals against predicted values, to identify and correct heteroscedasticity.\n\n\n\n\n\n\\[\nt = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n\\tag{1}\\]\nwhere:\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu\\) is the population mean\n\\(s\\) is the sample standard deviation\n\\(n\\) is the sample size\n\nIt also can be written as:\n\\[\nt = \\frac{\\bar{x} - \\mu}{s_x/\\sqrt{n}}\n\\tag{2}\\]\nwhere:\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu\\) is the population mean\n\\(s_x\\) is the sample standard deviation\n\\(n\\) is the sample size\n\n\n\nThe one-sample t-test should be run when you have a single sample of data and you want to compare the mean of that sample to a known or hypothesized population mean.\nExample in kinesiology: A kinesiologist wants to know if a new exercise program improves muscle strength in older adults. The kinesiologist recruits a sample of 20 older adults and has them complete the exercise program for 8 weeks. The kinesiologist measures muscle strength using a dynamometer before and after the 8 week program. The kinesiologist wants to know if the mean muscle strength of the sample is significantly different from the population mean muscle strength of older adults (which is hypothesized to be 40 kg). The kinesiologist would run a one-sample t-test to compare the mean muscle strength of the sample (after completing the exercise program) to the hypothesized population mean of 40 kg. If the t-value is significant, the kinesiologist can conclude that the exercise program does improve muscle strength in older adults.\n\n\n\nThe test makes several assumptions about the data:\n\nIndependence: The observations in the sample are independent of one another.\nNormality: The population from which the sample is drawn is normally distributed.\nEqual variances: The population variances of the two groups are equal.\nRandom sampling: The sample is drawn randomly and independently from the population.\nSample size: The sample size is large enough (usually greater than 30) for the Central Limit Theorem to be applied.\n\nIt is important to check these assumptions before running the one-sample t-test to ensure the validity of the test results. In case the sample size is small or the data distribution is not normal, a non-parametric test such as the Wilcoxon signed-rank test should be used instead.\n\n\n\nWhen reporting the results of a one-sample t-test in APA style, you should include the following information:\n\nThe test statistic and the associated degrees of freedom (df). For example: “t(df) = 2.45, p = .03.”\nThe p-value of the test. This should be rounded to two decimal places and reported as a probability (e.g., “p = .03” rather than “p &lt; .05”).\nThe sample size (n). This should be reported as a whole number (e.g., “n = 20”).\nThe mean and standard deviation of the sample. For example: “M = 5.6, SD = 1.2.”\nThe direction of the effect. For example, “The mean score was significantly higher than the hypothesized mean (M = 4.0, t(df) = 2.45, p = .03).”\nAny relevant effect size measures. For example, you might report the Cohen’s d effect size as “d = 0.87.”\n\nIt is also good practice to include a brief description of the research question or hypothesis being tested, as well as a description of the sample and any relevant study variables.\nFor example: “In this study, we tested the hypothesis that the mean score on a memory task would be significantly higher than 4.0. A sample of 20 participants completed the task, with a mean score of 5.6 (SD = 1.2). The one-sample t-test revealed a significant difference, t(df) = 2.45, p = .03, d = 0.87, indicating that the mean score was significantly higher than the hypothesized mean.”\n\n\n\nThe results of the one-sample t test indicated that the mean (M = X, SD = Y) was significantly different from the hypothesized value (t(df) = t-value, p &lt; .05).\nIn a one-sample t test, the mean of the sample was significantly different from the hypothesized mean (t(df) = t-value, p &lt; .05). Specifically, the mean of the sample was X (SD = standard deviation) while the hypothesized mean was Y.\nThe results of the one-sample t test indicated that the mean of the sample (M = X, SD = Y) was significantly different from the hypothesized mean (μ = t) t(df) = t-value, p &lt; .05.\n\n\n\n\n\n\nThe independent-samples t-test should be run when comparing the means of two independent groups. For example, in the field of kinesiology, an independent-samples t-test can be used to compare the muscle strength of a group of individuals who have completed a resistance training program to a group of individuals who have not completed a resistance training program. The independent variable would be whether or not the individual completed the resistance training program and the dependent variable would be muscle strength. The t-test would be used to determine if there is a significant difference in muscle strength between the two groups, indicating that the resistance training program had an effect on muscle strength.\n\n\n\nThe assumptions of the independent-samples t-test include:\n\nNormality: The data should be approximately normally distributed within each group.\nIndependence: The observations in each group should be independent of one another.\nEqual variances: The variances of the two groups should be roughly equal.\nRandom Sampling: The sample of each group should be random and representative of the population.\nEqual sample size: The sample size in each group should be equal or similar.\n\nIt is important to note that not all these assumptions need to be perfectly met for the test to be valid, but the deviations from these assumptions should be small. If the data do not meet these assumptions, the non-parametric version of the independent-samples t-test, such as the Mann-Whitney U test, can be used instead.\n\n\n\nTo report the results of an independent samples t-test in APA style, you should include the following information:\n\nThe type of test that was conducted (e.g., “An independent samples t-test was conducted to compare the mean scores of two groups on a measure of stress.”)\nThe sample size for each group (e.g., “The sample consisted of 20 participants in Group A and 25 participants in Group B.”)\nThe mean and standard deviation for each group (e.g., “The mean score for Group A was M = 3.5, SD = 1.2, and the mean score for Group B was M = 2.8, SD = 0.9.”)\nThe t-value and p-value obtained from the test (e.g., “The t-value was t(43) = 2.3, p = .03, indicating that there was a significant difference between the mean scores of the two groups, with Group A scoring higher than Group B.”)\nThe effect size (e.g., “The effect size for the difference between the two groups was d = .7, indicating a moderate effect.”)\n\nIt is also a good idea to provide a brief interpretation of the results, explaining what they mean in the context of your research question or hypothesis.\nHere is an example of how you might report the results of an independent samples t-test in APA style:\n\n\n\n“An independent samples t-test was conducted to compare the mean scores of two groups on a measure of stress. The sample consisted of 20 participants in Group A and 25 participants in Group B. The mean score for Group A was M = 3.5, SD = 1.2, and the mean score for Group B was M = 2.8, SD = 0.9. The t-value was t(43) = 2.3, p = .03, indicating that there was a significant difference between the mean scores of the two groups, with Group A scoring higher than Group B. The effect size for the difference between the two groups was d = .7, indicating a moderate effect. These results suggest that participants in Group A experienced significantly higher levels of stress than those in Group B.”\n“The purpose of this study was to examine the effect of a new teaching method on student achievement. A sample of 50 students was randomly assigned to either the experimental group, which received the new teaching method, or the control group, which received the traditional teaching method. Student achievement was measured using a standardized test. The results of the independent samples t-test showed that there was a statistically significant difference between the experimental and control groups, t(48) = 2.57, p = .01. The experimental group had a higher mean score on the achievement test than the control group. These findings suggest that the new teaching method was effective in improving student achievement. However, it is important to note that the small sample size and lack of generalizability to other populations are limitations of this study.”\n\n\n\n\n\n\nThe paired-samples t-test should be run when you have two sets of related (or paired) data that you want to compare. For example, if you want to compare the effectiveness of two different treatments on a group of patients, you would use a paired-samples t-test. This test is also commonly used in pre- and post-test designs, where you want to compare scores before and after an intervention or treatment. Additionally, if you want to compare the mean differences between two groups or conditions, but you want to control for individual differences, you can use a paired-samples t-test.\n\n\n\nThe assumptions of the paired-samples t-test include:\n\nIndependence: The observations within each pair are independent of one another.\nNormality: The differences between the pairs of observations are approximately normally distributed.\nEqual variances: The variances of the differences between the pairs of observations are equal.\nPaired data: The observations are paired, meaning that each individual is measured twice, once before and once after some intervention, or in two different conditions.\nRandom Sampling: The sample being used is selected randomly from the population.\n\nIt’s important to note that violations of these assumptions may lead to inaccurate results, so it’s necessary to check them before applying the test. Checking for normality can be done using a normal probability plot, and checking for equal variances can be done using Levene’s test. The paired sample t-test is sensitive to the violation of normality and equal variances assumptions, thus if the assumptions are not met, there are other options that can be used, such as the Wilcoxon signed-rank test which is a non-parametric version of the paired-samples t-test.\n\n\n\nWhen reporting the results of a paired-samples t-test, it is important to include the following information:\n\nThe test statistic (e.g. t-value) and the associated p-value. The t-value tells us how many standard errors the mean difference is from zero, and the p-value tells us the probability of observing a t-value as extreme as the one we calculated under the assumption that the null hypothesis is true.\nThe sample size (e.g. the number of pairs of observations).\nThe mean difference and the standard deviation of the differences.\nThe effect size, such as Cohen’s d, which is a measure of the magnitude of the difference between the means.\n\nExample:\n“A paired-samples t-test was conducted to compare the pre-test and post-test scores of a group of students. The sample size was 20 pairs of observations. The mean difference between the pre-test and post-test scores was 5.3 (SD = 2.5). The t-value was 3.87, with a p-value of 0.001. The effect size (Cohen’s d) was 0.67, which indicates a moderate effect size.”\n“The results of the paired-samples t-test revealed that there was a statistically significant difference between the pre-test and post-test scores of the students, t(19) = 3.87, p = 0.001. The mean difference was 5.3 (95% CI [3.4, 7.2]), and the effect size (d = 0.67) suggests moderate effect size.”\n\n\n\n\n\n\nA one-way ANOVA (Analysis of Variance) is used to test for differences in the mean of a continuous outcome variable across two or more categorical groups. It is used when you have one independent variable (also known as a factor) with two or more levels or groups and one continuous dependent variable.\nIn other words, you should run a one-way ANOVA when:\n\nYou want to compare the means of a continuous outcome variable across two or more groups.\nYou have one independent variable (factor) with two or more levels or groups\nThe dependent variable is continuous\n\nExample: A researcher wants to know if there is a difference in the mean test scores of students who studied using different methods (Method A, Method B, Method C). The researcher collect data on test scores and the method used. The test scores are continuous variable and method of study is categorical variable with 3 levels. So, the researcher can use one-way ANOVA to test for the difference in mean test scores across different method of study.\n\n\n\nThe one-way ANOVA (analysis of variance) makes several assumptions about the data being analyzed:\n\nIndependence: The observations in each group are independent of each other and do not affect the observations in the other groups.\nNormality: The data within each group is normally distributed, or at least approximately normally distributed. This assumption can be checked using normality tests such as the Shapiro-Wilk test.\nEqual variances: The variances of the data within each group are equal. This assumption can be checked using tests such as the Levene’s test.\nRandom sampling: The data are randomly sampled from the population, so that the sample is representative of the population.\n\nViolations of these assumptions can lead to biased or incorrect results. If the assumptions are not met, non-parametric alternatives such as Kruskal-Wallis test could be used.\n\n\n\nWhen reporting the results of a one-way ANOVA, it is important to include the following information:\n\nThe F-value and the associated p-value. The F-value tells us how much variation in the dependent variable is accounted for by the independent variable, and the p-value tells us the probability of observing an F-value as extreme as the one we calculated under the assumption that the null hypothesis is true.\nThe sample size for each group, or the number of observations in each group.\nThe means and standard deviations for each group.\nThe effect size, such as eta-squared (η²) or omega-squared (ω²), which is a measure of the proportion of variance in the dependent variable that is accounted for by the independent variable.\n\nExample:\n“A one-way ANOVA was conducted to compare the scores of three groups of students on a test. The sample size for each group was 10, 10, and 12. The means and standard deviations for each group were: Group 1 = 80 (SD = 5), Group 2 = 75 (SD = 4), Group 3 = 70 (SD = 3). The F-value was 12.5, with a p-value of 0.001. The effect size (η²) was 0.17, which indicates a moderate effect size.”\n“The results of the one-way ANOVA revealed that there was a statistically significant difference between the scores of the three groups of students, F(2, 28) = 12.5, p = 0.001. Post-hoc comparisons revealed that group 1 significantly different from group 2 (p = 0.05) and group 3 (p = 0.001). The mean scores for each group were: Group 1 = 80 (95% CI [78, 82]), Group 2 = 75 (95% CI [73, 77]), Group 3 = 70 (95% CI [69, 72]). The effect size (η² = 0.17) suggests that the independent variable accounted for a moderate proportion of variance in the dependent variable.”\n\n\n\n\n\n\nYou should run a Between-subjects Two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and the levels of these independent variables are different between groups of participants.\nAn example related to physical activity could be comparing the effect of two different types of exercise programs (e.g. resistance training vs. cardio) on muscle mass gain in two different age groups (e.g. older adults vs. younger adults). In this example, the independent variables would be the type of exercise program and the age group, and the dependent variable would be muscle mass gain. The levels of the independent variables would be different between groups of participants, as the older adults would be in one group and the younger adults would be in another. A Between-subjects Two-way ANOVA would allow you to test for any interactions between the two independent variables (i.e. whether the effect of the exercise program on muscle mass gain is different in older adults vs. younger adults) and any main effects of each independent variable on the dependent variable.\n\n\n\nThe assumptions of the between-subjects two-way ANOVA are as follows:\n\nIndependence: The observations in each group are independent of each other, meaning that the responses of one participant do not affect the responses of another participant.\nNormality: The distribution of the residuals (the difference between the observed and predicted values) is approximately normal. It is important to check the normality assumptions using normality test such as the Shapiro-Wilk test and check for outliers using box plots and histograms.\nEqual variances: The variances of the residuals are equal across all groups and levels of the independent variables. This assumption can be checked using Levene’s test for equality of variances.\nAdditivity: The effect of each independent variable on the dependent variable is additive, meaning that the effect of one independent variable does not depend on the level of the other independent variable.\nLinearity: The relationship between the independent variables and the dependent variable is linear, meaning that a straight line can be used to represent the relationship.\nIndependence of errors: the residuals are independent, meaning that the residuals of one observation are not correlated with the residuals of any other observation.\n\nIt’s important to note that when these assumptions are not met, the results of the ANOVA should be interpreted with caution and alternative methods of analysis should be considered.\n\n\n\nWhen reporting the results of a between-subjects Two-way ANOVA, you should include the following information:\n\nA description of the study design, including the independent variables, dependent variable, and the levels of each independent variable.\nThe results of the ANOVA, including the F-value, degrees of freedom, and p-value for each independent variable and any interaction between the two independent variables.\nA summary of the main findings, including any significant main effects or interactions between the independent variables.\nFollow-up tests, such as post-hoc tests, to determine which specific levels of the independent variables were responsible for the significant effects.\n\nExample:\n“The study aimed to examine the effect of two different types of physical education programs (e.g. traditional vs. adventure-based) on physical fitness in two different age groups (e.g. younger children vs. older children). A between-subjects Two-way ANOVA was conducted, with the independent variables being the type of program and the age group, and the dependent variable being physical fitness. The results of the ANOVA showed a significant main effect of the type of program, F (1, 48) = 8.32, p = 0.006, with the adventure-based program resulting in higher physical fitness scores than the traditional program. A significant interaction was also found between the type of program and the age group, F (1, 48) = 4.12, p = 0.047. Follow-up tests showed that the adventure-based program resulted in significantly higher physical fitness scores in older children compared to the traditional program, but there was no significant difference in younger children.”\n\n\n\n\nYou should run a Within-subjects Two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and the levels of these independent variables are the same for all participants, but are manipulated within each participant.\nAn example related to motor skill learning could be comparing the effect of two different types of feedback (e.g. verbal vs. visual) on the learning of a new motor skill (e.g. throwing a ball) in a group of participants. In this example, the independent variables would be the type of feedback and the time of testing (e.g. pre-test and post-test), and the dependent variable would be the accuracy of the throwing skill. The levels of the independent variables would be the same for all participants, as each participant would receive both types of feedback and be tested both before and after training. A Within-subjects Two-way ANOVA would allow you to test for any interactions between the two independent variables (i.e. whether the effect of feedback on motor skill learning is different at the pre-test vs. the post-test) and any main effects of each independent variable on the dependent variable.\n\n\nThe assumptions of the within-subjects two-way ANOVA (also known as a repeated-measures ANOVA) include:\n\nIndependence: The observations within each cell of the design must be independent of one another.\nNormality: The observations within each cell should be approximately normally distributed.\nEqual variances: The variances of the observations within each cell should be approximately equal.\nSphericity: The variances of the differences between the observations for each condition should be approximately equal across the levels of the other independent variable. This assumption is often tested using Mauchly’s test.\nNo carryover effects: There should be no carryover effects from one level of one independent variable to the next level of the same independent variable.\nNo missing data: There should be no missing data in the dataset.\n\nIt is important to note that when the assumptions of the within-subjects two-way ANOVA are not met, the results may not be reliable and alternative methods such as mixed-design ANOVA or non-parametric methods may be needed.\n\n\n\nWhen reporting the results of a within-subjects Two-way ANOVA, you should first indicate the dependent variable, the independent variables and the levels of each independent variable. You should then report the main effect of each independent variable on the dependent variable, as well as any interaction effects between the independent variables.\nFor example, if you were studying the effect of two different types of practice schedules (random vs. blocked) and two different types of feedback (verbal vs. visual) on motor skill learning, your report would look something like this:\nDependent variable: Motor skill learning Independent variables: Practice schedule (random vs. blocked) and feedback (verbal vs. visual)\nMain Effects:\n\nPractice schedule: There was a significant main effect of practice schedule on motor skill learning, F(1,24) = 7.32, p = .012, ηp² = .234, such that participants who practiced in a random schedule showed better motor skill learning than those who practiced in a blocked schedule.\nFeedback: There was a significant main effect of feedback on motor skill learning, F(1,24) = 4.56, p = .045, ηp² = .158, such that participants who received visual feedback showed better motor skill learning than those who received verbal feedback.\n\nInteraction Effects:\n\nThere was no significant interaction between practice schedule and feedback on motor skill learning, F(1,24) = .21, p = .65, ηp² = .009.\n\nIt is worth noting that p values less than 0.05 would be considered statistically significant, and ηp² indicates the effect size of the interaction effects.\nIt is also important to report the means and standard deviations of the dependent variable within each level of the independent variables. This will give a more detailed understanding of the pattern of results.\n\n\n\n\n\n\nYou should run a mixed-factors two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and one of the independent variables is a between-subjects variable and the other is a within-subjects variable.\nA mixed-factors two-way ANOVA is useful when you want to examine the effect of a manipulation that varies within subjects (e.g. different levels of a treatment) while also taking into account individual differences among participants (e.g. gender, age, etc.).\nAn example of when to run a mixed-factors two-way ANOVA would be if you wanted to investigate the effect of two different types of exercise programs (e.g. resistance training vs. cardio) on muscle mass gain in two different age groups (e.g. older adults vs. younger adults) but the program is applied to the same group of people. In this example, the independent variables would be the type of exercise program (between-subjects) and the age group (within-subjects) and the dependent variable would be muscle mass gain.\nA mixed-factors two-way ANOVA would allow you to test for any interactions between the two independent variables, and any main effects of each independent variable on the dependent variable, while also taking into account the individual differences among participants.\n\n\n\nThe assumptions of the mixed-factors two-way ANOVA (also known as a mixed-design two-way ANOVA) include:\n\nIndependence of observations: Each participant’s response should be independent of the responses of other participants.\nNormality: The residuals (the difference between the observed and predicted values) should be approximately normally distributed.\nEqual variances: The variances of the residuals should be equal across all levels of the independent variables.\nSphericity: The variances of the differences between the levels of the within-subjects variable should be equal.\nLinearity: The relationship between the independent and dependent variables should be linear.\nAdditivity: The effect of each independent variable should be additive, meaning that the effect of one variable should not depend on the level of the other variable.\n\nIt’s important to note that the violation of these assumptions can lead to inaccurate results, therefore, it’s important to check them by using various graphical methods, like box plots, histograms and Q-Q plots, and statistical methods like Shapiro-Wilk test, Levene’s test, and Mauchly’s test.\n\n\n\nWhen reporting the results of a mixed-factors Two-way ANOVA, you should include the following information:\n\nA description of the study design, including the independent variables, dependent variable, and the levels of each independent variable. Specify which variable is the within-subject variable and which one is the between-subject variable.\nThe results of the ANOVA, including the F-value, degrees of freedom, and p-value for each independent variable and any interaction between the two independent variables.\nA summary of the main findings, including any significant main effects or interactions between the independent variables.\nFollow-up tests, such as post-hoc tests, to determine which specific levels of the independent variables were responsible for the significant effects.\n\nExample:\n“The study aimed to examine the effect of two different types of motor development programs (e.g. traditional vs. adventure-based) on balance skills in two different age groups (e.g. preschool children vs. school-aged children). A mixed-factors Two-way ANOVA was conducted, with the independent variables being time (within-subject variable) and the age group (between-subject variable) and the dependent variable being balance skills. The results of the ANOVA showed a significant main effect of time, F (1, 48) = 8.32, p = 0.006, with post-test resulting in higher balance skills scores than pretest. A significant interaction was also found between time and the age group, F (1, 48) = 4.12, p = 0.047. Follow-up tests showed that post-test resulted in significantly higher balance skills scores in preschool children compared to pre-test, but there was no significant difference in school-aged children.”\nIt is important to note that in a mixed-factors ANOVA, the assumptions of normality and equal variances are tested at each level of the within-subject variable separately.\n\n\n\n\nThe Pearson correlation coefficient (r) is used to measure the strength and direction of the linear relationship between two continuous variables. It is appropriate to use when you want to determine if there is a linear relationship between two variables and the data are at least interval level. It is important to note that the Pearson correlation coefficient only measures linear relationships, and it is not appropriate to use if the relationship between the variables is non-linear.\nIt is generally considered appropriate to use the Pearson correlation coefficient when the following conditions are met:\n\nThe data for both variables is continuous (i.e., interval or ratio level).\nBoth variables are normally distributed or the sample size is large enough (n&gt;30)\nThe variables are not categorical\nThe data are free from outliers\nThe relationship between the two variables is believed to be linear\n\nIt’s also worth noting that the Pearson correlation coefficient assumes that there is no causality between the two variables, it just measures the association between them. If you want to establish causality, you should use other statistical techniques such as regression analysis.\n\n\nWhen reporting the results of a Pearson correlation coefficient, it is important to include the following information:\n\nThe correlation coefficient (r) and the associated p-value. The correlation coefficient tells us the strength and direction of the linear relationship between two variables, and the p-value tells us the probability of observing a correlation coefficient as extreme as the one we calculated under the assumption that there is no correlation.\nThe sample size (e.g. the number of observations)\nThe scatter plot of the data with the line of best fit and the equation of that line.\nThe effect size, such as Cohen’s d, which is a measure of the magnitude of the correlation.\n\nExample:\n“A Pearson correlation coefficient was calculated to examine the relationship between hours of sleep and test scores of a group of students. The sample size was 30. The correlation coefficient was 0.75, with a p-value of 0.001. The scatter plot of the data with the line of best fit showing a positive correlation and equation of the line y = 0.5x+50 . The effect size (Cohen’s d) was 0.5, which indicates a moderate effect size.”\n“The results of the Pearson correlation coefficient revealed a statistically significant positive correlation between hours of sleep and test scores of the students (r(28) = 0.75, p = 0.001). The scatter plot of the data with the line of best fit y = 0.5x+50 illustrates the positive correlation. The effect size (d = 0.5) suggests a moderate correlation.”"
  },
  {
    "objectID": "supplemental/stats-tests.html#simple-linear-regression",
    "href": "supplemental/stats-tests.html#simple-linear-regression",
    "title": "Statistical Tests",
    "section": "",
    "text": "Simple linear regression is a statistical method used to model the relationship between two variables, where one variable (called the independent variable or predictor variable) is used to predict the other variable (called the dependent variable or response variable). The relationship between the two variables is assumed to be linear, meaning that the change in the dependent variable is proportional to the change in the independent variable.\nThe goal of simple linear regression is to find the best-fitting line that describes the relationship between the two variables. This line is called the regression line, and it is defined by an equation of the form y = mx + b, where y is the dependent variable, x is the independent variable, m is the slope of the line, and b is the y-intercept of the line.\nTo find the values of m and b that best fit the data, simple linear regression uses a method called least squares regression. This method minimizes the sum of the squared differences between the predicted values of y and the actual values of y for each value of x. The resulting regression line can be used to predict the value of y for any given value of x within the range of the data.\nSimple linear regression is commonly used in many fields, including economics, social sciences, and engineering, to analyze the relationship between two variables and make predictions based on that relationship.\n\n\nTo conduct a hypothesis test in the context of simple linear regression, follow these steps:\n\nState the research question(s) and assess the nature of the variables (continuous, discrete), and identify the dependent (outcome) and independent variables.\nState the null and alternative hypotheses: The null hypothesis (H₀) typically states that there is no relationship between the predictor (independent) variable and the response (dependent) variable, i.e., the slope of the regression line (β₁) is equal to zero. The alternative hypothesis (H₁) states that there is a relationship between the predictor and response variables, i.e., the slope is not equal to zero.\nH₀: β₁ = 0 H₁: β₁ ≠ 0\nCollect data: Gather a sample of paired data points for the predictor and response variables.\nPrepare data (diagnostics): Ensure that the data is appropriate for linear regression (i.e., there is a linear relationship, the residuals are normally distributed, homoscedasticity is present, and extreme outliers are not present).\n\nLinearity:\n\nScatterplot: Create a scatterplot of the response variable against the predictor variable. Visually inspect the plot to determine if the relationship appears to be linear. If the data points form a pattern that roughly resembles a straight line, it suggests a linear relationship. If the pattern is curved, it indicates that the relationship may be nonlinear.\nResidual plot: After fitting the linear regression model, plot the residuals (observed values minus predicted values) against the predictor variable or the predicted values. A random scattering of residuals around the horizontal axis (zero) suggests that the linear model is appropriate. If there is a pattern or trend in the residual plot, it indicates a potential violation of the linearity assumption.\nCorrelation coefficient (Pearson’s r): Calculate the correlation coefficient between the predictor and response variables. Pearson’s r ranges from -1 to 1, with values close to -1 or 1 suggesting a strong linear relationship, and values close to 0 indicating a weak or no linear relationship. While the correlation coefficient can provide information about the strength and direction of the relationship, it doesn’t necessarily imply causation or indicate that a linear regression model is appropriate.\nPartial regression plots (added-variable plots): Partial regression plots can help assess the linearity assumption in multiple regression settings. These plots show the relationship between a response variable and a predictor variable, controlling for the effects of other predictor variables in the model. If the partial regression plots display a linear pattern, it supports the linearity assumption.\n\n\nEstimate the regression coefficients: Using the sample data, calculate the slope (β₁) and the intercept (β₀) of the regression line using the least squares method or another appropriate method.\nCalculate the test statistic: Compute the t-statistic for the hypothesis test using the following formula:\nt = (b₁ - 0) / SE(b₁)\nHere, b₁ is the estimated slope of the regression line, and SE(b₁) is the standard error of the slope.\nDetermine the degrees of freedom: Calculate the degrees of freedom for the t-distribution, which is equal to the number of data points (n) minus the number of estimated parameters (2 for simple linear regression: the slope and the intercept).\ndf = n - 2\nDetermine the critical value or p-value: Based on the chosen significance level (α, usually 0.05), determine the critical t-value from the t-distribution table, or calculate the p-value for the observed t-statistic. The p-value is the probability of observing a t-statistic as extreme or more extreme than the one calculated, assuming the null hypothesis is true.\nMake a decision: Compare the calculated t-statistic to the critical value or the p-value to the significance level:\n\nIf the absolute value of the t-statistic is greater than the critical value, or if the p-value is less than the significance level (p &lt; α), reject the null hypothesis. This suggests that there is a significant relationship between the predictor and response variables.\nIf the absolute value of the t-statistic is less than or equal to the critical value, or if the p-value is greater than or equal to the significance level (p ≥ α), fail to reject the null hypothesis. This suggests that there is no significant relationship between the predictor and response variables.\n\nInterpret the results: Based on the decision made in the previous step, interpret the results in the context of your research question or study. If you rejected the null hypothesis, you can also report the estimated regression coefficients and the coefficient of determination (R²) to describe the strength and direction of the relationship between the predictor and response variables."
  },
  {
    "objectID": "supplemental/stats-tests.html#example",
    "href": "supplemental/stats-tests.html#example",
    "title": "Statistical Tests",
    "section": "",
    "text": "Can VO2max be predicted from BMI?\nVariables:\nV02max: predicted/dependent (continuous)\nBMI: predictor/independent (continuous)\n\n\n\nH₀: β₁ = 0; H₁: β₁ ≠ 0\n\n\n\nThe following variables have been recorded for each individual:\n\nAge (in years)\nGender (1 = Male, 2 = Female)\nResting eart Rate (RHR, in beats per minute)\nVO2 Max (in mL/kg/min)\nBody Mass Index (BMI)\n\nThe dataset can be found here: physical-fitness.csv\n\n\n\n\n\n\n\n\nIf you violate the assumption of equal variance (also known as homoscedasticity) in a simple linear regression, this can have several consequences for your model:\n\nBiased estimates: The estimated coefficients may be biased, which means that they may not accurately reflect the true relationship between the dependent variable and the independent variable.\nInaccurate standard errors: The standard errors of the estimated coefficients may be inaccurate, which means that the confidence intervals and hypothesis tests based on them may be incorrect.\nInvalid hypothesis tests: The F-test and t-tests used to assess the significance of the regression coefficients may not be valid if the assumption of equal variance is violated.\nInefficient estimates: The estimates may be less efficient than they would be under homoscedasticity, which means that you may need a larger sample size to achieve the same level of precision in your estimates.\n\nTo address this issue, you may want to consider using alternative regression techniques that are robust to heteroscedasticity, such as weighted least squares regression or generalized least squares regression. Alternatively, you may want to transform the variables or use nonparametric methods that do not assume equal variance. You can also use diagnostic plots, such as a plot of residuals against predicted values, to identify and correct heteroscedasticity."
  },
  {
    "objectID": "supplemental/stats-tests.html#one-sample-t-test",
    "href": "supplemental/stats-tests.html#one-sample-t-test",
    "title": "Statistical Tests",
    "section": "",
    "text": "\\[\nt = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n\\tag{1}\\]\nwhere:\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu\\) is the population mean\n\\(s\\) is the sample standard deviation\n\\(n\\) is the sample size\n\nIt also can be written as:\n\\[\nt = \\frac{\\bar{x} - \\mu}{s_x/\\sqrt{n}}\n\\tag{2}\\]\nwhere:\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu\\) is the population mean\n\\(s_x\\) is the sample standard deviation\n\\(n\\) is the sample size\n\n\n\nThe one-sample t-test should be run when you have a single sample of data and you want to compare the mean of that sample to a known or hypothesized population mean.\nExample in kinesiology: A kinesiologist wants to know if a new exercise program improves muscle strength in older adults. The kinesiologist recruits a sample of 20 older adults and has them complete the exercise program for 8 weeks. The kinesiologist measures muscle strength using a dynamometer before and after the 8 week program. The kinesiologist wants to know if the mean muscle strength of the sample is significantly different from the population mean muscle strength of older adults (which is hypothesized to be 40 kg). The kinesiologist would run a one-sample t-test to compare the mean muscle strength of the sample (after completing the exercise program) to the hypothesized population mean of 40 kg. If the t-value is significant, the kinesiologist can conclude that the exercise program does improve muscle strength in older adults.\n\n\n\nThe test makes several assumptions about the data:\n\nIndependence: The observations in the sample are independent of one another.\nNormality: The population from which the sample is drawn is normally distributed.\nEqual variances: The population variances of the two groups are equal.\nRandom sampling: The sample is drawn randomly and independently from the population.\nSample size: The sample size is large enough (usually greater than 30) for the Central Limit Theorem to be applied.\n\nIt is important to check these assumptions before running the one-sample t-test to ensure the validity of the test results. In case the sample size is small or the data distribution is not normal, a non-parametric test such as the Wilcoxon signed-rank test should be used instead.\n\n\n\nWhen reporting the results of a one-sample t-test in APA style, you should include the following information:\n\nThe test statistic and the associated degrees of freedom (df). For example: “t(df) = 2.45, p = .03.”\nThe p-value of the test. This should be rounded to two decimal places and reported as a probability (e.g., “p = .03” rather than “p &lt; .05”).\nThe sample size (n). This should be reported as a whole number (e.g., “n = 20”).\nThe mean and standard deviation of the sample. For example: “M = 5.6, SD = 1.2.”\nThe direction of the effect. For example, “The mean score was significantly higher than the hypothesized mean (M = 4.0, t(df) = 2.45, p = .03).”\nAny relevant effect size measures. For example, you might report the Cohen’s d effect size as “d = 0.87.”\n\nIt is also good practice to include a brief description of the research question or hypothesis being tested, as well as a description of the sample and any relevant study variables.\nFor example: “In this study, we tested the hypothesis that the mean score on a memory task would be significantly higher than 4.0. A sample of 20 participants completed the task, with a mean score of 5.6 (SD = 1.2). The one-sample t-test revealed a significant difference, t(df) = 2.45, p = .03, d = 0.87, indicating that the mean score was significantly higher than the hypothesized mean.”\n\n\n\nThe results of the one-sample t test indicated that the mean (M = X, SD = Y) was significantly different from the hypothesized value (t(df) = t-value, p &lt; .05).\nIn a one-sample t test, the mean of the sample was significantly different from the hypothesized mean (t(df) = t-value, p &lt; .05). Specifically, the mean of the sample was X (SD = standard deviation) while the hypothesized mean was Y.\nThe results of the one-sample t test indicated that the mean of the sample (M = X, SD = Y) was significantly different from the hypothesized mean (μ = t) t(df) = t-value, p &lt; .05."
  },
  {
    "objectID": "supplemental/stats-tests.html#independent-samples-t-test",
    "href": "supplemental/stats-tests.html#independent-samples-t-test",
    "title": "Statistical Tests",
    "section": "",
    "text": "The independent-samples t-test should be run when comparing the means of two independent groups. For example, in the field of kinesiology, an independent-samples t-test can be used to compare the muscle strength of a group of individuals who have completed a resistance training program to a group of individuals who have not completed a resistance training program. The independent variable would be whether or not the individual completed the resistance training program and the dependent variable would be muscle strength. The t-test would be used to determine if there is a significant difference in muscle strength between the two groups, indicating that the resistance training program had an effect on muscle strength.\n\n\n\nThe assumptions of the independent-samples t-test include:\n\nNormality: The data should be approximately normally distributed within each group.\nIndependence: The observations in each group should be independent of one another.\nEqual variances: The variances of the two groups should be roughly equal.\nRandom Sampling: The sample of each group should be random and representative of the population.\nEqual sample size: The sample size in each group should be equal or similar.\n\nIt is important to note that not all these assumptions need to be perfectly met for the test to be valid, but the deviations from these assumptions should be small. If the data do not meet these assumptions, the non-parametric version of the independent-samples t-test, such as the Mann-Whitney U test, can be used instead.\n\n\n\nTo report the results of an independent samples t-test in APA style, you should include the following information:\n\nThe type of test that was conducted (e.g., “An independent samples t-test was conducted to compare the mean scores of two groups on a measure of stress.”)\nThe sample size for each group (e.g., “The sample consisted of 20 participants in Group A and 25 participants in Group B.”)\nThe mean and standard deviation for each group (e.g., “The mean score for Group A was M = 3.5, SD = 1.2, and the mean score for Group B was M = 2.8, SD = 0.9.”)\nThe t-value and p-value obtained from the test (e.g., “The t-value was t(43) = 2.3, p = .03, indicating that there was a significant difference between the mean scores of the two groups, with Group A scoring higher than Group B.”)\nThe effect size (e.g., “The effect size for the difference between the two groups was d = .7, indicating a moderate effect.”)\n\nIt is also a good idea to provide a brief interpretation of the results, explaining what they mean in the context of your research question or hypothesis.\nHere is an example of how you might report the results of an independent samples t-test in APA style:\n\n\n\n“An independent samples t-test was conducted to compare the mean scores of two groups on a measure of stress. The sample consisted of 20 participants in Group A and 25 participants in Group B. The mean score for Group A was M = 3.5, SD = 1.2, and the mean score for Group B was M = 2.8, SD = 0.9. The t-value was t(43) = 2.3, p = .03, indicating that there was a significant difference between the mean scores of the two groups, with Group A scoring higher than Group B. The effect size for the difference between the two groups was d = .7, indicating a moderate effect. These results suggest that participants in Group A experienced significantly higher levels of stress than those in Group B.”\n“The purpose of this study was to examine the effect of a new teaching method on student achievement. A sample of 50 students was randomly assigned to either the experimental group, which received the new teaching method, or the control group, which received the traditional teaching method. Student achievement was measured using a standardized test. The results of the independent samples t-test showed that there was a statistically significant difference between the experimental and control groups, t(48) = 2.57, p = .01. The experimental group had a higher mean score on the achievement test than the control group. These findings suggest that the new teaching method was effective in improving student achievement. However, it is important to note that the small sample size and lack of generalizability to other populations are limitations of this study.”"
  },
  {
    "objectID": "supplemental/stats-tests.html#paired-samples-t-test",
    "href": "supplemental/stats-tests.html#paired-samples-t-test",
    "title": "Statistical Tests",
    "section": "",
    "text": "The paired-samples t-test should be run when you have two sets of related (or paired) data that you want to compare. For example, if you want to compare the effectiveness of two different treatments on a group of patients, you would use a paired-samples t-test. This test is also commonly used in pre- and post-test designs, where you want to compare scores before and after an intervention or treatment. Additionally, if you want to compare the mean differences between two groups or conditions, but you want to control for individual differences, you can use a paired-samples t-test.\n\n\n\nThe assumptions of the paired-samples t-test include:\n\nIndependence: The observations within each pair are independent of one another.\nNormality: The differences between the pairs of observations are approximately normally distributed.\nEqual variances: The variances of the differences between the pairs of observations are equal.\nPaired data: The observations are paired, meaning that each individual is measured twice, once before and once after some intervention, or in two different conditions.\nRandom Sampling: The sample being used is selected randomly from the population.\n\nIt’s important to note that violations of these assumptions may lead to inaccurate results, so it’s necessary to check them before applying the test. Checking for normality can be done using a normal probability plot, and checking for equal variances can be done using Levene’s test. The paired sample t-test is sensitive to the violation of normality and equal variances assumptions, thus if the assumptions are not met, there are other options that can be used, such as the Wilcoxon signed-rank test which is a non-parametric version of the paired-samples t-test.\n\n\n\nWhen reporting the results of a paired-samples t-test, it is important to include the following information:\n\nThe test statistic (e.g. t-value) and the associated p-value. The t-value tells us how many standard errors the mean difference is from zero, and the p-value tells us the probability of observing a t-value as extreme as the one we calculated under the assumption that the null hypothesis is true.\nThe sample size (e.g. the number of pairs of observations).\nThe mean difference and the standard deviation of the differences.\nThe effect size, such as Cohen’s d, which is a measure of the magnitude of the difference between the means.\n\nExample:\n“A paired-samples t-test was conducted to compare the pre-test and post-test scores of a group of students. The sample size was 20 pairs of observations. The mean difference between the pre-test and post-test scores was 5.3 (SD = 2.5). The t-value was 3.87, with a p-value of 0.001. The effect size (Cohen’s d) was 0.67, which indicates a moderate effect size.”\n“The results of the paired-samples t-test revealed that there was a statistically significant difference between the pre-test and post-test scores of the students, t(19) = 3.87, p = 0.001. The mean difference was 5.3 (95% CI [3.4, 7.2]), and the effect size (d = 0.67) suggests moderate effect size.”"
  },
  {
    "objectID": "supplemental/stats-tests.html#one-way-anova",
    "href": "supplemental/stats-tests.html#one-way-anova",
    "title": "Statistical Tests",
    "section": "",
    "text": "A one-way ANOVA (Analysis of Variance) is used to test for differences in the mean of a continuous outcome variable across two or more categorical groups. It is used when you have one independent variable (also known as a factor) with two or more levels or groups and one continuous dependent variable.\nIn other words, you should run a one-way ANOVA when:\n\nYou want to compare the means of a continuous outcome variable across two or more groups.\nYou have one independent variable (factor) with two or more levels or groups\nThe dependent variable is continuous\n\nExample: A researcher wants to know if there is a difference in the mean test scores of students who studied using different methods (Method A, Method B, Method C). The researcher collect data on test scores and the method used. The test scores are continuous variable and method of study is categorical variable with 3 levels. So, the researcher can use one-way ANOVA to test for the difference in mean test scores across different method of study.\n\n\n\nThe one-way ANOVA (analysis of variance) makes several assumptions about the data being analyzed:\n\nIndependence: The observations in each group are independent of each other and do not affect the observations in the other groups.\nNormality: The data within each group is normally distributed, or at least approximately normally distributed. This assumption can be checked using normality tests such as the Shapiro-Wilk test.\nEqual variances: The variances of the data within each group are equal. This assumption can be checked using tests such as the Levene’s test.\nRandom sampling: The data are randomly sampled from the population, so that the sample is representative of the population.\n\nViolations of these assumptions can lead to biased or incorrect results. If the assumptions are not met, non-parametric alternatives such as Kruskal-Wallis test could be used.\n\n\n\nWhen reporting the results of a one-way ANOVA, it is important to include the following information:\n\nThe F-value and the associated p-value. The F-value tells us how much variation in the dependent variable is accounted for by the independent variable, and the p-value tells us the probability of observing an F-value as extreme as the one we calculated under the assumption that the null hypothesis is true.\nThe sample size for each group, or the number of observations in each group.\nThe means and standard deviations for each group.\nThe effect size, such as eta-squared (η²) or omega-squared (ω²), which is a measure of the proportion of variance in the dependent variable that is accounted for by the independent variable.\n\nExample:\n“A one-way ANOVA was conducted to compare the scores of three groups of students on a test. The sample size for each group was 10, 10, and 12. The means and standard deviations for each group were: Group 1 = 80 (SD = 5), Group 2 = 75 (SD = 4), Group 3 = 70 (SD = 3). The F-value was 12.5, with a p-value of 0.001. The effect size (η²) was 0.17, which indicates a moderate effect size.”\n“The results of the one-way ANOVA revealed that there was a statistically significant difference between the scores of the three groups of students, F(2, 28) = 12.5, p = 0.001. Post-hoc comparisons revealed that group 1 significantly different from group 2 (p = 0.05) and group 3 (p = 0.001). The mean scores for each group were: Group 1 = 80 (95% CI [78, 82]), Group 2 = 75 (95% CI [73, 77]), Group 3 = 70 (95% CI [69, 72]). The effect size (η² = 0.17) suggests that the independent variable accounted for a moderate proportion of variance in the dependent variable.”"
  },
  {
    "objectID": "supplemental/stats-tests.html#between-subjects-two-way-anova",
    "href": "supplemental/stats-tests.html#between-subjects-two-way-anova",
    "title": "Statistical Tests",
    "section": "",
    "text": "You should run a Between-subjects Two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and the levels of these independent variables are different between groups of participants.\nAn example related to physical activity could be comparing the effect of two different types of exercise programs (e.g. resistance training vs. cardio) on muscle mass gain in two different age groups (e.g. older adults vs. younger adults). In this example, the independent variables would be the type of exercise program and the age group, and the dependent variable would be muscle mass gain. The levels of the independent variables would be different between groups of participants, as the older adults would be in one group and the younger adults would be in another. A Between-subjects Two-way ANOVA would allow you to test for any interactions between the two independent variables (i.e. whether the effect of the exercise program on muscle mass gain is different in older adults vs. younger adults) and any main effects of each independent variable on the dependent variable.\n\n\n\nThe assumptions of the between-subjects two-way ANOVA are as follows:\n\nIndependence: The observations in each group are independent of each other, meaning that the responses of one participant do not affect the responses of another participant.\nNormality: The distribution of the residuals (the difference between the observed and predicted values) is approximately normal. It is important to check the normality assumptions using normality test such as the Shapiro-Wilk test and check for outliers using box plots and histograms.\nEqual variances: The variances of the residuals are equal across all groups and levels of the independent variables. This assumption can be checked using Levene’s test for equality of variances.\nAdditivity: The effect of each independent variable on the dependent variable is additive, meaning that the effect of one independent variable does not depend on the level of the other independent variable.\nLinearity: The relationship between the independent variables and the dependent variable is linear, meaning that a straight line can be used to represent the relationship.\nIndependence of errors: the residuals are independent, meaning that the residuals of one observation are not correlated with the residuals of any other observation.\n\nIt’s important to note that when these assumptions are not met, the results of the ANOVA should be interpreted with caution and alternative methods of analysis should be considered.\n\n\n\nWhen reporting the results of a between-subjects Two-way ANOVA, you should include the following information:\n\nA description of the study design, including the independent variables, dependent variable, and the levels of each independent variable.\nThe results of the ANOVA, including the F-value, degrees of freedom, and p-value for each independent variable and any interaction between the two independent variables.\nA summary of the main findings, including any significant main effects or interactions between the independent variables.\nFollow-up tests, such as post-hoc tests, to determine which specific levels of the independent variables were responsible for the significant effects.\n\nExample:\n“The study aimed to examine the effect of two different types of physical education programs (e.g. traditional vs. adventure-based) on physical fitness in two different age groups (e.g. younger children vs. older children). A between-subjects Two-way ANOVA was conducted, with the independent variables being the type of program and the age group, and the dependent variable being physical fitness. The results of the ANOVA showed a significant main effect of the type of program, F (1, 48) = 8.32, p = 0.006, with the adventure-based program resulting in higher physical fitness scores than the traditional program. A significant interaction was also found between the type of program and the age group, F (1, 48) = 4.12, p = 0.047. Follow-up tests showed that the adventure-based program resulted in significantly higher physical fitness scores in older children compared to the traditional program, but there was no significant difference in younger children.”"
  },
  {
    "objectID": "supplemental/stats-tests.html#within-subjects-two-way-anova",
    "href": "supplemental/stats-tests.html#within-subjects-two-way-anova",
    "title": "Statistical Tests",
    "section": "",
    "text": "You should run a Within-subjects Two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and the levels of these independent variables are the same for all participants, but are manipulated within each participant.\nAn example related to motor skill learning could be comparing the effect of two different types of feedback (e.g. verbal vs. visual) on the learning of a new motor skill (e.g. throwing a ball) in a group of participants. In this example, the independent variables would be the type of feedback and the time of testing (e.g. pre-test and post-test), and the dependent variable would be the accuracy of the throwing skill. The levels of the independent variables would be the same for all participants, as each participant would receive both types of feedback and be tested both before and after training. A Within-subjects Two-way ANOVA would allow you to test for any interactions between the two independent variables (i.e. whether the effect of feedback on motor skill learning is different at the pre-test vs. the post-test) and any main effects of each independent variable on the dependent variable.\n\n\nThe assumptions of the within-subjects two-way ANOVA (also known as a repeated-measures ANOVA) include:\n\nIndependence: The observations within each cell of the design must be independent of one another.\nNormality: The observations within each cell should be approximately normally distributed.\nEqual variances: The variances of the observations within each cell should be approximately equal.\nSphericity: The variances of the differences between the observations for each condition should be approximately equal across the levels of the other independent variable. This assumption is often tested using Mauchly’s test.\nNo carryover effects: There should be no carryover effects from one level of one independent variable to the next level of the same independent variable.\nNo missing data: There should be no missing data in the dataset.\n\nIt is important to note that when the assumptions of the within-subjects two-way ANOVA are not met, the results may not be reliable and alternative methods such as mixed-design ANOVA or non-parametric methods may be needed.\n\n\n\nWhen reporting the results of a within-subjects Two-way ANOVA, you should first indicate the dependent variable, the independent variables and the levels of each independent variable. You should then report the main effect of each independent variable on the dependent variable, as well as any interaction effects between the independent variables.\nFor example, if you were studying the effect of two different types of practice schedules (random vs. blocked) and two different types of feedback (verbal vs. visual) on motor skill learning, your report would look something like this:\nDependent variable: Motor skill learning Independent variables: Practice schedule (random vs. blocked) and feedback (verbal vs. visual)\nMain Effects:\n\nPractice schedule: There was a significant main effect of practice schedule on motor skill learning, F(1,24) = 7.32, p = .012, ηp² = .234, such that participants who practiced in a random schedule showed better motor skill learning than those who practiced in a blocked schedule.\nFeedback: There was a significant main effect of feedback on motor skill learning, F(1,24) = 4.56, p = .045, ηp² = .158, such that participants who received visual feedback showed better motor skill learning than those who received verbal feedback.\n\nInteraction Effects:\n\nThere was no significant interaction between practice schedule and feedback on motor skill learning, F(1,24) = .21, p = .65, ηp² = .009.\n\nIt is worth noting that p values less than 0.05 would be considered statistically significant, and ηp² indicates the effect size of the interaction effects.\nIt is also important to report the means and standard deviations of the dependent variable within each level of the independent variables. This will give a more detailed understanding of the pattern of results."
  },
  {
    "objectID": "supplemental/stats-tests.html#mixed-design-two-way-anova",
    "href": "supplemental/stats-tests.html#mixed-design-two-way-anova",
    "title": "Statistical Tests",
    "section": "",
    "text": "You should run a mixed-factors two-way ANOVA when you have two independent variables (also known as factors) that you want to test the effect of on a dependent variable, and one of the independent variables is a between-subjects variable and the other is a within-subjects variable.\nA mixed-factors two-way ANOVA is useful when you want to examine the effect of a manipulation that varies within subjects (e.g. different levels of a treatment) while also taking into account individual differences among participants (e.g. gender, age, etc.).\nAn example of when to run a mixed-factors two-way ANOVA would be if you wanted to investigate the effect of two different types of exercise programs (e.g. resistance training vs. cardio) on muscle mass gain in two different age groups (e.g. older adults vs. younger adults) but the program is applied to the same group of people. In this example, the independent variables would be the type of exercise program (between-subjects) and the age group (within-subjects) and the dependent variable would be muscle mass gain.\nA mixed-factors two-way ANOVA would allow you to test for any interactions between the two independent variables, and any main effects of each independent variable on the dependent variable, while also taking into account the individual differences among participants.\n\n\n\nThe assumptions of the mixed-factors two-way ANOVA (also known as a mixed-design two-way ANOVA) include:\n\nIndependence of observations: Each participant’s response should be independent of the responses of other participants.\nNormality: The residuals (the difference between the observed and predicted values) should be approximately normally distributed.\nEqual variances: The variances of the residuals should be equal across all levels of the independent variables.\nSphericity: The variances of the differences between the levels of the within-subjects variable should be equal.\nLinearity: The relationship between the independent and dependent variables should be linear.\nAdditivity: The effect of each independent variable should be additive, meaning that the effect of one variable should not depend on the level of the other variable.\n\nIt’s important to note that the violation of these assumptions can lead to inaccurate results, therefore, it’s important to check them by using various graphical methods, like box plots, histograms and Q-Q plots, and statistical methods like Shapiro-Wilk test, Levene’s test, and Mauchly’s test.\n\n\n\nWhen reporting the results of a mixed-factors Two-way ANOVA, you should include the following information:\n\nA description of the study design, including the independent variables, dependent variable, and the levels of each independent variable. Specify which variable is the within-subject variable and which one is the between-subject variable.\nThe results of the ANOVA, including the F-value, degrees of freedom, and p-value for each independent variable and any interaction between the two independent variables.\nA summary of the main findings, including any significant main effects or interactions between the independent variables.\nFollow-up tests, such as post-hoc tests, to determine which specific levels of the independent variables were responsible for the significant effects.\n\nExample:\n“The study aimed to examine the effect of two different types of motor development programs (e.g. traditional vs. adventure-based) on balance skills in two different age groups (e.g. preschool children vs. school-aged children). A mixed-factors Two-way ANOVA was conducted, with the independent variables being time (within-subject variable) and the age group (between-subject variable) and the dependent variable being balance skills. The results of the ANOVA showed a significant main effect of time, F (1, 48) = 8.32, p = 0.006, with post-test resulting in higher balance skills scores than pretest. A significant interaction was also found between time and the age group, F (1, 48) = 4.12, p = 0.047. Follow-up tests showed that post-test resulted in significantly higher balance skills scores in preschool children compared to pre-test, but there was no significant difference in school-aged children.”\nIt is important to note that in a mixed-factors ANOVA, the assumptions of normality and equal variances are tested at each level of the within-subject variable separately."
  },
  {
    "objectID": "supplemental/stats-tests.html#pearson-correlation-coefficient",
    "href": "supplemental/stats-tests.html#pearson-correlation-coefficient",
    "title": "Statistical Tests",
    "section": "",
    "text": "The Pearson correlation coefficient (r) is used to measure the strength and direction of the linear relationship between two continuous variables. It is appropriate to use when you want to determine if there is a linear relationship between two variables and the data are at least interval level. It is important to note that the Pearson correlation coefficient only measures linear relationships, and it is not appropriate to use if the relationship between the variables is non-linear.\nIt is generally considered appropriate to use the Pearson correlation coefficient when the following conditions are met:\n\nThe data for both variables is continuous (i.e., interval or ratio level).\nBoth variables are normally distributed or the sample size is large enough (n&gt;30)\nThe variables are not categorical\nThe data are free from outliers\nThe relationship between the two variables is believed to be linear\n\nIt’s also worth noting that the Pearson correlation coefficient assumes that there is no causality between the two variables, it just measures the association between them. If you want to establish causality, you should use other statistical techniques such as regression analysis.\n\n\nWhen reporting the results of a Pearson correlation coefficient, it is important to include the following information:\n\nThe correlation coefficient (r) and the associated p-value. The correlation coefficient tells us the strength and direction of the linear relationship between two variables, and the p-value tells us the probability of observing a correlation coefficient as extreme as the one we calculated under the assumption that there is no correlation.\nThe sample size (e.g. the number of observations)\nThe scatter plot of the data with the line of best fit and the equation of that line.\nThe effect size, such as Cohen’s d, which is a measure of the magnitude of the correlation.\n\nExample:\n“A Pearson correlation coefficient was calculated to examine the relationship between hours of sleep and test scores of a group of students. The sample size was 30. The correlation coefficient was 0.75, with a p-value of 0.001. The scatter plot of the data with the line of best fit showing a positive correlation and equation of the line y = 0.5x+50 . The effect size (Cohen’s d) was 0.5, which indicates a moderate effect size.”\n“The results of the Pearson correlation coefficient revealed a statistically significant positive correlation between hours of sleep and test scores of the students (r(28) = 0.75, p = 0.001). The scatter plot of the data with the line of best fit y = 0.5x+50 illustrates the positive correlation. The effect size (d = 0.5) suggests a moderate correlation.”"
  },
  {
    "objectID": "supplemental/stats-tests.html#wilcoxon-signed-rank",
    "href": "supplemental/stats-tests.html#wilcoxon-signed-rank",
    "title": "Statistical Tests",
    "section": "Wilcoxon signed-rank",
    "text": "Wilcoxon signed-rank\nThe Wilcoxon signed-rank test is a non-parametric test used to determine whether two related samples have the same median. It is used when the data do not meet the assumptions of a parametric test such as the t-test, such as when the data are not normally distributed or the sample size is small. The Wilcoxon signed-rank test is a good alternative to the t-test for comparing two related samples.\nYou should run the Wilcoxon signed-rank test when:\n\nYou have two related samples (e.g. pre-test and post-test scores for the same individuals)\nThe data are not normally distributed\nThe sample size is small\nYou want to compare the median of two related samples\n\nAn example of when you would use the Wilcoxon signed-rank test would be if you were studying the effectiveness of a new treatment for a medical condition, and you collected pre-treatment and post-treatment scores for a small group of patients. Since the sample size is small, and the distribution of scores is not normal, you would use the Wilcoxon signed-rank test to compare the median pre-treatment and post-treatment scores and determine if there was a significant difference between them.\n\nAssumptions\nIt is a robust test and doesn’t require the assumptions of normality, equal variances and large sample size that parametric tests like t-test require.\nThe Wilcoxon signed-rank test assumes the following:\n\nThe data are ordinal or continuous, not categorical.\nThe two samples being compared are related or dependent, meaning that the observations in one sample correspond to the observations in the other sample in some meaningful way.\nThe data are at least ordinal, it doesn’t assume normality.\nThe data are independent and randomly selected from the population.\nThe observations in the two samples should be continuous or ordinal, not categorical.\nThe data should be free of outliers, as they can have a large impact on the test results.\n\nIt is important to note that the Wilcoxon signed-rank test is a non-parametric test, so it is less powerful than a t-test and a parametric test. Therefore, it is advisable to use the Wilcoxon signed-rank test only when the assumptions of the t-test are not met.\n\n\nReporting Results\nWhen reporting the results of a Wilcoxon signed-rank test, you should include the following information:\n\nA description of the study design, including the dependent variable and the groups being compared.\nThe results of the test, including the test statistic (e.g. W) and the p-value.\nA summary of the main findings, including whether the difference between the groups is statistically significant.\nThe effect size, such as Cohen’s d or r, to indicate the magnitude of the difference between the groups.\n\nExample:\n“The study aimed to examine the effect of a physical therapy intervention on pain levels in patients with knee osteoarthritis. A Wilcoxon signed-rank test was conducted to compare the pain levels before and after the intervention. The results of the test showed a significant decrease in pain levels after the intervention, W = 45, p = 0.03. The effect size was r = 0.5, indicating a moderate effect size. This suggests that the physical therapy intervention was effective in reducing pain levels in patients with knee osteoarthritis.”\nIt is important to note that the Wilcoxon signed-rank test is a non-parametric test that is used when the data are not normally distributed or the sample size is small. This test is used to compare two related samples or matched-pairs data."
  },
  {
    "objectID": "supplemental/stats-tests.html#mann-whitney-u-test",
    "href": "supplemental/stats-tests.html#mann-whitney-u-test",
    "title": "Statistical Tests",
    "section": "Mann-Whitney U test",
    "text": "Mann-Whitney U test\nThe Mann-Whitney U test is a non-parametric test that is used to compare two independent groups to determine whether there is a significant difference in the distribution of scores between the two groups. This test is used when the assumptions of a parametric test such as the independent t-test cannot be met. These assumptions include normality of the data and equal variances between groups.\n\n\nThe Mann-Whitney U test is equivalent to the Independent-Samples t-test.\nThe Mann-Whitney U test is particularly useful when the data are not normally distributed, when the sample size is small, or when the data have outliers. It is also used when the data are ordinal or non-normally distributed, and when the variances of the two groups are not equal.\nAn example of when to run the Mann-Whitney U test is when you want to compare the muscle mass gain of two groups of athletes, one group using a new supplement, and the other using a placebo. The muscle mass gain is measured in kilograms and the sample size is small(less than 30), thus, it would be appropriate to use the Mann-Whitney U test to determine if there is a significant difference in muscle mass gain between the two groups.\n\nAssumptions\nThe Mann-Whitney U test is a non-parametric test that is used to compare the medians of two independent groups. In order for the test to be valid, the following assumptions must be met:\n\nIndependence: The observations in each group must be independent of one another. This means that there should be no relationship between the observations within a group.\nOrdinal or continuous data: The data must be ordinal or continuous in nature. The Mann-Whitney U test cannot be used for categorical or discrete data.\nNo ties: There should be no ties in the data. Ties occur when two or more observations have the same value.\nNo outliers: The data should not contain outliers. Outliers are observations that are far away from the rest of the data and can have a strong impact on the results of the test.\nNo normal distribution: The data do not need to follow a normal distribution, which makes the test a good option when dealing with non-normal data.\nSame population : The two groups being compared should be sampled from the same population.\n\nIt is important to check for these assumptions before running the test and report the results accordingly.\n\n\nReporting results\nWhen reporting the results of a Mann-Whitney U test, you should include the following information:\n\nA brief description of the test and its purpose.\nThe test statistic (U) and the p-value.\nA statement about the outcome of the test, such as whether the null hypothesis was rejected or not.\nA summary of the main findings, such as the differences in the two groups being compared.\nA visual representation of the data, such as box plots or histograms, to help users understand the results.\n\nExample:\n“Mann-Whitney U Test\nPurpose: To compare the differences in physical activity levels between two groups of individuals (e.g. active vs. sedentary).\nTest statistic: U = 50\np-value: 0.03\nOutcome: The null hypothesis is rejected.\nFindings: The active group had significantly higher physical activity levels than the sedentary group.\nVisual representation: A box plot is shown to help the user understand the distribution of physical activity levels in the two groups. The active group has a higher median value and a smaller interquartile range than the sedentary group.”\nIt is important to note that the Mann-Whitney U test is a non-parametric test that is used to compare two independent samples when the data are not normally distributed. This test is also useful to compare two groups when the sample size is small."
  },
  {
    "objectID": "supplemental/stats-tests.html#spearman-rho-correlation-coefficient",
    "href": "supplemental/stats-tests.html#spearman-rho-correlation-coefficient",
    "title": "Statistical Tests",
    "section": "Spearman Rho Correlation Coefficient",
    "text": "Spearman Rho Correlation Coefficient\n\nWhen to use it?\nThe Spearman rank-order correlation coefficient (Spearman’s rho, or simply rho) is a nonparametric measure of the correlation between two variables. It is used when the assumptions of the Pearson correlation coefficient, such as normality of the data, are not met, or when the variables are ordinal or interval with non-linear relationship.\nSpearman’s rho should be used when your data are ordinal or interval and non-normally distributed. Or when you suspect that the relationship between the two variables is non-linear.\nIt’s also useful when your data have outliers or extreme values as it is less affected by them compared to Pearson correlation coefficient.\nIt’s also useful when you want to investigate the correlation between two ordinal variables, or when you want to investigate the correlation between an ordinal variable and an interval variable.\nKeep in mind that, Spearman’s rho assumes that the relationship between the two variables is monotonic, it does not test for linearity.\n\n\nReporting results\nWhen reporting the results of a Spearman’s rank correlation coefficient (rho), it is important to include the following information:\n\nThe correlation coefficient (rho) and the associated p-value. The correlation coefficient tells us the strength and direction of the monotonic relationship between two variables, and the p-value tells us the probability of observing a correlation coefficient as extreme as the one we calculated under the assumption that there is no correlation.\nThe sample size (e.g. the number of observations)\nA scatter plot of the data with the line of best fit if possible\nThe effect size, such as Cohen’s d, which is a measure of the magnitude of the correlation.\n\nExample:\n“A Spearman’s rank correlation coefficient was calculated to examine the relationship between blood pressure and weight of a group of patients. The sample size was 40. The correlation coefficient was 0.6, with a p-value of 0.001. The scatter plot of the data with the line of best fit showing a positive correlation. The effect size (Cohen’s d) was 0.3, which indicates a weak effect size.”\n“The results of the Spearman’s rank correlation coefficient revealed a statistically significant positive correlation between blood pressure and weight of the patients (rho(38) = 0.6, p = 0.001). The scatter plot of the data with the line of best fit illustrates the positive correlation. The effect size (d = 0.3) suggests a weak correlation.”\nIt’s important to note that when there is a non-parametric test like spearman correlation, it is better to report the median, percentiles and interquartile range of the variables instead of mean and standard deviation."
  },
  {
    "objectID": "supplemental/terms.html",
    "href": "supplemental/terms.html",
    "title": "Terms and definitions",
    "section": "",
    "text": "Homoscedasticity\nis a term used in statistics to describe a situation where the variance or dispersion of errors or residuals is constant across all levels of a predictor variable. In simpler terms, it means that the spread of data points is consistent throughout the range of values of the independent variable.\nFor example, if we are studying the relationship between the weight of a person and their height, homoscedasticity means that the spread of weight values is consistent for individuals with the same height. This is in contrast to heteroscedasticity, where the spread of data points varies for different levels of the predictor variable.\nHomoscedasticity is an important assumption in many statistical tests, including regression analysis, ANOVA, and t-tests. Violations of homoscedasticity can result in biased or inefficient estimates of parameters, incorrect standard errors, and reduced statistical power. Therefore, it is important to test for homoscedasticity before applying these tests and to use appropriate techniques to correct for heteroscedasticity if it is detected."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html",
    "href": "supplemental/model-diagnostics-matrix.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of the model diagnostics - leverage, standardized residuals, and Cook’s distance. We assume the reader knowledge of the matrix form for multiple linear regression. Please see Matrix Form of Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#introduction",
    "href": "supplemental/model-diagnostics-matrix.html#introduction",
    "title": "Model Diagnostics",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation 1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation 2.\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "href": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "title": "Model Diagnostics",
    "section": "Matrix Form for the Regression Model",
    "text": "Matrix Form for the Regression Model\nWe can represent the Equation 1 and Equation 2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "href": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "title": "Model Diagnostics",
    "section": "Hat Matrix & Leverage",
    "text": "Hat Matrix & Leverage\nRecall from the notes Matrix Form of Linear Regression that \\(\\hat{\\boldsymbol{\\beta}}\\) can be written as the following:\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\n\\tag{5}\\]\nCombining Equation 4 and Equation 5, we can write \\(\\hat{\\mathbf{Y}}\\) as the following:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{Y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n&= \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\\\\n\\end{aligned}\n\\tag{6}\\]\nWe define the hat matrix as an \\(n \\times n\\) matrix of the form \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\). Thus Equation 6 becomes\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{H}\\mathbf{Y}\n\\tag{7}\\]\nThe diagonal elements of the hat matrix are a measure of how far the predictor variables of each observation are from the means of the predictor variables. For example, \\(h_{ii}\\) is a measure of how far the values of the predictor variables for the \\(i^{th}\\) observation, \\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\), are from the mean values of the predictor variables, \\(\\bar{x}_1, \\bar{x}_2, \\ldots, \\bar{x}_p\\). In the case of simple linear regression, the \\(i^{th}\\) diagonal, \\(h_{ii}\\), can be written as\n\\[\nh_{ii} =  \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n}(x_j-\\bar{x})^2}\n\\]\nWe call these diagonal elements, the leverage of each observation.\nThe diagonal elements of the hat matrix have the following properties:\n\n\\(0 \\leq h_ii \\leq 1\\)\n\\(\\sum\\limits_{i=1}^{n} h_{ii} = p+1\\), where \\(p\\) is the number of predictor variables in the model.\nThe mean hat value is \\(\\bar{h} = \\frac{\\sum\\limits_{i=1}^{n} h_{ii}}{n} = \\frac{p+1}{n}\\).\n\nUsing these properties, we consider a point to have high leverage if it has a leverage value that is more than 2 times the average. In other words, observations with leverage greater than \\(\\frac{2(p+1)}{n}\\) are considered to be high leverage points, i.e. outliers in the predictor variables. We are interested in flagging high leverage points, because they may have an influence on the regression coefficients.\nWhen there are high leverage points in the data, the regression line will tend towards those points; therefore, one property of high leverage points is that they tend to have small residuals. We will show this by rewriting the residuals from Equation 4 using Equation 7.\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{Y} - \\hat{\\mathbf{Y}} \\\\[10pt]\n& = \\mathbf{Y} - \\mathbf{H}\\mathbf{Y} \\\\[10pt]\n&= (1-\\mathbf{H})\\mathbf{Y}\n\\end{aligned}\n\\tag{8}\\]\nNote that the identity matrix and hat matrix are idempotent, i.e. \\(\\mathbf{I}\\mathbf{I} = \\mathbf{I}\\), \\(\\mathbf{H}\\mathbf{H} = \\mathbf{H}\\). Thus, \\((\\mathbf{I} - \\mathbf{H})\\) is also idempotent. These matrices are also symmetric. Using these properties and Equation 8, we have that the variance-covariance matrix of the residuals \\(\\boldsymbol{e}\\), is\n\\[\n\\begin{aligned}\nVar(\\mathbf{e}) &= \\mathbf{e}\\mathbf{e}^T \\\\[10pt]\n&=  (1-\\mathbf{H})Var(\\mathbf{Y})^T(1-\\mathbf{H})^T \\\\[10pt]\n&= (1-\\mathbf{H})\\hat{\\sigma}^2(1-\\mathbf{H})^T  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})(1-\\mathbf{H})  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})\n\\end{aligned}\n\\tag{9}\\]\nwhere \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^{n}e_i^2}{n-p-1}\\) is the estimated regression variance. Thus, the variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\hat{\\sigma}^2(1-h_{ii})\\). Therefore, the higher the leverage, the smaller the variance of the residual. Because the expected value of the residuals is 0, we conclude that points with high leverage tend to have smaller residuals than points with lower leverage."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "href": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "title": "Model Diagnostics",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIn general, we standardize a value by shifting by the expected value and rescaling by the standard deviation (or standard error). Thus, the \\(i^{th}\\) standardized residual takes the form\n\\[\nstd.res_i = \\frac{e_i - E(e_i)}{SE(e_i)}\n\\]\nThe expected value of the residuals is 0, i.e. \\(E(e_i) = 0\\). From Equation 9), the standard error of the residual is \\(SE(e_i) = \\hat{\\sigma}\\sqrt{1-h_{ii}}\\). Therefore,\n\\[\nstd.res_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}\n\\tag{10}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "href": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "title": "Model Diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance is a measure of how much each observation influences the model coefficients, and thus the predicted values. The Cook’s distance for the \\(i^{th}\\) observation can be written as\n\\[\nD_i = \\frac{(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})^T(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})}{(p+1)\\hat{\\sigma}}\n\\tag{11}\\]\nwhere \\(\\hat{\\mathbf{Y}}_{(i)}\\) is the vector of predicted values from the model fitted when the \\(i^{th}\\) observation is deleted. Cook’s Distance can be calculated without deleting observations one at a time, since Equation 12 below is mathematically equivalent to Equation 11.\n\\[\nD_i = \\frac{1}{p+1}std.res_i^2\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg] = \\frac{e_i^2}{(p+1)\\hat{\\sigma}^2(1-h_{ii})}\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg]\n\\tag{12}\\]"
  },
  {
    "objectID": "supplemental/log-transformations.html",
    "href": "supplemental/log-transformations.html",
    "title": "Log Transformations in Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides details about the model interpretation when the predictor and/or response variables are log-transformed. For simplicity, we will discuss transformations for the simple linear regression model as shown in Equation 1.\n\\[\n\\label{orig}\ny = \\beta_0 + \\beta_1 x\n\\tag{1}\\]\nAll results and interpretations can be easily extended to transformations in multiple regression models.\nNote: log refers to the natural logarithm."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the response variable",
    "text": "Log-transformation on the response variable\nSuppose we fit a linear regression model with \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(x\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 x, \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(x\\) and \\(\\log(y)\\) using the model in Equation 2.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 x\n\\tag{2}\\]\nIf we interpret the model in terms of \\(\\log(y)\\), then we can use the usual interpretations for slope and intercept. When reporting results, however, it is best to give all interpretations in terms of the original response variable \\(y\\), since interpretations using log-transformed variables are often more difficult to truly understand.\nIn order to get back on the original scale, we need to use the exponential function (also known as the anti-log), \\(\\exp\\{x\\} = e^x\\). Therefore, we use the model in Equation 2 for interpretations and predictions, we will use Equation 3 to state our conclusions in terms of \\(y\\).\n\\[\n\\begin{aligned}\n&\\exp\\{\\log(y)\\} = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\n\\end{aligned}\n\\tag{3}\\]\nIn order to interpret the slope and intercept, we need to first understand the relationship between the mean, median and log transformations.\n\nMean, Median, and Log Transformations\nSuppose we have a dataset y that contains the following observations:\n\n\n[1] 3 5 6 7 8\n\n\nIf we log-transform the values of y then calculate the mean and median, we have\n\n\n\n\n\nmean_log_y\nmedian_log_y\n\n\n\n\n1.70503\n1.79176\n\n\n\n\n\nIf we calculate the mean and median of y, then log-transform the mean and median, we have\n\n\n\n\n\nlog_mean\nlog_median\n\n\n\n\n1.75786\n1.79176\n\n\n\n\n\nThis is a simple illustration to show\n\n\\(\\text{Mean}[{\\log(y)}] \\neq \\log[\\text{Mean}(y)]\\) - the mean and log are not commutable\n\\(\\text{Median}[\\log(y)] = \\log[\\text{Median}(y)]\\) - the median and log are commutable\n\n\n\nInterpretaton of model coefficients\nUsing Equation 2, the mean \\(\\log(y)\\) for any given value of \\(x\\) is \\(\\beta_0 + \\beta_1 x\\); however, this does not indicate that the mean of \\(y = \\exp\\{\\beta_0 + \\beta_1 x\\}\\) (see previous section). From the assumptions of linear regression, we assume that for any given value of \\(x\\), the distribution of \\(\\log(y)\\) is Normal, and therefore symmetric. Thus the median of \\(\\log(y)\\) is equal to the mean of \\(\\log(y)\\), i.e \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x\\).\nSince the log and the median are commutable, \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x \\Rightarrow \\text{Median}(y) = \\exp\\{\\beta_0 + \\beta_1 x\\}\\). Thus, when we log-transform the response variable, the interpretation of the intercept and slope are in terms of the effect on the median of \\(y\\).\nIntercept: The intercept is expected median of \\(y\\) when the predictor variable equals 0. Therefore, when \\(x=0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x=0\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is the expected change in the median of \\(y\\) when \\(x\\) increases by 1 unit. The change in the median of \\(y\\) is\n\\[\n\\exp\\{[\\beta_0 + \\beta_1 (x+1)] - [\\beta_0 + \\beta_1 x]\\} = \\frac{\\exp\\{\\beta_0 + \\beta_1 (x+1)\\}}{\\exp\\{\\beta_0 + \\beta_1 x\\}} = \\frac{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\\exp\\{\\beta_1\\}}{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}} = \\exp\\{\\beta_1\\}\n\\]\nThus, the median of \\(y\\) for \\(x+1\\) is \\(\\exp\\{\\beta_1\\}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) increases by one unit, the median of \\(y\\) is expected to multiply by a factor of \\(\\exp\\{\\beta_1\\}\\)."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the predictor variable",
    "text": "Log-transformation on the predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(y\\), such that \\(y \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(y\\) using the model in #eq-log-x.\n\\[\ny = \\beta_0 + \\beta_1 \\log(x)\n\\tag{4}\\]\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e. \\(x = 1\\).\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the mean of \\(y\\) is expected to be \\(\\beta_0\\).\nSlope: The slope is interpreted in terms of the change in the mean of \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the mean of \\(y\\) is\n\\[\n\\begin{aligned}\n[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)] &= \\beta_1 [\\log(Cx) - \\log(x)] \\\\[10pt]\n& = \\beta_1[\\log(C) + \\log(x) - \\log(x)] \\\\[10pt]\n& = \\beta_1 \\log(C)\n\\end{aligned}\n\\]\nThus the mean of \\(y\\) changes by \\(\\beta_1 \\log(C)\\) units.\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(C)\\) units. For example, if \\(x\\) is doubled, then the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(2)\\) units."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the the response and predictor variable",
    "text": "Log-transformation on the the response and predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable and \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(\\log(y)\\) using the model in Equation 5.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 \\log(x)\n\\tag{5}\\]\nBecause the response variable is log-transformed, the interpretations on the original scale will be in terms of the median of \\(y\\) (see the section on the log-transformed response variable for more detail).\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e. \\(x = 1\\). Therefore, when \\(\\log(x) = 0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is interpreted in terms of the change in the median \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the median of \\(y\\) is\n\\[\n\\begin{aligned}\n\\exp\\{[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)]\\} &=\n\\exp\\{\\beta_1 [\\log(Cx) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1[\\log(C) + \\log(x) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1 \\log(C)\\} = C^{\\beta_1}\n\\end{aligned}\n\\]\nThus, the median of \\(y\\) for \\(Cx\\) is \\(C^{\\beta_1}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the median of \\(y\\) is expected to multiple by a factor of \\(C^{\\beta_1}\\). For example, if \\(x\\) is doubled, then the median of \\(y\\) is expected to multiply by \\(2^{\\beta_1}\\)."
  },
  {
    "objectID": "supplemental/tables.html",
    "href": "supplemental/tables.html",
    "title": "Statistical Tables",
    "section": "",
    "text": "The field of statistics relies heavily on mathematical formulas and calculations to make sense of data. Statistical tables, such as the z-table, t-table, f-table, and Pearson table, are essential tools for statisticians and researchers. These tables provide critical values for different probability distributions, enabling users to perform statistical tests, calculate confidence intervals, and make informed decisions based on data analysis.\n\nz-tableStudent’s tPearson rF-table\n\n\nTo interpret the table containing z-values from 0.00 to 4.00 and their corresponding one-tailed and two-tailed probabilities, follow these steps:\n\nIdentify the type of test: Determine whether you are conducting a one-tailed or two-tailed test. A one-tailed test is used when the direction of the relationship is hypothesized, while a two-tailed test is used when no specific direction is hypothesized.\nLocate the z-value: Calculate the z-value (z) for your data. This is typically obtained through hypothesis testing, such as the z-test or as part of the output of other tests like linear regression.\nFind the probabilities: In the table, locate the row with the z-value closest to the calculated z-value from your data. In that row, you will find the one-tailed and two-tailed probabilities associated with that z-value.\n\nFor one-tailed tests:\n\nThe one-tailed probability represents the probability of observing a value as extreme as the calculated z-value or more extreme in the specified direction, given that the null hypothesis is true.\n\nFor two-tailed tests:\n\nThe two-tailed probability represents the probability of observing a value as extreme as the calculated z-value or more extreme in either direction, given that the null hypothesis is true.\n\n\nCompare the probabilities with the desired significance level (α): The significance level, denoted as α, is the probability of rejecting the null hypothesis when it is true. Commonly used significance levels are 0.05 and 0.01. If the probability from the table is less than or equal to your chosen α, you can reject the null hypothesis, suggesting that there is a significant effect or relationship between the variables under consideration. If the probability is greater than α, you fail to reject the null hypothesis, meaning that there is not enough evidence to suggest a significant effect or relationship between the variables.\n\nKeep in mind that rejecting or failing to reject the null hypothesis does not prove causation, but rather indicates the presence or absence of a significant effect or relationship between the variables under certain assumptions.\nThe values under the one and two-tailed columns represent the area between the Mean and Z (in percent) in the normal distribution.\n\n\n\nProbabilities for z-values from 0.00 to 4.00\n\n\nz_value\none_tailed_probability\ntwo_tailed_probability\n\n\n\n\n0.00\n0.5000\n1.0000\n\n\n0.01\n0.4960\n0.9920\n\n\n0.02\n0.4920\n0.9840\n\n\n0.03\n0.4880\n0.9761\n\n\n0.04\n0.4840\n0.9681\n\n\n0.05\n0.4801\n0.9601\n\n\n0.06\n0.4761\n0.9522\n\n\n0.07\n0.4721\n0.9442\n\n\n0.08\n0.4681\n0.9362\n\n\n0.09\n0.4641\n0.9283\n\n\n0.10\n0.4602\n0.9203\n\n\n0.11\n0.4562\n0.9124\n\n\n0.12\n0.4522\n0.9045\n\n\n0.13\n0.4483\n0.8966\n\n\n0.14\n0.4443\n0.8887\n\n\n0.15\n0.4404\n0.8808\n\n\n0.16\n0.4364\n0.8729\n\n\n0.17\n0.4325\n0.8650\n\n\n0.18\n0.4286\n0.8572\n\n\n0.19\n0.4247\n0.8493\n\n\n0.20\n0.4207\n0.8415\n\n\n0.21\n0.4168\n0.8337\n\n\n0.22\n0.4129\n0.8259\n\n\n0.23\n0.4090\n0.8181\n\n\n0.24\n0.4052\n0.8103\n\n\n0.25\n0.4013\n0.8026\n\n\n0.26\n0.3974\n0.7949\n\n\n0.27\n0.3936\n0.7872\n\n\n0.28\n0.3897\n0.7795\n\n\n0.29\n0.3859\n0.7718\n\n\n0.30\n0.3821\n0.7642\n\n\n0.31\n0.3783\n0.7566\n\n\n0.32\n0.3745\n0.7490\n\n\n0.33\n0.3707\n0.7414\n\n\n0.34\n0.3669\n0.7339\n\n\n0.35\n0.3632\n0.7263\n\n\n0.36\n0.3594\n0.7188\n\n\n0.37\n0.3557\n0.7114\n\n\n0.38\n0.3520\n0.7039\n\n\n0.39\n0.3483\n0.6965\n\n\n0.40\n0.3446\n0.6892\n\n\n0.41\n0.3409\n0.6818\n\n\n0.42\n0.3372\n0.6745\n\n\n0.43\n0.3336\n0.6672\n\n\n0.44\n0.3300\n0.6599\n\n\n0.45\n0.3264\n0.6527\n\n\n0.46\n0.3228\n0.6455\n\n\n0.47\n0.3192\n0.6384\n\n\n0.48\n0.3156\n0.6312\n\n\n0.49\n0.3121\n0.6241\n\n\n0.50\n0.3085\n0.6171\n\n\n0.51\n0.3050\n0.6101\n\n\n0.52\n0.3015\n0.6031\n\n\n0.53\n0.2981\n0.5961\n\n\n0.54\n0.2946\n0.5892\n\n\n0.55\n0.2912\n0.5823\n\n\n0.56\n0.2877\n0.5755\n\n\n0.57\n0.2843\n0.5687\n\n\n0.58\n0.2810\n0.5619\n\n\n0.59\n0.2776\n0.5552\n\n\n0.60\n0.2743\n0.5485\n\n\n0.61\n0.2709\n0.5419\n\n\n0.62\n0.2676\n0.5353\n\n\n0.63\n0.2643\n0.5287\n\n\n0.64\n0.2611\n0.5222\n\n\n0.65\n0.2578\n0.5157\n\n\n0.66\n0.2546\n0.5093\n\n\n0.67\n0.2514\n0.5029\n\n\n0.68\n0.2483\n0.4965\n\n\n0.69\n0.2451\n0.4902\n\n\n0.70\n0.2420\n0.4839\n\n\n0.71\n0.2389\n0.4777\n\n\n0.72\n0.2358\n0.4715\n\n\n0.73\n0.2327\n0.4654\n\n\n0.74\n0.2296\n0.4593\n\n\n0.75\n0.2266\n0.4533\n\n\n0.76\n0.2236\n0.4473\n\n\n0.77\n0.2206\n0.4413\n\n\n0.78\n0.2177\n0.4354\n\n\n0.79\n0.2148\n0.4295\n\n\n0.80\n0.2119\n0.4237\n\n\n0.81\n0.2090\n0.4179\n\n\n0.82\n0.2061\n0.4122\n\n\n0.83\n0.2033\n0.4065\n\n\n0.84\n0.2005\n0.4009\n\n\n0.85\n0.1977\n0.3953\n\n\n0.86\n0.1949\n0.3898\n\n\n0.87\n0.1922\n0.3843\n\n\n0.88\n0.1894\n0.3789\n\n\n0.89\n0.1867\n0.3735\n\n\n0.90\n0.1841\n0.3681\n\n\n0.91\n0.1814\n0.3628\n\n\n0.92\n0.1788\n0.3576\n\n\n0.93\n0.1762\n0.3524\n\n\n0.94\n0.1736\n0.3472\n\n\n0.95\n0.1711\n0.3421\n\n\n0.96\n0.1685\n0.3371\n\n\n0.97\n0.1660\n0.3320\n\n\n0.98\n0.1635\n0.3271\n\n\n0.99\n0.1611\n0.3222\n\n\n1.00\n0.1587\n0.3173\n\n\n1.01\n0.1562\n0.3125\n\n\n1.02\n0.1539\n0.3077\n\n\n1.03\n0.1515\n0.3030\n\n\n1.04\n0.1492\n0.2983\n\n\n1.05\n0.1469\n0.2937\n\n\n1.06\n0.1446\n0.2891\n\n\n1.07\n0.1423\n0.2846\n\n\n1.08\n0.1401\n0.2801\n\n\n1.09\n0.1379\n0.2757\n\n\n1.10\n0.1357\n0.2713\n\n\n1.11\n0.1335\n0.2670\n\n\n1.12\n0.1314\n0.2627\n\n\n1.13\n0.1292\n0.2585\n\n\n1.14\n0.1271\n0.2543\n\n\n1.15\n0.1251\n0.2501\n\n\n1.16\n0.1230\n0.2460\n\n\n1.17\n0.1210\n0.2420\n\n\n1.18\n0.1190\n0.2380\n\n\n1.19\n0.1170\n0.2340\n\n\n1.20\n0.1151\n0.2301\n\n\n1.21\n0.1131\n0.2263\n\n\n1.22\n0.1112\n0.2225\n\n\n1.23\n0.1093\n0.2187\n\n\n1.24\n0.1075\n0.2150\n\n\n1.25\n0.1056\n0.2113\n\n\n1.26\n0.1038\n0.2077\n\n\n1.27\n0.1020\n0.2041\n\n\n1.28\n0.1003\n0.2005\n\n\n1.29\n0.0985\n0.1971\n\n\n1.30\n0.0968\n0.1936\n\n\n1.31\n0.0951\n0.1902\n\n\n1.32\n0.0934\n0.1868\n\n\n1.33\n0.0918\n0.1835\n\n\n1.34\n0.0901\n0.1802\n\n\n1.35\n0.0885\n0.1770\n\n\n1.36\n0.0869\n0.1738\n\n\n1.37\n0.0853\n0.1707\n\n\n1.38\n0.0838\n0.1676\n\n\n1.39\n0.0823\n0.1645\n\n\n1.40\n0.0808\n0.1615\n\n\n1.41\n0.0793\n0.1585\n\n\n1.42\n0.0778\n0.1556\n\n\n1.43\n0.0764\n0.1527\n\n\n1.44\n0.0749\n0.1499\n\n\n1.45\n0.0735\n0.1471\n\n\n1.46\n0.0721\n0.1443\n\n\n1.47\n0.0708\n0.1416\n\n\n1.48\n0.0694\n0.1389\n\n\n1.49\n0.0681\n0.1362\n\n\n1.50\n0.0668\n0.1336\n\n\n1.51\n0.0655\n0.1310\n\n\n1.52\n0.0643\n0.1285\n\n\n1.53\n0.0630\n0.1260\n\n\n1.54\n0.0618\n0.1236\n\n\n1.55\n0.0606\n0.1211\n\n\n1.56\n0.0594\n0.1188\n\n\n1.57\n0.0582\n0.1164\n\n\n1.58\n0.0571\n0.1141\n\n\n1.59\n0.0559\n0.1118\n\n\n1.60\n0.0548\n0.1096\n\n\n1.61\n0.0537\n0.1074\n\n\n1.62\n0.0526\n0.1052\n\n\n1.63\n0.0516\n0.1031\n\n\n1.64\n0.0505\n0.1010\n\n\n1.65\n0.0495\n0.0989\n\n\n1.66\n0.0485\n0.0969\n\n\n1.67\n0.0475\n0.0949\n\n\n1.68\n0.0465\n0.0930\n\n\n1.69\n0.0455\n0.0910\n\n\n1.70\n0.0446\n0.0891\n\n\n1.71\n0.0436\n0.0873\n\n\n1.72\n0.0427\n0.0854\n\n\n1.73\n0.0418\n0.0836\n\n\n1.74\n0.0409\n0.0819\n\n\n1.75\n0.0401\n0.0801\n\n\n1.76\n0.0392\n0.0784\n\n\n1.77\n0.0384\n0.0767\n\n\n1.78\n0.0375\n0.0751\n\n\n1.79\n0.0367\n0.0735\n\n\n1.80\n0.0359\n0.0719\n\n\n1.81\n0.0351\n0.0703\n\n\n1.82\n0.0344\n0.0688\n\n\n1.83\n0.0336\n0.0672\n\n\n1.84\n0.0329\n0.0658\n\n\n1.85\n0.0322\n0.0643\n\n\n1.86\n0.0314\n0.0629\n\n\n1.87\n0.0307\n0.0615\n\n\n1.88\n0.0301\n0.0601\n\n\n1.89\n0.0294\n0.0588\n\n\n1.90\n0.0287\n0.0574\n\n\n1.91\n0.0281\n0.0561\n\n\n1.92\n0.0274\n0.0549\n\n\n1.93\n0.0268\n0.0536\n\n\n1.94\n0.0262\n0.0524\n\n\n1.95\n0.0256\n0.0512\n\n\n1.96\n0.0250\n0.0500\n\n\n1.97\n0.0244\n0.0488\n\n\n1.98\n0.0239\n0.0477\n\n\n1.99\n0.0233\n0.0466\n\n\n2.00\n0.0228\n0.0455\n\n\n2.01\n0.0222\n0.0444\n\n\n2.02\n0.0217\n0.0434\n\n\n2.03\n0.0212\n0.0424\n\n\n2.04\n0.0207\n0.0414\n\n\n2.05\n0.0202\n0.0404\n\n\n2.06\n0.0197\n0.0394\n\n\n2.07\n0.0192\n0.0385\n\n\n2.08\n0.0188\n0.0375\n\n\n2.09\n0.0183\n0.0366\n\n\n2.10\n0.0179\n0.0357\n\n\n2.11\n0.0174\n0.0349\n\n\n2.12\n0.0170\n0.0340\n\n\n2.13\n0.0166\n0.0332\n\n\n2.14\n0.0162\n0.0324\n\n\n2.15\n0.0158\n0.0316\n\n\n2.16\n0.0154\n0.0308\n\n\n2.17\n0.0150\n0.0300\n\n\n2.18\n0.0146\n0.0293\n\n\n2.19\n0.0143\n0.0285\n\n\n2.20\n0.0139\n0.0278\n\n\n2.21\n0.0136\n0.0271\n\n\n2.22\n0.0132\n0.0264\n\n\n2.23\n0.0129\n0.0257\n\n\n2.24\n0.0125\n0.0251\n\n\n2.25\n0.0122\n0.0244\n\n\n2.26\n0.0119\n0.0238\n\n\n2.27\n0.0116\n0.0232\n\n\n2.28\n0.0113\n0.0226\n\n\n2.29\n0.0110\n0.0220\n\n\n2.30\n0.0107\n0.0214\n\n\n2.31\n0.0104\n0.0209\n\n\n2.32\n0.0102\n0.0203\n\n\n2.33\n0.0099\n0.0198\n\n\n2.34\n0.0096\n0.0193\n\n\n2.35\n0.0094\n0.0188\n\n\n2.36\n0.0091\n0.0183\n\n\n2.37\n0.0089\n0.0178\n\n\n2.38\n0.0087\n0.0173\n\n\n2.39\n0.0084\n0.0168\n\n\n2.40\n0.0082\n0.0164\n\n\n2.41\n0.0080\n0.0160\n\n\n2.42\n0.0078\n0.0155\n\n\n2.43\n0.0075\n0.0151\n\n\n2.44\n0.0073\n0.0147\n\n\n2.45\n0.0071\n0.0143\n\n\n2.46\n0.0069\n0.0139\n\n\n2.47\n0.0068\n0.0135\n\n\n2.48\n0.0066\n0.0131\n\n\n2.49\n0.0064\n0.0128\n\n\n2.50\n0.0062\n0.0124\n\n\n2.51\n0.0060\n0.0121\n\n\n2.52\n0.0059\n0.0117\n\n\n2.53\n0.0057\n0.0114\n\n\n2.54\n0.0055\n0.0111\n\n\n2.55\n0.0054\n0.0108\n\n\n2.56\n0.0052\n0.0105\n\n\n2.57\n0.0051\n0.0102\n\n\n2.58\n0.0049\n0.0099\n\n\n2.59\n0.0048\n0.0096\n\n\n2.60\n0.0047\n0.0093\n\n\n2.61\n0.0045\n0.0091\n\n\n2.62\n0.0044\n0.0088\n\n\n2.63\n0.0043\n0.0085\n\n\n2.64\n0.0041\n0.0083\n\n\n2.65\n0.0040\n0.0080\n\n\n2.66\n0.0039\n0.0078\n\n\n2.67\n0.0038\n0.0076\n\n\n2.68\n0.0037\n0.0074\n\n\n2.69\n0.0036\n0.0071\n\n\n2.70\n0.0035\n0.0069\n\n\n2.71\n0.0034\n0.0067\n\n\n2.72\n0.0033\n0.0065\n\n\n2.73\n0.0032\n0.0063\n\n\n2.74\n0.0031\n0.0061\n\n\n2.75\n0.0030\n0.0060\n\n\n2.76\n0.0029\n0.0058\n\n\n2.77\n0.0028\n0.0056\n\n\n2.78\n0.0027\n0.0054\n\n\n2.79\n0.0026\n0.0053\n\n\n2.80\n0.0026\n0.0051\n\n\n2.81\n0.0025\n0.0050\n\n\n2.82\n0.0024\n0.0048\n\n\n2.83\n0.0023\n0.0047\n\n\n2.84\n0.0023\n0.0045\n\n\n2.85\n0.0022\n0.0044\n\n\n2.86\n0.0021\n0.0042\n\n\n2.87\n0.0021\n0.0041\n\n\n2.88\n0.0020\n0.0040\n\n\n2.89\n0.0019\n0.0039\n\n\n2.90\n0.0019\n0.0037\n\n\n2.91\n0.0018\n0.0036\n\n\n2.92\n0.0018\n0.0035\n\n\n2.93\n0.0017\n0.0034\n\n\n2.94\n0.0016\n0.0033\n\n\n2.95\n0.0016\n0.0032\n\n\n2.96\n0.0015\n0.0031\n\n\n2.97\n0.0015\n0.0030\n\n\n2.98\n0.0014\n0.0029\n\n\n2.99\n0.0014\n0.0028\n\n\n3.00\n0.0013\n0.0027\n\n\n3.01\n0.0013\n0.0026\n\n\n3.02\n0.0013\n0.0025\n\n\n3.03\n0.0012\n0.0024\n\n\n3.04\n0.0012\n0.0024\n\n\n3.05\n0.0011\n0.0023\n\n\n3.06\n0.0011\n0.0022\n\n\n3.07\n0.0011\n0.0021\n\n\n3.08\n0.0010\n0.0021\n\n\n3.09\n0.0010\n0.0020\n\n\n3.10\n0.0010\n0.0019\n\n\n3.11\n0.0009\n0.0019\n\n\n3.12\n0.0009\n0.0018\n\n\n3.13\n0.0009\n0.0017\n\n\n3.14\n0.0008\n0.0017\n\n\n3.15\n0.0008\n0.0016\n\n\n3.16\n0.0008\n0.0016\n\n\n3.17\n0.0008\n0.0015\n\n\n3.18\n0.0007\n0.0015\n\n\n3.19\n0.0007\n0.0014\n\n\n3.20\n0.0007\n0.0014\n\n\n3.21\n0.0007\n0.0013\n\n\n3.22\n0.0006\n0.0013\n\n\n3.23\n0.0006\n0.0012\n\n\n3.24\n0.0006\n0.0012\n\n\n3.25\n0.0006\n0.0012\n\n\n3.26\n0.0006\n0.0011\n\n\n3.27\n0.0005\n0.0011\n\n\n3.28\n0.0005\n0.0010\n\n\n3.29\n0.0005\n0.0010\n\n\n3.30\n0.0005\n0.0010\n\n\n3.31\n0.0005\n0.0009\n\n\n3.32\n0.0005\n0.0009\n\n\n3.33\n0.0004\n0.0009\n\n\n3.34\n0.0004\n0.0008\n\n\n3.35\n0.0004\n0.0008\n\n\n3.36\n0.0004\n0.0008\n\n\n3.37\n0.0004\n0.0008\n\n\n3.38\n0.0004\n0.0007\n\n\n3.39\n0.0003\n0.0007\n\n\n3.40\n0.0003\n0.0007\n\n\n3.41\n0.0003\n0.0006\n\n\n3.42\n0.0003\n0.0006\n\n\n3.43\n0.0003\n0.0006\n\n\n3.44\n0.0003\n0.0006\n\n\n3.45\n0.0003\n0.0006\n\n\n3.46\n0.0003\n0.0005\n\n\n3.47\n0.0003\n0.0005\n\n\n3.48\n0.0003\n0.0005\n\n\n3.49\n0.0002\n0.0005\n\n\n3.50\n0.0002\n0.0005\n\n\n3.51\n0.0002\n0.0004\n\n\n3.52\n0.0002\n0.0004\n\n\n3.53\n0.0002\n0.0004\n\n\n3.54\n0.0002\n0.0004\n\n\n3.55\n0.0002\n0.0004\n\n\n3.56\n0.0002\n0.0004\n\n\n3.57\n0.0002\n0.0004\n\n\n3.58\n0.0002\n0.0003\n\n\n3.59\n0.0002\n0.0003\n\n\n3.60\n0.0002\n0.0003\n\n\n3.61\n0.0002\n0.0003\n\n\n3.62\n0.0001\n0.0003\n\n\n3.63\n0.0001\n0.0003\n\n\n3.64\n0.0001\n0.0003\n\n\n3.65\n0.0001\n0.0003\n\n\n3.66\n0.0001\n0.0003\n\n\n3.67\n0.0001\n0.0002\n\n\n3.68\n0.0001\n0.0002\n\n\n3.69\n0.0001\n0.0002\n\n\n3.70\n0.0001\n0.0002\n\n\n3.71\n0.0001\n0.0002\n\n\n3.72\n0.0001\n0.0002\n\n\n3.73\n0.0001\n0.0002\n\n\n3.74\n0.0001\n0.0002\n\n\n3.75\n0.0001\n0.0002\n\n\n3.76\n0.0001\n0.0002\n\n\n3.77\n0.0001\n0.0002\n\n\n3.78\n0.0001\n0.0002\n\n\n3.79\n0.0001\n0.0002\n\n\n3.80\n0.0001\n0.0001\n\n\n3.81\n0.0001\n0.0001\n\n\n3.82\n0.0001\n0.0001\n\n\n3.83\n0.0001\n0.0001\n\n\n3.84\n0.0001\n0.0001\n\n\n3.85\n0.0001\n0.0001\n\n\n3.86\n0.0001\n0.0001\n\n\n3.87\n0.0001\n0.0001\n\n\n3.88\n0.0001\n0.0001\n\n\n3.89\n0.0001\n0.0001\n\n\n3.90\n0.0000\n0.0001\n\n\n3.91\n0.0000\n0.0001\n\n\n3.92\n0.0000\n0.0001\n\n\n3.93\n0.0000\n0.0001\n\n\n3.94\n0.0000\n0.0001\n\n\n3.95\n0.0000\n0.0001\n\n\n3.96\n0.0000\n0.0001\n\n\n3.97\n0.0000\n0.0001\n\n\n3.98\n0.0000\n0.0001\n\n\n3.99\n0.0000\n0.0001\n\n\n4.00\n0.0000\n0.0001\n\n\n\n\n\n\n\n\n\n\nt-table distribution for two-tailed test\n\n\ndf\nalpha\ntcritical\n\n\n\n\n1\n0.050\n12.706\n\n\n1\n0.010\n9.925\n\n\n1\n0.001\n12.924\n\n\n2\n0.050\n2.776\n\n\n2\n0.010\n4.032\n\n\n2\n0.001\n5.959\n\n\n3\n0.050\n2.365\n\n\n3\n0.010\n3.355\n\n\n3\n0.001\n4.781\n\n\n4\n0.050\n2.228\n\n\n4\n0.010\n3.106\n\n\n4\n0.001\n4.318\n\n\n5\n0.050\n2.160\n\n\n5\n0.010\n2.977\n\n\n5\n0.001\n4.073\n\n\n6\n0.050\n2.120\n\n\n6\n0.010\n2.898\n\n\n6\n0.001\n3.922\n\n\n7\n0.050\n2.093\n\n\n7\n0.010\n2.845\n\n\n7\n0.001\n3.819\n\n\n8\n0.050\n2.074\n\n\n8\n0.010\n2.807\n\n\n8\n0.001\n3.745\n\n\n9\n0.050\n2.060\n\n\n9\n0.010\n2.779\n\n\n9\n0.001\n3.690\n\n\n10\n0.050\n2.048\n\n\n10\n0.010\n2.756\n\n\n10\n0.001\n3.646\n\n\n11\n0.050\n12.706\n\n\n11\n0.010\n9.925\n\n\n11\n0.001\n12.924\n\n\n12\n0.050\n2.776\n\n\n12\n0.010\n4.032\n\n\n12\n0.001\n5.959\n\n\n13\n0.050\n2.365\n\n\n13\n0.010\n3.355\n\n\n13\n0.001\n4.781\n\n\n14\n0.050\n2.228\n\n\n14\n0.010\n3.106\n\n\n14\n0.001\n4.318\n\n\n15\n0.050\n2.160\n\n\n15\n0.010\n2.977\n\n\n15\n0.001\n4.073\n\n\n16\n0.050\n2.120\n\n\n16\n0.010\n2.898\n\n\n16\n0.001\n3.922\n\n\n17\n0.050\n2.093\n\n\n17\n0.010\n2.845\n\n\n17\n0.001\n3.819\n\n\n18\n0.050\n2.074\n\n\n18\n0.010\n2.807\n\n\n18\n0.001\n3.745\n\n\n19\n0.050\n2.060\n\n\n19\n0.010\n2.779\n\n\n19\n0.001\n3.690\n\n\n20\n0.050\n2.048\n\n\n20\n0.010\n2.756\n\n\n20\n0.001\n3.646\n\n\n21\n0.050\n12.706\n\n\n21\n0.010\n9.925\n\n\n21\n0.001\n12.924\n\n\n22\n0.050\n2.776\n\n\n22\n0.010\n4.032\n\n\n22\n0.001\n5.959\n\n\n23\n0.050\n2.365\n\n\n23\n0.010\n3.355\n\n\n23\n0.001\n4.781\n\n\n24\n0.050\n2.228\n\n\n24\n0.010\n3.106\n\n\n24\n0.001\n4.318\n\n\n25\n0.050\n2.160\n\n\n25\n0.010\n2.977\n\n\n25\n0.001\n4.073\n\n\n26\n0.050\n2.120\n\n\n26\n0.010\n2.898\n\n\n26\n0.001\n3.922\n\n\n27\n0.050\n2.093\n\n\n27\n0.010\n2.845\n\n\n27\n0.001\n3.819\n\n\n28\n0.050\n2.074\n\n\n28\n0.010\n2.807\n\n\n28\n0.001\n3.745\n\n\n29\n0.050\n2.060\n\n\n29\n0.010\n2.779\n\n\n29\n0.001\n3.690\n\n\n30\n0.050\n2.048\n\n\n30\n0.010\n2.756\n\n\n30\n0.001\n3.646\n\n\n\n\n\n\nt-table distribution for one-tailed test\n\n\ndf\nalpha\ntcritical\n\n\n\n\n1\n0.050\n6.314\n\n\n1\n0.010\n6.965\n\n\n1\n0.001\n10.215\n\n\n2\n0.050\n2.132\n\n\n2\n0.010\n3.365\n\n\n2\n0.001\n5.208\n\n\n3\n0.050\n1.895\n\n\n3\n0.010\n2.896\n\n\n3\n0.001\n4.297\n\n\n4\n0.050\n1.812\n\n\n4\n0.010\n2.718\n\n\n4\n0.001\n3.930\n\n\n5\n0.050\n1.771\n\n\n5\n0.010\n2.624\n\n\n5\n0.001\n3.733\n\n\n6\n0.050\n1.746\n\n\n6\n0.010\n2.567\n\n\n6\n0.001\n3.610\n\n\n7\n0.050\n1.729\n\n\n7\n0.010\n2.528\n\n\n7\n0.001\n3.527\n\n\n8\n0.050\n1.717\n\n\n8\n0.010\n2.500\n\n\n8\n0.001\n3.467\n\n\n9\n0.050\n1.708\n\n\n9\n0.010\n2.479\n\n\n9\n0.001\n3.421\n\n\n10\n0.050\n1.701\n\n\n10\n0.010\n2.462\n\n\n10\n0.001\n3.385\n\n\n11\n0.050\n6.314\n\n\n11\n0.010\n6.965\n\n\n11\n0.001\n10.215\n\n\n12\n0.050\n2.132\n\n\n12\n0.010\n3.365\n\n\n12\n0.001\n5.208\n\n\n13\n0.050\n1.895\n\n\n13\n0.010\n2.896\n\n\n13\n0.001\n4.297\n\n\n14\n0.050\n1.812\n\n\n14\n0.010\n2.718\n\n\n14\n0.001\n3.930\n\n\n15\n0.050\n1.771\n\n\n15\n0.010\n2.624\n\n\n15\n0.001\n3.733\n\n\n16\n0.050\n1.746\n\n\n16\n0.010\n2.567\n\n\n16\n0.001\n3.610\n\n\n17\n0.050\n1.729\n\n\n17\n0.010\n2.528\n\n\n17\n0.001\n3.527\n\n\n18\n0.050\n1.717\n\n\n18\n0.010\n2.500\n\n\n18\n0.001\n3.467\n\n\n19\n0.050\n1.708\n\n\n19\n0.010\n2.479\n\n\n19\n0.001\n3.421\n\n\n20\n0.050\n1.701\n\n\n20\n0.010\n2.462\n\n\n20\n0.001\n3.385\n\n\n21\n0.050\n6.314\n\n\n21\n0.010\n6.965\n\n\n21\n0.001\n10.215\n\n\n22\n0.050\n2.132\n\n\n22\n0.010\n3.365\n\n\n22\n0.001\n5.208\n\n\n23\n0.050\n1.895\n\n\n23\n0.010\n2.896\n\n\n23\n0.001\n4.297\n\n\n24\n0.050\n1.812\n\n\n24\n0.010\n2.718\n\n\n24\n0.001\n3.930\n\n\n25\n0.050\n1.771\n\n\n25\n0.010\n2.624\n\n\n25\n0.001\n3.733\n\n\n26\n0.050\n1.746\n\n\n26\n0.010\n2.567\n\n\n26\n0.001\n3.610\n\n\n27\n0.050\n1.729\n\n\n27\n0.010\n2.528\n\n\n27\n0.001\n3.527\n\n\n28\n0.050\n1.717\n\n\n28\n0.010\n2.500\n\n\n28\n0.001\n3.467\n\n\n29\n0.050\n1.708\n\n\n29\n0.010\n2.479\n\n\n29\n0.001\n3.421\n\n\n30\n0.050\n1.701\n\n\n30\n0.010\n2.462\n\n\n30\n0.001\n3.385\n\n\n\n\n\n\n\nTo interpret the table containing critical values for Pearson’s correlation coefficient for both one-tailed and two-tailed tests with sample sizes ranging from 5 to 100, follow these steps:\n\nIdentify the type of test: Determine whether you are conducting a one-tailed or two-tailed test. A one-tailed test is used when the direction of the relationship is hypothesized, while a two-tailed test is used when no specific direction is hypothesized.\nChoose the desired significance level (α): The significance level, denoted as α, is the probability of rejecting the null hypothesis when it is true. Commonly used significance levels are 0.05 and 0.01.\nLocate the degrees of freedom (df): Degrees of freedom (df) are calculated as the sample size (n) minus 2. Find the row in the table corresponding to the df of your data.\nFind the critical value: In the table, locate the critical value corresponding to the selected test type (one-tailed or two-tailed), significance level (α), and degrees of freedom (df). This critical value is the threshold at which you will reject or fail to reject the null hypothesis.\nCompare the critical value with the calculated Pearson’s correlation coefficient (r): Calculate the Pearson’s correlation coefficient (r) for your data. If the absolute value of the calculated r is greater than or equal to the critical value found in the table, you can reject the null hypothesis, concluding that there is a significant relationship between the two variables. If the absolute value of the calculated r is less than the critical value, you fail to reject the null hypothesis, meaning that there is not enough evidence to suggest a significant relationship between the two variables.\n\nRemember that rejecting or failing to reject the null hypothesis does not prove causation, but rather indicates the presence or absence of a significant correlation between the two variables.\n\n\n\nCritical values for Pearson’s correlation coefficient\n\n\nalpha\ndegrees_of_freedom\ncritical_value\ntest_tail\n\n\n\n\n0.05\n3\n2.353\none-tailed\n\n\n0.05\n4\n2.353\none-tailed\n\n\n0.05\n5\n2.353\none-tailed\n\n\n0.05\n6\n2.353\none-tailed\n\n\n0.05\n7\n2.353\none-tailed\n\n\n0.05\n8\n2.353\none-tailed\n\n\n0.05\n9\n2.353\none-tailed\n\n\n0.05\n10\n2.353\none-tailed\n\n\n0.05\n11\n2.353\none-tailed\n\n\n0.05\n12\n2.353\none-tailed\n\n\n0.05\n13\n2.353\none-tailed\n\n\n0.05\n14\n2.353\none-tailed\n\n\n0.05\n15\n2.353\none-tailed\n\n\n0.05\n16\n2.353\none-tailed\n\n\n0.05\n17\n2.353\none-tailed\n\n\n0.05\n18\n2.353\none-tailed\n\n\n0.05\n19\n2.353\none-tailed\n\n\n0.05\n20\n2.353\none-tailed\n\n\n0.05\n21\n2.353\none-tailed\n\n\n0.05\n22\n2.353\none-tailed\n\n\n0.05\n23\n2.353\none-tailed\n\n\n0.05\n24\n2.353\none-tailed\n\n\n0.05\n25\n2.353\none-tailed\n\n\n0.05\n26\n2.353\none-tailed\n\n\n0.05\n27\n2.353\none-tailed\n\n\n0.05\n28\n2.353\none-tailed\n\n\n0.05\n29\n2.353\none-tailed\n\n\n0.05\n30\n2.353\none-tailed\n\n\n0.05\n31\n2.353\none-tailed\n\n\n0.05\n32\n2.353\none-tailed\n\n\n0.05\n33\n2.353\none-tailed\n\n\n0.05\n34\n2.353\none-tailed\n\n\n0.05\n35\n2.353\none-tailed\n\n\n0.05\n36\n2.353\none-tailed\n\n\n0.05\n37\n2.353\none-tailed\n\n\n0.05\n38\n2.353\none-tailed\n\n\n0.05\n39\n2.353\none-tailed\n\n\n0.05\n40\n2.353\none-tailed\n\n\n0.05\n41\n2.353\none-tailed\n\n\n0.05\n42\n2.353\none-tailed\n\n\n0.05\n43\n2.353\none-tailed\n\n\n0.05\n44\n2.353\none-tailed\n\n\n0.05\n45\n2.353\none-tailed\n\n\n0.05\n46\n2.353\none-tailed\n\n\n0.05\n47\n2.353\none-tailed\n\n\n0.05\n48\n2.353\none-tailed\n\n\n0.05\n49\n2.353\none-tailed\n\n\n0.05\n50\n2.353\none-tailed\n\n\n0.05\n51\n2.353\none-tailed\n\n\n0.05\n52\n2.353\none-tailed\n\n\n0.05\n53\n2.353\none-tailed\n\n\n0.05\n54\n2.353\none-tailed\n\n\n0.05\n55\n2.353\none-tailed\n\n\n0.05\n56\n2.353\none-tailed\n\n\n0.05\n57\n2.353\none-tailed\n\n\n0.05\n58\n2.353\none-tailed\n\n\n0.05\n59\n2.353\none-tailed\n\n\n0.05\n60\n2.353\none-tailed\n\n\n0.05\n61\n2.353\none-tailed\n\n\n0.05\n62\n2.353\none-tailed\n\n\n0.05\n63\n2.353\none-tailed\n\n\n0.05\n64\n2.353\none-tailed\n\n\n0.05\n65\n2.353\none-tailed\n\n\n0.05\n66\n2.353\none-tailed\n\n\n0.05\n67\n2.353\none-tailed\n\n\n0.05\n68\n2.353\none-tailed\n\n\n0.05\n69\n2.353\none-tailed\n\n\n0.05\n70\n2.353\none-tailed\n\n\n0.05\n71\n2.353\none-tailed\n\n\n0.05\n72\n2.353\none-tailed\n\n\n0.05\n73\n2.353\none-tailed\n\n\n0.05\n74\n2.353\none-tailed\n\n\n0.05\n75\n2.353\none-tailed\n\n\n0.05\n76\n2.353\none-tailed\n\n\n0.05\n77\n2.353\none-tailed\n\n\n0.05\n78\n2.353\none-tailed\n\n\n0.05\n79\n2.353\none-tailed\n\n\n0.05\n80\n2.353\none-tailed\n\n\n0.05\n81\n2.353\none-tailed\n\n\n0.05\n82\n2.353\none-tailed\n\n\n0.05\n83\n2.353\none-tailed\n\n\n0.05\n84\n2.353\none-tailed\n\n\n0.05\n85\n2.353\none-tailed\n\n\n0.05\n86\n2.353\none-tailed\n\n\n0.05\n87\n2.353\none-tailed\n\n\n0.05\n88\n2.353\none-tailed\n\n\n0.05\n89\n2.353\none-tailed\n\n\n0.05\n90\n2.353\none-tailed\n\n\n0.05\n91\n2.353\none-tailed\n\n\n0.05\n92\n2.353\none-tailed\n\n\n0.05\n93\n2.353\none-tailed\n\n\n0.05\n94\n2.353\none-tailed\n\n\n0.05\n95\n2.353\none-tailed\n\n\n0.05\n96\n2.353\none-tailed\n\n\n0.05\n97\n2.353\none-tailed\n\n\n0.05\n98\n2.353\none-tailed\n\n\n0.01\n3\n2.353\none-tailed\n\n\n0.01\n4\n2.353\none-tailed\n\n\n0.01\n5\n2.353\none-tailed\n\n\n0.01\n6\n2.353\none-tailed\n\n\n0.01\n7\n2.353\none-tailed\n\n\n0.01\n8\n2.353\none-tailed\n\n\n0.01\n9\n2.353\none-tailed\n\n\n0.01\n10\n2.353\none-tailed\n\n\n0.01\n11\n2.353\none-tailed\n\n\n0.01\n12\n2.353\none-tailed\n\n\n0.01\n13\n2.353\none-tailed\n\n\n0.01\n14\n2.353\none-tailed\n\n\n0.01\n15\n2.353\none-tailed\n\n\n0.01\n16\n2.353\none-tailed\n\n\n0.01\n17\n2.353\none-tailed\n\n\n0.01\n18\n2.353\none-tailed\n\n\n0.01\n19\n2.353\none-tailed\n\n\n0.01\n20\n2.353\none-tailed\n\n\n0.01\n21\n2.353\none-tailed\n\n\n0.01\n22\n2.353\none-tailed\n\n\n0.01\n23\n2.353\none-tailed\n\n\n0.01\n24\n2.353\none-tailed\n\n\n0.01\n25\n2.353\none-tailed\n\n\n0.01\n26\n2.353\none-tailed\n\n\n0.01\n27\n2.353\none-tailed\n\n\n0.01\n28\n2.353\none-tailed\n\n\n0.01\n29\n2.353\none-tailed\n\n\n0.01\n30\n2.353\none-tailed\n\n\n0.01\n31\n2.353\none-tailed\n\n\n0.01\n32\n2.353\none-tailed\n\n\n0.01\n33\n2.353\none-tailed\n\n\n0.01\n34\n2.353\none-tailed\n\n\n0.01\n35\n2.353\none-tailed\n\n\n0.01\n36\n2.353\none-tailed\n\n\n0.01\n37\n2.353\none-tailed\n\n\n0.01\n38\n2.353\none-tailed\n\n\n0.01\n39\n2.353\none-tailed\n\n\n0.01\n40\n2.353\none-tailed\n\n\n0.01\n41\n2.353\none-tailed\n\n\n0.01\n42\n2.353\none-tailed\n\n\n0.01\n43\n2.353\none-tailed\n\n\n0.01\n44\n2.353\none-tailed\n\n\n0.01\n45\n2.353\none-tailed\n\n\n0.01\n46\n2.353\none-tailed\n\n\n0.01\n47\n2.353\none-tailed\n\n\n0.01\n48\n2.353\none-tailed\n\n\n0.01\n49\n2.353\none-tailed\n\n\n0.01\n50\n2.353\none-tailed\n\n\n0.01\n51\n2.353\none-tailed\n\n\n0.01\n52\n2.353\none-tailed\n\n\n0.01\n53\n2.353\none-tailed\n\n\n0.01\n54\n2.353\none-tailed\n\n\n0.01\n55\n2.353\none-tailed\n\n\n0.01\n56\n2.353\none-tailed\n\n\n0.01\n57\n2.353\none-tailed\n\n\n0.01\n58\n2.353\none-tailed\n\n\n0.01\n59\n2.353\none-tailed\n\n\n0.01\n60\n2.353\none-tailed\n\n\n0.01\n61\n2.353\none-tailed\n\n\n0.01\n62\n2.353\none-tailed\n\n\n0.01\n63\n2.353\none-tailed\n\n\n0.01\n64\n2.353\none-tailed\n\n\n0.01\n65\n2.353\none-tailed\n\n\n0.01\n66\n2.353\none-tailed\n\n\n0.01\n67\n2.353\none-tailed\n\n\n0.01\n68\n2.353\none-tailed\n\n\n0.01\n69\n2.353\none-tailed\n\n\n0.01\n70\n2.353\none-tailed\n\n\n0.01\n71\n2.353\none-tailed\n\n\n0.01\n72\n2.353\none-tailed\n\n\n0.01\n73\n2.353\none-tailed\n\n\n0.01\n74\n2.353\none-tailed\n\n\n0.01\n75\n2.353\none-tailed\n\n\n0.01\n76\n2.353\none-tailed\n\n\n0.01\n77\n2.353\none-tailed\n\n\n0.01\n78\n2.353\none-tailed\n\n\n0.01\n79\n2.353\none-tailed\n\n\n0.01\n80\n2.353\none-tailed\n\n\n0.01\n81\n2.353\none-tailed\n\n\n0.01\n82\n2.353\none-tailed\n\n\n0.01\n83\n2.353\none-tailed\n\n\n0.01\n84\n2.353\none-tailed\n\n\n0.01\n85\n2.353\none-tailed\n\n\n0.01\n86\n2.353\none-tailed\n\n\n0.01\n87\n2.353\none-tailed\n\n\n0.01\n88\n2.353\none-tailed\n\n\n0.01\n89\n2.353\none-tailed\n\n\n0.01\n90\n2.353\none-tailed\n\n\n0.01\n91\n2.353\none-tailed\n\n\n0.01\n92\n2.353\none-tailed\n\n\n0.01\n93\n2.353\none-tailed\n\n\n0.01\n94\n2.353\none-tailed\n\n\n0.01\n95\n2.353\none-tailed\n\n\n0.01\n96\n2.353\none-tailed\n\n\n0.01\n97\n2.353\none-tailed\n\n\n0.01\n98\n2.353\none-tailed\n\n\n0.05\n3\n3.182\ntwo-tailed\n\n\n0.05\n4\n3.182\ntwo-tailed\n\n\n0.05\n5\n3.182\ntwo-tailed\n\n\n0.05\n6\n3.182\ntwo-tailed\n\n\n0.05\n7\n3.182\ntwo-tailed\n\n\n0.05\n8\n3.182\ntwo-tailed\n\n\n0.05\n9\n3.182\ntwo-tailed\n\n\n0.05\n10\n3.182\ntwo-tailed\n\n\n0.05\n11\n3.182\ntwo-tailed\n\n\n0.05\n12\n3.182\ntwo-tailed\n\n\n0.05\n13\n3.182\ntwo-tailed\n\n\n0.05\n14\n3.182\ntwo-tailed\n\n\n0.05\n15\n3.182\ntwo-tailed\n\n\n0.05\n16\n3.182\ntwo-tailed\n\n\n0.05\n17\n3.182\ntwo-tailed\n\n\n0.05\n18\n3.182\ntwo-tailed\n\n\n0.05\n19\n3.182\ntwo-tailed\n\n\n0.05\n20\n3.182\ntwo-tailed\n\n\n0.05\n21\n3.182\ntwo-tailed\n\n\n0.05\n22\n3.182\ntwo-tailed\n\n\n0.05\n23\n3.182\ntwo-tailed\n\n\n0.05\n24\n3.182\ntwo-tailed\n\n\n0.05\n25\n3.182\ntwo-tailed\n\n\n0.05\n26\n3.182\ntwo-tailed\n\n\n0.05\n27\n3.182\ntwo-tailed\n\n\n0.05\n28\n3.182\ntwo-tailed\n\n\n0.05\n29\n3.182\ntwo-tailed\n\n\n0.05\n30\n3.182\ntwo-tailed\n\n\n0.05\n31\n3.182\ntwo-tailed\n\n\n0.05\n32\n3.182\ntwo-tailed\n\n\n0.05\n33\n3.182\ntwo-tailed\n\n\n0.05\n34\n3.182\ntwo-tailed\n\n\n0.05\n35\n3.182\ntwo-tailed\n\n\n0.05\n36\n3.182\ntwo-tailed\n\n\n0.05\n37\n3.182\ntwo-tailed\n\n\n0.05\n38\n3.182\ntwo-tailed\n\n\n0.05\n39\n3.182\ntwo-tailed\n\n\n0.05\n40\n3.182\ntwo-tailed\n\n\n0.05\n41\n3.182\ntwo-tailed\n\n\n0.05\n42\n3.182\ntwo-tailed\n\n\n0.05\n43\n3.182\ntwo-tailed\n\n\n0.05\n44\n3.182\ntwo-tailed\n\n\n0.05\n45\n3.182\ntwo-tailed\n\n\n0.05\n46\n3.182\ntwo-tailed\n\n\n0.05\n47\n3.182\ntwo-tailed\n\n\n0.05\n48\n3.182\ntwo-tailed\n\n\n0.05\n49\n3.182\ntwo-tailed\n\n\n0.05\n50\n3.182\ntwo-tailed\n\n\n0.05\n51\n3.182\ntwo-tailed\n\n\n0.05\n52\n3.182\ntwo-tailed\n\n\n0.05\n53\n3.182\ntwo-tailed\n\n\n0.05\n54\n3.182\ntwo-tailed\n\n\n0.05\n55\n3.182\ntwo-tailed\n\n\n0.05\n56\n3.182\ntwo-tailed\n\n\n0.05\n57\n3.182\ntwo-tailed\n\n\n0.05\n58\n3.182\ntwo-tailed\n\n\n0.05\n59\n3.182\ntwo-tailed\n\n\n0.05\n60\n3.182\ntwo-tailed\n\n\n0.05\n61\n3.182\ntwo-tailed\n\n\n0.05\n62\n3.182\ntwo-tailed\n\n\n0.05\n63\n3.182\ntwo-tailed\n\n\n0.05\n64\n3.182\ntwo-tailed\n\n\n0.05\n65\n3.182\ntwo-tailed\n\n\n0.05\n66\n3.182\ntwo-tailed\n\n\n0.05\n67\n3.182\ntwo-tailed\n\n\n0.05\n68\n3.182\ntwo-tailed\n\n\n0.05\n69\n3.182\ntwo-tailed\n\n\n0.05\n70\n3.182\ntwo-tailed\n\n\n0.05\n71\n3.182\ntwo-tailed\n\n\n0.05\n72\n3.182\ntwo-tailed\n\n\n0.05\n73\n3.182\ntwo-tailed\n\n\n0.05\n74\n3.182\ntwo-tailed\n\n\n0.05\n75\n3.182\ntwo-tailed\n\n\n0.05\n76\n3.182\ntwo-tailed\n\n\n0.05\n77\n3.182\ntwo-tailed\n\n\n0.05\n78\n3.182\ntwo-tailed\n\n\n0.05\n79\n3.182\ntwo-tailed\n\n\n0.05\n80\n3.182\ntwo-tailed\n\n\n0.05\n81\n3.182\ntwo-tailed\n\n\n0.05\n82\n3.182\ntwo-tailed\n\n\n0.05\n83\n3.182\ntwo-tailed\n\n\n0.05\n84\n3.182\ntwo-tailed\n\n\n0.05\n85\n3.182\ntwo-tailed\n\n\n0.05\n86\n3.182\ntwo-tailed\n\n\n0.05\n87\n3.182\ntwo-tailed\n\n\n0.05\n88\n3.182\ntwo-tailed\n\n\n0.05\n89\n3.182\ntwo-tailed\n\n\n0.05\n90\n3.182\ntwo-tailed\n\n\n0.05\n91\n3.182\ntwo-tailed\n\n\n0.05\n92\n3.182\ntwo-tailed\n\n\n0.05\n93\n3.182\ntwo-tailed\n\n\n0.05\n94\n3.182\ntwo-tailed\n\n\n0.05\n95\n3.182\ntwo-tailed\n\n\n0.05\n96\n3.182\ntwo-tailed\n\n\n0.05\n97\n3.182\ntwo-tailed\n\n\n0.05\n98\n3.182\ntwo-tailed\n\n\n0.01\n3\n3.182\ntwo-tailed\n\n\n0.01\n4\n3.182\ntwo-tailed\n\n\n0.01\n5\n3.182\ntwo-tailed\n\n\n0.01\n6\n3.182\ntwo-tailed\n\n\n0.01\n7\n3.182\ntwo-tailed\n\n\n0.01\n8\n3.182\ntwo-tailed\n\n\n0.01\n9\n3.182\ntwo-tailed\n\n\n0.01\n10\n3.182\ntwo-tailed\n\n\n0.01\n11\n3.182\ntwo-tailed\n\n\n0.01\n12\n3.182\ntwo-tailed\n\n\n0.01\n13\n3.182\ntwo-tailed\n\n\n0.01\n14\n3.182\ntwo-tailed\n\n\n0.01\n15\n3.182\ntwo-tailed\n\n\n0.01\n16\n3.182\ntwo-tailed\n\n\n0.01\n17\n3.182\ntwo-tailed\n\n\n0.01\n18\n3.182\ntwo-tailed\n\n\n0.01\n19\n3.182\ntwo-tailed\n\n\n0.01\n20\n3.182\ntwo-tailed\n\n\n0.01\n21\n3.182\ntwo-tailed\n\n\n0.01\n22\n3.182\ntwo-tailed\n\n\n0.01\n23\n3.182\ntwo-tailed\n\n\n0.01\n24\n3.182\ntwo-tailed\n\n\n0.01\n25\n3.182\ntwo-tailed\n\n\n0.01\n26\n3.182\ntwo-tailed\n\n\n0.01\n27\n3.182\ntwo-tailed\n\n\n0.01\n28\n3.182\ntwo-tailed\n\n\n0.01\n29\n3.182\ntwo-tailed\n\n\n0.01\n30\n3.182\ntwo-tailed\n\n\n0.01\n31\n3.182\ntwo-tailed\n\n\n0.01\n32\n3.182\ntwo-tailed\n\n\n0.01\n33\n3.182\ntwo-tailed\n\n\n0.01\n34\n3.182\ntwo-tailed\n\n\n0.01\n35\n3.182\ntwo-tailed\n\n\n0.01\n36\n3.182\ntwo-tailed\n\n\n0.01\n37\n3.182\ntwo-tailed\n\n\n0.01\n38\n3.182\ntwo-tailed\n\n\n0.01\n39\n3.182\ntwo-tailed\n\n\n0.01\n40\n3.182\ntwo-tailed\n\n\n0.01\n41\n3.182\ntwo-tailed\n\n\n0.01\n42\n3.182\ntwo-tailed\n\n\n0.01\n43\n3.182\ntwo-tailed\n\n\n0.01\n44\n3.182\ntwo-tailed\n\n\n0.01\n45\n3.182\ntwo-tailed\n\n\n0.01\n46\n3.182\ntwo-tailed\n\n\n0.01\n47\n3.182\ntwo-tailed\n\n\n0.01\n48\n3.182\ntwo-tailed\n\n\n0.01\n49\n3.182\ntwo-tailed\n\n\n0.01\n50\n3.182\ntwo-tailed\n\n\n0.01\n51\n3.182\ntwo-tailed\n\n\n0.01\n52\n3.182\ntwo-tailed\n\n\n0.01\n53\n3.182\ntwo-tailed\n\n\n0.01\n54\n3.182\ntwo-tailed\n\n\n0.01\n55\n3.182\ntwo-tailed\n\n\n0.01\n56\n3.182\ntwo-tailed\n\n\n0.01\n57\n3.182\ntwo-tailed\n\n\n0.01\n58\n3.182\ntwo-tailed\n\n\n0.01\n59\n3.182\ntwo-tailed\n\n\n0.01\n60\n3.182\ntwo-tailed\n\n\n0.01\n61\n3.182\ntwo-tailed\n\n\n0.01\n62\n3.182\ntwo-tailed\n\n\n0.01\n63\n3.182\ntwo-tailed\n\n\n0.01\n64\n3.182\ntwo-tailed\n\n\n0.01\n65\n3.182\ntwo-tailed\n\n\n0.01\n66\n3.182\ntwo-tailed\n\n\n0.01\n67\n3.182\ntwo-tailed\n\n\n0.01\n68\n3.182\ntwo-tailed\n\n\n0.01\n69\n3.182\ntwo-tailed\n\n\n0.01\n70\n3.182\ntwo-tailed\n\n\n0.01\n71\n3.182\ntwo-tailed\n\n\n0.01\n72\n3.182\ntwo-tailed\n\n\n0.01\n73\n3.182\ntwo-tailed\n\n\n0.01\n74\n3.182\ntwo-tailed\n\n\n0.01\n75\n3.182\ntwo-tailed\n\n\n0.01\n76\n3.182\ntwo-tailed\n\n\n0.01\n77\n3.182\ntwo-tailed\n\n\n0.01\n78\n3.182\ntwo-tailed\n\n\n0.01\n79\n3.182\ntwo-tailed\n\n\n0.01\n80\n3.182\ntwo-tailed\n\n\n0.01\n81\n3.182\ntwo-tailed\n\n\n0.01\n82\n3.182\ntwo-tailed\n\n\n0.01\n83\n3.182\ntwo-tailed\n\n\n0.01\n84\n3.182\ntwo-tailed\n\n\n0.01\n85\n3.182\ntwo-tailed\n\n\n0.01\n86\n3.182\ntwo-tailed\n\n\n0.01\n87\n3.182\ntwo-tailed\n\n\n0.01\n88\n3.182\ntwo-tailed\n\n\n0.01\n89\n3.182\ntwo-tailed\n\n\n0.01\n90\n3.182\ntwo-tailed\n\n\n0.01\n91\n3.182\ntwo-tailed\n\n\n0.01\n92\n3.182\ntwo-tailed\n\n\n0.01\n93\n3.182\ntwo-tailed\n\n\n0.01\n94\n3.182\ntwo-tailed\n\n\n0.01\n95\n3.182\ntwo-tailed\n\n\n0.01\n96\n3.182\ntwo-tailed\n\n\n0.01\n97\n3.182\ntwo-tailed\n\n\n0.01\n98\n3.182\ntwo-tailed\n\n\n\n\n\n\n\nTo interpret the F-table containing critical F-values for various degrees of freedom and significance levels, follow these steps:\n\nIdentify the degrees of freedom: Determine the numerator degrees of freedom (df1) and the denominator degrees of freedom (df2) for your data. This typically depends on the specific statistical test or model you are using, such as ANOVA or regression analysis.\nChoose the significance level (α): Select the desired significance level (α) for your test. Commonly used significance levels are 0.05 and 0.01. The significance level represents the probability of rejecting the null hypothesis when it is true.\nLocate the critical F-value: In the F-table, find the row with the correct df1 and the column with the correct df2. At the intersection of this row and column, locate the critical F-value for your chosen significance level (α).\nCalculate the F-value: Using your data, calculate the F-value (F) as part of your statistical test or model.\nCompare the F-value with the critical F-value: If the calculated F-value is greater than the critical F-value from the table, you can reject the null hypothesis, suggesting that there is a significant effect or relationship between the variables under consideration. If the calculated F-value is less than or equal to the critical F-value, you fail to reject the null hypothesis, meaning that there is not enough evidence to suggest a significant effect or relationship between the variables.\n\nKeep in mind that rejecting or failing to reject the null hypothesis does not prove causation, but rather indicates the presence or absence of a significant effect or relationship between the variables under certain assumptions. Also, remember that the F-table provides critical F-values for specific degrees of freedom and significance levels, so ensure that you use the correct values when interpreting the table.\nFor the F-test:\n\ndf1 (numerator degrees of freedom): This typically represents the degrees of freedom associated with the factor or group being tested. In ANOVA, for example, df1 is the number of groups minus one (k - 1), where k is the number of groups being compared.\ndf2 (denominator degrees of freedom): This typically represents the degrees of freedom associated with the error or residual variation within the groups. In ANOVA, for example, df2 is the total number of observations minus the number of groups (N - k), where N is the total number of observations across all groups.\n\n\n\n\nCritical F-values for F-test\n\n\ndf1\ndf2\nalpha\ncritical_f_value\n\n\n\n\n1\n1\n0.05\n161.448\n\n\n2\n1\n0.05\n199.500\n\n\n3\n1\n0.05\n215.707\n\n\n4\n1\n0.05\n224.583\n\n\n5\n1\n0.05\n230.162\n\n\n6\n1\n0.05\n233.986\n\n\n7\n1\n0.05\n236.768\n\n\n8\n1\n0.05\n238.883\n\n\n9\n1\n0.05\n240.543\n\n\n10\n1\n0.05\n241.882\n\n\n1\n2\n0.05\n18.513\n\n\n2\n2\n0.05\n19.000\n\n\n3\n2\n0.05\n19.164\n\n\n4\n2\n0.05\n19.247\n\n\n5\n2\n0.05\n19.296\n\n\n6\n2\n0.05\n19.330\n\n\n7\n2\n0.05\n19.353\n\n\n8\n2\n0.05\n19.371\n\n\n9\n2\n0.05\n19.385\n\n\n10\n2\n0.05\n19.396\n\n\n1\n3\n0.05\n10.128\n\n\n2\n3\n0.05\n9.552\n\n\n3\n3\n0.05\n9.277\n\n\n4\n3\n0.05\n9.117\n\n\n5\n3\n0.05\n9.013\n\n\n6\n3\n0.05\n8.941\n\n\n7\n3\n0.05\n8.887\n\n\n8\n3\n0.05\n8.845\n\n\n9\n3\n0.05\n8.812\n\n\n10\n3\n0.05\n8.786\n\n\n1\n4\n0.05\n7.709\n\n\n2\n4\n0.05\n6.944\n\n\n3\n4\n0.05\n6.591\n\n\n4\n4\n0.05\n6.388\n\n\n5\n4\n0.05\n6.256\n\n\n6\n4\n0.05\n6.163\n\n\n7\n4\n0.05\n6.094\n\n\n8\n4\n0.05\n6.041\n\n\n9\n4\n0.05\n5.999\n\n\n10\n4\n0.05\n5.964\n\n\n1\n5\n0.05\n6.608\n\n\n2\n5\n0.05\n5.786\n\n\n3\n5\n0.05\n5.409\n\n\n4\n5\n0.05\n5.192\n\n\n5\n5\n0.05\n5.050\n\n\n6\n5\n0.05\n4.950\n\n\n7\n5\n0.05\n4.876\n\n\n8\n5\n0.05\n4.818\n\n\n9\n5\n0.05\n4.772\n\n\n10\n5\n0.05\n4.735\n\n\n1\n6\n0.05\n5.987\n\n\n2\n6\n0.05\n5.143\n\n\n3\n6\n0.05\n4.757\n\n\n4\n6\n0.05\n4.534\n\n\n5\n6\n0.05\n4.387\n\n\n6\n6\n0.05\n4.284\n\n\n7\n6\n0.05\n4.207\n\n\n8\n6\n0.05\n4.147\n\n\n9\n6\n0.05\n4.099\n\n\n10\n6\n0.05\n4.060\n\n\n1\n7\n0.05\n5.591\n\n\n2\n7\n0.05\n4.737\n\n\n3\n7\n0.05\n4.347\n\n\n4\n7\n0.05\n4.120\n\n\n5\n7\n0.05\n3.972\n\n\n6\n7\n0.05\n3.866\n\n\n7\n7\n0.05\n3.787\n\n\n8\n7\n0.05\n3.726\n\n\n9\n7\n0.05\n3.677\n\n\n10\n7\n0.05\n3.637\n\n\n1\n8\n0.05\n5.318\n\n\n2\n8\n0.05\n4.459\n\n\n3\n8\n0.05\n4.066\n\n\n4\n8\n0.05\n3.838\n\n\n5\n8\n0.05\n3.687\n\n\n6\n8\n0.05\n3.581\n\n\n7\n8\n0.05\n3.500\n\n\n8\n8\n0.05\n3.438\n\n\n9\n8\n0.05\n3.388\n\n\n10\n8\n0.05\n3.347\n\n\n1\n9\n0.05\n5.117\n\n\n2\n9\n0.05\n4.256\n\n\n3\n9\n0.05\n3.863\n\n\n4\n9\n0.05\n3.633\n\n\n5\n9\n0.05\n3.482\n\n\n6\n9\n0.05\n3.374\n\n\n7\n9\n0.05\n3.293\n\n\n8\n9\n0.05\n3.230\n\n\n9\n9\n0.05\n3.179\n\n\n10\n9\n0.05\n3.137\n\n\n1\n10\n0.05\n4.965\n\n\n2\n10\n0.05\n4.103\n\n\n3\n10\n0.05\n3.708\n\n\n4\n10\n0.05\n3.478\n\n\n5\n10\n0.05\n3.326\n\n\n6\n10\n0.05\n3.217\n\n\n7\n10\n0.05\n3.135\n\n\n8\n10\n0.05\n3.072\n\n\n9\n10\n0.05\n3.020\n\n\n10\n10\n0.05\n2.978\n\n\n1\n11\n0.05\n4.844\n\n\n2\n11\n0.05\n3.982\n\n\n3\n11\n0.05\n3.587\n\n\n4\n11\n0.05\n3.357\n\n\n5\n11\n0.05\n3.204\n\n\n6\n11\n0.05\n3.095\n\n\n7\n11\n0.05\n3.012\n\n\n8\n11\n0.05\n2.948\n\n\n9\n11\n0.05\n2.896\n\n\n10\n11\n0.05\n2.854\n\n\n1\n12\n0.05\n4.747\n\n\n2\n12\n0.05\n3.885\n\n\n3\n12\n0.05\n3.490\n\n\n4\n12\n0.05\n3.259\n\n\n5\n12\n0.05\n3.106\n\n\n6\n12\n0.05\n2.996\n\n\n7\n12\n0.05\n2.913\n\n\n8\n12\n0.05\n2.849\n\n\n9\n12\n0.05\n2.796\n\n\n10\n12\n0.05\n2.753\n\n\n1\n13\n0.05\n4.667\n\n\n2\n13\n0.05\n3.806\n\n\n3\n13\n0.05\n3.411\n\n\n4\n13\n0.05\n3.179\n\n\n5\n13\n0.05\n3.025\n\n\n6\n13\n0.05\n2.915\n\n\n7\n13\n0.05\n2.832\n\n\n8\n13\n0.05\n2.767\n\n\n9\n13\n0.05\n2.714\n\n\n10\n13\n0.05\n2.671\n\n\n1\n14\n0.05\n4.600\n\n\n2\n14\n0.05\n3.739\n\n\n3\n14\n0.05\n3.344\n\n\n4\n14\n0.05\n3.112\n\n\n5\n14\n0.05\n2.958\n\n\n6\n14\n0.05\n2.848\n\n\n7\n14\n0.05\n2.764\n\n\n8\n14\n0.05\n2.699\n\n\n9\n14\n0.05\n2.646\n\n\n10\n14\n0.05\n2.602\n\n\n1\n15\n0.05\n4.543\n\n\n2\n15\n0.05\n3.682\n\n\n3\n15\n0.05\n3.287\n\n\n4\n15\n0.05\n3.056\n\n\n5\n15\n0.05\n2.901\n\n\n6\n15\n0.05\n2.790\n\n\n7\n15\n0.05\n2.707\n\n\n8\n15\n0.05\n2.641\n\n\n9\n15\n0.05\n2.588\n\n\n10\n15\n0.05\n2.544\n\n\n1\n16\n0.05\n4.494\n\n\n2\n16\n0.05\n3.634\n\n\n3\n16\n0.05\n3.239\n\n\n4\n16\n0.05\n3.007\n\n\n5\n16\n0.05\n2.852\n\n\n6\n16\n0.05\n2.741\n\n\n7\n16\n0.05\n2.657\n\n\n8\n16\n0.05\n2.591\n\n\n9\n16\n0.05\n2.538\n\n\n10\n16\n0.05\n2.494\n\n\n1\n17\n0.05\n4.451\n\n\n2\n17\n0.05\n3.592\n\n\n3\n17\n0.05\n3.197\n\n\n4\n17\n0.05\n2.965\n\n\n5\n17\n0.05\n2.810\n\n\n6\n17\n0.05\n2.699\n\n\n7\n17\n0.05\n2.614\n\n\n8\n17\n0.05\n2.548\n\n\n9\n17\n0.05\n2.494\n\n\n10\n17\n0.05\n2.450\n\n\n1\n18\n0.05\n4.414\n\n\n2\n18\n0.05\n3.555\n\n\n3\n18\n0.05\n3.160\n\n\n4\n18\n0.05\n2.928\n\n\n5\n18\n0.05\n2.773\n\n\n6\n18\n0.05\n2.661\n\n\n7\n18\n0.05\n2.577\n\n\n8\n18\n0.05\n2.510\n\n\n9\n18\n0.05\n2.456\n\n\n10\n18\n0.05\n2.412\n\n\n1\n19\n0.05\n4.381\n\n\n2\n19\n0.05\n3.522\n\n\n3\n19\n0.05\n3.127\n\n\n4\n19\n0.05\n2.895\n\n\n5\n19\n0.05\n2.740\n\n\n6\n19\n0.05\n2.628\n\n\n7\n19\n0.05\n2.544\n\n\n8\n19\n0.05\n2.477\n\n\n9\n19\n0.05\n2.423\n\n\n10\n19\n0.05\n2.378\n\n\n1\n20\n0.05\n4.351\n\n\n2\n20\n0.05\n3.493\n\n\n3\n20\n0.05\n3.098\n\n\n4\n20\n0.05\n2.866\n\n\n5\n20\n0.05\n2.711\n\n\n6\n20\n0.05\n2.599\n\n\n7\n20\n0.05\n2.514\n\n\n8\n20\n0.05\n2.447\n\n\n9\n20\n0.05\n2.393\n\n\n10\n20\n0.05\n2.348\n\n\n1\n21\n0.05\n4.325\n\n\n2\n21\n0.05\n3.467\n\n\n3\n21\n0.05\n3.072\n\n\n4\n21\n0.05\n2.840\n\n\n5\n21\n0.05\n2.685\n\n\n6\n21\n0.05\n2.573\n\n\n7\n21\n0.05\n2.488\n\n\n8\n21\n0.05\n2.420\n\n\n9\n21\n0.05\n2.366\n\n\n10\n21\n0.05\n2.321\n\n\n1\n22\n0.05\n4.301\n\n\n2\n22\n0.05\n3.443\n\n\n3\n22\n0.05\n3.049\n\n\n4\n22\n0.05\n2.817\n\n\n5\n22\n0.05\n2.661\n\n\n6\n22\n0.05\n2.549\n\n\n7\n22\n0.05\n2.464\n\n\n8\n22\n0.05\n2.397\n\n\n9\n22\n0.05\n2.342\n\n\n10\n22\n0.05\n2.297\n\n\n1\n23\n0.05\n4.279\n\n\n2\n23\n0.05\n3.422\n\n\n3\n23\n0.05\n3.028\n\n\n4\n23\n0.05\n2.796\n\n\n5\n23\n0.05\n2.640\n\n\n6\n23\n0.05\n2.528\n\n\n7\n23\n0.05\n2.442\n\n\n8\n23\n0.05\n2.375\n\n\n9\n23\n0.05\n2.320\n\n\n10\n23\n0.05\n2.275\n\n\n1\n24\n0.05\n4.260\n\n\n2\n24\n0.05\n3.403\n\n\n3\n24\n0.05\n3.009\n\n\n4\n24\n0.05\n2.776\n\n\n5\n24\n0.05\n2.621\n\n\n6\n24\n0.05\n2.508\n\n\n7\n24\n0.05\n2.423\n\n\n8\n24\n0.05\n2.355\n\n\n9\n24\n0.05\n2.300\n\n\n10\n24\n0.05\n2.255\n\n\n1\n25\n0.05\n4.242\n\n\n2\n25\n0.05\n3.385\n\n\n3\n25\n0.05\n2.991\n\n\n4\n25\n0.05\n2.759\n\n\n5\n25\n0.05\n2.603\n\n\n6\n25\n0.05\n2.490\n\n\n7\n25\n0.05\n2.405\n\n\n8\n25\n0.05\n2.337\n\n\n9\n25\n0.05\n2.282\n\n\n10\n25\n0.05\n2.236\n\n\n1\n26\n0.05\n4.225\n\n\n2\n26\n0.05\n3.369\n\n\n3\n26\n0.05\n2.975\n\n\n4\n26\n0.05\n2.743\n\n\n5\n26\n0.05\n2.587\n\n\n6\n26\n0.05\n2.474\n\n\n7\n26\n0.05\n2.388\n\n\n8\n26\n0.05\n2.321\n\n\n9\n26\n0.05\n2.265\n\n\n10\n26\n0.05\n2.220\n\n\n1\n27\n0.05\n4.210\n\n\n2\n27\n0.05\n3.354\n\n\n3\n27\n0.05\n2.960\n\n\n4\n27\n0.05\n2.728\n\n\n5\n27\n0.05\n2.572\n\n\n6\n27\n0.05\n2.459\n\n\n7\n27\n0.05\n2.373\n\n\n8\n27\n0.05\n2.305\n\n\n9\n27\n0.05\n2.250\n\n\n10\n27\n0.05\n2.204\n\n\n1\n28\n0.05\n4.196\n\n\n2\n28\n0.05\n3.340\n\n\n3\n28\n0.05\n2.947\n\n\n4\n28\n0.05\n2.714\n\n\n5\n28\n0.05\n2.558\n\n\n6\n28\n0.05\n2.445\n\n\n7\n28\n0.05\n2.359\n\n\n8\n28\n0.05\n2.291\n\n\n9\n28\n0.05\n2.236\n\n\n10\n28\n0.05\n2.190\n\n\n1\n29\n0.05\n4.183\n\n\n2\n29\n0.05\n3.328\n\n\n3\n29\n0.05\n2.934\n\n\n4\n29\n0.05\n2.701\n\n\n5\n29\n0.05\n2.545\n\n\n6\n29\n0.05\n2.432\n\n\n7\n29\n0.05\n2.346\n\n\n8\n29\n0.05\n2.278\n\n\n9\n29\n0.05\n2.223\n\n\n10\n29\n0.05\n2.177\n\n\n1\n30\n0.05\n4.171\n\n\n2\n30\n0.05\n3.316\n\n\n3\n30\n0.05\n2.922\n\n\n4\n30\n0.05\n2.690\n\n\n5\n30\n0.05\n2.534\n\n\n6\n30\n0.05\n2.421\n\n\n7\n30\n0.05\n2.334\n\n\n8\n30\n0.05\n2.266\n\n\n9\n30\n0.05\n2.211\n\n\n10\n30\n0.05\n2.165\n\n\n1\n31\n0.05\n4.160\n\n\n2\n31\n0.05\n3.305\n\n\n3\n31\n0.05\n2.911\n\n\n4\n31\n0.05\n2.679\n\n\n5\n31\n0.05\n2.523\n\n\n6\n31\n0.05\n2.409\n\n\n7\n31\n0.05\n2.323\n\n\n8\n31\n0.05\n2.255\n\n\n9\n31\n0.05\n2.199\n\n\n10\n31\n0.05\n2.153\n\n\n1\n32\n0.05\n4.149\n\n\n2\n32\n0.05\n3.295\n\n\n3\n32\n0.05\n2.901\n\n\n4\n32\n0.05\n2.668\n\n\n5\n32\n0.05\n2.512\n\n\n6\n32\n0.05\n2.399\n\n\n7\n32\n0.05\n2.313\n\n\n8\n32\n0.05\n2.244\n\n\n9\n32\n0.05\n2.189\n\n\n10\n32\n0.05\n2.142\n\n\n1\n33\n0.05\n4.139\n\n\n2\n33\n0.05\n3.285\n\n\n3\n33\n0.05\n2.892\n\n\n4\n33\n0.05\n2.659\n\n\n5\n33\n0.05\n2.503\n\n\n6\n33\n0.05\n2.389\n\n\n7\n33\n0.05\n2.303\n\n\n8\n33\n0.05\n2.235\n\n\n9\n33\n0.05\n2.179\n\n\n10\n33\n0.05\n2.133\n\n\n1\n34\n0.05\n4.130\n\n\n2\n34\n0.05\n3.276\n\n\n3\n34\n0.05\n2.883\n\n\n4\n34\n0.05\n2.650\n\n\n5\n34\n0.05\n2.494\n\n\n6\n34\n0.05\n2.380\n\n\n7\n34\n0.05\n2.294\n\n\n8\n34\n0.05\n2.225\n\n\n9\n34\n0.05\n2.170\n\n\n10\n34\n0.05\n2.123\n\n\n1\n35\n0.05\n4.121\n\n\n2\n35\n0.05\n3.267\n\n\n3\n35\n0.05\n2.874\n\n\n4\n35\n0.05\n2.641\n\n\n5\n35\n0.05\n2.485\n\n\n6\n35\n0.05\n2.372\n\n\n7\n35\n0.05\n2.285\n\n\n8\n35\n0.05\n2.217\n\n\n9\n35\n0.05\n2.161\n\n\n10\n35\n0.05\n2.114\n\n\n1\n36\n0.05\n4.113\n\n\n2\n36\n0.05\n3.259\n\n\n3\n36\n0.05\n2.866\n\n\n4\n36\n0.05\n2.634\n\n\n5\n36\n0.05\n2.477\n\n\n6\n36\n0.05\n2.364\n\n\n7\n36\n0.05\n2.277\n\n\n8\n36\n0.05\n2.209\n\n\n9\n36\n0.05\n2.153\n\n\n10\n36\n0.05\n2.106\n\n\n1\n37\n0.05\n4.105\n\n\n2\n37\n0.05\n3.252\n\n\n3\n37\n0.05\n2.859\n\n\n4\n37\n0.05\n2.626\n\n\n5\n37\n0.05\n2.470\n\n\n6\n37\n0.05\n2.356\n\n\n7\n37\n0.05\n2.270\n\n\n8\n37\n0.05\n2.201\n\n\n9\n37\n0.05\n2.145\n\n\n10\n37\n0.05\n2.098\n\n\n1\n38\n0.05\n4.098\n\n\n2\n38\n0.05\n3.245\n\n\n3\n38\n0.05\n2.852\n\n\n4\n38\n0.05\n2.619\n\n\n5\n38\n0.05\n2.463\n\n\n6\n38\n0.05\n2.349\n\n\n7\n38\n0.05\n2.262\n\n\n8\n38\n0.05\n2.194\n\n\n9\n38\n0.05\n2.138\n\n\n10\n38\n0.05\n2.091\n\n\n1\n39\n0.05\n4.091\n\n\n2\n39\n0.05\n3.238\n\n\n3\n39\n0.05\n2.845\n\n\n4\n39\n0.05\n2.612\n\n\n5\n39\n0.05\n2.456\n\n\n6\n39\n0.05\n2.342\n\n\n7\n39\n0.05\n2.255\n\n\n8\n39\n0.05\n2.187\n\n\n9\n39\n0.05\n2.131\n\n\n10\n39\n0.05\n2.084\n\n\n1\n40\n0.05\n4.085\n\n\n2\n40\n0.05\n3.232\n\n\n3\n40\n0.05\n2.839\n\n\n4\n40\n0.05\n2.606\n\n\n5\n40\n0.05\n2.449\n\n\n6\n40\n0.05\n2.336\n\n\n7\n40\n0.05\n2.249\n\n\n8\n40\n0.05\n2.180\n\n\n9\n40\n0.05\n2.124\n\n\n10\n40\n0.05\n2.077\n\n\n1\n41\n0.05\n4.079\n\n\n2\n41\n0.05\n3.226\n\n\n3\n41\n0.05\n2.833\n\n\n4\n41\n0.05\n2.600\n\n\n5\n41\n0.05\n2.443\n\n\n6\n41\n0.05\n2.330\n\n\n7\n41\n0.05\n2.243\n\n\n8\n41\n0.05\n2.174\n\n\n9\n41\n0.05\n2.118\n\n\n10\n41\n0.05\n2.071\n\n\n1\n42\n0.05\n4.073\n\n\n2\n42\n0.05\n3.220\n\n\n3\n42\n0.05\n2.827\n\n\n4\n42\n0.05\n2.594\n\n\n5\n42\n0.05\n2.438\n\n\n6\n42\n0.05\n2.324\n\n\n7\n42\n0.05\n2.237\n\n\n8\n42\n0.05\n2.168\n\n\n9\n42\n0.05\n2.112\n\n\n10\n42\n0.05\n2.065\n\n\n1\n43\n0.05\n4.067\n\n\n2\n43\n0.05\n3.214\n\n\n3\n43\n0.05\n2.822\n\n\n4\n43\n0.05\n2.589\n\n\n5\n43\n0.05\n2.432\n\n\n6\n43\n0.05\n2.318\n\n\n7\n43\n0.05\n2.232\n\n\n8\n43\n0.05\n2.163\n\n\n9\n43\n0.05\n2.106\n\n\n10\n43\n0.05\n2.059\n\n\n1\n44\n0.05\n4.062\n\n\n2\n44\n0.05\n3.209\n\n\n3\n44\n0.05\n2.816\n\n\n4\n44\n0.05\n2.584\n\n\n5\n44\n0.05\n2.427\n\n\n6\n44\n0.05\n2.313\n\n\n7\n44\n0.05\n2.226\n\n\n8\n44\n0.05\n2.157\n\n\n9\n44\n0.05\n2.101\n\n\n10\n44\n0.05\n2.054\n\n\n1\n45\n0.05\n4.057\n\n\n2\n45\n0.05\n3.204\n\n\n3\n45\n0.05\n2.812\n\n\n4\n45\n0.05\n2.579\n\n\n5\n45\n0.05\n2.422\n\n\n6\n45\n0.05\n2.308\n\n\n7\n45\n0.05\n2.221\n\n\n8\n45\n0.05\n2.152\n\n\n9\n45\n0.05\n2.096\n\n\n10\n45\n0.05\n2.049\n\n\n1\n46\n0.05\n4.052\n\n\n2\n46\n0.05\n3.200\n\n\n3\n46\n0.05\n2.807\n\n\n4\n46\n0.05\n2.574\n\n\n5\n46\n0.05\n2.417\n\n\n6\n46\n0.05\n2.304\n\n\n7\n46\n0.05\n2.216\n\n\n8\n46\n0.05\n2.147\n\n\n9\n46\n0.05\n2.091\n\n\n10\n46\n0.05\n2.044\n\n\n1\n47\n0.05\n4.047\n\n\n2\n47\n0.05\n3.195\n\n\n3\n47\n0.05\n2.802\n\n\n4\n47\n0.05\n2.570\n\n\n5\n47\n0.05\n2.413\n\n\n6\n47\n0.05\n2.299\n\n\n7\n47\n0.05\n2.212\n\n\n8\n47\n0.05\n2.143\n\n\n9\n47\n0.05\n2.086\n\n\n10\n47\n0.05\n2.039\n\n\n1\n48\n0.05\n4.043\n\n\n2\n48\n0.05\n3.191\n\n\n3\n48\n0.05\n2.798\n\n\n4\n48\n0.05\n2.565\n\n\n5\n48\n0.05\n2.409\n\n\n6\n48\n0.05\n2.295\n\n\n7\n48\n0.05\n2.207\n\n\n8\n48\n0.05\n2.138\n\n\n9\n48\n0.05\n2.082\n\n\n10\n48\n0.05\n2.035\n\n\n1\n49\n0.05\n4.038\n\n\n2\n49\n0.05\n3.187\n\n\n3\n49\n0.05\n2.794\n\n\n4\n49\n0.05\n2.561\n\n\n5\n49\n0.05\n2.404\n\n\n6\n49\n0.05\n2.290\n\n\n7\n49\n0.05\n2.203\n\n\n8\n49\n0.05\n2.134\n\n\n9\n49\n0.05\n2.077\n\n\n10\n49\n0.05\n2.030\n\n\n1\n50\n0.05\n4.034\n\n\n2\n50\n0.05\n3.183\n\n\n3\n50\n0.05\n2.790\n\n\n4\n50\n0.05\n2.557\n\n\n5\n50\n0.05\n2.400\n\n\n6\n50\n0.05\n2.286\n\n\n7\n50\n0.05\n2.199\n\n\n8\n50\n0.05\n2.130\n\n\n9\n50\n0.05\n2.073\n\n\n10\n50\n0.05\n2.026\n\n\n1\n1\n0.01\n4052.181\n\n\n2\n1\n0.01\n4999.500\n\n\n3\n1\n0.01\n5403.352\n\n\n4\n1\n0.01\n5624.583\n\n\n5\n1\n0.01\n5763.650\n\n\n6\n1\n0.01\n5858.986\n\n\n7\n1\n0.01\n5928.356\n\n\n8\n1\n0.01\n5981.070\n\n\n9\n1\n0.01\n6022.473\n\n\n10\n1\n0.01\n6055.847\n\n\n1\n2\n0.01\n98.503\n\n\n2\n2\n0.01\n99.000\n\n\n3\n2\n0.01\n99.166\n\n\n4\n2\n0.01\n99.249\n\n\n5\n2\n0.01\n99.299\n\n\n6\n2\n0.01\n99.333\n\n\n7\n2\n0.01\n99.356\n\n\n8\n2\n0.01\n99.374\n\n\n9\n2\n0.01\n99.388\n\n\n10\n2\n0.01\n99.399\n\n\n1\n3\n0.01\n34.116\n\n\n2\n3\n0.01\n30.817\n\n\n3\n3\n0.01\n29.457\n\n\n4\n3\n0.01\n28.710\n\n\n5\n3\n0.01\n28.237\n\n\n6\n3\n0.01\n27.911\n\n\n7\n3\n0.01\n27.672\n\n\n8\n3\n0.01\n27.489\n\n\n9\n3\n0.01\n27.345\n\n\n10\n3\n0.01\n27.229\n\n\n1\n4\n0.01\n21.198\n\n\n2\n4\n0.01\n18.000\n\n\n3\n4\n0.01\n16.694\n\n\n4\n4\n0.01\n15.977\n\n\n5\n4\n0.01\n15.522\n\n\n6\n4\n0.01\n15.207\n\n\n7\n4\n0.01\n14.976\n\n\n8\n4\n0.01\n14.799\n\n\n9\n4\n0.01\n14.659\n\n\n10\n4\n0.01\n14.546\n\n\n1\n5\n0.01\n16.258\n\n\n2\n5\n0.01\n13.274\n\n\n3\n5\n0.01\n12.060\n\n\n4\n5\n0.01\n11.392\n\n\n5\n5\n0.01\n10.967\n\n\n6\n5\n0.01\n10.672\n\n\n7\n5\n0.01\n10.456\n\n\n8\n5\n0.01\n10.289\n\n\n9\n5\n0.01\n10.158\n\n\n10\n5\n0.01\n10.051\n\n\n1\n6\n0.01\n13.745\n\n\n2\n6\n0.01\n10.925\n\n\n3\n6\n0.01\n9.780\n\n\n4\n6\n0.01\n9.148\n\n\n5\n6\n0.01\n8.746\n\n\n6\n6\n0.01\n8.466\n\n\n7\n6\n0.01\n8.260\n\n\n8\n6\n0.01\n8.102\n\n\n9\n6\n0.01\n7.976\n\n\n10\n6\n0.01\n7.874\n\n\n1\n7\n0.01\n12.246\n\n\n2\n7\n0.01\n9.547\n\n\n3\n7\n0.01\n8.451\n\n\n4\n7\n0.01\n7.847\n\n\n5\n7\n0.01\n7.460\n\n\n6\n7\n0.01\n7.191\n\n\n7\n7\n0.01\n6.993\n\n\n8\n7\n0.01\n6.840\n\n\n9\n7\n0.01\n6.719\n\n\n10\n7\n0.01\n6.620\n\n\n1\n8\n0.01\n11.259\n\n\n2\n8\n0.01\n8.649\n\n\n3\n8\n0.01\n7.591\n\n\n4\n8\n0.01\n7.006\n\n\n5\n8\n0.01\n6.632\n\n\n6\n8\n0.01\n6.371\n\n\n7\n8\n0.01\n6.178\n\n\n8\n8\n0.01\n6.029\n\n\n9\n8\n0.01\n5.911\n\n\n10\n8\n0.01\n5.814\n\n\n1\n9\n0.01\n10.561\n\n\n2\n9\n0.01\n8.022\n\n\n3\n9\n0.01\n6.992\n\n\n4\n9\n0.01\n6.422\n\n\n5\n9\n0.01\n6.057\n\n\n6\n9\n0.01\n5.802\n\n\n7\n9\n0.01\n5.613\n\n\n8\n9\n0.01\n5.467\n\n\n9\n9\n0.01\n5.351\n\n\n10\n9\n0.01\n5.257\n\n\n1\n10\n0.01\n10.044\n\n\n2\n10\n0.01\n7.559\n\n\n3\n10\n0.01\n6.552\n\n\n4\n10\n0.01\n5.994\n\n\n5\n10\n0.01\n5.636\n\n\n6\n10\n0.01\n5.386\n\n\n7\n10\n0.01\n5.200\n\n\n8\n10\n0.01\n5.057\n\n\n9\n10\n0.01\n4.942\n\n\n10\n10\n0.01\n4.849\n\n\n1\n11\n0.01\n9.646\n\n\n2\n11\n0.01\n7.206\n\n\n3\n11\n0.01\n6.217\n\n\n4\n11\n0.01\n5.668\n\n\n5\n11\n0.01\n5.316\n\n\n6\n11\n0.01\n5.069\n\n\n7\n11\n0.01\n4.886\n\n\n8\n11\n0.01\n4.744\n\n\n9\n11\n0.01\n4.632\n\n\n10\n11\n0.01\n4.539\n\n\n1\n12\n0.01\n9.330\n\n\n2\n12\n0.01\n6.927\n\n\n3\n12\n0.01\n5.953\n\n\n4\n12\n0.01\n5.412\n\n\n5\n12\n0.01\n5.064\n\n\n6\n12\n0.01\n4.821\n\n\n7\n12\n0.01\n4.640\n\n\n8\n12\n0.01\n4.499\n\n\n9\n12\n0.01\n4.388\n\n\n10\n12\n0.01\n4.296\n\n\n1\n13\n0.01\n9.074\n\n\n2\n13\n0.01\n6.701\n\n\n3\n13\n0.01\n5.739\n\n\n4\n13\n0.01\n5.205\n\n\n5\n13\n0.01\n4.862\n\n\n6\n13\n0.01\n4.620\n\n\n7\n13\n0.01\n4.441\n\n\n8\n13\n0.01\n4.302\n\n\n9\n13\n0.01\n4.191\n\n\n10\n13\n0.01\n4.100\n\n\n1\n14\n0.01\n8.862\n\n\n2\n14\n0.01\n6.515\n\n\n3\n14\n0.01\n5.564\n\n\n4\n14\n0.01\n5.035\n\n\n5\n14\n0.01\n4.695\n\n\n6\n14\n0.01\n4.456\n\n\n7\n14\n0.01\n4.278\n\n\n8\n14\n0.01\n4.140\n\n\n9\n14\n0.01\n4.030\n\n\n10\n14\n0.01\n3.939\n\n\n1\n15\n0.01\n8.683\n\n\n2\n15\n0.01\n6.359\n\n\n3\n15\n0.01\n5.417\n\n\n4\n15\n0.01\n4.893\n\n\n5\n15\n0.01\n4.556\n\n\n6\n15\n0.01\n4.318\n\n\n7\n15\n0.01\n4.142\n\n\n8\n15\n0.01\n4.004\n\n\n9\n15\n0.01\n3.895\n\n\n10\n15\n0.01\n3.805\n\n\n1\n16\n0.01\n8.531\n\n\n2\n16\n0.01\n6.226\n\n\n3\n16\n0.01\n5.292\n\n\n4\n16\n0.01\n4.773\n\n\n5\n16\n0.01\n4.437\n\n\n6\n16\n0.01\n4.202\n\n\n7\n16\n0.01\n4.026\n\n\n8\n16\n0.01\n3.890\n\n\n9\n16\n0.01\n3.780\n\n\n10\n16\n0.01\n3.691\n\n\n1\n17\n0.01\n8.400\n\n\n2\n17\n0.01\n6.112\n\n\n3\n17\n0.01\n5.185\n\n\n4\n17\n0.01\n4.669\n\n\n5\n17\n0.01\n4.336\n\n\n6\n17\n0.01\n4.102\n\n\n7\n17\n0.01\n3.927\n\n\n8\n17\n0.01\n3.791\n\n\n9\n17\n0.01\n3.682\n\n\n10\n17\n0.01\n3.593\n\n\n1\n18\n0.01\n8.285\n\n\n2\n18\n0.01\n6.013\n\n\n3\n18\n0.01\n5.092\n\n\n4\n18\n0.01\n4.579\n\n\n5\n18\n0.01\n4.248\n\n\n6\n18\n0.01\n4.015\n\n\n7\n18\n0.01\n3.841\n\n\n8\n18\n0.01\n3.705\n\n\n9\n18\n0.01\n3.597\n\n\n10\n18\n0.01\n3.508\n\n\n1\n19\n0.01\n8.185\n\n\n2\n19\n0.01\n5.926\n\n\n3\n19\n0.01\n5.010\n\n\n4\n19\n0.01\n4.500\n\n\n5\n19\n0.01\n4.171\n\n\n6\n19\n0.01\n3.939\n\n\n7\n19\n0.01\n3.765\n\n\n8\n19\n0.01\n3.631\n\n\n9\n19\n0.01\n3.523\n\n\n10\n19\n0.01\n3.434\n\n\n1\n20\n0.01\n8.096\n\n\n2\n20\n0.01\n5.849\n\n\n3\n20\n0.01\n4.938\n\n\n4\n20\n0.01\n4.431\n\n\n5\n20\n0.01\n4.103\n\n\n6\n20\n0.01\n3.871\n\n\n7\n20\n0.01\n3.699\n\n\n8\n20\n0.01\n3.564\n\n\n9\n20\n0.01\n3.457\n\n\n10\n20\n0.01\n3.368\n\n\n1\n21\n0.01\n8.017\n\n\n2\n21\n0.01\n5.780\n\n\n3\n21\n0.01\n4.874\n\n\n4\n21\n0.01\n4.369\n\n\n5\n21\n0.01\n4.042\n\n\n6\n21\n0.01\n3.812\n\n\n7\n21\n0.01\n3.640\n\n\n8\n21\n0.01\n3.506\n\n\n9\n21\n0.01\n3.398\n\n\n10\n21\n0.01\n3.310\n\n\n1\n22\n0.01\n7.945\n\n\n2\n22\n0.01\n5.719\n\n\n3\n22\n0.01\n4.817\n\n\n4\n22\n0.01\n4.313\n\n\n5\n22\n0.01\n3.988\n\n\n6\n22\n0.01\n3.758\n\n\n7\n22\n0.01\n3.587\n\n\n8\n22\n0.01\n3.453\n\n\n9\n22\n0.01\n3.346\n\n\n10\n22\n0.01\n3.258\n\n\n1\n23\n0.01\n7.881\n\n\n2\n23\n0.01\n5.664\n\n\n3\n23\n0.01\n4.765\n\n\n4\n23\n0.01\n4.264\n\n\n5\n23\n0.01\n3.939\n\n\n6\n23\n0.01\n3.710\n\n\n7\n23\n0.01\n3.539\n\n\n8\n23\n0.01\n3.406\n\n\n9\n23\n0.01\n3.299\n\n\n10\n23\n0.01\n3.211\n\n\n1\n24\n0.01\n7.823\n\n\n2\n24\n0.01\n5.614\n\n\n3\n24\n0.01\n4.718\n\n\n4\n24\n0.01\n4.218\n\n\n5\n24\n0.01\n3.895\n\n\n6\n24\n0.01\n3.667\n\n\n7\n24\n0.01\n3.496\n\n\n8\n24\n0.01\n3.363\n\n\n9\n24\n0.01\n3.256\n\n\n10\n24\n0.01\n3.168\n\n\n1\n25\n0.01\n7.770\n\n\n2\n25\n0.01\n5.568\n\n\n3\n25\n0.01\n4.675\n\n\n4\n25\n0.01\n4.177\n\n\n5\n25\n0.01\n3.855\n\n\n6\n25\n0.01\n3.627\n\n\n7\n25\n0.01\n3.457\n\n\n8\n25\n0.01\n3.324\n\n\n9\n25\n0.01\n3.217\n\n\n10\n25\n0.01\n3.129\n\n\n1\n26\n0.01\n7.721\n\n\n2\n26\n0.01\n5.526\n\n\n3\n26\n0.01\n4.637\n\n\n4\n26\n0.01\n4.140\n\n\n5\n26\n0.01\n3.818\n\n\n6\n26\n0.01\n3.591\n\n\n7\n26\n0.01\n3.421\n\n\n8\n26\n0.01\n3.288\n\n\n9\n26\n0.01\n3.182\n\n\n10\n26\n0.01\n3.094\n\n\n1\n27\n0.01\n7.677\n\n\n2\n27\n0.01\n5.488\n\n\n3\n27\n0.01\n4.601\n\n\n4\n27\n0.01\n4.106\n\n\n5\n27\n0.01\n3.785\n\n\n6\n27\n0.01\n3.558\n\n\n7\n27\n0.01\n3.388\n\n\n8\n27\n0.01\n3.256\n\n\n9\n27\n0.01\n3.149\n\n\n10\n27\n0.01\n3.062\n\n\n1\n28\n0.01\n7.636\n\n\n2\n28\n0.01\n5.453\n\n\n3\n28\n0.01\n4.568\n\n\n4\n28\n0.01\n4.074\n\n\n5\n28\n0.01\n3.754\n\n\n6\n28\n0.01\n3.528\n\n\n7\n28\n0.01\n3.358\n\n\n8\n28\n0.01\n3.226\n\n\n9\n28\n0.01\n3.120\n\n\n10\n28\n0.01\n3.032\n\n\n1\n29\n0.01\n7.598\n\n\n2\n29\n0.01\n5.420\n\n\n3\n29\n0.01\n4.538\n\n\n4\n29\n0.01\n4.045\n\n\n5\n29\n0.01\n3.725\n\n\n6\n29\n0.01\n3.499\n\n\n7\n29\n0.01\n3.330\n\n\n8\n29\n0.01\n3.198\n\n\n9\n29\n0.01\n3.092\n\n\n10\n29\n0.01\n3.005\n\n\n1\n30\n0.01\n7.562\n\n\n2\n30\n0.01\n5.390\n\n\n3\n30\n0.01\n4.510\n\n\n4\n30\n0.01\n4.018\n\n\n5\n30\n0.01\n3.699\n\n\n6\n30\n0.01\n3.473\n\n\n7\n30\n0.01\n3.304\n\n\n8\n30\n0.01\n3.173\n\n\n9\n30\n0.01\n3.067\n\n\n10\n30\n0.01\n2.979\n\n\n1\n31\n0.01\n7.530\n\n\n2\n31\n0.01\n5.362\n\n\n3\n31\n0.01\n4.484\n\n\n4\n31\n0.01\n3.993\n\n\n5\n31\n0.01\n3.675\n\n\n6\n31\n0.01\n3.449\n\n\n7\n31\n0.01\n3.281\n\n\n8\n31\n0.01\n3.149\n\n\n9\n31\n0.01\n3.043\n\n\n10\n31\n0.01\n2.955\n\n\n1\n32\n0.01\n7.499\n\n\n2\n32\n0.01\n5.336\n\n\n3\n32\n0.01\n4.459\n\n\n4\n32\n0.01\n3.969\n\n\n5\n32\n0.01\n3.652\n\n\n6\n32\n0.01\n3.427\n\n\n7\n32\n0.01\n3.258\n\n\n8\n32\n0.01\n3.127\n\n\n9\n32\n0.01\n3.021\n\n\n10\n32\n0.01\n2.934\n\n\n1\n33\n0.01\n7.471\n\n\n2\n33\n0.01\n5.312\n\n\n3\n33\n0.01\n4.437\n\n\n4\n33\n0.01\n3.948\n\n\n5\n33\n0.01\n3.630\n\n\n6\n33\n0.01\n3.406\n\n\n7\n33\n0.01\n3.238\n\n\n8\n33\n0.01\n3.106\n\n\n9\n33\n0.01\n3.000\n\n\n10\n33\n0.01\n2.913\n\n\n1\n34\n0.01\n7.444\n\n\n2\n34\n0.01\n5.289\n\n\n3\n34\n0.01\n4.416\n\n\n4\n34\n0.01\n3.927\n\n\n5\n34\n0.01\n3.611\n\n\n6\n34\n0.01\n3.386\n\n\n7\n34\n0.01\n3.218\n\n\n8\n34\n0.01\n3.087\n\n\n9\n34\n0.01\n2.981\n\n\n10\n34\n0.01\n2.894\n\n\n1\n35\n0.01\n7.419\n\n\n2\n35\n0.01\n5.268\n\n\n3\n35\n0.01\n4.396\n\n\n4\n35\n0.01\n3.908\n\n\n5\n35\n0.01\n3.592\n\n\n6\n35\n0.01\n3.368\n\n\n7\n35\n0.01\n3.200\n\n\n8\n35\n0.01\n3.069\n\n\n9\n35\n0.01\n2.963\n\n\n10\n35\n0.01\n2.876\n\n\n1\n36\n0.01\n7.396\n\n\n2\n36\n0.01\n5.248\n\n\n3\n36\n0.01\n4.377\n\n\n4\n36\n0.01\n3.890\n\n\n5\n36\n0.01\n3.574\n\n\n6\n36\n0.01\n3.351\n\n\n7\n36\n0.01\n3.183\n\n\n8\n36\n0.01\n3.052\n\n\n9\n36\n0.01\n2.946\n\n\n10\n36\n0.01\n2.859\n\n\n1\n37\n0.01\n7.373\n\n\n2\n37\n0.01\n5.229\n\n\n3\n37\n0.01\n4.360\n\n\n4\n37\n0.01\n3.873\n\n\n5\n37\n0.01\n3.558\n\n\n6\n37\n0.01\n3.334\n\n\n7\n37\n0.01\n3.167\n\n\n8\n37\n0.01\n3.036\n\n\n9\n37\n0.01\n2.930\n\n\n10\n37\n0.01\n2.843\n\n\n1\n38\n0.01\n7.353\n\n\n2\n38\n0.01\n5.211\n\n\n3\n38\n0.01\n4.343\n\n\n4\n38\n0.01\n3.858\n\n\n5\n38\n0.01\n3.542\n\n\n6\n38\n0.01\n3.319\n\n\n7\n38\n0.01\n3.152\n\n\n8\n38\n0.01\n3.021\n\n\n9\n38\n0.01\n2.915\n\n\n10\n38\n0.01\n2.828\n\n\n1\n39\n0.01\n7.333\n\n\n2\n39\n0.01\n5.194\n\n\n3\n39\n0.01\n4.327\n\n\n4\n39\n0.01\n3.843\n\n\n5\n39\n0.01\n3.528\n\n\n6\n39\n0.01\n3.305\n\n\n7\n39\n0.01\n3.137\n\n\n8\n39\n0.01\n3.006\n\n\n9\n39\n0.01\n2.901\n\n\n10\n39\n0.01\n2.814\n\n\n1\n40\n0.01\n7.314\n\n\n2\n40\n0.01\n5.179\n\n\n3\n40\n0.01\n4.313\n\n\n4\n40\n0.01\n3.828\n\n\n5\n40\n0.01\n3.514\n\n\n6\n40\n0.01\n3.291\n\n\n7\n40\n0.01\n3.124\n\n\n8\n40\n0.01\n2.993\n\n\n9\n40\n0.01\n2.888\n\n\n10\n40\n0.01\n2.801\n\n\n1\n41\n0.01\n7.296\n\n\n2\n41\n0.01\n5.163\n\n\n3\n41\n0.01\n4.299\n\n\n4\n41\n0.01\n3.815\n\n\n5\n41\n0.01\n3.501\n\n\n6\n41\n0.01\n3.278\n\n\n7\n41\n0.01\n3.111\n\n\n8\n41\n0.01\n2.980\n\n\n9\n41\n0.01\n2.875\n\n\n10\n41\n0.01\n2.788\n\n\n1\n42\n0.01\n7.280\n\n\n2\n42\n0.01\n5.149\n\n\n3\n42\n0.01\n4.285\n\n\n4\n42\n0.01\n3.802\n\n\n5\n42\n0.01\n3.488\n\n\n6\n42\n0.01\n3.266\n\n\n7\n42\n0.01\n3.099\n\n\n8\n42\n0.01\n2.968\n\n\n9\n42\n0.01\n2.863\n\n\n10\n42\n0.01\n2.776\n\n\n1\n43\n0.01\n7.264\n\n\n2\n43\n0.01\n5.136\n\n\n3\n43\n0.01\n4.273\n\n\n4\n43\n0.01\n3.790\n\n\n5\n43\n0.01\n3.476\n\n\n6\n43\n0.01\n3.254\n\n\n7\n43\n0.01\n3.087\n\n\n8\n43\n0.01\n2.957\n\n\n9\n43\n0.01\n2.851\n\n\n10\n43\n0.01\n2.764\n\n\n1\n44\n0.01\n7.248\n\n\n2\n44\n0.01\n5.123\n\n\n3\n44\n0.01\n4.261\n\n\n4\n44\n0.01\n3.778\n\n\n5\n44\n0.01\n3.465\n\n\n6\n44\n0.01\n3.243\n\n\n7\n44\n0.01\n3.076\n\n\n8\n44\n0.01\n2.946\n\n\n9\n44\n0.01\n2.840\n\n\n10\n44\n0.01\n2.754\n\n\n1\n45\n0.01\n7.234\n\n\n2\n45\n0.01\n5.110\n\n\n3\n45\n0.01\n4.249\n\n\n4\n45\n0.01\n3.767\n\n\n5\n45\n0.01\n3.454\n\n\n6\n45\n0.01\n3.232\n\n\n7\n45\n0.01\n3.066\n\n\n8\n45\n0.01\n2.935\n\n\n9\n45\n0.01\n2.830\n\n\n10\n45\n0.01\n2.743\n\n\n1\n46\n0.01\n7.220\n\n\n2\n46\n0.01\n5.099\n\n\n3\n46\n0.01\n4.238\n\n\n4\n46\n0.01\n3.757\n\n\n5\n46\n0.01\n3.444\n\n\n6\n46\n0.01\n3.222\n\n\n7\n46\n0.01\n3.056\n\n\n8\n46\n0.01\n2.925\n\n\n9\n46\n0.01\n2.820\n\n\n10\n46\n0.01\n2.733\n\n\n1\n47\n0.01\n7.207\n\n\n2\n47\n0.01\n5.087\n\n\n3\n47\n0.01\n4.228\n\n\n4\n47\n0.01\n3.747\n\n\n5\n47\n0.01\n3.434\n\n\n6\n47\n0.01\n3.213\n\n\n7\n47\n0.01\n3.046\n\n\n8\n47\n0.01\n2.916\n\n\n9\n47\n0.01\n2.811\n\n\n10\n47\n0.01\n2.724\n\n\n1\n48\n0.01\n7.194\n\n\n2\n48\n0.01\n5.077\n\n\n3\n48\n0.01\n4.218\n\n\n4\n48\n0.01\n3.737\n\n\n5\n48\n0.01\n3.425\n\n\n6\n48\n0.01\n3.204\n\n\n7\n48\n0.01\n3.037\n\n\n8\n48\n0.01\n2.907\n\n\n9\n48\n0.01\n2.802\n\n\n10\n48\n0.01\n2.715\n\n\n1\n49\n0.01\n7.182\n\n\n2\n49\n0.01\n5.066\n\n\n3\n49\n0.01\n4.208\n\n\n4\n49\n0.01\n3.728\n\n\n5\n49\n0.01\n3.416\n\n\n6\n49\n0.01\n3.195\n\n\n7\n49\n0.01\n3.028\n\n\n8\n49\n0.01\n2.898\n\n\n9\n49\n0.01\n2.793\n\n\n10\n49\n0.01\n2.706\n\n\n1\n50\n0.01\n7.171\n\n\n2\n50\n0.01\n5.057\n\n\n3\n50\n0.01\n4.199\n\n\n4\n50\n0.01\n3.720\n\n\n5\n50\n0.01\n3.408\n\n\n6\n50\n0.01\n3.186\n\n\n7\n50\n0.01\n3.020\n\n\n8\n50\n0.01\n2.890\n\n\n9\n50\n0.01\n2.785\n\n\n10\n50\n0.01\n2.698"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html",
    "href": "supplemental/model-selection-criteria.html",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of Akaike’s Information Criterion (AIC) and Schwarz’s Bayesian Information Criterion (BIC). We assume the reader knowledge of the matrix form for multiple linear regression.Please see Matrix Notation for Multiple Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "href": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)",
    "text": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)\nTo understand the formulas for AIC and BIC, we will first briefly explain the likelihood function and maximum likelihood estimates for regression.\nLet \\(\\mathbf{Y}\\) be \\(n \\times 1\\) matrix of responses, \\(\\mathbf{X}\\), the \\(n \\times (p+1)\\) matrix of predictors, and \\(\\boldsymbol{\\beta}\\), \\((p+1) \\times 1\\) matrix of coefficients. If the multiple linear regression model is correct then,\n\\[\n\\mathbf{Y} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2)\n\\tag{1}\\]\nWhen we do linear regression, our goal is to estimate the unknown parameters \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) from Equation 1. In Matrix Notation for Multiple Linear Regression, we showed a way to estimate these parameters using matrix alegbra. Another approach for estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is using maximum likelihood estimation.\nA likelihood function is used to summarise the evidence from the data in support of each possible value of a model parameter. Using Equation 1, we will write the likelihood function for linear regression as\n\\[\nL(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) = \\prod\\limits_{i=1}^n (2\\pi \\sigma^2)^{-\\frac{1}{2}} \\exp\\bigg\\{-\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})\\bigg\\}\n\\tag{2}\\]\nwhere \\(Y_i\\) is the \\(i^{th}\\) response and \\(\\mathbf{X}_i\\) is the vector of predictors for the \\(i^{th}\\) observation. One approach estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is to find the values of those parameters that maximize the likelihood in Equation 2, i.e. maximum likelhood estimation. To make the calculations more manageable, instead of maximizing the likelihood function, we will instead maximize its logarithm, i.e. the log-likelihood function. The values of the parameters that maximize the log-likelihood function are those that maximize the likelihood function. The log-likelihood function we will maximize is\n\\[\n\\begin{aligned}\n\\log L(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) &= \\sum\\limits_{i=1}^n -\\frac{1}{2}\\log(2\\pi\\sigma^2) -\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta}) \\\\\n&= -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\\\\n\\end{aligned}\n\\tag{3}\\]\n\nThe maximum likelihood estimate of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) are \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\hspace{10mm} \\hat{\\sigma}^2 = \\frac{1}{n}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta}) = \\frac{1}{n}RSS\n\\tag{4}\\]\nwhere \\(RSS\\) is the residual sum of squares. Note that the maximum likelihood estimate is not exactly equal to the estimate of \\(\\sigma^2\\) we typically use \\(\\frac{RSS}{n-p-1}\\). This is because the maximum likelihood estimate of \\(\\sigma^2\\) in Equation 4 is a biased estimator of \\(\\sigma^2\\). When \\(n\\) is much larger than the number of predictors \\(p\\), then the differences in these two estimates are trivial."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#aic",
    "href": "supplemental/model-selection-criteria.html#aic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "AIC",
    "text": "AIC\nAkaike’s Information Criterion (AIC) is\n\\[\nAIC = -2 \\log L + 2(p+1)\n\\tag{5}\\]\nwhere \\(\\log L\\) is the log-likelihood. This is the general form of AIC that can be applied to a variety of models, but for now, let’s focus on AIC for mutliple linear regression.\n\\[\n\\begin{aligned}\nAIC &= -2 \\log L + 2(p+1) \\\\\n&= -2\\bigg[-\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\bigg] + 2(p+1) \\\\\n&= n\\log\\big(2\\pi\\frac{RSS}{n}\\big) + \\frac{1}{RSS/n}RSS \\\\\n&= n\\log(2\\pi) + n\\log(RSS) - n\\log(n) + 2(p+1)\n\\end{aligned}\n\\tag{6}\\]"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#bic",
    "href": "supplemental/model-selection-criteria.html#bic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "BIC",
    "text": "BIC\n[To be added.]"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Do I have to use jamovi for the statistical analyses that would be demonstrated in this course? How about SPSS?\n\n\nThis course will involve statistical analyses done with jamovi (thejamoviproject2022?) , a free, open source statistical package based on R (rcoreteam2017?). To supplement the course, I will provide links to several resources that cover SPSS (spssinc.2008?), including written and video tutorials. If you learn jamovi, you will be able to transfer your skills to other statistical programs. Jamovi also has a lot of resources available such as guides, manuals, and tutorials."
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "KIN 610 - Learn",
    "section": "",
    "text": "Quiz"
  },
  {
    "objectID": "Untitled.html#practice-questions---week-5",
    "href": "Untitled.html#practice-questions---week-5",
    "title": "KIN 610 - Learn",
    "section": "",
    "text": "Quiz"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "CSUN aims to make all learning experiences as accessible as possible, and has a variety of resources available to help support students. If you believe the design of this course poses barriers to effectively participate or demonstrate your learning, please contact me to discuss possible options and adjustments.\n\nThe IT Help Center (818)677-1400, helpcenter@csun.edu is available to help with Canvas, CSUN e-mail, SOLAR/Portal, and other technical issues.\nCSUN Device Loaner Program (https://bit.ly/3t1G0An) provides devices that can be checked out that includes laptops, webcams, hotspots and headsets\nThe Learning Resource Center (818) 677-2033 The mission of the LRC is to enable students to improve their academic performance through a variety of learning programs, including workshops, one-on-one and group tutoring, supplemental instruction classes and interactive subject area computer programs and videos. Student who use the LRC learning programs will develop and strengthen their critical thinking skills, study strategies, writing skills and performance in subject matter courses.\nUniversity Counseling Services (818) 677-2366, Bayramian Hall 520. UCS provides resources and information to assist students in dealing with a variety of large and small psychological obstacles that may interfere with academic progress and/or relationship satisfaction. Services include individual, group, and crisis counseling.\nIn accordance with the CSUN Accessibility Policy (https://bit.ly/3yqGHE9), CSUN is working to ensure that campus communication and course materials are accessible to everyone. Please reach out to me if you have difficulty with any of the materials for this course.\nIf you have a disability and need accommodations, please register with the Disability Resources and Educational Services (DRES) office or the National Center on Deafness (NCOD).\n\nThe DRES office can be reached at (818) 677-2684.\nNCOD can be reached at (818) 677-2611.\nReasonable accommodations and services will be provided to students if requests are made in a timely manner and with appropriate documentation\nIf you would like to discuss your need for accommodations with me, please drop in office hours or contact me to set up an appointment.\n\nFood Pantry (https://bit.ly/38nTsVH) at CSUN: Anybody who faces challenges securing food or housing and believes this impacts course performance, should contact CSUN’s Food Pantry website and the corresponding contacts. If you also feel comfortable contacting me, the department chair, or the Dean’s Office, we can also facilitate assistance. You don’t have to be alone in this moment.\nEmergency MataCare grants (https://bit.ly/2WAZkIz), one-time grants to prevent evictions, urgent child care issues, etc. - DACA (Deferred Action for Childhood Arrivals) Resources: Check out the Central American Resource Center facebook page (https://bit.ly/2Yg0p9z), legal resources listed on CSUN’s Educational Opportunity Program (EOP) Dream Center that was created to support all undocumented students & allies (Dream Center flyer). CSUN President Harrison issued a support statement on the CSUN homepage for DACA and resources.\nHelp lines (https://bit.ly/3sYbMOo)(after hours when the University Counseling is closed) for numerous topics/needs (e.g., suicide, drug, rape, LGBQT, military, or any crisis). You don’t have to manage these feelings alone.\nPride Center (https://bit.ly/3jqNZUi) offers support and resources to lesbian, gay, bisexual, transgender, queer, & questioning students, faculty, & staff.\nKlotz Student Health Center (https://bit.ly/3zx1Y0s): Numerous health services including primary care, dental, nutritional counseling, acupuncture, massage and lots more.\nCareer Center (https://bit.ly/3jtTcL2) for resume writing & interviewing and much more; Matty’s Closet (https://bit.ly/3jAResx) has free professional clothes for students who need interview or professional attire.\nUSU 9https://bit.ly/38uz59j) for more student services; Clubs & Organizations (https://bit.ly/38tBhOa): Hopefully a dozen people have already advised you to “get involved” (https://bit.ly/3ysqYVb) at CSUN in something that interests you.\nAssociated Students (https://bit.ly/3yuWjGT) offers recycling, and a Children’s Center providing child care\nFinancial Aid & Scholarships (https://bit.ly/3sYFzqr) offers aid for applications\nUniversity Library https://bit.ly/3yuIEQ9) for many additional academic resources\nVeterans Resource Center (https://bit.ly/38qYtg7) assists CSUN students as they transition from military service to academic success.\n\nTitle 5, California Code of Regulations,§ 41301. Standards for Student Conduct – (a) Campus Community Values: The university is committed to maintaining a safe and healthy living and learning environment for students, faculty, and staff. Each member of the campus community should choose behaviors that contribute toward this end. Students are expected to be good citizens and to engage in responsible behaviors that reflect well upon their university, to be civil to one another and to others in the campus community, and contribute positively to student and university life.\nCSUN with A HEART If you are facing challenges related to food insecurity, housing precarity/homelessness, mental health, access to technology, eldercare/childcare, or healthcare, you can find guidance, help, and resources from CSUN with A HEART (https://www.csun.edu/heart).\n\n\nAs a professor, I am committed to providing students with the highest quality of education and support. To this end, I will be offering weekly office hours every Thursday from 2-4 pm or by appointment via Zoom. Additionally, I am readily available to answer questions and provide guidance via email.\nA lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "",
    "text": "As a professor, I am committed to providing students with the highest quality of education and support. To this end, I will be offering weekly office hours every Thursday from 2-4 pm or by appointment via Zoom. Additionally, I am readily available to answer questions and provide guidance via email.\nA lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class."
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Exam 1 will be taken in class.\n\n\n\n\nYou must use a lab computer to complete Exam 1.\nYou can ONLY access:\n\nyour “Déjà vu” folder in Google Drive for notes\nthe course’s site at KIN 610 - Spring 2023 (drfurtado.github.io)\n\n\n\n\n\n\nComplete Exam 1 in class\nSave the Word file (Exam 1 - Par 1) as PDF.\nExport a clean* version of the Output as PDF (Exam 1 - Part 2)\nVisit our course in Canvas to submit both Part 1 and Part 2\n\n\n\n\n\n\n\nAnswerOnly submit what is relevant to each of the 5 questions - delete everything else. Be careful when deleting stuff from the output in jamovi. DO NOT select “ALL”; otherwise, it will delete everything.\n\n\n\n\n\n\n\n\n\n\n\n\nThe following variables have been recorded for each individual:\n\nAge (in years)\nGender (1 = Male, 2 = Female)\nResting eart Rate (RHR, in beats per minute)\nVO2 Max (in mL/kg/min)\nBody Mass Index (BMI)\n\nThe dataset can be found here: physical-fitness.csv\n\n\n\nUsing the provided dataset, complete the following tasks:\n\n\nCalculate N, mean, median, and mode ONLY of the participants’ BMI. Provide the `Descriptives Table` below – use the `variables across rows` format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nCompare the mean, median, and mode ONLY of BMI for male and female participants separately. Provide the `Descriptives Table` below – use the `variables across rows` format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss which measure of central tendency best represents the center of the data for this variable and whether the choice differs between the two gender groups.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWhen data is not normally distributed, the median is often a better measure of central tendency than the mean. The median is the middle number in an ordered dataset. It is less sensitive to outliers and skewed data than the mean. The choice does not differ between the two gender groups as in both cases the distribution of scores for BMI are deviating from normality.\n\n\n\n\n\n\n\nUsing the provided dataset, complete the following tasks:\n\n\nCalculate the range, variance, and standard deviation of the participants’ ages. Provide the Descriptives Table below – use the variables across rows format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nCompare the range, variance, and standard deviation of ages for male and female participants separately. Provide the Descriptives Table below – use the variables across rows format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nWhich of these measures (range, variance, standard deviation) would you include when reporting the data and why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAs stated in class, when the variable is approximating normality, the most appropriate measure of variability is the variance or the standard deviation. The standard deviation has the advantage of representing the variability in the same scale as the variable, in this case, years.\n\n\n\n\n\n\n\n\nUsing the provided dataset, complete the following tasks:\n\n\nCreate a histogram and a Q-Q plot of the participants’ ages. Provide the graphs below (side-by-side).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nBased on these visualizations, assess whether the distribution of ages appears to be normally distributed for the entire dataset and separately for male and female participants.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBased on the visualizations only, it is difficult to tell “ages” (including males and females) is normally distributed. More information is needed.\nWhen splitting by gender, the data for both males and females appear to be deviating from normality. Both histograms are skewed and the dots on the qq-plots are touching the line\n\n\n\n\n\n\nPerform a Shapiro-Wilk test and calculate the zkurt & zskew to further evaluate the normality of the age distribution for the entire dataset and for each gender group and interpret the results. Create a table containing skewness, kurtosis, and the Shapiro-Wilk test and provide it below.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nEntire data: the data is approximating normality based on the zkurt, zskew (values within +- 2.0) and the Shapiro-wilk test (p &gt; .05).\nMale only: the is approximating normality based on the zkurt and zskew (values within +- 2.0) but deviating from normality based on the SW test (p &lt; .05).\nFemale only: same as males (values are slightly different)\n\n\n\n\n\n\n\nUsing the provided dataset, complete the following tasks:\n\n\nCalculate the Pearson’s correlation coefficient between the participants’ ages and their resting heart rates (RHR).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nCalculate the Pearson’s correlation coefficient between the participants’ ages and their RHR separately for male and female participants.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMales\n\nFemales\n\n\n\n\n\n\n\nDescribe the strength and direction of the relationship between these variables for the entire dataset and each gender group and discuss any potential factors that may contribute to the observed correlations.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBased on the criteria discussed in class, the association for both males and females, and gender combined are:\n\npositive and very strong\nsignificant (p &lt; .001)\n\nSome factors that may contribute to the observed results are sample size, outliers, etc.\n\n\n\n\n\n\n\nUsing the provided dataset, complete the following tasks:\n\n\nPerform a simple linear regression analysis with the participants’ VO2 Max as the dependent variable and their BMI as the independent variable.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nClick here to see results\n\n\n\n\n\n\nPerform separate simple linear regression analyses for male and female participants, with VO2 Max as the dependent variable and BMI as the independent variable.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nClick here to see results\n\n\n\nClick here to see results\n\n\n\n\n\n\n\nReport and compare the regression coefficients (slopes), intercepts, and R-squared values for the entire dataset and each gender group. Interpret the results and discuss the implications of these findings for the effectiveness of the physical fitness program for different gender groups\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nSlope: -1.56 bmi index (the change in y that you get when you increase x by 1 unit)\nIntercept: 81.73 (the value of y that you get when x = 0)\n\n\n\nSlope: -1.12 bmi index (the change in y that you get when you increase x by 1 unit)\nIntercept: 72.98 (the value of y that you get when x = 0)\n\n\n\nSlope: -1.67 bmi index (the change in y that you get when you increase x by 1 unit)\nIntercept: 82.67 (the value of y that you get when x = 0)\n\n\n\nThe scatterplot shows the relationship between BMI and VO2max, with each point representing a participant’s BMI and VO2max values. The regression line shows the estimated linear relationship between BMI and VO2max based on the data.\nThe slope of the regression line represents the change in VO2max for a one-unit increase in BMI, holding all other variables constant. In this case, it indicates that for each one-unit increase in BMI, we expect VO2max to decrease by 1.56 units, on average.\nThe intercept of the regression line represents the expected value of VO2max when BMI is equal to zero. However, in this case, it is not meaningful to interpret the intercept in this way, since BMI cannot be equal to zero.\nOverall, these results suggest that there is a negative linear relationship between BMI and VO2max, with higher BMI values associated with lower VO2max values. However, it is important to note that correlation does not imply causation, and there may be other factors that influence the relationship between BMI and VO2max. Additionally, the strength of the relationship and the accuracy of the estimated slope may be assessed using additional statistical metrics, such as R-squared and p-values."
  },
  {
    "objectID": "exams/exam-1.html#overview",
    "href": "exams/exam-1.html#overview",
    "title": "Exam 1",
    "section": "",
    "text": "Exam 1 will be taken in class."
  },
  {
    "objectID": "exams/exam-1.html#requirements-resources",
    "href": "exams/exam-1.html#requirements-resources",
    "title": "Exam 1",
    "section": "",
    "text": "You must use a lab computer to complete Exam 1.\nYou can ONLY access:\n\nyour “Déjà vu” folder in Google Drive for notes\nthe course’s site at KIN 610 - Spring 2023 (drfurtado.github.io)"
  },
  {
    "objectID": "exams/exam-1.html#submission",
    "href": "exams/exam-1.html#submission",
    "title": "Exam 1",
    "section": "",
    "text": "Complete Exam 1 in class\nSave the Word file (Exam 1 - Par 1) as PDF.\nExport a clean* version of the Output as PDF (Exam 1 - Part 2)\nVisit our course in Canvas to submit both Part 1 and Part 2\n\n\n\n\n\n\n\nAnswerOnly submit what is relevant to each of the 5 questions - delete everything else. Be careful when deleting stuff from the output in jamovi. DO NOT select “ALL”; otherwise, it will delete everything."
  },
  {
    "objectID": "exams/exam-1.html#dataset",
    "href": "exams/exam-1.html#dataset",
    "title": "Exam 1",
    "section": "",
    "text": "The following variables have been recorded for each individual:\n\nAge (in years)\nGender (1 = Male, 2 = Female)\nResting eart Rate (RHR, in beats per minute)\nVO2 Max (in mL/kg/min)\nBody Mass Index (BMI)\n\nThe dataset can be found here: physical-fitness.csv"
  },
  {
    "objectID": "exams/exam-1.html#measures-of-central-tendency-20-pts.",
    "href": "exams/exam-1.html#measures-of-central-tendency-20-pts.",
    "title": "Exam 1",
    "section": "",
    "text": "Using the provided dataset, complete the following tasks:\n\n\nCalculate N, mean, median, and mode ONLY of the participants’ BMI. Provide the `Descriptives Table` below – use the `variables across rows` format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nCompare the mean, median, and mode ONLY of BMI for male and female participants separately. Provide the `Descriptives Table` below – use the `variables across rows` format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss which measure of central tendency best represents the center of the data for this variable and whether the choice differs between the two gender groups.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWhen data is not normally distributed, the median is often a better measure of central tendency than the mean. The median is the middle number in an ordered dataset. It is less sensitive to outliers and skewed data than the mean. The choice does not differ between the two gender groups as in both cases the distribution of scores for BMI are deviating from normality."
  },
  {
    "objectID": "exams/exam-1.html#measures-of-variability-20-pts.",
    "href": "exams/exam-1.html#measures-of-variability-20-pts.",
    "title": "Exam 1",
    "section": "",
    "text": "Using the provided dataset, complete the following tasks:\n\n\nCalculate the range, variance, and standard deviation of the participants’ ages. Provide the Descriptives Table below – use the variables across rows format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nCompare the range, variance, and standard deviation of ages for male and female participants separately. Provide the Descriptives Table below – use the variables across rows format.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nWhich of these measures (range, variance, standard deviation) would you include when reporting the data and why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAs stated in class, when the variable is approximating normality, the most appropriate measure of variability is the variance or the standard deviation. The standard deviation has the advantage of representing the variability in the same scale as the variable, in this case, years."
  },
  {
    "objectID": "exams/exam-1.html#normality-and-displaying-data-20-pts.",
    "href": "exams/exam-1.html#normality-and-displaying-data-20-pts.",
    "title": "Exam 1",
    "section": "",
    "text": "Using the provided dataset, complete the following tasks:\n\n\nCreate a histogram and a Q-Q plot of the participants’ ages. Provide the graphs below (side-by-side).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nBased on these visualizations, assess whether the distribution of ages appears to be normally distributed for the entire dataset and separately for male and female participants.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBased on the visualizations only, it is difficult to tell “ages” (including males and females) is normally distributed. More information is needed.\nWhen splitting by gender, the data for both males and females appear to be deviating from normality. Both histograms are skewed and the dots on the qq-plots are touching the line\n\n\n\n\n\n\nPerform a Shapiro-Wilk test and calculate the zkurt & zskew to further evaluate the normality of the age distribution for the entire dataset and for each gender group and interpret the results. Create a table containing skewness, kurtosis, and the Shapiro-Wilk test and provide it below.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nEntire data: the data is approximating normality based on the zkurt, zskew (values within +- 2.0) and the Shapiro-wilk test (p &gt; .05).\nMale only: the is approximating normality based on the zkurt and zskew (values within +- 2.0) but deviating from normality based on the SW test (p &lt; .05).\nFemale only: same as males (values are slightly different)"
  },
  {
    "objectID": "exams/exam-1.html#correlation-20-pts.",
    "href": "exams/exam-1.html#correlation-20-pts.",
    "title": "Exam 1",
    "section": "",
    "text": "Using the provided dataset, complete the following tasks:\n\n\nCalculate the Pearson’s correlation coefficient between the participants’ ages and their resting heart rates (RHR).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nCalculate the Pearson’s correlation coefficient between the participants’ ages and their RHR separately for male and female participants.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMales\n\nFemales\n\n\n\n\n\n\n\nDescribe the strength and direction of the relationship between these variables for the entire dataset and each gender group and discuss any potential factors that may contribute to the observed correlations.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBased on the criteria discussed in class, the association for both males and females, and gender combined are:\n\npositive and very strong\nsignificant (p &lt; .001)\n\nSome factors that may contribute to the observed results are sample size, outliers, etc."
  },
  {
    "objectID": "exams/exam-1.html#simple-linear-regression-20-pts.",
    "href": "exams/exam-1.html#simple-linear-regression-20-pts.",
    "title": "Exam 1",
    "section": "",
    "text": "Using the provided dataset, complete the following tasks:\n\n\nPerform a simple linear regression analysis with the participants’ VO2 Max as the dependent variable and their BMI as the independent variable.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nClick here to see results\n\n\n\n\n\n\nPerform separate simple linear regression analyses for male and female participants, with VO2 Max as the dependent variable and BMI as the independent variable.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nClick here to see results\n\n\n\nClick here to see results\n\n\n\n\n\n\n\nReport and compare the regression coefficients (slopes), intercepts, and R-squared values for the entire dataset and each gender group. Interpret the results and discuss the implications of these findings for the effectiveness of the physical fitness program for different gender groups\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nSlope: -1.56 bmi index (the change in y that you get when you increase x by 1 unit)\nIntercept: 81.73 (the value of y that you get when x = 0)\n\n\n\nSlope: -1.12 bmi index (the change in y that you get when you increase x by 1 unit)\nIntercept: 72.98 (the value of y that you get when x = 0)\n\n\n\nSlope: -1.67 bmi index (the change in y that you get when you increase x by 1 unit)\nIntercept: 82.67 (the value of y that you get when x = 0)\n\n\n\nThe scatterplot shows the relationship between BMI and VO2max, with each point representing a participant’s BMI and VO2max values. The regression line shows the estimated linear relationship between BMI and VO2max based on the data.\nThe slope of the regression line represents the change in VO2max for a one-unit increase in BMI, holding all other variables constant. In this case, it indicates that for each one-unit increase in BMI, we expect VO2max to decrease by 1.56 units, on average.\nThe intercept of the regression line represents the expected value of VO2max when BMI is equal to zero. However, in this case, it is not meaningful to interpret the intercept in this way, since BMI cannot be equal to zero.\nOverall, these results suggest that there is a negative linear relationship between BMI and VO2max, with higher BMI values associated with lower VO2max values. However, it is important to note that correlation does not imply causation, and there may be other factors that influence the relationship between BMI and VO2max. Additionally, the strength of the relationship and the accuracy of the estimated slope may be assessed using additional statistical metrics, such as R-squared and p-values."
  },
  {
    "objectID": "exams/final-review.html",
    "href": "exams/final-review.html",
    "title": "Final Review",
    "section": "",
    "text": "t-test: The t-test is a statistical test used to compare the means of two groups. It helps determine whether there is a significant difference between the means of the two groups.\n\nOne-samples t-test: used when there is one group that needs to be compared to population value.\nIndependent samples t-test: used when the two groups being compared are independent (e.g., comparing the mean strength of two different groups of athletes)\nPaired samples t-test: used when the two groups being compared are dependent or related (e.g., comparing the mean strength of the same group of athletes before and after a training program)\n\nOne-way ANOVA: One-way Analysis of Variance (ANOVA) is used to compare the means of three or more groups. It tests the null hypothesis that all group means are equal. If the p-value is less than the chosen significance level, the null hypothesis can be rejected, indicating that there is a significant difference between at least two of the groups.\nRepeated measures ANOVA: Repeated measures ANOVA is used to analyze data when the same participants are measured multiple times under different conditions or at different time points. This test takes into account the within-subject variability and is useful in determining whether there is a significant effect of the different conditions or time points on the dependent variable.\nBetween and within subjects ANOVA: This type of ANOVA is used when there are both between-subjects factors and within-subjects factors in an experiment. It allows you to analyze the main effects and interactions of these factors on the dependent variable.\nNonparametric tests: Nonparametric tests are used when the assumptions of parametric tests (e.g., normality, equal variances) are not met. Examples of nonparametric tests that can be used as alternatives to the tests above include:\n\nMann-Whitney U test: a nonparametric alternative to the independent samples t-test\nWilcoxon signed-rank test: a nonparametric alternative to the paired samples t-test\nKruskal-Wallis H test: a nonparametric alternative to the one-way ANOVA\nFriedman test: a nonparametric alternative to the repeated measures ANOVA"
  },
  {
    "objectID": "exams/final-review.html#overview",
    "href": "exams/final-review.html#overview",
    "title": "Final Review",
    "section": "",
    "text": "t-test: The t-test is a statistical test used to compare the means of two groups. It helps determine whether there is a significant difference between the means of the two groups.\n\nOne-samples t-test: used when there is one group that needs to be compared to population value.\nIndependent samples t-test: used when the two groups being compared are independent (e.g., comparing the mean strength of two different groups of athletes)\nPaired samples t-test: used when the two groups being compared are dependent or related (e.g., comparing the mean strength of the same group of athletes before and after a training program)\n\nOne-way ANOVA: One-way Analysis of Variance (ANOVA) is used to compare the means of three or more groups. It tests the null hypothesis that all group means are equal. If the p-value is less than the chosen significance level, the null hypothesis can be rejected, indicating that there is a significant difference between at least two of the groups.\nRepeated measures ANOVA: Repeated measures ANOVA is used to analyze data when the same participants are measured multiple times under different conditions or at different time points. This test takes into account the within-subject variability and is useful in determining whether there is a significant effect of the different conditions or time points on the dependent variable.\nBetween and within subjects ANOVA: This type of ANOVA is used when there are both between-subjects factors and within-subjects factors in an experiment. It allows you to analyze the main effects and interactions of these factors on the dependent variable.\nNonparametric tests: Nonparametric tests are used when the assumptions of parametric tests (e.g., normality, equal variances) are not met. Examples of nonparametric tests that can be used as alternatives to the tests above include:\n\nMann-Whitney U test: a nonparametric alternative to the independent samples t-test\nWilcoxon signed-rank test: a nonparametric alternative to the paired samples t-test\nKruskal-Wallis H test: a nonparametric alternative to the one-way ANOVA\nFriedman test: a nonparametric alternative to the repeated measures ANOVA"
  },
  {
    "objectID": "exams/final-review.html#datasets",
    "href": "exams/final-review.html#datasets",
    "title": "Final Review",
    "section": "Datasets",
    "text": "Datasets\n\nDataset 1\n Download\nBrief description of the dataset:\n\nThe dataset contains information on 30 individuals.\nEach individual’s record includes their ID, age, gender, “before” and “after” scores for a stretching intervention, and reaction time.\nThe age of the individuals ranges from 20 to 49 years old.\nThere are 15 male and 15 female individuals in the dataset.\n\n\n\n\nDataset 2\n Download\nBrief description of the dataset:\n\nThe dataset contains information on 24 individuals.\nOutcome variable: sit-up test (repetitions)\nEach individual’s record includes their ID, gender, age group, condition, and scores on three time measures (pre, mid, and posttest).\nThe age groups are categorized as young (8-10) and old (11-13)\nThe conditions are labeled as A, B, and C."
  },
  {
    "objectID": "exams/final-review.html#research-questions",
    "href": "exams/final-review.html#research-questions",
    "title": "Final Review",
    "section": "Research questions",
    "text": "Research questions\nFind below a list of research questions along with corresponding database links. To answer each question, perform the appropriate statistical procedure using the relevant database.\n\n\n\n\n\n\nFor all research questions below, test the hypothesis using \\(\\alpha\\) = .05 and two-tailed tests.\n\n\n\n\nResearch question 1\nUsing database 1, run the appropriate test to answer the research question below:\n\nIs there a difference in flexibility (before) among college athletes compared to a population mean flexibility score of 35?\n\nProvide the following:\n\nthe independent and dependent variables and specify the level (nominal, ordinal, continuous)\nthe \\(H_0\\) and the \\(H_A\\) hypotheses\nwhether any assumptions were violated (state none, if all assumptions were confirmed)\n\nDisregard the assumption of test of independence since a random technique was not used\n\nthe test used to answer the research question\n\nConsider the nature of the dependent variable and the result of the Shapiro-Will test\n\nif the assumption of normality does not apply (or was violated), what test should be used instead?\nthe test decision (reject or fail to reject the \\(H_0\\)) + explanation\n\nuse the p-value and the test statistic value to explain your decision\n\nconclusion in one paragraph (does not have to be in APA style)\ninformation on the meaningfulness of the result (effect size)\njamovi output (Name the output Research Question 1)\n\ntest’s main table\nany assumption check tables\ndescriptives table\ndescriptives plot\n\n\nDo not close jamovi; continue on to answer Research Question 2\n\n\nResearch Question 2\nUsing database 1, run the appropriate test to answer the research question below:\n\nIs there a difference in reaction time between male and female athletes?\n\nProvide the following:\n\nthe independent and dependent variables and specify the level (nominal, ordinal, continuous)\nthe \\(H_0\\) and the \\(H_A\\) hypotheses\nwhether any assumptions were violated (state none, if all assumptions were confirmed)\n\nDisregard the assumption of test of independence since a random technique was not used\n\nthe test used to answer the research question\n\nConsider the nature of the dependent variable and the result of the Shapiro-Will test\n\nif the assumption of normality does not apply (or was violated), what test should be used instead?\nthe test decision (reject or fail to reject the \\(H_0\\)) + explanation\n\nuse the p-value and the test statistic value to explain your decision\n\nconclusion in one paragraph (does not have to be in APA style)\ninformation on the meaningfulness of the result (effect size)\njamovi output (Name the output Research Question 2)\n\ntest’s main table\nany assumption check tables\ndescriptives table\ndescriptives plot\n\n\nDo not close jamovi; continue on to answer Research Question 3\n\n\nResearch Question 3\nUsing database 1, run the appropriate test to answer the research question below:\n\nDoes a stretching intervention program lead to increased flexibility in middle-aged adults?\n\nProvide the following:\n\nthe independent and dependent variables and specify the level (nominal, ordinal, continuous)\nthe \\(H_0\\) and the \\(H_A\\) hypotheses\nwhether any assumptions were violated (state none, if all assumptions were confirmed)\n\nDisregard the assumption of test of independence since a random technique was not used\n\nthe test used to answer the research question\n\nConsider the nature of the dependent variable and the result of the Shapiro-Will test\n\nif the assumption of normality does not apply (or was violated), what test should be used instead?\nthe test decision (reject or fail to reject the \\(H_0\\)) + explanation\n\nuse the p-value and the test statistic value to explain your decision\n\nconclusion in one paragraph (does not have to be in APA style)\ninformation on the meaningfulness of the result (effect size)\njamovi output (Name the output Research Question 3)\n\ntest’s main table\nany assumption check tables\ndescriptives table\ndescriptives plot\n\n\n\n\nResearch Question 4\nUsing database 2, run the appropriate test to answer the research question below:\n\nIs there a significant interaction between age group and condition on sit-up scores (Score1)?\n\nProvide the following:\n\nthe independent and dependent variables and specify the level (nominal, ordinal, continuous)\nthe \\(H_0\\) and the \\(H_A\\) hypotheses\nwhether any assumptions were violated (state none, if all assumptions were confirmed)\n\nDisregard the assumption of test of independence since a random technique was not used\n\nthe test used to answer the research question 1. Consider the nature of the dependent variable and the result of the Shapiro-Will test\nif the assumption of normality does not apply (or was violated), what test should be used instead?\nthe test decision (reject or fail to reject the \\(H_0\\)) + explanation\n\nuse the p-value and the test statistic value to explain your decision\n\nconclusion in one paragraph (does not have to be in APA style)\ninformation on the meaningfulness of the result (effect size)\njamovi output (Name the output Research Question 4)\n\ntest’s main table\nany assumption check tables\nany post-hoc table\ndescriptives table\ndescriptives plot\n\n\n\n\nResearch Question 5\nUsing database 2, run the appropriate test to answer the research question below:\nIs there a significant difference in scores across time (pre, mid, posttest)?\nProvide the following:\n\nthe independent and dependent variables and specify the level (nominal, ordinal, continuous)\nthe \\(H_0\\) and the \\(H_A\\) hypotheses\nwhether any assumptions were violated (state none, if all assumptions were confirmed)\n\nDisregard the assumption of test of independence since a random technique was not used\n\nthe test used to answer the research question\n\nConsider the nature of the dependent variable and the result of the Shapiro-Will test\n\nif the assumption of normality does not apply (or was violated), what test should be used instead?\nthe test decision (reject or fail to reject the \\(H_0\\)) + explanation\n\nuse the p-value and the test statistic value to explain your decision\n\nconclusion in one paragraph (does not have to be in APA style)\ninformation on the meaningfulness of the result (effect size)\njamovi output (Name the output Research Question 5)\n\ntest’s main table\nany assumption check tables\nany post-hoc table\ndescriptives table\ndescriptives plot\n\n\n\n\nResearch Question 6\nUsing database 2, run the appropriate test to answer the research question below:\n\nIs there a significant difference in scores (Scores3) across the three conditions (A, B, and C)?\n\nProvide the following:\n\nthe independent and dependent variables and specify the level (nominal, ordinal, continuous)\nthe \\(H_0\\) and the \\(H_A\\) hypotheses\nwhether any assumptions were violated (state none, if all assumptions were confirmed)\n\nDisregard the assumption of test of independence since a random technique was not used\n\nthe test used to answer the research question\n\nConsider the nature of the dependent variable and the result of the Shapiro-Will test\n\nif the assumption of normality does not apply (or was violated), what test should be used instead?\nthe test decision (reject or fail to reject the \\(H_0\\)) + explanation\n\nuse the p-value and the test statistic value to explain your decision\n\nconclusion in one paragraph (does not have to be in APA style)\ninformation on the meaningfulness of the result (effect size)\njamovi output (Name the output Research Question 6)\n\ntest’s main table\nany assumption check tables\nany post-hoc table\ndescriptives table\ndescriptives plot"
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#timeline",
    "href": "project-description.html#timeline",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team’s project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you’re interested in potentially using for the final project. If you’re unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick “Start a new conversation”.\nMake the title “Your Team Name: Project Title”. For example, “Teaching Team: Our Awesome Presentation”.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click “Insert 1 item.” This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou’re done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group’s video, then click “Reply” to post a question for the group. You may not post a question that’s already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e. it shouldn’t be “Why did you use a bar plot instead of a pie chart”?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group’s specific presentation, i.e demonstrating that you’ve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "syllabus2.html",
    "href": "syllabus2.html",
    "title": "Syllabus",
    "section": "",
    "text": "(navarro2022?)\nDownload the syllabus as PDF"
  },
  {
    "objectID": "syllabus2.html#sec-course-description",
    "href": "syllabus2.html#sec-course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course focuses on the introductory statistical techniques used in social science research. Students will be introduced to concepts such as reliability, validity, measures of central tendency, variability, probability, and statistical techniques including: t tests (independent & dependent samples), Analysis of Variance (ANOVA), Chi-square, correlation, and regression.\nStudents are expected to take the material/concepts presented in this course and apply them through a series of homework assignments and quizzes. The overall goal of the course is not only to help students understand the mathematical/statistical concepts presented but also to assist in the application of these procedures."
  },
  {
    "objectID": "syllabus2.html#expectations-and-goals",
    "href": "syllabus2.html#expectations-and-goals",
    "title": "Syllabus",
    "section": "Expectations and Goals",
    "text": "Expectations and Goals\nUpon completion of this course, you will be able to adequately:\n\nIntroduce statistical concepts utilized in research within the social sciences\nApply the mathematical/statistical techniques presented for social science research\nDemonstrate an ability to analyze and interpret data within the social sciences\nProvide practical examples as to when statistical techniques presented are appropriate methods for analysis."
  },
  {
    "objectID": "syllabus2.html#text-readings-instructional-resources",
    "href": "syllabus2.html#text-readings-instructional-resources",
    "title": "Syllabus",
    "section": "Text, readings & instructional resources",
    "text": "Text, readings & instructional resources\n\nRequired eBook (free)\n(navarro2022?)\n\n\nOptional Textbook\n\n\nOther readings\nAll extra study content for this course can be found in the course’s website.\n\n\nInstructional resources\n\njamovi Statistical Software(thejamoviproject2021?) (Free)\njamovi Video Tutorials (Free)"
  },
  {
    "objectID": "syllabus2.html#sec-structure-requirements",
    "href": "syllabus2.html#sec-structure-requirements",
    "title": "Syllabus",
    "section": "Structure & Requirements",
    "text": "Structure & Requirements\nI will adopt the 4 “Ps”1 in this course. This means that while taking this course you will be asked to prepare, participate, practice, and perform.\nYou are responsible for the material covered in class prior to attending each class. Note that the week’s readings are specified in the course schedule.\nIn addition to these readings, the instructor may assign supplemental readings throughout the semester. These supplemental readings do not appear on the schedule as these readings will be assigned at the instructor’s discretion.\nThe assignments used to enhance your learning experience in this course include:\n\nParticipation & Attendance\nClass presence and participation points are given to encourage your active class participation and discussion. You will be rewarded with a perfect score as long as you frequently come to class and actively contribute to the class discussion during lectures.\nAlthough it is not required, most students send their professor a brief e-mail to explain their absence in advance.\n\n\nPreparedness\nYou will be evaluated on your preparedness by completing the a quiz and the major takeaways assignment before each class.\n\n\nQuizzes\nBefore each class, you will complete a multiple-choice quiz on the week’s topic. You must score 100% on each quiz. If you score below 100%, you will have to retake the quiz until you score 100%. You can only move to the following quiz if you score 100% on a quiz.\n\n\nLabs\nStudents will complete four (4) labs on this course. The purpose of each lab is to assist students in applying their understanding of the statistical procedures discussed in class as well as to provide an opportunity for students to respond to the readings.\n\n\n\n\n\n\nWarning\n\n\n\nYou are allowed to discuss the labs with other students (and with the instructor), but you must write the final answers yourself in your own words. Solutions prepared “in committee” or by, copying or paraphrasing someone else’s work is not acceptable; your hand-in assignments must represent your thoughts.\n\n\n\n\nExams\nYou will complete two (2) exams in this course. Students may use their notes and textbook for the exams, but no outside resource other than a calculator can be used.\nEach exam has between six to ten questions, with each question worth 10 points. Exams must be completed in the allotted time. The exams (and quizzes) focus on concepts and interpretation, with most of the computational activities occurring in the homework assignments.\nAlthough the quizzes and exams will not focus on previously tested material (they are not meant to be cumulative), knowledge of previously tested material may be inherently required to answer questions related to new material.\nMost of the computational activities will be via lab assignments. In addition, selected readings will be assigned throughout the semester. The content of these readings will be included in exam and quiz questions and homework assignments.\n\n\nDejavu\nOrganization is a prerequisite for effective learning. Throughout the semester, you will be asked to organize the material presented in class in a single directory in Google Drive.\nThe directory should have a Doc file (essential links), the syllabus in PDF format, and several subdirectories for each topic covered in the course. Inside each subdirectory, you must include the week’s lesson in PDF format and any assignments or activities you did. The structure of the main directory should look like this:\nKIN610\n\nEssential Links\nSyllabus in pdf\n(navarro2022?) ebook\n\nWeek 1: &lt;topic&gt;\n\nLesson in pdf\nAny assignment and/or activity completed\n\nWeek 2 &lt;topic&gt; …."
  },
  {
    "objectID": "syllabus2.html#course-policy",
    "href": "syllabus2.html#course-policy",
    "title": "Syllabus",
    "section": "Course Policy",
    "text": "Course Policy\nI will detail the policy for this course below. Basically, don’t cheat and try to learn stuff.\n\nGrading\n\n\n\nAssignment\nPercentage\n\n\n\n\nParticipation & Attendance\n5%\n\n\nWeekly Quizzes\n10%\n\n\nMajor Takeaways2\n20%\n\n\nLabs\n20%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\ndeJavu\n5%\n\n\n\n\n\nGrading Scale\nA 93.00-100.00 | A- 90.00-92.99 B+ 87.00-89.99 | B 83.00-86.99 | B- 80.00-82.99 C+ 77.00-79.99 | C 73.00-76.99 | C- 70.00-72.99 D+ 67.00-69.99 | D 63.00-66.99 | D- 60.00-62.99 F &lt;59.99\n\n\n\n\n\n\nNote\n\n\n\nIn recognition of the fact that grading, however carefully done, will always be imperfect, this class will utilize a “round up” rule for assigning final grades. I will round up from .5% and above, but anything below this will round down. In other words, 79.5 will round up to 80, while 79.4 will round down to 79 even.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRequests for an Incomplete (I) must conform to university policies. Among other requirements, “I” is possible only for instances in which you are demonstrating passing work in the class.\n\n\n\n\nAttendance\n\nShowing up is 80 percent of life – Woody Allen, via Marshall Brickman\n\nAttendance will be taken at the beginning of every class; please, plan accordingly.\n\n\nE-mail\nPlease, do not use the built-in email (Inbox) in Canvas. Instead, use your CSUN Gmail to communicate with me.\nIf your message concerns a non-private matter (e.g., assignments, content, deadlines, etc.), then please post your question to our mailing list, which can be answered by any student taking the course. The mailing list address is provided in Canvas.\n\n\nOffice Hours\n\nIn-person\nThursdays from 2-4 pm at RE 289.\n\n\nOnline via Zoom\nBy appointment only: www.calendly.com/drfurtado\n\n\n\nLate Assignments\nIt is important to note that late assignments are assessed a 10% deduction for each day it is late, not to exceed four days. After the fourth day of the deadline, no assignments will be accepted. Therefore, it is important to plan ahead and submit all assignments on time to receive full credit for your work. The instructor reserves the right to make exceptions to this policy on a case-by-case basis.\n\n\nExtra Credit\nThere is no individual extra credit granted. Therefore, do not plan to make-up poor grades at the end of the semester by asking to do extra credit work. I might provide extra credit opportunities, but these will be offered to the entire class, not to individuals.\n\n\nDisabilities\nFederal law mandates the provision of services at the university-level to qualified students with disabilities.\nThis instructor, in conjunction with California State University Northridge, is committed to upholding and maintaining all aspects of the federal Americans with Disabilities Act of 1990 (ADA) and Section 504 of the Rehabilitation Act of 1973.\nIf you are a student with a disability and wish to request accommodations, please contact the office of Students with Disabilities Resources located in 110 Student Services Building, or call (818) 677-2684 for an appointment. Any information regarding your disability will remain confidential. Because many accommodations require early planning, requests for accommodations should be made as early as possible. Any requests for accommodations will be reviewed in a timely manner to determine their appropriateness to this setting.\n\n\nAcademic Dishonesty\nTL;DR: Don’t cheat!\nPlease, stop and read the information below; this is important!\n\n\n\n\n\n\nImportant\n\n\n\nEach student is expected to be familiar with, and abide by, the conditions of student conduct, as presented in the CSUN Catalog, with emphasis on sections entitled, Student Conduct Code, Academic Dishonesty, Faculty Policy on Academic Dishonesty, and Penalties. Any student engaging in academic dishonesty (e.g., cheating, fabrication, facilitating academic dishonesty, plagiarism) is subject to discipline, which may include a failing grade in the course, and may also be subject to more severe discipline by the University. Students are encouraged to visit the link below and become familiar with the Standards for Student Conduct.\nhttp://www.csun.edu/a&r/soc/studentconduct.html\n\n\n\nAbout Plagiarism\nPlagiarism means using words, ideas, or arguments from another person or source without citation3. Cite all sources consulted to any extent (including material from the internet), whether or not assigned and whether or not quoted directly. For quotations, four or more words used in sequence must be set off in quotation marks, with the source identified.\nPlagiarism is a serious violation of the CSUN Student Conduct Code.. Any form of cheating will immediately earn you a failing grade for the entire course. By remaining enrolled, you consent to this policy.\n\nTurnitin (see below) will detect such misconducts as it checks every submission against a database of papers, as well as against the Internet.\n\nWhat is Turnitin?\nTurnitin is an automated system that instructors can use to quickly and easily compare each student’s assignment with billions of websites, as well as an enormous database of student papers that grows with each submission. Accordingly, you will be expected to submit assignments through the Canvas Assignment Tool in electronic format. After the assignment is processed, as an instructor, I receive a report from Turnitin that states if and how another author’s work was used in the assignment."
  },
  {
    "objectID": "syllabus2.html#sec-final-notes",
    "href": "syllabus2.html#sec-final-notes",
    "title": "Syllabus",
    "section": "Final (yet important) Notes",
    "text": "Final (yet important) Notes\n\nHow to Access our Course and Get Started\n\nLog into Canvas: https://canvas.csun.edu\nUnder “My Courses,” locate our course and click on it.\nThis will take you to the course home page.\n\n\n\nTechnology Requirements and Support:\n\nA computer and access to the internet (reliable connection)\nFirefox, Safari, etc. (web browser)\n\n\n\nWhat I Expect of You:\n\nPlan your schedule to ensure you several hours per week to spend on this class and take time to identify where and when you’ll do your learning.\nReview the due dates for the assignments (refer to our Course Schedule in Canvas) to orient yourself to the flow of the learning.\nThis course requires regular engagement and practice using jamovi (Statistical Package)."
  },
  {
    "objectID": "syllabus2.html#sec-success",
    "href": "syllabus2.html#sec-success",
    "title": "Syllabus",
    "section": "How to be Success in this Course",
    "text": "How to be Success in this Course\nConsider the goals you have for engaging in this course as you determine how to allocate time to complete course requirements.\nEach student has a different pace when comes to studying for a course. Thus, I will let you figure out how many hours you need to reserve each week for this course. Regardless of the number of hours chosen, try to divide your time so that you devote more time to assignments and assigned readings.\nThe Module Time chart below provides a visual representation of the typical time spent completing a module, followed by an example weekly schedule."
  },
  {
    "objectID": "syllabus2.html#sec-student-support-services",
    "href": "syllabus2.html#sec-student-support-services",
    "title": "Syllabus",
    "section": "Student Support Services",
    "text": "Student Support Services\nCSUN aims to make all learning experiences as accessible as possible, and has a variety of resources available to help support students. If you believe the design of this course poses barriers to effectively participate or demonstrate your learning, please contact me to discuss possible options and adjustments.\n\nThe IT Help Center (818)677-1400, helpcenter@csun.edu is available to help with Canvas, CSUN e-mail, SOLAR/Portal, and other technical issues.\nCSUN Device Loaner Program (https://bit.ly/3t1G0An) provides devices that can be checked out that includes laptops, webcams, hotspots and headsets\nThe Learning Resource Center (818) 677-2033 The mission of the LRC is to enable students to improve their academic performance through a variety of learning programs, including workshops, one-on-one and group tutoring, supplemental instruction classes and interactive subject area computer programs and videos. Student who use the LRC learning programs will develop and strengthen their critical thinking skills, study strategies, writing skills and performance in subject matter courses.\nUniversity Counseling Services (818) 677-2366, Bayramian Hall 520. UCS provides resources and information to assist students in dealing with a variety of large and small psychological obstacles that may interfere with academic progress and/or relationship satisfaction. Services include individual, group, and crisis counseling.\nIn accordance with the CSUN Accessibility Policy (https://bit.ly/3yqGHE9), CSUN is working to ensure that campus communication and course materials are accessible to everyone. Please reach out to me if you have difficulty with any of the materials for this course.\nIf you have a disability and need accommodations, please register with the Disability Resources and Educational Services (DRES) office or the National Center on Deafness (NCOD).\n\nThe DRES office can be reached at (818) 677-2684.\nNCOD can be reached at (818) 677-2611.\nReasonable accommodations and services will be provided to students if requests are made in a timely manner and with appropriate documentation\nIf you would like to discuss your need for accommodations with me, please drop in office hours or contact me to set up an appointment.\n\nFood Pantry (https://bit.ly/38nTsVH) at CSUN: Anybody who faces challenges securing food or housing and believes this impacts course performance, should contact CSUN’s Food Pantry website and the corresponding contacts. If you also feel comfortable contacting me, the department chair, or the Dean’s Office, we can also facilitate assistance. You don’t have to be alone in this moment.\nEmergency MataCare grants (https://bit.ly/2WAZkIz), one-time grants to prevent evictions, urgent child care issues, etc. - DACA (Deferred Action for Childhood Arrivals) Resources: Check out the Central American Resource Center facebook page (https://bit.ly/2Yg0p9z), legal resources listed on CSUN’s Educational Opportunity Program (EOP) Dream Center that was created to support all undocumented students & allies (Dream Center flyer). CSUN President Harrison issued a support statement on the CSUN homepage for DACA and resources.\nHelp lines (https://bit.ly/3sYbMOo)(after hours when the University Counseling is closed) for numerous topics/needs (e.g., suicide, drug, rape, LGBQT, military, or any crisis). You don’t have to manage these feelings alone.\nPride Center (https://bit.ly/3jqNZUi) offers support and resources to lesbian, gay, bisexual, transgender, queer, & questioning students, faculty, & staff.\nKlotz Student Health Center (https://bit.ly/3zx1Y0s): Numerous health services including primary care, dental, nutritional counseling, acupuncture, massage and lots more.\nCareer Center (https://bit.ly/3jtTcL2) for resume writing & interviewing and much more; Matty’s Closet (https://bit.ly/3jAResx) has free professional clothes for students who need interview or professional attire.\nUSU 9https://bit.ly/38uz59j) for more student services; Clubs & Organizations (https://bit.ly/38tBhOa): Hopefully a dozen people have already advised you to “get involved” (https://bit.ly/3ysqYVb) at CSUN in something that interests you.\nAssociated Students (https://bit.ly/3yuWjGT) offers recycling, and a Children’s Center providing child care\nFinancial Aid & Scholarships (https://bit.ly/3sYFzqr) offers aid for applications\nUniversity Library https://bit.ly/3yuIEQ9) for many additional academic resources\nVeterans Resource Center (https://bit.ly/38qYtg7) assists CSUN students as they transition from military service to academic success.\n\nTitle 5, California Code of Regulations,§ 41301. Standards for Student Conduct – (a) Campus Community Values: The university is committed to maintaining a safe and healthy living and learning environment for students, faculty, and staff. Each member of the campus community should choose behaviors that contribute toward this end. Students are expected to be good citizens and to engage in responsible behaviors that reflect well upon their university, to be civil to one another and to others in the campus community, and contribute positively to student and university life.\nCSUN with A HEART If you are facing challenges related to food insecurity, housing precarity/homelessness, mental health, access to technology, eldercare/childcare, or healthcare, you can find guidance, help, and resources from CSUN with A HEART (https://www.csun.edu/heart)."
  },
  {
    "objectID": "syllabus2.html#footnotes",
    "href": "syllabus2.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nInspired by Mine Çetinkaya-Rundel teaching philosophy.↩︎\nThe lowest score will be dropped at the end of the semester.↩︎\nExcept for Homeworks. your hand-in assignments must represent your own thoughts (refer to Academic Dishonesty Policy for more information); especially, the information about PLAGIARISM.↩︎"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "",
    "text": "Download the syllabus as PDF"
  },
  {
    "objectID": "course-syllabus.html#sec-course-description",
    "href": "course-syllabus.html#sec-course-description",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Course Description",
    "text": "Course Description\nThis course focuses on the introductory statistical techniques used in social science research. Students will be introduced to concepts such as reliability, validity, measures of central tendency, variability, probability, and statistical techniques including: t tests (independent & dependent samples), Analysis of Variance (ANOVA), Chi-square, correlation, and regression.\nStudents are expected to take the material/concepts presented in this course and apply them through a series of homework assignments and quizzes. The overall goal of the course is not only to help students understand the mathematical/statistical concepts presented but also to assist in the application of these procedures."
  },
  {
    "objectID": "course-syllabus.html#expectations-and-goals",
    "href": "course-syllabus.html#expectations-and-goals",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Expectations and Goals",
    "text": "Expectations and Goals\nUpon completion of this course, you will be able to adequately:\n\nIntroduce statistical concepts utilized in research within the social sciences\nApply the mathematical/statistical techniques presented for social science research\nDemonstrate an ability to analyze and interpret data within the social sciences\nProvide practical examples as to when statistical techniques presented are appropriate methods for analysis."
  },
  {
    "objectID": "course-syllabus.html#text-readings-instructional-resources",
    "href": "course-syllabus.html#text-readings-instructional-resources",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Text, readings & instructional resources",
    "text": "Text, readings & instructional resources\n\nRequired eBook (free)\n(navarro2022?)\n\n\nOptional Textbook\nWeir and Vincent (2021)\n\n\nOther readings\nAll extra study content for this course can be found in the course’s website.\n\n\nInstructional resources\n\njamovi Statistical Software (thejamoviproject2021?) (Free)\njamovi Video Tutorials (poulson2019?) (Free)"
  },
  {
    "objectID": "course-syllabus.html#sec-structure-requirements",
    "href": "course-syllabus.html#sec-structure-requirements",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Structure & Requirements",
    "text": "Structure & Requirements\nI will adopt the 4 “Ps”1 in this course. This means that while taking this course you will be asked to prepare, participate, practice, and perform.\nYou are responsible for the material covered in class prior to attending each class. Note that the week’s readings are specified in the course schedule.\nIn addition to these readings, the instructor may assign supplemental readings throughout the semester. These supplemental readings do not appear on the schedule as these readings will be assigned at the instructor’s discretion.\nThe assignments used to enhance your learning experience in this course include:\n\nParticipation & Attendance2\nClass presence and participation points are given to encourage your active class participation and discussion. You will be rewarded with a perfect score as long as you frequently come to class and actively contribute to the class discussion during lectures.\nIn addition, some in-class activities will count toward participation points. These are unannounced assignments.\n\n\nPreparedness\nYou will be evaluated on your preparedness by completing the a quiz and the major takeaways assignment before each class.\n\n\nQuizzes\nBefore each class, you will complete a multiple-choice quiz on the week’s topic. You must score 100% on each quiz. If you score below 100%, you will have to retake the quiz until you score 100%. You can only move to the following quiz if you score 100% on a quiz.\nA few notes about quizzes:\n\nYou will be allowed to take the quiz as many times as you want (as long as the quiz is still open);\nThe highest score of taken attempts will be recorded for grading purposes;\nYou will be presented with ten questions on each attempt. Questions are drawn from a database comprised of more than ten questions;\nQuizzes are timed; once started, students have 20 minutes to complete each attempt.\n\n\n\nLabs\nStudents will complete several labs in this course. The purpose of each lab is to assist students in applying their understanding of the statistical procedures discussed in class as well as to provide an opportunity for students to respond to the readings.\n\n\n\n\n\n\nWarning\n\n\n\nYou are allowed to discuss the labs with other students (and with the instructor), but you must write the final answers yourself in your own words. Solutions prepared “in committee” or by, copying or paraphrasing someone else’s work is not acceptable; your hand-in assignments must represent your thoughts.\n\n\n\n\nMajor Takeaways\nYou will be evaluated on your preparedness by submitting an assignment before each class. This assignment is meant to be a reflection of your learning. You will be asked to submit at least ten major takeaways from the readings. The content of the assignment must come from the assigned readings for the corresponding class session.\n\n\nExams\nYou will complete two (2) exams in this course. Students may use their notes and textbook for the exams, but no outside resource other than a calculator can be used.\nEach exam has between six to ten questions, with each question worth 10 points. Exams must be completed in the allotted time. The exams (and quizzes) focus on concepts and interpretation, with most of the computational activities occurring in the homework assignments.\nAlthough the quizzes and exams will not focus on previously tested material (they are not meant to be cumulative), knowledge of previously tested material may be inherently required to answer questions related to new material.\nMost of the computational activities will be via lab assignments. In addition, selected readings will be assigned throughout the semester. The content of these readings will be included in exam and quiz questions and homework assignments.\n\n\nDéjà vu\nOrganization is a prerequisite for effective learning. Throughout the semester, you will be asked to organize the material presented in class in a single directory in Google Drive.\nThe directory should have a Doc file (essential links), the syllabus in PDF format, and several sub-directories for each topic covered in the course. Inside each sub-directory, you must include the week’s lesson in PDF format and any assignments or activities you did. The structure of the main directory should look like this:\nKIN610\n\nEssential Links\nSyllabus in pdf\nNavarro and Foxcroft (2022) ebook\n\nWeek 1: &lt;topic&gt;\n\nLesson in pdf\nAny assignment and/or activity completed\n\nWeek 2 &lt;topic&gt; ….\nSubmission\n\nCopy the link to the “KIN610” folder - see below\nSubmit the link to the assignment on Canvas"
  },
  {
    "objectID": "course-syllabus.html#sec-course-policy",
    "href": "course-syllabus.html#sec-course-policy",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Course Policy",
    "text": "Course Policy\nI will detail the policy for this course below. Basically, don’t cheat and try to learn stuff.\n\nGrading\n\n\n\nAssignment\nPercentage\n\n\n\n\nParticipation & Attendance\n5%\n\n\nWeekly Quizzes\n10%\n\n\nMajor Takeaways3\n20%\n\n\nLabs\n20%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\nDéjà vu\n5%\n\n\n\n\n\nGrading Scale\nA 93.00-100.00 | A- 90.00-92.99 B+ 87.00-89.99 | B 83.00-86.99 | B- 80.00-82.99 C+ 77.00-79.99 | C 73.00-76.99 | C- 70.00-72.99 D+ 67.00-69.99 | D 63.00-66.99 | D- 60.00-62.99 F &lt;59.99\n\n\n\n\n\n\nNote\n\n\n\nIn recognition of the fact that grading, however carefully done, will always be imperfect, this class will utilize a “round up” rule for assigning final grades. I will round up from .5% and above, but anything below this will round down. In other words, 79.5 will round up to 80, while 79.4 will round down to 79 even.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRequests for an Incomplete (I) must conform to university policies. Among other requirements, “I” is possible only for instances in which you are demonstrating passing work in the class.\n\n\n\n\nAttendance\n\nShowing up is 80 percent of life – Woody Allen, via Marshall Brickman\n\nAttendance will be taken at the beginning of every class; please, plan accordingly.\n\n\nE-mail\nPlease, do not use the built-in email (Inbox) in Canvas. Instead, use your CSUN Gmail to communicate with me.\nIf your message concerns a non-private matter (e.g., assignments, content, deadlines, etc.), then please post your question to our mailing list, which can be answered by any student taking the course. The mailing list address is provided in Canvas.\n\n\nOffice Hours\n\nIn-person\nThursdays from 2-4 pm at RE 289.\n\n\nOnline via Zoom\nBy appointment only: www.calendly.com/drfurtado\n\n\n\nLate Assignments\nIt is important to note that late assignments are assessed a 10% deduction for each day it is late, not to exceed four days. After the fourth day of the deadline, no assignments will be accepted. Therefore, it is important to plan ahead and submit all assignments on time to receive full credit for your work. The instructor reserves the right to make exceptions to this policy on a case-by-case basis.\n\n\nExtra Credit\nThere is no individual extra credit granted. Therefore, do not plan to make-up poor grades at the end of the semester by asking to do extra credit work. I might provide extra credit opportunities, but these will be offered to the entire class, not to individuals.\n\n\nDisabilities\nFederal law mandates the provision of services at the university-level to qualified students with disabilities.\nThis instructor, in conjunction with California State University Northridge, is committed to upholding and maintaining all aspects of the federal Americans with Disabilities Act of 1990 (ADA) and Section 504 of the Rehabilitation Act of 1973.\nIf you are a student with a disability and wish to request accommodations, please contact the office of Students with Disabilities Resources located in 110 Student Services Building, or call (818) 677-2684 for an appointment. Any information regarding your disability will remain confidential. Because many accommodations require early planning, requests for accommodations should be made as early as possible. Any requests for accommodations will be reviewed in a timely manner to determine their appropriateness to this setting.\n\n\nAcademic Dishonesty\nTL;DR: Don’t cheat!\nPlease, stop and read the information below; this is important!\n\n\n\n\n\n\nImportant\n\n\n\nEach student is expected to be familiar with, and abide by, the conditions of student conduct, as presented in the CSUN Catalog, with emphasis on sections entitled, Student Conduct Code, Academic Dishonesty, Faculty Policy on Academic Dishonesty, and Penalties. Any student engaging in academic dishonesty (e.g., cheating, fabrication, facilitating academic dishonesty, plagiarism) is subject to discipline, which may include a failing grade in the course, and may also be subject to more severe discipline by the University. Students are encouraged to visit the link below and become familiar with the Standards for Student Conduct.\nhttp://www.csun.edu/a&r/soc/studentconduct.html\n\n\n\nAbout Plagiarism\nPlagiarism means using words, ideas, or arguments from another person or source without citation4. Cite all sources consulted to any extent (including material from the internet), whether or not assigned and whether or not quoted directly. For quotations, four or more words used in sequence must be set off in quotation marks, with the source identified.\nPlagiarism is a serious violation of the CSUN Student Conduct Code.. Any form of cheating will immediately earn you a failing grade for the entire course. By remaining enrolled, you consent to this policy.\n\nTurnitin (see below) will detect such misconducts as it checks every submission against a database of papers, as well as against the Internet.\n\nWhat is Turnitin?\nTurnitin is an automated system that instructors can use to quickly and easily compare each student’s assignment with billions of websites, as well as an enormous database of student papers that grows with each submission. Accordingly, you will be expected to submit assignments through the Canvas Assignment Tool in electronic format. After the assignment is processed, as an instructor, I receive a report from Turnitin that states if and how another author’s work was used in the assignment."
  },
  {
    "objectID": "course-syllabus.html#sec-final-notes",
    "href": "course-syllabus.html#sec-final-notes",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Final (yet important) Notes",
    "text": "Final (yet important) Notes\n\nHow to Access our Course and Get Started\n\nLog into Canvas: https://canvas.csun.edu\nUnder “My Courses,” locate our course and click on it.\nThis will take you to the course home page.\n\n\n\nTechnology Requirements and Support:\n\nA computer and access to the internet (reliable connection)\nFirefox, Safari, etc. (web browser)\n\n\n\nWhat I Expect of You:\n\nPlan your schedule to ensure you several hours per week to spend on this class and take time to identify where and when you’ll do your learning.\nReview the due dates for the assignments (refer to our Course Schedule in Canvas) to orient yourself to the flow of the learning.\nThis course requires regular engagement and practice using jamovi (Statistical Package)."
  },
  {
    "objectID": "course-syllabus.html#sec-success",
    "href": "course-syllabus.html#sec-success",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "How to be Success in this Course",
    "text": "How to be Success in this Course\nConsider the goals you have for engaging in this course as you determine how to allocate time to complete course requirements.\nEach student has a different pace when comes to studying for a course. Thus, I will let you figure out how many hours you need to reserve each week for this course. Regardless of the number of hours chosen, try to divide your time so that you devote more time to assignments and assigned readings."
  },
  {
    "objectID": "course-syllabus.html#sec-student-support-services",
    "href": "course-syllabus.html#sec-student-support-services",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Student Support Services",
    "text": "Student Support Services\nCSUN aims to make all learning experiences as accessible as possible, and has a variety of resources available to help support students. If you believe the design of this course poses barriers to effectively participate or demonstrate your learning, please contact me to discuss possible options and adjustments.\n\nThe IT Help Center (818)677-1400, helpcenter@csun.edu is available to help with Canvas, CSUN e-mail, SOLAR/Portal, and other technical issues.\nCSUN Device Loaner Program (https://bit.ly/3t1G0An) provides devices that can be checked out that includes laptops, webcams, hotspots and headsets\nThe Learning Resource Center (818) 677-2033 The mission of the LRC is to enable students to improve their academic performance through a variety of learning programs, including workshops, one-on-one and group tutoring, supplemental instruction classes and interactive subject area computer programs and videos. Student who use the LRC learning programs will develop and strengthen their critical thinking skills, study strategies, writing skills and performance in subject matter courses.\nUniversity Counseling Services (818) 677-2366, Bayramian Hall 520. UCS provides resources and information to assist students in dealing with a variety of large and small psychological obstacles that may interfere with academic progress and/or relationship satisfaction. Services include individual, group, and crisis counseling.\nIn accordance with the CSUN Accessibility Policy (https://bit.ly/3yqGHE9), CSUN is working to ensure that campus communication and course materials are accessible to everyone. Please reach out to me if you have difficulty with any of the materials for this course.\nIf you have a disability and need accommodations, please register with the Disability Resources and Educational Services (DRES) office or the National Center on Deafness (NCOD).\n\nThe DRES office can be reached at (818) 677-2684.\nNCOD can be reached at (818) 677-2611.\nReasonable accommodations and services will be provided to students if requests are made in a timely manner and with appropriate documentation\nIf you would like to discuss your need for accommodations with me, please drop in office hours or contact me to set up an appointment.\n\nFood Pantry (https://bit.ly/38nTsVH) at CSUN: Anybody who faces challenges securing food or housing and believes this impacts course performance, should contact CSUN’s Food Pantry website and the corresponding contacts. If you also feel comfortable contacting me, the department chair, or the Dean’s Office, we can also facilitate assistance. You don’t have to be alone in this moment.\nEmergency MataCare grants (https://bit.ly/2WAZkIz), one-time grants to prevent evictions, urgent child care issues, etc. - DACA (Deferred Action for Childhood Arrivals) Resources: Check out the Central American Resource Center facebook page (https://bit.ly/2Yg0p9z), legal resources listed on CSUN’s Educational Opportunity Program (EOP) Dream Center that was created to support all undocumented students & allies (Dream Center flyer). CSUN President Harrison issued a support statement on the CSUN homepage for DACA and resources.\nHelp lines (https://bit.ly/3sYbMOo)(after hours when the University Counseling is closed) for numerous topics/needs (e.g., suicide, drug, rape, LGBQT, military, or any crisis). You don’t have to manage these feelings alone.\nPride Center (https://bit.ly/3jqNZUi) offers support and resources to lesbian, gay, bisexual, transgender, queer, & questioning students, faculty, & staff.\nKlotz Student Health Center (https://bit.ly/3zx1Y0s): Numerous health services including primary care, dental, nutritional counseling, acupuncture, massage and lots more.\nCareer Center (https://bit.ly/3jtTcL2) for resume writing & interviewing and much more; Matty’s Closet (https://bit.ly/3jAResx) has free professional clothes for students who need interview or professional attire.\nUSU 9https://bit.ly/38uz59j) for more student services; Clubs & Organizations (https://bit.ly/38tBhOa): Hopefully a dozen people have already advised you to “get involved” (https://bit.ly/3ysqYVb) at CSUN in something that interests you.\nAssociated Students (https://bit.ly/3yuWjGT) offers recycling, and a Children’s Center providing child care\nFinancial Aid & Scholarships (https://bit.ly/3sYFzqr) offers aid for applications\nUniversity Library https://bit.ly/3yuIEQ9) for many additional academic resources\nVeterans Resource Center (https://bit.ly/38qYtg7) assists CSUN students as they transition from military service to academic success.\n\nTitle 5, California Code of Regulations,§ 41301. Standards for Student Conduct – (a) Campus Community Values: The university is committed to maintaining a safe and healthy living and learning environment for students, faculty, and staff. Each member of the campus community should choose behaviors that contribute toward this end. Students are expected to be good citizens and to engage in responsible behaviors that reflect well upon their university, to be civil to one another and to others in the campus community, and contribute positively to student and university life.\nCSUN with A HEART If you are facing challenges related to food insecurity, housing precarity/homelessness, mental health, access to technology, eldercare/childcare, or healthcare, you can find guidance, help, and resources from CSUN with A HEART (https://www.csun.edu/heart)."
  },
  {
    "objectID": "course-syllabus.html#diversity-inclusion",
    "href": "course-syllabus.html#diversity-inclusion",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official CSUN records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "course-syllabus.html#course-schedule",
    "href": "course-syllabus.html#course-schedule",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Course Schedule",
    "text": "Course Schedule\nOptional Textbook: Weir and Vincent (2021); Required ebook: Navarro and Foxcroft (2022)\n\n\n\n\nWeek5\nDate6\nReading7\nAssignments8\n\n\n\n\n\nWk01\nJan 26\nCourse Introduction (Online via Zoom)\nRead and study the Syllabus\n\n\n\nWK02\nFeb 2\nIntroduction to jamovi & Data Collection\nLab 1\n\n\n\nWK03\nFeb 9\nIntroduction to Statistics and Measurement\nQuiz; Major Takeaways\n\n\n\nWK04\nFeb 16\nOrganizing and Displaying Data\nPercentiles\nQuizzes; Major Takeaways\n\n\n\nWK05\nFeb 23\nMeasures of Central Tendency\nMeasures of Variability\nQuizzes; Major Takeaways; Lab 2\n\n\n\nWK06\nMar 2\nFundamentals of Inferential Statistical\n\nQuiz; Major Takeaways\n\n\n\nWK07\nMar 9\nCorrelation and Bivariate Regression\nQuiz; Major Takeaways\n\n\n\nWK08\nMar 16\nMultiple Correlation and Multiple Regression\nQuiz; Major Takeaways; Lab 3\n\n\n\nWK09\nMar 23\nSpring Recess\nTake a rest!\n\n\n\nWK10\nMar 30\nExam 19\nRefer to Canvas\n\n\n\nWK11\nApr 6\nThe Student’s t-test\nQuiz; Major Takeaways\n\n\n\nWK12\nApr 13\nOne-way Analysis of Variance\nQuiz; Major Takeaways; Lab 4\n\n\n\nWK13\nApr 20\nAnalysis of Variance With Repeated Measures\nQuiz; Major Takeaways\n\n\n\nWK14\nApr 27\n\nFactorial Analysis of Variance: Between-Between\nQuiz; Major Takeaways\n\n\n\nWK15\nMay 4\n\nFactorial Analysis of Variance: Between-Within, Within-Within\nQuiz; Major Takeaways; Lab 5\n\n\n\nWK16\nMay 11\nFinal Review\nQuiz; Major Takeaways\n\n\n\nFinal’s Week\nMay 18\n5:30PM - 7:30PM\nRedwood Hall 276\nExam 210\nRefer to Canvas"
  },
  {
    "objectID": "course-syllabus.html#footnotes",
    "href": "course-syllabus.html#footnotes",
    "title": "KIN 610: Quantitative Analysis of Research in Kinesiology",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe schedule is subject to change.↩︎\nClass Dates: Aug 29, 2022 - Dec 12, 2022↩︎\nStudents are expected to read and study the assigned chapters prior to attending each class meeting.↩︎\nQuizzes and Major Takeaways assignments are due before class; other assignment are due after class.↩︎\nThe schedule is subject to change.↩︎\nClass Dates: Aug 29, 2022 - Dec 12, 2022↩︎\nStudents are expected to read and study the assigned chapters prior to attending each class meeting.↩︎\nQuizzes and Major Takeaways assignments are due before class; other assignment are due after class.↩︎\nCovers all previously covered topics.↩︎\nCovers mainly topics presented after Exam 1.↩︎"
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They’ll be able to help diagnose the issue."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html",
    "href": "CopyOfcourse-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#course-info",
    "href": "CopyOfcourse-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\n\n\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nLectures\nTue & Thu\n1:45 pm - 3:00 pm\nReuben-Cooke Building 130\n\n\nSection 1\nMon\n1:45 pm - 3:00 pm\nPerkins LINK 087 (Classroom 3)\n\n\nSection 2\nMon\n3:30 pm - 4:45 pm\nOld Chemistry 003\n\n\nSection 3\nMon\n5:15 pm - 6:30 pm\nSocial Sciences 311"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#learning-objectives",
    "href": "CopyOfcourse-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nfit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nuse Quarto to write reproducible reports and GitHub for version control and collaboration.\ncommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#community",
    "href": "CopyOfcourse-syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at sta210-s22.github.io/website.\nI will regularly send course announcements via email and Sakai, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course forum Conversations. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#textbooks",
    "href": "CopyOfcourse-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#lectures-and-labs",
    "href": "CopyOfcourse-syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. More information on loaner laptops can be found here."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#teams",
    "href": "CopyOfcourse-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as their central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member’s relative contribution for each project."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#assessment",
    "href": "CopyOfcourse-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of six components: application exercises, homework assignments, labs, exams, projects, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the readings and lectures. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Tuesday lectures are due Friday by 11:59 pm ET, and AEs from Thursday lectures are due Sunday by 11:59 pm ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s GitHub repository on the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be three, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on the conceptual understanding of the content, and they may also include small analysis and computational tasks. The content of the exam will be related to the content in the prepare, practice, and perform assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting, data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#grading",
    "href": "CopyOfcourse-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2.33% x 6)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#five-tips-for-success",
    "href": "CopyOfcourse-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won’t know where to begin asking questions. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours, and let me help you identify a good (re)starting point."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#course-policies",
    "href": "CopyOfcourse-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nTL;DR: Don’t cheat!\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard:\nStudents affirm their commitment to uphold the values of the Duke University community by signing a pledge that states:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;\nI will act if the Standard is compromised\n\nRegardless of course delivery format, it is your responsibility to understand and follow Duke policies regarding academic integrity, including doing one’s own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Duke Community Standard. If you have any questions about how to follow these requirements, please contact Jeanna McCullers (jeanna.mccullers@duke.edu), Director of the Office of Student Conduct.\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email Dr. Çetinkaya-Rundel and our head TA Rick Presman before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Dr. Çetinkaya-Rundel know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Lab time is dedicated to working on your lab assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others’ time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 919-681-9355. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nAll lectures will be recorded and available on Panopto, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get permission from me ahead of time and these recordings should be used for personal study only, no for distribution. The full policy on recording of lectures falls under the Duke University Policy on Intellectual Property Rights, available at provost.duke.edu/sites/default/files/FHB_App_P.pdf. Unauthorized distribution is a cause for disciplinary action by the Judicial Board."
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#learning-during-a-pandemic",
    "href": "CopyOfcourse-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n\nNote: If you’ve read this far in the syllabus, email me a picture of your pet if you have one or your favourite meme!"
  },
  {
    "objectID": "CopyOfcourse-syllabus.html#important-dates",
    "href": "CopyOfcourse-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 5: Classes begin (Monday meeting schedule)\nJanuary 6: Regular class meeting schedule begins\nJanuary 17: Martin Luther King, Jr. Day holiday, no classes are held\nJanuary 19: Drop/add ends\nMarch 7-11: Spring recess, no classes are held\nMarch 23: Last day to withdraw with W\nApril 20: Classes end\nApril 21-24: Reading period\nApril 25-30: Final exams\n\nClick here for the full Duke academic calendar."
  }
]